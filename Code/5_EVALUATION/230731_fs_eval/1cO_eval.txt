Entered file!
Imports done!
*** RUN *** 
eval_1cO
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48175182481751827, 'r1_recall': 0.6, 'r1_f1': 0.5344129554655871, 'pegasus_entailment': 0.18178536805013815, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7692307692307693, 'r1_recall': 0.4046242774566474, 'r1_f1': 0.5303030303030304, 'pegasus_entailment': 0.5297707840800285, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 20}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29411764705882354, 'r1_recall': 0.6896551724137931, 'r1_f1': 0.41237113402061853, 'pegasus_entailment': 0.5508156545460224, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6951219512195121, 'r1_recall': 0.4418604651162791, 'r1_f1': 0.5402843601895735, 'pegasus_entailment': 0.2669356878226002, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7448979591836735, 'r1_recall': 0.41954022988505746, 'r1_f1': 0.5367647058823529, 'pegasus_entailment': 0.15087692425586283, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5063291139240507, 'r1_recall': 0.3076923076923077, 'r1_f1': 0.3827751196172249, 'pegasus_entailment': 0.8677401741345724, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16666666666666666, 'r1_recall': 0.53125, 'r1_f1': 0.2537313432835821, 'pegasus_entailment': 0.4110431563109159, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2987012987012987, 'r1_recall': 0.7419354838709677, 'r1_f1': 0.4259259259259259, 'pegasus_entailment': 0.42918085555235547, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7529411764705882, 'r1_recall': 0.42953020134228187, 'r1_f1': 0.547008547008547, 'pegasus_entailment': 0.9811601837476095, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6099290780141844, 'r1_recall': 0.6231884057971014, 'r1_f1': 0.6164874551971327, 'pegasus_entailment': 0.39599873423576354, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7682926829268293, 'r1_recall': 0.42, 'r1_f1': 0.5431034482758621, 'pegasus_entailment': 0.3210448037832975, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6455696202531646, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.5151515151515151, 'pegasus_entailment': 0.5012285029515624, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 16}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7945205479452054, 'r1_recall': 0.5420560747663551, 'r1_f1': 0.6444444444444444, 'pegasus_entailment': 0.9614620606104533, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.684931506849315, 'r1_recall': 0.5681818181818182, 'r1_f1': 0.6211180124223602, 'pegasus_entailment': 0.3117890707217157, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8875, 'r1_recall': 0.3697916666666667, 'r1_f1': 0.5220588235294118, 'pegasus_entailment': 0.4304343710343043, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25225225225225223, 'r1_recall': 0.4745762711864407, 'r1_f1': 0.32941176470588235, 'pegasus_entailment': 0.6622668355703354, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 18, 'pegasus_ari': 35, 'pegasus_smog': 23}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43661971830985913, 'r1_recall': 0.31313131313131315, 'r1_f1': 0.3647058823529412, 'pegasus_entailment': 0.21777700881163278, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8454545454545455, 'r1_recall': 0.31208053691275167, 'r1_f1': 0.4558823529411764, 'pegasus_entailment': 0.554664871096611, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6446280991735537, 'r1_recall': 0.484472049689441, 'r1_f1': 0.5531914893617021, 'pegasus_entailment': 0.6262162402272224, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5569620253164557, 'r1_recall': 0.5057471264367817, 'r1_f1': 0.5301204819277108, 'pegasus_entailment': 0.050799655728042126, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6521739130434783, 'r1_recall': 0.32967032967032966, 'r1_f1': 0.43795620437956206, 'pegasus_entailment': 0.6870786212384701, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.5343511450381679, 'pegasus_entailment': 0.6007582941092551, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.627906976744186, 'r1_recall': 0.25, 'r1_f1': 0.3576158940397351, 'pegasus_entailment': 0.6701377630233765, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.578125, 'r1_recall': 0.27205882352941174, 'r1_f1': 0.37, 'pegasus_entailment': 0.3163067203713581, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4583333333333333, 'r1_recall': 0.44, 'r1_f1': 0.4489795918367347, 'pegasus_entailment': 0.6612414494156837, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7096774193548387, 'r1_recall': 0.582010582010582, 'r1_f1': 0.6395348837209301, 'pegasus_entailment': 0.8597082644701004, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6632653061224489, 'r1_recall': 0.4744525547445255, 'r1_f1': 0.5531914893617021, 'pegasus_entailment': 0.115182538703084, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8533333333333334, 'r1_recall': 0.23880597014925373, 'r1_f1': 0.3731778425655977, 'pegasus_entailment': 0.5342993557453155, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6216216216216216, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.6133333333333333, 'pegasus_entailment': 0.5430801436305046, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6511627906976745, 'r1_recall': 0.24778761061946902, 'r1_f1': 0.358974358974359, 'pegasus_entailment': 0.7990411917368571, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4766355140186916, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.5257731958762886, 'pegasus_entailment': 0.6982113420963287, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6971428571428572, 'r1_recall': 0.6069651741293532, 'r1_f1': 0.648936170212766, 'pegasus_entailment': 0.6563763978580633, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3879310344827586, 'r1_recall': 0.4368932038834951, 'r1_f1': 0.410958904109589, 'pegasus_entailment': 0.1928290418931283, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5875, 'r1_recall': 0.4845360824742268, 'r1_f1': 0.5310734463276836, 'pegasus_entailment': 0.28477739600930363, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41414141414141414, 'r1_recall': 0.4880952380952381, 'r1_f1': 0.44808743169398907, 'pegasus_entailment': 0.13945735269226134, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6376811594202898, 'r1_recall': 0.3793103448275862, 'r1_f1': 0.4756756756756757, 'pegasus_entailment': 0.49522723505894345, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5591397849462365, 'r1_recall': 0.7536231884057971, 'r1_f1': 0.6419753086419753, 'pegasus_entailment': 0.25826055871584686, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35, 'r1_recall': 0.5147058823529411, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.020772657939232886, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3626373626373626, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.4852941176470589, 'pegasus_entailment': 0.604122057557106, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6403508771929824, 'r1_recall': 0.4397590361445783, 'r1_f1': 0.5214285714285714, 'pegasus_entailment': 0.19038020819425583, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 18, 'pegasus_ari': 36, 'pegasus_smog': 25}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6947368421052632, 'r1_recall': 0.4125, 'r1_f1': 0.5176470588235293, 'pegasus_entailment': 0.3180138866882771, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.631578947368421, 'r1_recall': 0.4675324675324675, 'r1_f1': 0.5373134328358209, 'pegasus_entailment': 0.34851029763619107, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.2054794520547945, 'r1_f1': 0.30927835051546393, 'pegasus_entailment': 0.11054343295594056, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 23, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.638095238095238, 'r1_recall': 0.5447154471544715, 'r1_f1': 0.587719298245614, 'pegasus_entailment': 0.6081371173262596, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5972222222222222, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.5733333333333334, 'pegasus_entailment': 0.4570208316047986, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.6, 'r1_f1': 0.576923076923077, 'pegasus_entailment': 0.7413633565107981, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 19, 'pegasus_ari': 35, 'pegasus_smog': 24}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6388888888888888, 'r1_recall': 0.19491525423728814, 'r1_f1': 0.2987012987012987, 'pegasus_entailment': 0.894045352935791, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 18, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5041322314049587, 'r1_recall': 0.5495495495495496, 'r1_f1': 0.5258620689655172, 'pegasus_entailment': 0.9390382915735245, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47619047619047616, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.48763107461854815, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47368421052631576, 'r1_recall': 0.34615384615384615, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.324445441365242, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28313253012048195, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.3916666666666667, 'pegasus_entailment': 0.7201154232025146, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.275, 'r1_recall': 0.6470588235294118, 'r1_f1': 0.3859649122807018, 'pegasus_entailment': 0.36115710546728225, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43119266055045874, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.5136612021857924, 'pegasus_entailment': 0.42472778578909737, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6024844720496895, 'r1_recall': 0.5480225988700564, 'r1_f1': 0.5739644970414202, 'pegasus_entailment': 0.42442747950553894, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.75, 'r1_recall': 0.42134831460674155, 'r1_f1': 0.539568345323741, 'pegasus_entailment': 0.47062842063605786, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44642857142857145, 'r1_recall': 0.6944444444444444, 'r1_f1': 0.5434782608695653, 'pegasus_entailment': 0.7175350273028016, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8411214953271028, 'r1_recall': 0.35856573705179284, 'r1_f1': 0.5027932960893855, 'pegasus_entailment': 0.38889935861031216, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3779527559055118, 'r1_recall': 0.75, 'r1_f1': 0.5026178010471204, 'pegasus_entailment': 0.4372549284307752, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6752136752136753, 'r1_recall': 0.6528925619834711, 'r1_f1': 0.6638655462184875, 'pegasus_entailment': 0.5254844288807362, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7317073170731707, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.641711229946524, 'pegasus_entailment': 0.4256434179842472, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5652173913043478, 'r1_recall': 0.5909090909090909, 'r1_f1': 0.5777777777777778, 'pegasus_entailment': 0.9505124489466349, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5135135135135135, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.5205479452054794, 'pegasus_entailment': 0.014486105103666583, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.675, 'r1_recall': 0.32142857142857145, 'r1_f1': 0.435483870967742, 'pegasus_entailment': 0.602344791094462, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.631578947368421, 'r1_recall': 0.4948453608247423, 'r1_f1': 0.5549132947976879, 'pegasus_entailment': 0.5945390667766333, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5098039215686274, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.5252525252525253, 'pegasus_entailment': 0.22580873547121882, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 13}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7, 'r1_recall': 0.49606299212598426, 'r1_f1': 0.5806451612903225, 'pegasus_entailment': 0.8900693535804749, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4420289855072464, 'r1_recall': 0.5754716981132075, 'r1_f1': 0.5, 'pegasus_entailment': 0.5563710439833812, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6438356164383562, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.5562130177514792, 'pegasus_entailment': 0.5339444611066332, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5495495495495496, 'r1_recall': 0.5304347826086957, 'r1_f1': 0.5398230088495576, 'pegasus_entailment': 0.287658934306819, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6818181818181818, 'r1_recall': 0.4411764705882353, 'r1_f1': 0.5357142857142857, 'pegasus_entailment': 0.2811031835299218, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5630252100840336, 'r1_recall': 0.4036144578313253, 'r1_f1': 0.47017543859649125, 'pegasus_entailment': 0.43587724468670785, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43, 'r1_recall': 0.6323529411764706, 'r1_f1': 0.511904761904762, 'pegasus_entailment': 0.28296943604946134, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.509090909090909, 'r1_recall': 0.42424242424242425, 'r1_f1': 0.46280991735537186, 'pegasus_entailment': 0.5353816617280245, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 20}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.9259259259259259, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.5535055350553506, 'pegasus_entailment': 0.6907937129338583, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2894736842105263, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.3548387096774194, 'pegasus_entailment': 0.5304952128790319, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6818181818181818, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.5960264900662252, 'pegasus_entailment': 0.435140423476696, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44285714285714284, 'r1_recall': 0.484375, 'r1_f1': 0.4626865671641791, 'pegasus_entailment': 0.3599080489948392, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7045454545454546, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.6458333333333334, 'pegasus_entailment': 0.8204518556594849, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5089285714285714, 'r1_recall': 0.6627906976744186, 'r1_f1': 0.5757575757575757, 'pegasus_entailment': 0.2142426606733352, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6935483870967742, 'r1_recall': 0.6417910447761194, 'r1_f1': 0.6666666666666666, 'pegasus_entailment': 0.4379569838444392, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5584415584415584, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.5548387096774194, 'pegasus_entailment': 0.48704378062393516, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.9285714285714286, 'r1_recall': 0.5048543689320388, 'r1_f1': 0.6540880503144654, 'pegasus_entailment': 0.9514749050140381, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3942307692307692, 'r1_recall': 0.6307692307692307, 'r1_f1': 0.485207100591716, 'pegasus_entailment': 0.9346030354499817, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5529411764705883, 'r1_recall': 0.5402298850574713, 'r1_f1': 0.5465116279069768, 'pegasus_entailment': 0.1555082550039515, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5161290322580645, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.5925925925925926, 'pegasus_entailment': 0.19918043399229646, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37272727272727274, 'r1_recall': 0.47126436781609193, 'r1_f1': 0.416243654822335, 'pegasus_entailment': 0.025691937480587512, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5217391304347826, 'r1_recall': 0.3076923076923077, 'r1_f1': 0.3870967741935484, 'pegasus_entailment': 0.7383507490158081, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32989690721649484, 'r1_recall': 0.7111111111111111, 'r1_f1': 0.45070422535211263, 'pegasus_entailment': 0.7822010308504105, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7912087912087912, 'r1_recall': 0.34615384615384615, 'r1_f1': 0.4816053511705685, 'pegasus_entailment': 0.5755564719438553, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5571428571428572, 'r1_f1': 0.5270270270270271, 'pegasus_entailment': 0.5006761844269931, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.652542372881356, 'r1_recall': 0.4010416666666667, 'r1_f1': 0.4967741935483871, 'pegasus_entailment': 0.49457064643502235, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 26}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5102040816326531, 'r1_recall': 0.373134328358209, 'r1_f1': 0.4310344827586207, 'pegasus_entailment': 0.617621099948883, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43902439024390244, 'r1_recall': 0.7397260273972602, 'r1_f1': 0.5510204081632653, 'pegasus_entailment': 0.4546136357676005, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5662650602409639, 'r1_recall': 0.4017094017094017, 'r1_f1': 0.47000000000000003, 'pegasus_entailment': 0.48831429627413553, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2872340425531915, 'r1_recall': 0.27835051546391754, 'r1_f1': 0.28272251308900526, 'pegasus_entailment': 0.0005805986935835487, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 14}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7176470588235294, 'r1_recall': 0.3446327683615819, 'r1_f1': 0.4656488549618321, 'pegasus_entailment': 0.5262224525213242, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4945054945054945, 'r1_recall': 0.4639175257731959, 'r1_f1': 0.4787234042553192, 'pegasus_entailment': 0.6347532837341229, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5514018691588785, 'r1_recall': 0.46825396825396826, 'r1_f1': 0.5064377682403433, 'pegasus_entailment': 0.7043420188128948, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3619047619047619, 'r1_recall': 0.5846153846153846, 'r1_f1': 0.4470588235294118, 'pegasus_entailment': 0.5252441428601742, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5252525252525253, 'r1_recall': 0.4642857142857143, 'r1_f1': 0.49289099526066354, 'pegasus_entailment': 0.7093105858657509, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3902439024390244, 'r1_recall': 0.5245901639344263, 'r1_f1': 0.4475524475524476, 'pegasus_entailment': 0.006841100206656847, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5588235294117647, 'r1_recall': 0.40425531914893614, 'r1_f1': 0.4691358024691358, 'pegasus_entailment': 0.2356725912541151, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5736434108527132, 'r1_recall': 0.6434782608695652, 'r1_f1': 0.6065573770491803, 'pegasus_entailment': 0.5820010732859373, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45384615384615384, 'r1_recall': 0.5267857142857143, 'r1_f1': 0.48760330578512395, 'pegasus_entailment': 0.9632653743028641, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4566929133858268, 'r1_recall': 0.725, 'r1_f1': 0.5603864734299516, 'pegasus_entailment': 0.8017744362354279, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.3875968992248062, 'r1_f1': 0.4901960784313725, 'pegasus_entailment': 0.4897066717036068, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.5381165919282511, 'pegasus_entailment': 0.4143504405704637, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5891472868217055, 'r1_recall': 0.475, 'r1_f1': 0.5259515570934257, 'pegasus_entailment': 0.887201209863027, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4606741573033708, 'r1_recall': 0.5466666666666666, 'r1_f1': 0.5, 'pegasus_entailment': 0.2017803080379963, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 15, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44, 'r1_recall': 0.55, 'r1_f1': 0.48888888888888893, 'pegasus_entailment': 0.29920753557235, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7962962962962963, 'r1_recall': 0.6231884057971014, 'r1_f1': 0.6991869918699186, 'pegasus_entailment': 0.7021621316671371, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6578947368421053, 'r1_recall': 0.5639097744360902, 'r1_f1': 0.6072874493927126, 'pegasus_entailment': 0.3579535230528563, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.550561797752809, 'r1_recall': 0.620253164556962, 'r1_f1': 0.5833333333333334, 'pegasus_entailment': 0.2737341605592519, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5490196078431373, 'r1_recall': 0.6292134831460674, 'r1_f1': 0.5863874345549738, 'pegasus_entailment': 0.32439310926323134, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.671875, 'r1_recall': 0.33076923076923076, 'r1_f1': 0.44329896907216493, 'pegasus_entailment': 0.5969335613772273, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7931034482758621, 'r1_recall': 0.38764044943820225, 'r1_f1': 0.5207547169811321, 'pegasus_entailment': 0.5260416748235002, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8854166666666666, 'r1_recall': 0.48295454545454547, 'r1_f1': 0.625, 'pegasus_entailment': 0.6347041474655271, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.580952380952381, 'r1_recall': 0.4552238805970149, 'r1_f1': 0.5104602510460251, 'pegasus_entailment': 0.5528987122452236, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41304347826086957, 'r1_recall': 0.6063829787234043, 'r1_f1': 0.49137931034482757, 'pegasus_entailment': 0.18965284483662495, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6774193548387096, 'r1_recall': 0.49606299212598426, 'r1_f1': 0.5727272727272728, 'pegasus_entailment': 0.725162866152823, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7066666666666667, 'r1_recall': 0.6022727272727273, 'r1_f1': 0.6503067484662576, 'pegasus_entailment': 0.850172221660614, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5185185185185185, 'r1_recall': 0.48695652173913045, 'r1_f1': 0.5022421524663677, 'pegasus_entailment': 0.5767028058568636, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4742268041237113, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.5317919075144509, 'pegasus_entailment': 0.02144444799341727, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25, 'r1_recall': 0.4883720930232558, 'r1_f1': 0.3307086614173228, 'pegasus_entailment': 0.799594558775425, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.6964285714285714, 'r1_f1': 0.6446280991735538, 'pegasus_entailment': 0.7132963877666043, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6774193548387096, 'r1_recall': 0.6412213740458015, 'r1_f1': 0.6588235294117646, 'pegasus_entailment': 0.8474135249853134, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53125, 'r1_recall': 0.6375, 'r1_f1': 0.5795454545454545, 'pegasus_entailment': 0.20344213396310806, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5686274509803921, 'r1_recall': 0.49572649572649574, 'r1_f1': 0.5296803652968037, 'pegasus_entailment': 0.7655135989189148, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 23}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48148148148148145, 'r1_recall': 0.6724137931034483, 'r1_f1': 0.5611510791366906, 'pegasus_entailment': 0.9657464981079101, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34375, 'r1_recall': 0.7457627118644068, 'r1_f1': 0.4705882352941176, 'pegasus_entailment': 0.4929047065787017, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.77, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.532871972318339, 'pegasus_entailment': 0.3773427919174234, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7307692307692307, 'r1_recall': 0.47107438016528924, 'r1_f1': 0.5728643216080401, 'pegasus_entailment': 0.5818921029567719, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6511627906976745, 'r1_recall': 0.5419354838709678, 'r1_f1': 0.591549295774648, 'pegasus_entailment': 0.5777065825648606, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6442307692307693, 'r1_recall': 0.4110429447852761, 'r1_f1': 0.50187265917603, 'pegasus_entailment': 0.40919795017689464, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6268656716417911, 'r1_recall': 0.4158415841584158, 'r1_f1': 0.5, 'pegasus_entailment': 0.8048814932505289, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6293103448275862, 'r1_recall': 0.6033057851239669, 'r1_f1': 0.6160337552742615, 'pegasus_entailment': 0.6233444482088089, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.5376344086021505, 'r1_f1': 0.4926108374384236, 'pegasus_entailment': 0.05360198058770038, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.652542372881356, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.6135458167330677, 'pegasus_entailment': 0.5840281501412392, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6474358974358975, 'r1_recall': 0.5459459459459459, 'r1_f1': 0.5923753665689149, 'pegasus_entailment': 0.612423574924469, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5116279069767442, 'r1_recall': 0.3793103448275862, 'r1_f1': 0.43564356435643564, 'pegasus_entailment': 0.28054939170833676, 'pegasus_flesch_kincaid': 9, 'pegasus_coleman_liau': 13, 'pegasus_ari': 10, 'pegasus_smog': 13}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4435483870967742, 'r1_recall': 0.625, 'r1_f1': 0.5188679245283019, 'pegasus_entailment': 0.4855717221895854, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 23}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46464646464646464, 'r1_recall': 0.4946236559139785, 'r1_f1': 0.47916666666666663, 'pegasus_entailment': 0.7202407022317251, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5043478260869565, 'r1_recall': 0.5132743362831859, 'r1_f1': 0.5087719298245613, 'pegasus_entailment': 0.38198481537401674, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6329113924050633, 'r1_recall': 0.625, 'r1_f1': 0.6289308176100629, 'pegasus_entailment': 0.44419862143695354, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.5833333333333334, 'pegasus_entailment': 0.3856965935168167, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7920792079207921, 'r1_recall': 0.3827751196172249, 'r1_f1': 0.5161290322580645, 'pegasus_entailment': 0.9681071639060974, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 19, 'pegasus_ari': 33, 'pegasus_smog': 26}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7413793103448276, 'r1_recall': 0.47513812154696133, 'r1_f1': 0.579124579124579, 'pegasus_entailment': 0.7001461517065763, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4189189189189189, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.46616541353383456, 'pegasus_entailment': 0.5384326167404652, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7971014492753623, 'r1_recall': 0.3395061728395062, 'r1_f1': 0.4761904761904762, 'pegasus_entailment': 0.43049867264926434, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.375886524822695, 'r1_recall': 0.6463414634146342, 'r1_f1': 0.4753363228699551, 'pegasus_entailment': 0.8130142241716385, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5145631067961165, 'r1_recall': 0.5520833333333334, 'r1_f1': 0.5326633165829147, 'pegasus_entailment': 0.4409090995322913, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.746268656716418, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.6289308176100628, 'pegasus_entailment': 0.4352599476114847, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7068965517241379, 'r1_recall': 0.422680412371134, 'r1_f1': 0.529032258064516, 'pegasus_entailment': 0.42314238101243973, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5786163522012578, 'r1_recall': 0.5542168674698795, 'r1_f1': 0.5661538461538461, 'pegasus_entailment': 0.3734171912074089, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3524590163934426, 'r1_recall': 0.7288135593220338, 'r1_f1': 0.47513812154696133, 'pegasus_entailment': 0.10246949456632137, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6615384615384615, 'r1_recall': 0.49710982658959535, 'r1_f1': 0.5676567656765676, 'pegasus_entailment': 0.5550262483302504, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36363636363636365, 'r1_recall': 0.49382716049382713, 'r1_f1': 0.418848167539267, 'pegasus_entailment': 0.20356799320628247, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.37583892617449666, 'r1_f1': 0.46666666666666673, 'pegasus_entailment': 0.47941884491592646, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.463768115942029, 'r1_recall': 0.6881720430107527, 'r1_f1': 0.5541125541125541, 'pegasus_entailment': 0.1678030776383821, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.631578947368421, 'r1_recall': 0.37267080745341613, 'r1_f1': 0.46874999999999994, 'pegasus_entailment': 0.46970735024660826, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.20930232558139536, 'r1_recall': 0.23684210526315788, 'r1_f1': 0.2222222222222222, 'pegasus_entailment': 0.7681211233139038, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 31, 'pegasus_smog': 25}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5526315789473685, 'r1_recall': 0.7777777777777778, 'r1_f1': 0.6461538461538462, 'pegasus_entailment': 0.33698047725483776, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.49382716049382713, 'pegasus_entailment': 0.4743861917522736, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5779816513761468, 'r1_recall': 0.38650306748466257, 'r1_f1': 0.463235294117647, 'pegasus_entailment': 0.35307550492386025, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6565656565656566, 'r1_recall': 0.5963302752293578, 'r1_f1': 0.625, 'pegasus_entailment': 0.2895719207444927, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6788990825688074, 'r1_recall': 0.42045454545454547, 'r1_f1': 0.5192982456140351, 'pegasus_entailment': 0.6654799059033394, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7307692307692307, 'r1_recall': 0.38, 'r1_f1': 0.5, 'pegasus_entailment': 0.5129775378853083, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.5236363636363637, 'pegasus_entailment': 0.5439522240000466, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6355140186915887, 'r1_recall': 0.4563758389261745, 'r1_f1': 0.5312500000000001, 'pegasus_entailment': 0.817920446395874, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 14}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47572815533980584, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5051546391752576, 'pegasus_entailment': 0.6750752491255602, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3902439024390244, 'r1_recall': 0.6233766233766234, 'r1_f1': 0.4799999999999999, 'pegasus_entailment': 0.6136297757426897, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5753424657534246, 'r1_f1': 0.5350318471337578, 'pegasus_entailment': 0.2615992260107305, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8283582089552238, 'r1_recall': 0.3016304347826087, 'r1_f1': 0.44223107569721115, 'pegasus_entailment': 0.7848821779092153, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4411764705882353, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.4878048780487804, 'pegasus_entailment': 0.5848982608877122, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46616541353383456, 'r1_recall': 0.5, 'r1_f1': 0.48249027237354086, 'pegasus_entailment': 0.5858209684491158, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5161290322580645, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5245901639344263, 'pegasus_entailment': 0.37224212698638437, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.712, 'r1_recall': 0.37872340425531914, 'r1_f1': 0.4944444444444444, 'pegasus_entailment': 0.5476447565015405, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5384615384615384, 'r1_recall': 0.4605263157894737, 'r1_f1': 0.49645390070921985, 'pegasus_entailment': 0.3292924801353365, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5376344086021505, 'r1_recall': 0.5813953488372093, 'r1_f1': 0.5586592178770949, 'pegasus_entailment': 0.6451246105134487, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40816326530612246, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.4624277456647399, 'pegasus_entailment': 0.33054607221856713, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.6, 'r1_f1': 0.5714285714285713, 'pegasus_entailment': 0.980827271938324, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.75, 'r1_recall': 0.43902439024390244, 'r1_f1': 0.5538461538461539, 'pegasus_entailment': 0.6932511751850446, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7603305785123967, 'r1_recall': 0.3205574912891986, 'r1_f1': 0.4509803921568627, 'pegasus_entailment': 0.37868129027386505, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8285714285714286, 'r1_recall': 0.3240223463687151, 'r1_f1': 0.46586345381526106, 'pegasus_entailment': 0.6217206075477103, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7227722772277227, 'r1_recall': 0.6403508771929824, 'r1_f1': 0.6790697674418604, 'pegasus_entailment': 0.6891281423158944, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7205882352941176, 'r1_recall': 0.3769230769230769, 'r1_f1': 0.49494949494949486, 'pegasus_entailment': 0.5500873321667313, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43859649122807015, 'r1_recall': 0.4807692307692308, 'r1_f1': 0.4587155963302752, 'pegasus_entailment': 0.5025365278124809, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5053763440860215, 'r1_recall': 0.5595238095238095, 'r1_f1': 0.5310734463276836, 'pegasus_entailment': 0.2519184873284151, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7474747474747475, 'r1_recall': 0.4567901234567901, 'r1_f1': 0.5670498084291188, 'pegasus_entailment': 0.7673285827040672, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5362318840579711, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.5068493150684933, 'pegasus_entailment': 0.26276704523479566, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8255813953488372, 'r1_recall': 0.4930555555555556, 'r1_f1': 0.6173913043478262, 'pegasus_entailment': 0.1721124886535108, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6447368421052632, 'r1_recall': 0.6533333333333333, 'r1_f1': 0.6490066225165563, 'pegasus_entailment': 0.48598835337907076, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5352112676056338, 'r1_recall': 0.3140495867768595, 'r1_f1': 0.3958333333333333, 'pegasus_entailment': 0.795929471651713, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8382352941176471, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.6368715083798883, 'pegasus_entailment': 0.3392493070969067, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 22, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5306122448979592, 'r1_recall': 0.4785276073619632, 'r1_f1': 0.503225806451613, 'pegasus_entailment': 0.3982768716911475, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4962962962962963, 'r1_recall': 0.3806818181818182, 'r1_f1': 0.4308681672025723, 'pegasus_entailment': 0.48916769089798134, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6818181818181818, 'r1_recall': 0.75, 'r1_f1': 0.7142857142857143, 'pegasus_entailment': 0.44986320519819856, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4189189189189189, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.46268656716417905, 'pegasus_entailment': 0.5097693314310163, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 20}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3181818181818182, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4117647058823529, 'pegasus_entailment': 0.243674186617136, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.423728813559322, 'r1_recall': 0.5102040816326531, 'r1_f1': 0.46296296296296297, 'pegasus_entailment': 0.16534906178712844, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6170212765957447, 'r1_recall': 0.6692307692307692, 'r1_f1': 0.6420664206642066, 'pegasus_entailment': 0.5695380562101491, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34444444444444444, 'r1_recall': 0.6739130434782609, 'r1_f1': 0.45588235294117646, 'pegasus_entailment': 0.281889091944322, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5363636363636364, 'r1_recall': 0.5175438596491229, 'r1_f1': 0.5267857142857143, 'pegasus_entailment': 0.6375877883595725, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5433070866141733, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.5798319327731093, 'pegasus_entailment': 0.23082588923474154, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.743421052631579, 'r1_recall': 0.5159817351598174, 'r1_f1': 0.6091644204851753, 'pegasus_entailment': 0.6555523946881294, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5603448275862069, 'r1_recall': 0.7926829268292683, 'r1_f1': 0.6565656565656566, 'pegasus_entailment': 0.262993637326872, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4224137931034483, 'r1_recall': 0.5568181818181818, 'r1_f1': 0.48039215686274506, 'pegasus_entailment': 0.5990305364131927, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5673076923076923, 'r1_recall': 0.5841584158415841, 'r1_f1': 0.575609756097561, 'pegasus_entailment': 0.48912263922393323, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5876288659793815, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.5560975609756098, 'pegasus_entailment': 0.6370003238320351, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30392156862745096, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.41333333333333333, 'pegasus_entailment': 0.22253310400992632, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7027027027027027, 'r1_recall': 0.26262626262626265, 'r1_f1': 0.3823529411764706, 'pegasus_entailment': 0.602169968187809, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 19, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5769230769230769, 'r1_recall': 0.47468354430379744, 'r1_f1': 0.5208333333333333, 'pegasus_entailment': 0.6719934217631817, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6173913043478261, 'r1_recall': 0.44936708860759494, 'r1_f1': 0.5201465201465202, 'pegasus_entailment': 0.2733655528863892, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5304347826086957, 'r1_recall': 0.3160621761658031, 'r1_f1': 0.3961038961038961, 'pegasus_entailment': 0.7078131586313248, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7281553398058253, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.7211538461538461, 'pegasus_entailment': 0.4994008175563067, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 21, 'pegasus_ari': 35, 'pegasus_smog': 25}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5681818181818182, 'r1_recall': 0.4, 'r1_f1': 0.4694835680751174, 'pegasus_entailment': 0.5878954206903776, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35294117647058826, 'r1_recall': 0.23076923076923078, 'r1_f1': 0.2790697674418605, 'pegasus_entailment': 0.8728303710619608, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 23, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4189189189189189, 'r1_recall': 0.5081967213114754, 'r1_f1': 0.45925925925925926, 'pegasus_entailment': 0.18777691821257272, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3069306930693069, 'r1_recall': 0.5, 'r1_f1': 0.38036809815950917, 'pegasus_entailment': 0.20025359685532748, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43636363636363634, 'r1_recall': 0.4067796610169492, 'r1_f1': 0.4210526315789474, 'pegasus_entailment': 0.5251989712317785, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5230769230769231, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.5573770491803279, 'pegasus_entailment': 0.754004979133606, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.47619047619047616, 'pegasus_entailment': 0.1242806821440657, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2524271844660194, 'r1_recall': 0.65, 'r1_f1': 0.3636363636363636, 'pegasus_entailment': 0.4592316187918186, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6974789915966386, 'r1_recall': 0.4797687861271676, 'r1_f1': 0.5684931506849316, 'pegasus_entailment': 0.7932569533586502, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5888888888888889, 'r1_recall': 0.6625, 'r1_f1': 0.6235294117647059, 'pegasus_entailment': 0.05460089935271147, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7473684210526316, 'r1_recall': 0.398876404494382, 'r1_f1': 0.5201465201465201, 'pegasus_entailment': 0.216259041801095, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7777777777777778, 'r1_recall': 0.30434782608695654, 'r1_f1': 0.43750000000000006, 'pegasus_entailment': 0.751456211010615, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6352941176470588, 'r1_recall': 0.40298507462686567, 'r1_f1': 0.4931506849315068, 'pegasus_entailment': 0.46946863387711346, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7244897959183674, 'r1_recall': 0.29218106995884774, 'r1_f1': 0.4164222873900293, 'pegasus_entailment': 0.7199756443500519, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3902439024390244, 'r1_recall': 0.3902439024390244, 'r1_f1': 0.3902439024390244, 'pegasus_entailment': 0.898977980017662, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7246376811594203, 'r1_recall': 0.32894736842105265, 'r1_f1': 0.4524886877828054, 'pegasus_entailment': 0.5160205413897833, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3977272727272727, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.4375, 'pegasus_entailment': 0.5160830318927765, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8018018018018018, 'r1_recall': 0.3991031390134529, 'r1_f1': 0.5329341317365269, 'pegasus_entailment': 0.08134023026408006, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42424242424242425, 'r1_recall': 0.24778761061946902, 'r1_f1': 0.3128491620111732, 'pegasus_entailment': 0.24558495730161667, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35714285714285715, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.43103448275862066, 'pegasus_entailment': 0.8656584322452545, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7340425531914894, 'r1_recall': 0.3812154696132597, 'r1_f1': 0.5018181818181818, 'pegasus_entailment': 0.40783558785915375, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7596153846153846, 'r1_recall': 0.4463276836158192, 'r1_f1': 0.5622775800711743, 'pegasus_entailment': 0.6763238708178202, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.625, 'r1_f1': 0.6122448979591836, 'pegasus_entailment': 0.7927062118736407, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6166666666666667, 'r1_recall': 0.5103448275862069, 'r1_f1': 0.5584905660377358, 'pegasus_entailment': 0.43855541412319454, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18072289156626506, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.2702702702702703, 'pegasus_entailment': 0.00815879578779762, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.3291139240506329, 'pegasus_entailment': 0.33787208423018456, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5903614457831325, 'r1_recall': 0.4117647058823529, 'r1_f1': 0.4851485148514851, 'pegasus_entailment': 0.2902673247808707, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6065573770491803, 'r1_recall': 0.5211267605633803, 'r1_f1': 0.5606060606060606, 'pegasus_entailment': 0.8487038016319275, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38461538461538464, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.4794520547945205, 'pegasus_entailment': 0.08801694173598662, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4647887323943662, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.43421052631578944, 'pegasus_entailment': 0.7160237232844034, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7142857142857143, 'r1_recall': 0.6172839506172839, 'r1_f1': 0.662251655629139, 'pegasus_entailment': 0.48573107889387757, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6197183098591549, 'r1_recall': 0.5301204819277109, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.7194520325574558, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6122448979591837, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.5741626794258374, 'pegasus_entailment': 0.20429670034354785, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7521367521367521, 'r1_recall': 0.2619047619047619, 'r1_f1': 0.3885209713024283, 'pegasus_entailment': 0.670480215549469, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6987951807228916, 'r1_recall': 0.26126126126126126, 'r1_f1': 0.380327868852459, 'pegasus_entailment': 0.4263632893562317, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5964912280701754, 'r1_recall': 0.4358974358974359, 'r1_f1': 0.5037037037037038, 'pegasus_entailment': 0.9336917996406555, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 12}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7195121951219512, 'r1_recall': 0.5673076923076923, 'r1_f1': 0.6344086021505376, 'pegasus_entailment': 0.40403237864375113, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3018867924528302, 'r1_recall': 0.4383561643835616, 'r1_f1': 0.35754189944134085, 'pegasus_entailment': 0.6582596702501178, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5416666666666666, 'r1_recall': 0.6, 'r1_f1': 0.5693430656934306, 'pegasus_entailment': 0.006132937269285321, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 16}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6049382716049383, 'r1_recall': 0.6805555555555556, 'r1_f1': 0.6405228758169934, 'pegasus_entailment': 0.5643481274601072, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5578947368421052, 'r1_recall': 0.654320987654321, 'r1_f1': 0.6022727272727273, 'pegasus_entailment': 0.34203640022315085, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5189873417721519, 'r1_recall': 0.5394736842105263, 'r1_f1': 0.5290322580645163, 'pegasus_entailment': 0.1465138370792071, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5909090909090909, 'r1_recall': 0.4642857142857143, 'r1_f1': 0.52, 'pegasus_entailment': 0.1258727590320632, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7604166666666666, 'r1_recall': 0.46496815286624205, 'r1_f1': 0.5770750988142292, 'pegasus_entailment': 0.30608674173709005, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7789473684210526, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.6192468619246861, 'pegasus_entailment': 0.49823063164949416, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5051546391752577, 'r1_recall': 0.5212765957446809, 'r1_f1': 0.5130890052356021, 'pegasus_entailment': 0.4960579574108124, 'pegasus_flesch_kincaid': 45, 'pegasus_coleman_liau': 18, 'pegasus_ari': 55, 'pegasus_smog': 28}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6727272727272727, 'r1_recall': 0.581151832460733, 'r1_f1': 0.6235955056179774, 'pegasus_entailment': 0.4022718380826215, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.6530612244897959, 'r1_f1': 0.547008547008547, 'pegasus_entailment': 0.7487787008285522, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4588235294117647, 'r1_recall': 0.46987951807228917, 'r1_f1': 0.4642857142857143, 'pegasus_entailment': 0.8259239494800568, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7066666666666667, 'r1_recall': 0.6794871794871795, 'r1_f1': 0.6928104575163399, 'pegasus_entailment': 0.056996120198164135, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 11}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.6790123456790124, 'r1_f1': 0.6432748538011697, 'pegasus_entailment': 0.2773915040306747, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6990291262135923, 'r1_recall': 0.5255474452554745, 'r1_f1': 0.6000000000000001, 'pegasus_entailment': 0.6405126377940178, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25806451612903225, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.3503649635036496, 'pegasus_entailment': 0.23564434486130872, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43636363636363634, 'r1_recall': 0.4067796610169492, 'r1_f1': 0.4210526315789474, 'pegasus_entailment': 0.8837871849536896, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.631578947368421, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.5806451612903225, 'pegasus_entailment': 0.2944067592965439, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.556390977443609, 'r1_recall': 0.47435897435897434, 'r1_f1': 0.5121107266435986, 'pegasus_entailment': 0.2006383672511826, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4260869565217391, 'r1_recall': 0.7538461538461538, 'r1_f1': 0.5444444444444445, 'pegasus_entailment': 0.7904357016086578, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5789473684210527, 'r1_recall': 0.375, 'r1_f1': 0.45517241379310347, 'pegasus_entailment': 0.6187712773680687, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.2246352918446064, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4444444444444444, 'r1_recall': 0.6233766233766234, 'r1_f1': 0.518918918918919, 'pegasus_entailment': 0.09650830049067735, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4247787610619469, 'r1_recall': 0.6, 'r1_f1': 0.4974093264248705, 'pegasus_entailment': 0.4580438952893019, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.5, 'pegasus_entailment': 0.5660878885537386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 19}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4482758620689655, 'r1_recall': 0.5131578947368421, 'r1_f1': 0.47852760736196326, 'pegasus_entailment': 0.38575074076652527, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4336283185840708, 'r1_recall': 0.5764705882352941, 'r1_f1': 0.4949494949494949, 'pegasus_entailment': 0.6352870106697083, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5942028985507246, 'r1_recall': 0.6259541984732825, 'r1_f1': 0.6096654275092938, 'pegasus_entailment': 0.6841803242762884, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 32, 'pegasus_smog': 22}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4125, 'r1_recall': 0.3113207547169811, 'r1_f1': 0.3548387096774193, 'pegasus_entailment': 0.26143373918603174, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7604166666666666, 'r1_recall': 0.3989071038251366, 'r1_f1': 0.5232974910394265, 'pegasus_entailment': 0.5598664935678244, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49382716049382713, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5095541401273886, 'pegasus_entailment': 0.29495545228322345, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6097560975609756, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.5747126436781609, 'pegasus_entailment': 0.5878821043588687, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7538461538461538, 'r1_recall': 0.4537037037037037, 'r1_f1': 0.5664739884393063, 'pegasus_entailment': 0.6170497536659241, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5046728971962616, 'r1_recall': 0.5346534653465347, 'r1_f1': 0.5192307692307693, 'pegasus_entailment': 0.15290266481461004, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5727272727272728, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.6057692307692308, 'pegasus_entailment': 0.094654880464077, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5373134328358209, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.5255474452554744, 'pegasus_entailment': 0.24073971901088953, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8113207547169812, 'r1_recall': 0.6466165413533834, 'r1_f1': 0.7196652719665273, 'pegasus_entailment': 0.5281308628618717, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5913978494623656, 'r1_recall': 0.6111111111111112, 'r1_f1': 0.6010928961748635, 'pegasus_entailment': 0.32750848432381946, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 13}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7362637362637363, 'r1_recall': 0.5826086956521739, 'r1_f1': 0.6504854368932038, 'pegasus_entailment': 0.6616340180238088, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 24}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.5194805194805195, 'pegasus_entailment': 0.4427349840601285, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.9210526315789473, 'r1_recall': 0.5072463768115942, 'r1_f1': 0.6542056074766355, 'pegasus_entailment': 0.9252457320690155, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.176, 'r1_recall': 0.44, 'r1_f1': 0.2514285714285714, 'pegasus_entailment': 0.5020774362928933, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23369565217391305, 'r1_recall': 0.7678571428571429, 'r1_f1': 0.3583333333333334, 'pegasus_entailment': 0.13103171344846487, 'pegasus_flesch_kincaid': 32, 'pegasus_coleman_liau': 20, 'pegasus_ari': 39, 'pegasus_smog': 26}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23076923076923078, 'r1_recall': 0.3191489361702128, 'r1_f1': 0.2678571428571429, 'pegasus_entailment': 0.6236653923988342, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48148148148148145, 'r1_recall': 0.36619718309859156, 'r1_f1': 0.416, 'pegasus_entailment': 0.395742295930783, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7093023255813954, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.4535315985130111, 'pegasus_entailment': 0.6374862889448801, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 14, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5909090909090909, 'r1_recall': 0.5693430656934306, 'r1_f1': 0.5799256505576208, 'pegasus_entailment': 0.5371318521598974, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7391304347826086, 'r1_recall': 0.5604395604395604, 'r1_f1': 0.6375, 'pegasus_entailment': 0.8968136608600616, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5688073394495413, 'r1_recall': 0.46616541353383456, 'r1_f1': 0.5123966942148761, 'pegasus_entailment': 0.8533709347248077, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.780952380952381, 'r1_recall': 0.5, 'r1_f1': 0.6096654275092938, 'pegasus_entailment': 0.23764581009745597, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6724137931034483, 'r1_recall': 0.582089552238806, 'r1_f1': 0.624, 'pegasus_entailment': 0.5350146691004435, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4423076923076923, 'r1_recall': 0.46, 'r1_f1': 0.4509803921568628, 'pegasus_entailment': 0.6031006034463644, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.5625, 'r1_f1': 0.5, 'pegasus_entailment': 0.4810639382340014, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5862068965517241, 'r1_recall': 0.4146341463414634, 'r1_f1': 0.48571428571428565, 'pegasus_entailment': 0.4998279809951782, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22340425531914893, 'r1_recall': 0.4375, 'r1_f1': 0.295774647887324, 'pegasus_entailment': 0.0941219142638147, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.391304347826087, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.4645161290322581, 'pegasus_entailment': 0.3402019952889532, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3181818181818182, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.42000000000000004, 'pegasus_entailment': 0.12679536803625524, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5256410256410257, 'r1_recall': 0.5394736842105263, 'r1_f1': 0.5324675324675324, 'pegasus_entailment': 0.5190983125551915, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7786885245901639, 'r1_recall': 0.5163043478260869, 'r1_f1': 0.6209150326797385, 'pegasus_entailment': 0.5905992612242699, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47761194029850745, 'r1_recall': 0.47761194029850745, 'r1_f1': 0.47761194029850745, 'pegasus_entailment': 0.4521008829275767, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7087378640776699, 'r1_recall': 0.43452380952380953, 'r1_f1': 0.5387453874538746, 'pegasus_entailment': 0.4984510079026222, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.552, 'r1_recall': 0.5227272727272727, 'r1_f1': 0.5369649805447471, 'pegasus_entailment': 0.7675888737042745, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8271604938271605, 'r1_recall': 0.4240506329113924, 'r1_f1': 0.5606694560669456, 'pegasus_entailment': 0.5261592318614324, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 22}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7692307692307693, 'r1_recall': 0.2702702702702703, 'r1_f1': 0.4, 'pegasus_entailment': 0.8665445446968079, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3359375, 'r1_recall': 0.7818181818181819, 'r1_f1': 0.46994535519125685, 'pegasus_entailment': 0.5805074632167816, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7128712871287128, 'r1_recall': 0.36548223350253806, 'r1_f1': 0.4832214765100671, 'pegasus_entailment': 0.5660738249619802, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6086956521739131, 'r1_recall': 0.23333333333333334, 'r1_f1': 0.3373493975903614, 'pegasus_entailment': 0.45539774000644684, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6542056074766355, 'r1_recall': 0.5691056910569106, 'r1_f1': 0.608695652173913, 'pegasus_entailment': 0.8143491347630819, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7272727272727273, 'r1_recall': 0.6095238095238096, 'r1_f1': 0.6632124352331606, 'pegasus_entailment': 0.4795482226036256, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7647058823529411, 'r1_recall': 0.4961832061068702, 'r1_f1': 0.6018518518518519, 'pegasus_entailment': 0.39050119668245314, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3770491803278688, 'r1_recall': 0.6865671641791045, 'r1_f1': 0.48677248677248675, 'pegasus_entailment': 0.2327062984307607, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4025974025974026, 'r1_recall': 0.543859649122807, 'r1_f1': 0.4626865671641791, 'pegasus_entailment': 0.35773088596761227, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30578512396694213, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.41573033707865165, 'pegasus_entailment': 0.1199556349311024, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.782051282051282, 'r1_recall': 0.4765625, 'r1_f1': 0.5922330097087379, 'pegasus_entailment': 0.6229246333241463, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7433628318584071, 'r1_recall': 0.47191011235955055, 'r1_f1': 0.5773195876288659, 'pegasus_entailment': 0.6796540468931198, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6771653543307087, 'r1_recall': 0.5276073619631901, 'r1_f1': 0.593103448275862, 'pegasus_entailment': 0.78120356798172, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.631578947368421, 'r1_recall': 0.37305699481865284, 'r1_f1': 0.46905537459283386, 'pegasus_entailment': 0.6570470677688718, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5604395604395604, 'r1_recall': 0.504950495049505, 'r1_f1': 0.53125, 'pegasus_entailment': 0.4491119459271431, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4406779661016949, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.5148514851485149, 'pegasus_entailment': 0.4642395251430571, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5142857142857142, 'r1_recall': 0.4, 'r1_f1': 0.45, 'pegasus_entailment': 0.11117073590867221, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4745762711864407, 'r1_recall': 0.5490196078431373, 'r1_f1': 0.5090909090909091, 'pegasus_entailment': 0.2947807766031474, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.725, 'r1_recall': 0.5878378378378378, 'r1_f1': 0.6492537313432836, 'pegasus_entailment': 0.4778098426759243, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5818181818181818, 'r1_recall': 0.48854961832061067, 'r1_f1': 0.5311203319502075, 'pegasus_entailment': 0.3682476137764752, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 14}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.59, 'r1_recall': 0.5, 'r1_f1': 0.5412844036697249, 'pegasus_entailment': 0.4319249603431672, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6260869565217392, 'r1_recall': 0.5538461538461539, 'r1_f1': 0.5877551020408163, 'pegasus_entailment': 0.5042111653601751, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43356643356643354, 'r1_recall': 0.5210084033613446, 'r1_f1': 0.4732824427480916, 'pegasus_entailment': 0.3478018407477066, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7263157894736842, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.5774058577405858, 'pegasus_entailment': 0.37836961417924614, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6825396825396826, 'r1_recall': 0.4777777777777778, 'r1_f1': 0.5620915032679739, 'pegasus_entailment': 0.6016083558400472, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5402298850574713, 'r1_recall': 0.3533834586466165, 'r1_f1': 0.42727272727272725, 'pegasus_entailment': 0.028844032323831925, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6461538461538462, 'r1_recall': 0.39622641509433965, 'r1_f1': 0.4912280701754387, 'pegasus_entailment': 0.6675587147474289, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.54, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.5046728971962616, 'pegasus_entailment': 0.7527267634868622, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6129032258064516, 'r1_recall': 0.4453125, 'r1_f1': 0.5158371040723982, 'pegasus_entailment': 0.18200385527597973, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3717948717948718, 'r1_recall': 0.5087719298245614, 'r1_f1': 0.42962962962962964, 'pegasus_entailment': 0.3351079416461289, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7019867549668874, 'r1_recall': 0.5549738219895288, 'r1_f1': 0.6198830409356725, 'pegasus_entailment': 0.6309217046946287, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6790123456790124, 'r1_recall': 0.3741496598639456, 'r1_f1': 0.4824561403508772, 'pegasus_entailment': 0.7921883165836334, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5838509316770186, 'r1_recall': 0.6103896103896104, 'r1_f1': 0.5968253968253967, 'pegasus_entailment': 0.5411360956262797, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5102040816326531, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5780346820809249, 'pegasus_entailment': 0.7546318769454956, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6283185840707964, 'r1_recall': 0.6173913043478261, 'r1_f1': 0.6228070175438597, 'pegasus_entailment': 0.22404377863858826, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6888888888888889, 'r1_recall': 0.40522875816993464, 'r1_f1': 0.5102880658436214, 'pegasus_entailment': 0.3734349850565195, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5445544554455446, 'r1_recall': 0.5392156862745098, 'r1_f1': 0.5418719211822661, 'pegasus_entailment': 0.4909207866585348, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 13, 'pegasus_ari': 16, 'pegasus_smog': 11}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32941176470588235, 'r1_recall': 0.49122807017543857, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.469983721151948, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.390625, 'r1_f1': 0.4807692307692308, 'pegasus_entailment': 0.7120684087276459, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 23, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.660377358490566, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.546875, 'pegasus_entailment': 0.9052218496799469, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4639175257731959, 'r1_recall': 0.8490566037735849, 'r1_f1': 0.6, 'pegasus_entailment': 0.505066389683634, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6559139784946236, 'r1_recall': 0.6559139784946236, 'r1_f1': 0.6559139784946236, 'pegasus_entailment': 0.436427965760231, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6266666666666667, 'r1_recall': 0.8103448275862069, 'r1_f1': 0.706766917293233, 'pegasus_entailment': 0.41610150085762143, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6857142857142857, 'r1_recall': 0.7058823529411765, 'r1_f1': 0.6956521739130436, 'pegasus_entailment': 0.7652232520282268, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5966386554621849, 'r1_recall': 0.44936708860759494, 'r1_f1': 0.5126353790613719, 'pegasus_entailment': 0.7038217902183532, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4069767441860465, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.48951048951048953, 'pegasus_entailment': 0.279714023694396, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5925925925925926, 'r1_recall': 0.5369127516778524, 'r1_f1': 0.5633802816901408, 'pegasus_entailment': 0.541371887922287, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7088607594936709, 'r1_recall': 0.40875912408759124, 'r1_f1': 0.5185185185185185, 'pegasus_entailment': 0.5181742280721664, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6197183098591549, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6423357664233577, 'pegasus_entailment': 0.5996604352258146, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.675, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.5654450261780104, 'pegasus_entailment': 0.5291013207286597, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43434343434343436, 'r1_recall': 0.5375, 'r1_f1': 0.48044692737430167, 'pegasus_entailment': 0.7869200507799784, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6764705882352942, 'r1_recall': 0.36220472440944884, 'r1_f1': 0.47179487179487184, 'pegasus_entailment': 0.49316704118003446, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6776859504132231, 'r1_recall': 0.41624365482233505, 'r1_f1': 0.5157232704402515, 'pegasus_entailment': 0.36211913901691634, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7203389830508474, 'r1_recall': 0.3497942386831276, 'r1_f1': 0.4709141274238227, 'pegasus_entailment': 0.38203488166133565, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7361111111111112, 'r1_recall': 0.381294964028777, 'r1_f1': 0.5023696682464455, 'pegasus_entailment': 0.8390110731124878, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.06666666666666667, 'r1_recall': 0.0410958904109589, 'r1_f1': 0.05084745762711865, 'pegasus_entailment': 0.9551213383674622, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 0, 'pegasus_ari': 16, 'pegasus_smog': 8}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32432432432432434, 'r1_recall': 0.39344262295081966, 'r1_f1': 0.3555555555555555, 'pegasus_entailment': 0.01903404953191057, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6923076923076923, 'r1_recall': 0.313953488372093, 'r1_f1': 0.43200000000000005, 'pegasus_entailment': 0.6090950518846512, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 25, 'pegasus_ari': 23, 'pegasus_smog': 23}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.5070422535211269, 'pegasus_entailment': 0.2527882878979047, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7692307692307693, 'r1_recall': 0.45977011494252873, 'r1_f1': 0.5755395683453237, 'pegasus_entailment': 0.4173222954074542, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5535714285714286, 'r1_recall': 0.4305555555555556, 'r1_f1': 0.484375, 'pegasus_entailment': 0.3040982659906149, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.654320987654321, 'r1_recall': 0.5435897435897435, 'r1_f1': 0.5938375350140055, 'pegasus_entailment': 0.689051728695631, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5606060606060606, 'r1_recall': 0.5068493150684932, 'r1_f1': 0.5323741007194245, 'pegasus_entailment': 0.0718043209053576, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4594594594594595, 'r1_recall': 0.68, 'r1_f1': 0.5483870967741935, 'pegasus_entailment': 0.6689626284642145, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5377358490566038, 'r1_recall': 0.5, 'r1_f1': 0.5181818181818182, 'pegasus_entailment': 0.5875349505804479, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.803921568627451, 'r1_recall': 0.3271276595744681, 'r1_f1': 0.46502835538752363, 'pegasus_entailment': 0.4420715455586712, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6226415094339622, 'r1_recall': 0.559322033898305, 'r1_f1': 0.5892857142857142, 'pegasus_entailment': 0.1588039305061102, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6422764227642277, 'r1_recall': 0.47023809523809523, 'r1_f1': 0.5429553264604812, 'pegasus_entailment': 0.657431403795878, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5130434782608696, 'r1_recall': 0.4573643410852713, 'r1_f1': 0.48360655737704916, 'pegasus_entailment': 0.5010573611652944, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.3624161073825503, 'r1_f1': 0.4518828451882845, 'pegasus_entailment': 0.4130391702055931, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.5798816568047337, 'r1_f1': 0.5816023738872403, 'pegasus_entailment': 0.43446122854948044, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5979381443298969, 'r1_recall': 0.44274809160305345, 'r1_f1': 0.5087719298245614, 'pegasus_entailment': 0.3314763270318508, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4608695652173913, 'r1_recall': 0.4274193548387097, 'r1_f1': 0.4435146443514644, 'pegasus_entailment': 0.5156310442835093, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4453125, 'r1_recall': 0.6867469879518072, 'r1_f1': 0.5402843601895735, 'pegasus_entailment': 0.7802543044090271, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2692307692307692, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.3589743589743589, 'pegasus_entailment': 0.30100649897940457, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7702702702702703, 'r1_recall': 0.49137931034482757, 'r1_f1': 0.6000000000000001, 'pegasus_entailment': 0.1285467520938255, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7528089887640449, 'r1_recall': 0.3621621621621622, 'r1_f1': 0.489051094890511, 'pegasus_entailment': 0.2543713478371501, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8888888888888888, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.48484848484848486, 'pegasus_entailment': 0.9620025157928467, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 25, 'pegasus_ari': 31, 'pegasus_smog': 27}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6947368421052632, 'r1_recall': 0.34285714285714286, 'r1_f1': 0.45913043478260873, 'pegasus_entailment': 0.5830815409620603, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6513761467889908, 'r1_recall': 0.4930555555555556, 'r1_f1': 0.5612648221343872, 'pegasus_entailment': 0.8594472706317902, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34579439252336447, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.43023255813953487, 'pegasus_entailment': 0.2351005698243777, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4318181818181818, 'r1_recall': 0.6333333333333333, 'r1_f1': 0.5135135135135135, 'pegasus_entailment': 0.14356283490390828, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.2345679012345679, 'r1_f1': 0.319327731092437, 'pegasus_entailment': 0.54438266903162, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 22, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6071428571428571, 'r1_recall': 0.49038461538461536, 'r1_f1': 0.5425531914893617, 'pegasus_entailment': 0.23501949990168214, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4520547945205479, 'r1_recall': 0.38372093023255816, 'r1_f1': 0.41509433962264153, 'pegasus_entailment': 0.5947982420523962, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 23}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.5072463768115941, 'pegasus_entailment': 0.8038830012083054, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7156862745098039, 'r1_recall': 0.44242424242424244, 'r1_f1': 0.5468164794007491, 'pegasus_entailment': 0.4935950506478548, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4827586206896552, 'r1_recall': 0.45901639344262296, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.921246349811554, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6017699115044248, 'r1_recall': 0.4533333333333333, 'r1_f1': 0.5171102661596958, 'pegasus_entailment': 0.5308939442038536, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 14}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5287356321839081, 'r1_recall': 0.5054945054945055, 'r1_f1': 0.5168539325842697, 'pegasus_entailment': 0.24530571336799767, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7272727272727273, 'r1_recall': 0.42748091603053434, 'r1_f1': 0.5384615384615384, 'pegasus_entailment': 0.5581103162840009, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4418604651162791, 'r1_recall': 0.6263736263736264, 'r1_f1': 0.5181818181818182, 'pegasus_entailment': 0.47054384152094525, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.5806451612903226, 'pegasus_entailment': 0.8511746376752853, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.7397260273972602, 'r1_f1': 0.7012987012987013, 'pegasus_entailment': 0.5545966029167175, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4883720930232558, 'r1_recall': 0.336, 'r1_f1': 0.3981042654028436, 'pegasus_entailment': 0.0865540656959638, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 13}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6162790697674418, 'r1_recall': 0.4649122807017544, 'r1_f1': 0.5299999999999999, 'pegasus_entailment': 0.6809664559550583, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4421052631578947, 'r1_recall': 0.47191011235955055, 'r1_f1': 0.45652173913043476, 'pegasus_entailment': 0.27584634501254185, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.4186046511627907, 'r1_f1': 0.42352941176470593, 'pegasus_entailment': 0.4247867092490196, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 18, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7068965517241379, 'r1_recall': 0.37104072398190047, 'r1_f1': 0.486646884272997, 'pegasus_entailment': 0.4308069184422493, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6601941747572816, 'r1_recall': 0.6017699115044248, 'r1_f1': 0.6296296296296297, 'pegasus_entailment': 0.49680881202220917, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 34, 'pegasus_smog': 22}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24615384615384617, 'r1_recall': 0.43243243243243246, 'r1_f1': 0.3137254901960784, 'pegasus_entailment': 0.33339310344308615, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.5121951219512195, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.7277114614844322, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5942028985507246, 'r1_recall': 0.38317757009345793, 'r1_f1': 0.46590909090909094, 'pegasus_entailment': 0.6449274234473705, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5094339622641509, 'r1_recall': 0.75, 'r1_f1': 0.6067415730337078, 'pegasus_entailment': 0.3627637289464474, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4731182795698925, 'r1_recall': 0.5, 'r1_f1': 0.48618784530386744, 'pegasus_entailment': 0.6506766527891159, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 30, 'pegasus_smog': 21}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6705882352941176, 'r1_recall': 0.6404494382022472, 'r1_f1': 0.6551724137931035, 'pegasus_entailment': 0.47334501296281817, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4186046511627907, 'r1_recall': 0.6101694915254238, 'r1_f1': 0.496551724137931, 'pegasus_entailment': 0.6563360942139601, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6438356164383562, 'r1_recall': 0.47474747474747475, 'r1_f1': 0.5465116279069767, 'pegasus_entailment': 0.6489680310090383, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6792452830188679, 'r1_recall': 0.375, 'r1_f1': 0.4832214765100672, 'pegasus_entailment': 0.34240482391032856, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5869565217391305, 'r1_recall': 0.574468085106383, 'r1_f1': 0.5806451612903226, 'pegasus_entailment': 0.2924678991548717, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.89937106918239, 'r1_recall': 0.2739463601532567, 'r1_f1': 0.41997063142437596, 'pegasus_entailment': 0.7042092587798834, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7657657657657657, 'r1_recall': 0.425, 'r1_f1': 0.5466237942122185, 'pegasus_entailment': 0.8043527662754059, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2631578947368421, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.33175355450236965, 'pegasus_entailment': 0.2162172528582492, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5855855855855856, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.6018518518518519, 'pegasus_entailment': 0.3761373112599055, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7471264367816092, 'r1_recall': 0.47794117647058826, 'r1_f1': 0.5829596412556054, 'pegasus_entailment': 0.8111821264028549, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5862068965517241, 'r1_recall': 0.6017699115044248, 'r1_f1': 0.593886462882096, 'pegasus_entailment': 0.432747317571193, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5862068965517241, 'r1_recall': 0.6, 'r1_f1': 0.5930232558139535, 'pegasus_entailment': 0.5963955819606781, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4823529411764706, 'r1_recall': 0.6212121212121212, 'r1_f1': 0.543046357615894, 'pegasus_entailment': 0.6258522073427836, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6714285714285714, 'r1_recall': 0.5108695652173914, 'r1_f1': 0.5802469135802468, 'pegasus_entailment': 0.3212683601304889, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5714285714285714, 'r1_recall': 0.43373493975903615, 'r1_f1': 0.4931506849315068, 'pegasus_entailment': 0.4744282681494951, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7692307692307693, 'r1_recall': 0.3968253968253968, 'r1_f1': 0.5235602094240838, 'pegasus_entailment': 0.11953641846776009, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.559322033898305, 'r1_recall': 0.3235294117647059, 'r1_f1': 0.40993788819875776, 'pegasus_entailment': 0.3829929046332836, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7674418604651163, 'r1_recall': 0.40993788819875776, 'r1_f1': 0.534412955465587, 'pegasus_entailment': 0.6425683200359344, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39325842696629215, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.4794520547945206, 'pegasus_entailment': 0.25073991615014773, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7371794871794872, 'r1_recall': 0.5088495575221239, 'r1_f1': 0.6020942408376964, 'pegasus_entailment': 0.3790850059594959, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.023244236401903134, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 17}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5596330275229358, 'r1_recall': 0.6039603960396039, 'r1_f1': 0.5809523809523809, 'pegasus_entailment': 0.3254898674786091, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2920353982300885, 'r1_recall': 0.673469387755102, 'r1_f1': 0.4074074074074074, 'pegasus_entailment': 0.5195352993905544, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21333333333333335, 'r1_recall': 0.34782608695652173, 'r1_f1': 0.2644628099173553, 'pegasus_entailment': 0.2407829195726663, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6583333333333333, 'r1_recall': 0.541095890410959, 'r1_f1': 0.5939849624060151, 'pegasus_entailment': 0.7520666066557169, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6491228070175439, 'r1_recall': 0.3854166666666667, 'r1_f1': 0.4836601307189542, 'pegasus_entailment': 0.7147587314248085, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6744186046511628, 'r1_recall': 0.3918918918918919, 'r1_f1': 0.49572649572649563, 'pegasus_entailment': 0.4653277573330949, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5915492957746479, 'r1_recall': 0.42424242424242425, 'r1_f1': 0.49411764705882355, 'pegasus_entailment': 0.11606937111355364, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48214285714285715, 'r1_recall': 0.6506024096385542, 'r1_f1': 0.5538461538461539, 'pegasus_entailment': 0.41578550409394666, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5257731958762887, 'r1_recall': 0.7183098591549296, 'r1_f1': 0.6071428571428571, 'pegasus_entailment': 0.8208841323852539, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5546218487394958, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.5641025641025642, 'pegasus_entailment': 0.25596804994468886, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6173913043478261, 'r1_recall': 0.4226190476190476, 'r1_f1': 0.5017667844522967, 'pegasus_entailment': 0.7767510563135147, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36619718309859156, 'r1_recall': 0.49056603773584906, 'r1_f1': 0.4193548387096774, 'pegasus_entailment': 0.6492298804223537, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7866666666666666, 'r1_recall': 0.5462962962962963, 'r1_f1': 0.644808743169399, 'pegasus_entailment': 0.4390016744534175, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.4336283185840708, 'r1_f1': 0.49746192893401014, 'pegasus_entailment': 0.3670660451898584, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39823008849557523, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.4891304347826088, 'pegasus_entailment': 0.061990017304196954, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6635514018691588, 'r1_recall': 0.3242009132420091, 'r1_f1': 0.43558282208588955, 'pegasus_entailment': 0.7128753014840186, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3142857142857143, 'r1_recall': 0.3142857142857143, 'r1_f1': 0.3142857142857143, 'pegasus_entailment': 0.9527797102928162, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 19}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47368421052631576, 'r1_recall': 0.7590361445783133, 'r1_f1': 0.5833333333333333, 'pegasus_entailment': 0.32734239590354264, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3409090909090909, 'r1_recall': 0.6122448979591837, 'r1_f1': 0.43795620437956206, 'pegasus_entailment': 0.27393093627567094, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.865979381443299, 'r1_recall': 0.49411764705882355, 'r1_f1': 0.6292134831460674, 'pegasus_entailment': 0.8337986171245575, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6204379562043796, 'r1_recall': 0.6589147286821705, 'r1_f1': 0.6390977443609023, 'pegasus_entailment': 0.44479179981863126, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.632183908045977, 'r1_f1': 0.5913978494623656, 'pegasus_entailment': 0.06764651872217656, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6966292134831461, 'r1_recall': 0.46616541353383456, 'r1_f1': 0.5585585585585585, 'pegasus_entailment': 0.4522191832462947, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5887096774193549, 'r1_recall': 0.6576576576576577, 'r1_f1': 0.6212765957446809, 'pegasus_entailment': 0.5083883376792073, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3787878787878788, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.43859649122807015, 'pegasus_entailment': 0.47334716375917196, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7261904761904762, 'r1_recall': 0.4357142857142857, 'r1_f1': 0.5446428571428572, 'pegasus_entailment': 0.9514151612917582, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7586206896551724, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.6330755278468132, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.5569620253164557, 'pegasus_entailment': 0.7285392845515162, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6458333333333334, 'r1_recall': 0.6019417475728155, 'r1_f1': 0.6231155778894473, 'pegasus_entailment': 0.4641721496979396, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35135135135135137, 'r1_recall': 0.582089552238806, 'r1_f1': 0.43820224719101125, 'pegasus_entailment': 0.28838587179780006, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5208333333333334, 'r1_recall': 0.5494505494505495, 'r1_f1': 0.5347593582887702, 'pegasus_entailment': 0.8290705382823944, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6764705882352942, 'r1_recall': 0.4825174825174825, 'r1_f1': 0.563265306122449, 'pegasus_entailment': 0.6520704853658875, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7532467532467533, 'r1_recall': 0.47540983606557374, 'r1_f1': 0.5829145728643216, 'pegasus_entailment': 0.1526496398728341, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6311475409836066, 'r1_recall': 0.463855421686747, 'r1_f1': 0.5347222222222221, 'pegasus_entailment': 0.2034175742107133, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5849056603773585, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.5740740740740741, 'pegasus_entailment': 0.4711110226344317, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43333333333333335, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.3880597014925374, 'pegasus_entailment': 0.7511650398373604, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7833333333333333, 'r1_recall': 0.46078431372549017, 'r1_f1': 0.5802469135802469, 'pegasus_entailment': 0.6352169997990131, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6893939393939394, 'r1_recall': 0.4212962962962963, 'r1_f1': 0.5229885057471264, 'pegasus_entailment': 0.5508205071091652, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6629213483146067, 'r1_recall': 0.48760330578512395, 'r1_f1': 0.5619047619047619, 'pegasus_entailment': 0.22380004605899254, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7108433734939759, 'r1_recall': 0.4125874125874126, 'r1_f1': 0.5221238938053098, 'pegasus_entailment': 0.25358527537900954, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4351145038167939, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.5229357798165137, 'pegasus_entailment': 0.4361530840396881, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4827586206896552, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5410628019323672, 'pegasus_entailment': 0.4297314465317565, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6417910447761194, 'r1_recall': 0.4215686274509804, 'r1_f1': 0.5088757396449705, 'pegasus_entailment': 0.25683648822208244, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 11, 'pegasus_ari': 11, 'pegasus_smog': 15}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5733333333333334, 'r1_recall': 0.37719298245614036, 'r1_f1': 0.45502645502645506, 'pegasus_entailment': 0.34887588035780936, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46226415094339623, 'r1_recall': 0.494949494949495, 'r1_f1': 0.47804878048780486, 'pegasus_entailment': 0.5656932145357132, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37362637362637363, 'r1_recall': 0.38202247191011235, 'r1_f1': 0.3777777777777777, 'pegasus_entailment': 0.2449243306182325, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8070175438596491, 'r1_recall': 0.5644171779141104, 'r1_f1': 0.6642599277978338, 'pegasus_entailment': 0.37195661664009094, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5784313725490197, 'r1_recall': 0.3241758241758242, 'r1_f1': 0.4154929577464789, 'pegasus_entailment': 0.7008368015289307, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7692307692307693, 'r1_recall': 0.21818181818181817, 'r1_f1': 0.33994334277620397, 'pegasus_entailment': 0.35753364814445376, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5037037037037037, 'r1_recall': 0.6238532110091743, 'r1_f1': 0.5573770491803278, 'pegasus_entailment': 0.6107790188863873, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425, 'r1_recall': 0.29310344827586204, 'r1_f1': 0.3469387755102041, 'pegasus_entailment': 0.8935857713222504, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 22, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6222222222222222, 'r1_recall': 0.30939226519337015, 'r1_f1': 0.4132841328413284, 'pegasus_entailment': 0.2361676240572706, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5161290322580645, 'r1_recall': 0.4155844155844156, 'r1_f1': 0.46043165467625896, 'pegasus_entailment': 0.1308608406689018, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 13, 'pegasus_ari': 12, 'pegasus_smog': 13}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.525, 'r1_f1': 0.5874125874125874, 'pegasus_entailment': 0.8259854912757874, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6483516483516484, 'r1_recall': 0.6344086021505376, 'r1_f1': 0.641304347826087, 'pegasus_entailment': 0.48925476521253586, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.375, 'r1_recall': 0.6296296296296297, 'r1_f1': 0.47004608294930866, 'pegasus_entailment': 0.2052067093512354, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49, 'r1_recall': 0.5444444444444444, 'r1_f1': 0.5157894736842104, 'pegasus_entailment': 0.38907412998378277, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36470588235294116, 'r1_recall': 0.4492753623188406, 'r1_f1': 0.40259740259740256, 'pegasus_entailment': 0.49971011135494336, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5714285714285714, 'r1_recall': 0.625, 'r1_f1': 0.5970149253731343, 'pegasus_entailment': 0.19274014770053327, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4222222222222222, 'r1_recall': 0.59375, 'r1_f1': 0.49350649350649345, 'pegasus_entailment': 0.8070272356271744, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3173076923076923, 'r1_recall': 0.7252747252747253, 'r1_f1': 0.44147157190635455, 'pegasus_entailment': 0.7414791931708654, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5135135135135135, 'r1_recall': 0.6477272727272727, 'r1_f1': 0.5728643216080402, 'pegasus_entailment': 0.39091730263317004, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39669421487603307, 'r1_recall': 0.7741935483870968, 'r1_f1': 0.5245901639344261, 'pegasus_entailment': 0.041545146593957076, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5081967213114754, 'r1_recall': 0.5794392523364486, 'r1_f1': 0.5414847161572052, 'pegasus_entailment': 0.5196079603396356, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4246575342465753, 'r1_recall': 0.49206349206349204, 'r1_f1': 0.45588235294117646, 'pegasus_entailment': 0.21510338020743802, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.784, 'r1_recall': 0.36981132075471695, 'r1_f1': 0.5025641025641026, 'pegasus_entailment': 0.38774944717685383, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 16, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4153846153846154, 'r1_recall': 0.421875, 'r1_f1': 0.4186046511627907, 'pegasus_entailment': 0.33093268796801567, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4367816091954023, 'r1_recall': 0.41304347826086957, 'r1_f1': 0.42458100558659223, 'pegasus_entailment': 0.28802012698724866, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.525, 'r1_recall': 0.63, 'r1_f1': 0.5727272727272728, 'pegasus_entailment': 0.5315403267741203, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 19}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5528455284552846, 'r1_recall': 0.4857142857142857, 'r1_f1': 0.5171102661596958, 'pegasus_entailment': 0.5712202663222948, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.582089552238806, 'r1_recall': 0.4148936170212766, 'r1_f1': 0.48447204968944096, 'pegasus_entailment': 0.2531167816370726, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.2125984251968504, 'r1_f1': 0.30857142857142855, 'pegasus_entailment': 0.8755706946055094, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 24, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37398373983739835, 'r1_recall': 0.647887323943662, 'r1_f1': 0.4742268041237113, 'pegasus_entailment': 0.5045976997353137, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.6382978723404256, 'r1_f1': 0.5172413793103449, 'pegasus_entailment': 0.37132522530321566, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5113636363636364, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.5232558139534884, 'pegasus_entailment': 0.3845200907671824, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37037037037037035, 'r1_recall': 0.6756756756756757, 'r1_f1': 0.478468899521531, 'pegasus_entailment': 0.31655394413974136, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.5669291338582678, 'pegasus_entailment': 0.2681337147951126, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36363636363636365, 'r1_recall': 0.625, 'r1_f1': 0.4597701149425288, 'pegasus_entailment': 0.2532407520338893, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.75, 'r1_recall': 0.4508670520231214, 'r1_f1': 0.5631768953068591, 'pegasus_entailment': 0.500275832414627, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7383177570093458, 'r1_recall': 0.47878787878787876, 'r1_f1': 0.5808823529411764, 'pegasus_entailment': 0.18498627468943596, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7142857142857143, 'r1_recall': 0.5612244897959183, 'r1_f1': 0.6285714285714286, 'pegasus_entailment': 0.40244511266549426, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5609756097560976, 'r1_recall': 0.12299465240641712, 'r1_f1': 0.2017543859649123, 'pegasus_entailment': 0.24831663817167282, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4880952380952381, 'r1_recall': 0.43157894736842106, 'r1_f1': 0.45810055865921784, 'pegasus_entailment': 0.5056429728865623, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49473684210526314, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.5628742514970059, 'pegasus_entailment': 0.4214203875511885, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4864864864864865, 'r1_recall': 0.32727272727272727, 'r1_f1': 0.391304347826087, 'pegasus_entailment': 0.8033253848552704, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24193548387096775, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.3614457831325301, 'pegasus_entailment': 0.32128898072987794, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5074626865671642, 'r1_recall': 0.4788732394366197, 'r1_f1': 0.4927536231884058, 'pegasus_entailment': 0.7767657041549683, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.4078947368421053, 'pegasus_entailment': 0.24570647033397108, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.3247863247863248, 'r1_f1': 0.39378238341968913, 'pegasus_entailment': 0.2409830091346521, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6302521008403361, 'r1_recall': 0.5725190839694656, 'r1_f1': 0.6, 'pegasus_entailment': 0.8497944623231888, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.589041095890411, 'r1_recall': 0.5119047619047619, 'r1_f1': 0.5477707006369427, 'pegasus_entailment': 0.4903647396713495, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 12}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6435643564356436, 'r1_recall': 0.3611111111111111, 'r1_f1': 0.4626334519572954, 'pegasus_entailment': 0.8977799713611603, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.5274725274725275, 'r1_f1': 0.4729064039408867, 'pegasus_entailment': 0.2593546151700947, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 15}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4264705882352941, 'r1_recall': 0.5272727272727272, 'r1_f1': 0.47154471544715443, 'pegasus_entailment': 0.6995634129270911, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6463414634146342, 'r1_recall': 0.5760869565217391, 'r1_f1': 0.6091954022988506, 'pegasus_entailment': 0.4071351333986968, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5866666666666667, 'r1_recall': 0.44, 'r1_f1': 0.5028571428571429, 'pegasus_entailment': 0.48848887253552675, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3888888888888889, 'r1_recall': 0.4057971014492754, 'r1_f1': 0.3971631205673759, 'pegasus_entailment': 0.5224158763885498, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5816326530612245, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.6162162162162163, 'pegasus_entailment': 0.5990487847477197, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6835443037974683, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.5966850828729282, 'pegasus_entailment': 0.5439601700151494, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.573170731707317, 'r1_recall': 0.5595238095238095, 'r1_f1': 0.5662650602409639, 'pegasus_entailment': 0.8950785398483276, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 18}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2549019607843137, 'r1_recall': 0.5, 'r1_f1': 0.33766233766233766, 'pegasus_entailment': 0.46063996118027717, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5615384615384615, 'r1_recall': 0.5104895104895105, 'r1_f1': 0.5347985347985347, 'pegasus_entailment': 0.322127893473953, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5365853658536586, 'r1_recall': 0.5057471264367817, 'r1_f1': 0.5207100591715976, 'pegasus_entailment': 0.9645131528377533, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 31, 'pegasus_smog': 25}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4897959183673469, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.46601941747572817, 'pegasus_entailment': 0.32837930725266534, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6063829787234043, 'r1_recall': 0.47107438016528924, 'r1_f1': 0.5302325581395348, 'pegasus_entailment': 0.5988380461931229, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.23076923076923078, 'r1_f1': 0.3243243243243243, 'pegasus_entailment': 0.8898718059062958, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 11, 'pegasus_smog': 15}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4752475247524752, 'r1_recall': 0.6857142857142857, 'r1_f1': 0.5614035087719298, 'pegasus_entailment': 0.4611890882253647, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4909090909090909, 'r1_recall': 0.375, 'r1_f1': 0.42519685039370075, 'pegasus_entailment': 0.6144258217148794, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4297520661157025, 'r1_recall': 0.5842696629213483, 'r1_f1': 0.4952380952380952, 'pegasus_entailment': 0.43418838347618777, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 15, 'pegasus_ari': 25, 'pegasus_smog': 17}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22448979591836735, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.3076923076923077, 'pegasus_entailment': 0.44074883429372375, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 13, 'pegasus_ari': 12, 'pegasus_smog': 13}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6551724137931034, 'r1_recall': 0.5533980582524272, 'r1_f1': 0.6, 'pegasus_entailment': 0.3662293450906873, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.14432989690721648, 'r1_recall': 0.4, 'r1_f1': 0.21212121212121207, 'pegasus_entailment': 0.3022824336294434, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.4827586206896552, 'pegasus_entailment': 0.9366413354873657, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 23, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3225806451612903, 'r1_recall': 0.7692307692307693, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.4895753338932991, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6379310344827587, 'r1_recall': 0.5, 'r1_f1': 0.5606060606060607, 'pegasus_entailment': 0.6354804734388987, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.6086956521739131, 'r1_f1': 0.6363636363636365, 'pegasus_entailment': 0.7016553059220314, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5042016806722689, 'r1_recall': 0.625, 'r1_f1': 0.5581395348837209, 'pegasus_entailment': 0.9331622918446859, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6261682242990654, 'r1_recall': 0.6146788990825688, 'r1_f1': 0.6203703703703702, 'pegasus_entailment': 0.8648368120193481, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7012987012987013, 'r1_recall': 0.391304347826087, 'r1_f1': 0.5023255813953489, 'pegasus_entailment': 0.2698058497044258, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8380952380952381, 'r1_recall': 0.25, 'r1_f1': 0.38512035010940915, 'pegasus_entailment': 0.5128796985372901, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.424, 'r1_recall': 0.4774774774774775, 'r1_f1': 0.4491525423728814, 'pegasus_entailment': 0.4073688543285243, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6746987951807228, 'r1_recall': 0.37583892617449666, 'r1_f1': 0.48275862068965525, 'pegasus_entailment': 0.5435478371800855, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7349397590361446, 'r1_recall': 0.40939597315436244, 'r1_f1': 0.5258620689655173, 'pegasus_entailment': 0.44174059107899666, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32, 'r1_recall': 0.32653061224489793, 'r1_f1': 0.3232323232323232, 'pegasus_entailment': 0.9052064418792725, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 13, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44761904761904764, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.5310734463276836, 'pegasus_entailment': 0.6588467806577682, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39655172413793105, 'r1_recall': 0.5679012345679012, 'r1_f1': 0.467005076142132, 'pegasus_entailment': 0.5701973494142294, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8378378378378378, 'r1_recall': 0.62, 'r1_f1': 0.7126436781609196, 'pegasus_entailment': 0.8976007997989655, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 19, 'pegasus_ari': 36, 'pegasus_smog': 25}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34513274336283184, 'r1_recall': 0.582089552238806, 'r1_f1': 0.4333333333333333, 'pegasus_entailment': 0.1518300213618204, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.717741935483871, 'r1_recall': 0.5174418604651163, 'r1_f1': 0.6013513513513514, 'pegasus_entailment': 0.650734084735935, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4457831325301205, 'r1_recall': 0.5, 'r1_f1': 0.4713375796178344, 'pegasus_entailment': 0.733650783697764, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5428571428571428, 'r1_recall': 0.4691358024691358, 'r1_f1': 0.5033112582781456, 'pegasus_entailment': 0.6449265076468388, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.646551724137931, 'r1_recall': 0.5319148936170213, 'r1_f1': 0.5836575875486382, 'pegasus_entailment': 0.1291865708772093, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3701923076923077, 'r1_recall': 0.5877862595419847, 'r1_f1': 0.4542772861356932, 'pegasus_entailment': 0.27673125080764294, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7058823529411765, 'r1_recall': 0.3380281690140845, 'r1_f1': 0.45714285714285713, 'pegasus_entailment': 0.4063834042754024, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 21}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6344086021505376, 'r1_recall': 0.6555555555555556, 'r1_f1': 0.644808743169399, 'pegasus_entailment': 0.8155909925699234, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.559322033898305, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.5689655172413793, 'pegasus_entailment': 0.4899814873933792, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.620253164556962, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.5648414985590778, 'pegasus_entailment': 0.3187099186082681, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6741573033707865, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.49792531120331956, 'pegasus_entailment': 0.7874514162540436, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.313953488372093, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.36241610738255037, 'pegasus_entailment': 0.6088342405855656, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5128205128205128, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.4624277456647398, 'pegasus_entailment': 0.7491100629170736, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7340425531914894, 'r1_recall': 0.43670886075949367, 'r1_f1': 0.5476190476190477, 'pegasus_entailment': 0.47331980150192976, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27710843373493976, 'r1_recall': 0.39655172413793105, 'r1_f1': 0.326241134751773, 'pegasus_entailment': 0.38975664461031556, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7692307692307693, 'r1_recall': 0.3314917127071823, 'r1_f1': 0.46332046332046334, 'pegasus_entailment': 0.6808736212551594, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5357142857142857, 'r1_recall': 0.31690140845070425, 'r1_f1': 0.39823008849557523, 'pegasus_entailment': 0.20682667405344546, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 13, 'pegasus_ari': 12, 'pegasus_smog': 11}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48484848484848486, 'r1_recall': 0.5052631578947369, 'r1_f1': 0.4948453608247423, 'pegasus_entailment': 0.18699574889615178, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6764705882352942, 'r1_recall': 0.4011627906976744, 'r1_f1': 0.5036496350364963, 'pegasus_entailment': 0.7458545863628387, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4807692307692308, 'r1_recall': 0.704225352112676, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.44807681627571583, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8571428571428571, 'r1_recall': 0.28846153846153844, 'r1_f1': 0.43165467625899273, 'pegasus_entailment': 0.10517142293974757, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5972222222222222, 'r1_recall': 0.46236559139784944, 'r1_f1': 0.5212121212121212, 'pegasus_entailment': 0.8259005770087242, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.68, 'r1_f1': 0.5257731958762887, 'pegasus_entailment': 0.31506797298789024, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6428571428571429, 'r1_recall': 0.5070422535211268, 'r1_f1': 0.5669291338582677, 'pegasus_entailment': 0.6545993636051813, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6086956521739131, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.5803108808290156, 'pegasus_entailment': 0.11026632506400347, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7941176470588235, 'r1_recall': 0.391304347826087, 'r1_f1': 0.5242718446601942, 'pegasus_entailment': 0.7438056270281473, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.5128205128205129, 'pegasus_entailment': 0.16541087557561696, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2717391304347826, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.32894736842105265, 'pegasus_entailment': 0.17491885212560496, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7364341085271318, 'r1_recall': 0.5337078651685393, 'r1_f1': 0.6188925081433224, 'pegasus_entailment': 0.443511168162028, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 22}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5172413793103449, 'r1_recall': 0.6164383561643836, 'r1_f1': 0.5624999999999999, 'pegasus_entailment': 0.23928909545065835, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5463917525773195, 'r1_recall': 0.6973684210526315, 'r1_f1': 0.6127167630057804, 'pegasus_entailment': 0.6560074491426349, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4369747899159664, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.49523809523809526, 'pegasus_entailment': 0.5227942019701004, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7361111111111112, 'r1_recall': 0.44166666666666665, 'r1_f1': 0.5520833333333333, 'pegasus_entailment': 0.2774569122120738, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.871244635193133, 'r1_recall': 0.28794326241134754, 'r1_f1': 0.4328358208955224, 'pegasus_entailment': 0.7379837152030733, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.528169014084507, 'r1_f1': 0.5725190839694656, 'pegasus_entailment': 0.5466727018356323, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8494623655913979, 'r1_recall': 0.43169398907103823, 'r1_f1': 0.5724637681159421, 'pegasus_entailment': 0.6834742486476898, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5416666666666666, 'r1_recall': 0.5591397849462365, 'r1_f1': 0.5502645502645503, 'pegasus_entailment': 0.8104002475738525, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6260869565217392, 'r1_recall': 0.6206896551724138, 'r1_f1': 0.6233766233766235, 'pegasus_entailment': 0.24366525728255511, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6231884057971014, 'r1_recall': 0.6615384615384615, 'r1_f1': 0.6417910447761194, 'pegasus_entailment': 0.30567327539029066, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6120689655172413, 'r1_recall': 0.45222929936305734, 'r1_f1': 0.5201465201465202, 'pegasus_entailment': 0.806418165564537, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29245283018867924, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.4025974025974026, 'pegasus_entailment': 0.3114537294954062, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5368421052631579, 'r1_recall': 0.5257731958762887, 'r1_f1': 0.5312500000000001, 'pegasus_entailment': 0.9617355465888977, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 33, 'pegasus_smog': 25}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2465753424657534, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.33333333333333326, 'pegasus_entailment': 0.30431996037562686, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5233644859813084, 'r1_recall': 0.5773195876288659, 'r1_f1': 0.5490196078431373, 'pegasus_entailment': 0.4914714887738228, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6309523809523809, 'r1_recall': 0.4690265486725664, 'r1_f1': 0.5380710659898477, 'pegasus_entailment': 0.7116579462599475, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6224489795918368, 'r1_recall': 0.45185185185185184, 'r1_f1': 0.5236051502145923, 'pegasus_entailment': 0.6703876396641135, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3157894736842105, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.40268456375838924, 'pegasus_entailment': 0.15304428292438388, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7058823529411765, 'r1_recall': 0.36, 'r1_f1': 0.4768211920529802, 'pegasus_entailment': 0.7677253186702728, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.06666666666666667
MEAN
0.564375831603636
MAX
0.9285714285714286
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.0410958904109589
MEAN
0.5031559286432151
MAX
0.8490566037735849
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.05084745762711865
MEAN
0.5099035607234765
MAX
0.7211538461538461
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.0005805986935835487
MEAN
0.4914886250206213
MAX
0.9811601837476095
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
9
MEAN
16
MAX
45
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
0
MEAN
17
MAX
25
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
10
MEAN
19
MAX
55
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
8
MEAN
18
MAX
28
{}
