Entered file!
Imports done!
*** RUN *** 
eval_1d2
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4084507042253521, 'r1_recall': 0.5272727272727272, 'r1_f1': 0.46031746031746035, 'pegasus_entailment': 0.7724915146827698, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6593406593406593, 'r1_recall': 0.3468208092485549, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.6576289087533951, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.4724409448818897, 'pegasus_entailment': 0.5390811171382666, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7349397590361446, 'r1_recall': 0.4728682170542636, 'r1_f1': 0.5754716981132076, 'pegasus_entailment': 0.4870912486997743, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7029702970297029, 'r1_recall': 0.40804597701149425, 'r1_f1': 0.5163636363636364, 'pegasus_entailment': 0.4424409940838814, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4178082191780822, 'r1_recall': 0.46923076923076923, 'r1_f1': 0.4420289855072464, 'pegasus_entailment': 0.3408838614821434, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16666666666666666, 'r1_recall': 0.375, 'r1_f1': 0.23076923076923078, 'pegasus_entailment': 0.28631126740947366, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22772277227722773, 'r1_recall': 0.7419354838709677, 'r1_f1': 0.3484848484848485, 'pegasus_entailment': 0.5533858048729599, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7415730337078652, 'r1_recall': 0.4429530201342282, 'r1_f1': 0.5546218487394958, 'pegasus_entailment': 0.47559825237840414, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6428571428571429, 'r1_recall': 0.5869565217391305, 'r1_f1': 0.6136363636363638, 'pegasus_entailment': 0.6252761855721474, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7027027027027027, 'r1_recall': 0.3466666666666667, 'r1_f1': 0.46428571428571436, 'pegasus_entailment': 0.516546007245779, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5892857142857143, 'r1_recall': 0.5546218487394958, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.889235277970632, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7887323943661971, 'r1_recall': 0.5233644859813084, 'r1_f1': 0.6292134831460674, 'pegasus_entailment': 0.7453572247177362, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5873015873015873, 'r1_recall': 0.42045454545454547, 'r1_f1': 0.4900662251655629, 'pegasus_entailment': 0.7580639521280924, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8701298701298701, 'r1_recall': 0.3489583333333333, 'r1_f1': 0.4981412639405205, 'pegasus_entailment': 0.655083179473877, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21052631578947367, 'r1_recall': 0.2033898305084746, 'r1_f1': 0.20689655172413796, 'pegasus_entailment': 0.6182583371798197, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4722222222222222, 'r1_recall': 0.3434343434343434, 'r1_f1': 0.39766081871345027, 'pegasus_entailment': 0.6825147171815237, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7951807228915663, 'r1_recall': 0.2214765100671141, 'r1_f1': 0.3464566929133859, 'pegasus_entailment': 0.38432972878217697, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6639344262295082, 'r1_recall': 0.5031055900621118, 'r1_f1': 0.5724381625441696, 'pegasus_entailment': 0.42666998878121376, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5494505494505495, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.5617977528089888, 'pegasus_entailment': 0.5804827511310577, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6194690265486725, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.47457627118644063, 'pegasus_entailment': 0.4292094074189663, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5693430656934306, 'r1_recall': 0.52, 'r1_f1': 0.5435540069686411, 'pegasus_entailment': 0.6179236595829328, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3963963963963964, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.4018264840182648, 'pegasus_entailment': 0.69203253587087, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 26}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6810344827586207, 'r1_recall': 0.5808823529411765, 'r1_f1': 0.626984126984127, 'pegasus_entailment': 0.5345117092132569, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3723404255319149, 'r1_recall': 0.7, 'r1_f1': 0.48611111111111105, 'pegasus_entailment': 0.6895427651082476, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6201117318435754, 'r1_recall': 0.5873015873015873, 'r1_f1': 0.6032608695652174, 'pegasus_entailment': 0.482532124966383, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5811965811965812, 'r1_recall': 0.49635036496350365, 'r1_f1': 0.5354330708661418, 'pegasus_entailment': 0.5321875838562846, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8620689655172413, 'r1_recall': 0.2798507462686567, 'r1_f1': 0.4225352112676056, 'pegasus_entailment': 0.6074931671222051, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42592592592592593, 'r1_recall': 0.3026315789473684, 'r1_f1': 0.3538461538461538, 'pegasus_entailment': 0.8554395437240601, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 12, 'pegasus_ari': 12, 'pegasus_smog': 11}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40404040404040403, 'r1_recall': 0.35398230088495575, 'r1_f1': 0.3773584905660377, 'pegasus_entailment': 0.5586630403995514, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 15, 'pegasus_ari': 30, 'pegasus_smog': 19}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4818181818181818, 'r1_recall': 0.6091954022988506, 'r1_f1': 0.5380710659898478, 'pegasus_entailment': 0.7331172972917557, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5688073394495413, 'r1_recall': 0.30845771144278605, 'r1_f1': 0.4, 'pegasus_entailment': 0.5389385223388672, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2708333333333333, 'r1_recall': 0.3786407766990291, 'r1_f1': 0.3157894736842105, 'pegasus_entailment': 0.6817261576652527, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6268656716417911, 'r1_recall': 0.4329896907216495, 'r1_f1': 0.5121951219512195, 'pegasus_entailment': 0.4571133553981781, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42016806722689076, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.49261083743842365, 'pegasus_entailment': 0.24310313016176224, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44, 'r1_recall': 0.5689655172413793, 'r1_f1': 0.49624060150375937, 'pegasus_entailment': 0.5995419124762217, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 16, 'pegasus_ari': 31, 'pegasus_smog': 22}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4824561403508772, 'r1_recall': 0.7971014492753623, 'r1_f1': 0.6010928961748634, 'pegasus_entailment': 0.3558418992906809, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3392857142857143, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.4222222222222223, 'pegasus_entailment': 0.7086844330769964, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2158273381294964, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.32608695652173914, 'pegasus_entailment': 0.5585499167442322, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5027027027027027, 'r1_recall': 0.5602409638554217, 'r1_f1': 0.5299145299145298, 'pegasus_entailment': 0.5907276675105095, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7029702970297029, 'r1_recall': 0.44375, 'r1_f1': 0.5440613026819924, 'pegasus_entailment': 0.6363784652203321, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5967741935483871, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.5323741007194245, 'pegasus_entailment': 0.6368355502684911, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5733333333333334, 'r1_recall': 0.589041095890411, 'r1_f1': 0.5810810810810811, 'pegasus_entailment': 0.4572935209920009, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8, 'r1_recall': 0.5203252032520326, 'r1_f1': 0.6305418719211824, 'pegasus_entailment': 0.8583741585413615, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3684210526315789, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.4046242774566474, 'pegasus_entailment': 0.6639065742492676, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4692737430167598, 'r1_recall': 0.56, 'r1_f1': 0.5106382978723405, 'pegasus_entailment': 0.47598588466644287, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.61, 'r1_recall': 0.5169491525423728, 'r1_f1': 0.5596330275229358, 'pegasus_entailment': 0.5543049506377429, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.7027027027027027, 'r1_f1': 0.5098039215686274, 'pegasus_entailment': 0.7242395494665418, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3708609271523179, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.47659574468085103, 'pegasus_entailment': 0.554472331268092, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3983739837398374, 'r1_recall': 0.47115384615384615, 'r1_f1': 0.4317180616740089, 'pegasus_entailment': 0.49961447566747663, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3082706766917293, 'r1_recall': 0.5540540540540541, 'r1_f1': 0.3961352657004831, 'pegasus_entailment': 0.5740776658058167, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24427480916030533, 'r1_recall': 0.6274509803921569, 'r1_f1': 0.3516483516483516, 'pegasus_entailment': 0.6189645236978928, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35537190082644626, 'r1_recall': 0.581081081081081, 'r1_f1': 0.441025641025641, 'pegasus_entailment': 0.4952914547175169, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.3107344632768362, 'r1_f1': 0.4119850187265918, 'pegasus_entailment': 0.2732164611419042, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6642857142857143, 'r1_recall': 0.5224719101123596, 'r1_f1': 0.5849056603773586, 'pegasus_entailment': 0.3126731589436531, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42727272727272725, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.5164835164835165, 'pegasus_entailment': 0.5515370219945908, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6196319018404908, 'r1_recall': 0.40239043824701193, 'r1_f1': 0.48792270531400955, 'pegasus_entailment': 0.5853856280446053, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39090909090909093, 'r1_recall': 0.671875, 'r1_f1': 0.4942528735632184, 'pegasus_entailment': 0.5879095159471035, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.6115702479338843, 'r1_f1': 0.6379310344827586, 'pegasus_entailment': 0.44853512570261955, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5918367346938775, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.30873304853836697, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42391304347826086, 'r1_recall': 0.4431818181818182, 'r1_f1': 0.4333333333333333, 'pegasus_entailment': 0.8287956515947977, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4358974358974359, 'r1_recall': 0.4722222222222222, 'r1_f1': 0.45333333333333337, 'pegasus_entailment': 0.3628084361553192, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5268817204301075, 'r1_recall': 0.2916666666666667, 'r1_f1': 0.3754789272030651, 'pegasus_entailment': 0.6636510118842125, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3894736842105263, 'r1_recall': 0.38144329896907214, 'r1_f1': 0.38541666666666663, 'pegasus_entailment': 0.6726335237423579, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30526315789473685, 'r1_recall': 0.6041666666666666, 'r1_f1': 0.4055944055944056, 'pegasus_entailment': 0.26413025458653766, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7254901960784313, 'r1_recall': 0.5826771653543307, 'r1_f1': 0.6462882096069869, 'pegasus_entailment': 0.5024576857686043, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31794871794871793, 'r1_recall': 0.5849056603773585, 'r1_f1': 0.4119601328903654, 'pegasus_entailment': 0.9247671961784363, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 24}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4097222222222222, 'r1_recall': 0.6145833333333334, 'r1_f1': 0.49166666666666664, 'pegasus_entailment': 0.3526182036846876, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6082474226804123, 'r1_recall': 0.5130434782608696, 'r1_f1': 0.5566037735849056, 'pegasus_entailment': 0.2738933617947623, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7230769230769231, 'r1_recall': 0.46078431372549017, 'r1_f1': 0.562874251497006, 'pegasus_entailment': 0.6452730645736059, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4327485380116959, 'r1_recall': 0.4457831325301205, 'r1_f1': 0.4391691394658754, 'pegasus_entailment': 0.6009947001934052, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2971014492753623, 'r1_recall': 0.6029411764705882, 'r1_f1': 0.3980582524271844, 'pegasus_entailment': 0.4221682965755463, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2972972972972973, 'r1_recall': 0.5, 'r1_f1': 0.3728813559322034, 'pegasus_entailment': 0.2889961926266551, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6638655462184874, 'r1_recall': 0.41578947368421054, 'r1_f1': 0.511326860841424, 'pegasus_entailment': 0.6325911656022072, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25280898876404495, 'r1_recall': 0.625, 'r1_f1': 0.36, 'pegasus_entailment': 0.24065336678177118, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.379746835443038, 'r1_recall': 0.7058823529411765, 'r1_f1': 0.49382716049382724, 'pegasus_entailment': 0.3533804578972714, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29357798165137616, 'r1_recall': 0.5, 'r1_f1': 0.36994219653179194, 'pegasus_entailment': 0.9561551511287689, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5818181818181818, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5981308411214953, 'pegasus_entailment': 0.49981139476100606, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5181818181818182, 'r1_recall': 0.6627906976744186, 'r1_f1': 0.5816326530612245, 'pegasus_entailment': 0.5459788478910923, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5223880597014925, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.5223880597014925, 'pegasus_entailment': 0.8432019501924515, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5180722891566265, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.5341614906832298, 'pegasus_entailment': 0.29760339111089706, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.71, 'r1_recall': 0.6893203883495146, 'r1_f1': 0.6995073891625615, 'pegasus_entailment': 0.3805353989203771, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.43243243243243246, 'pegasus_entailment': 0.44439053535461426, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.527027027027027, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.48447204968944096, 'pegasus_entailment': 0.9556332528591156, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5309734513274337, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.5853658536585366, 'pegasus_entailment': 0.4753687207897504, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3619047619047619, 'r1_recall': 0.4367816091954023, 'r1_f1': 0.39583333333333337, 'pegasus_entailment': 0.7331586927175522, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2716049382716049, 'r1_recall': 0.28205128205128205, 'r1_f1': 0.27672955974842767, 'pegasus_entailment': 0.42119892438252765, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2719298245614035, 'r1_recall': 0.6888888888888889, 'r1_f1': 0.389937106918239, 'pegasus_entailment': 0.8661567717790604, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7634408602150538, 'r1_recall': 0.34134615384615385, 'r1_f1': 0.4717607973421926, 'pegasus_entailment': 0.4846502721309662, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47191011235955055, 'r1_recall': 0.6, 'r1_f1': 0.5283018867924529, 'pegasus_entailment': 0.22750169615028426, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.5729166666666666, 'r1_f1': 0.5641025641025641, 'pegasus_entailment': 0.8042283654212952, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 33, 'pegasus_smog': 27}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425, 'r1_recall': 0.3805970149253731, 'r1_f1': 0.4015748031496063, 'pegasus_entailment': 0.42347376700490713, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 13}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31343283582089554, 'r1_recall': 0.5753424657534246, 'r1_f1': 0.4057971014492754, 'pegasus_entailment': 0.4569806487299502, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5094339622641509, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.484304932735426, 'pegasus_entailment': 0.44477460446069017, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.15463917525773196, 'r1_f1': 0.2307692307692308, 'pegasus_entailment': 0.9775312542915344, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4424778761061947, 'r1_recall': 0.5649717514124294, 'r1_f1': 0.4962779156327544, 'pegasus_entailment': 0.6841746978461742, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47572815533980584, 'r1_recall': 0.5051546391752577, 'r1_f1': 0.49, 'pegasus_entailment': 0.4672451963027318, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5306122448979592, 'r1_recall': 0.4126984126984127, 'r1_f1': 0.4642857142857143, 'pegasus_entailment': 0.7804876963297526, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3490566037735849, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.4327485380116959, 'pegasus_entailment': 0.6252047084271908, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3867924528301887, 'r1_recall': 0.36607142857142855, 'r1_f1': 0.37614678899082565, 'pegasus_entailment': 0.5853602214095494, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37681159420289856, 'r1_recall': 0.4262295081967213, 'r1_f1': 0.4, 'pegasus_entailment': 0.22727882644782463, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4639175257731959, 'r1_recall': 0.4787234042553192, 'r1_f1': 0.47120418848167545, 'pegasus_entailment': 0.7710384353995323, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5233644859813084, 'r1_recall': 0.48695652173913045, 'r1_f1': 0.5045045045045046, 'pegasus_entailment': 0.8629238605499268, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.547945205479452, 'r1_recall': 0.35714285714285715, 'r1_f1': 0.4324324324324324, 'pegasus_entailment': 0.7307569682598114, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3505747126436782, 'r1_recall': 0.7625, 'r1_f1': 0.4803149606299212, 'pegasus_entailment': 0.6758878976106644, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6710526315789473, 'r1_recall': 0.3953488372093023, 'r1_f1': 0.49756097560975604, 'pegasus_entailment': 0.44810023307800295, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49166666666666664, 'r1_recall': 0.5728155339805825, 'r1_f1': 0.5291479820627802, 'pegasus_entailment': 0.7231589108705521, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6979166666666666, 'r1_recall': 0.41875, 'r1_f1': 0.5234375, 'pegasus_entailment': 0.45678095519542694, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3790322580645161, 'r1_recall': 0.6266666666666667, 'r1_f1': 0.4723618090452261, 'pegasus_entailment': 0.6298145682667382, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34375, 'r1_recall': 0.55, 'r1_f1': 0.42307692307692313, 'pegasus_entailment': 0.6714966495831808, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.6040268456375839, 'pegasus_entailment': 0.927316352725029, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6020408163265306, 'r1_recall': 0.44360902255639095, 'r1_f1': 0.5108225108225107, 'pegasus_entailment': 0.22826587967574596, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7213114754098361, 'r1_recall': 0.5569620253164557, 'r1_f1': 0.6285714285714286, 'pegasus_entailment': 0.4885687637142837, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46956521739130436, 'r1_recall': 0.6067415730337079, 'r1_f1': 0.5294117647058824, 'pegasus_entailment': 0.6052300110459328, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.46923076923076923, 'r1_f1': 0.48412698412698413, 'pegasus_entailment': 0.6423696019919589, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851851851851851, 'r1_recall': 0.4438202247191011, 'r1_f1': 0.5047923322683706, 'pegasus_entailment': 0.6357724666595459, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7575757575757576, 'r1_recall': 0.42613636363636365, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.7660873532295227, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 19, 'pegasus_ari': 33, 'pegasus_smog': 23}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5841584158415841, 'r1_recall': 0.44029850746268656, 'r1_f1': 0.502127659574468, 'pegasus_entailment': 0.4436695694923401, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5092592592592593, 'r1_recall': 0.5851063829787234, 'r1_f1': 0.5445544554455446, 'pegasus_entailment': 0.5841448467690498, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6923076923076923, 'r1_recall': 0.3543307086614173, 'r1_f1': 0.46874999999999994, 'pegasus_entailment': 0.8002045949300131, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4766355140186916, 'r1_recall': 0.5795454545454546, 'r1_f1': 0.5230769230769231, 'pegasus_entailment': 0.7382049262523651, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5365853658536586, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.5546218487394958, 'pegasus_entailment': 0.7433254917462667, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 19}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39814814814814814, 'r1_recall': 0.5657894736842105, 'r1_f1': 0.46739130434782605, 'pegasus_entailment': 0.6243456929922104, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23232323232323232, 'r1_recall': 0.5348837209302325, 'r1_f1': 0.32394366197183094, 'pegasus_entailment': 0.45122377946972847, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7555555555555555, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.6732673267326731, 'pegasus_entailment': 0.9478484193483988, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5419847328244275, 'r1_recall': 0.5419847328244275, 'r1_f1': 0.5419847328244275, 'pegasus_entailment': 0.4712727442383766, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26, 'r1_recall': 0.65, 'r1_f1': 0.37142857142857144, 'pegasus_entailment': 0.47108266362920403, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.552, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.5702479338842975, 'pegasus_entailment': 0.9169735511144003, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 15, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5035460992907801, 'r1_recall': 0.6120689655172413, 'r1_f1': 0.5525291828793774, 'pegasus_entailment': 0.5796971842646599, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5256410256410257, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.5985401459854015, 'pegasus_entailment': 0.5310210337241491, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6834532374100719, 'r1_recall': 0.5026455026455027, 'r1_f1': 0.5792682926829269, 'pegasus_entailment': 0.1277024628361687, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.5950413223140496, 'r1_f1': 0.5255474452554746, 'pegasus_entailment': 0.9823962251345316, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 25}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.578125, 'r1_recall': 0.4774193548387097, 'r1_f1': 0.5229681978798586, 'pegasus_entailment': 0.8744952082633972, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6583333333333333, 'r1_recall': 0.48466257668711654, 'r1_f1': 0.5583038869257951, 'pegasus_entailment': 0.6053387373685837, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.475, 'r1_recall': 0.5643564356435643, 'r1_f1': 0.5158371040723981, 'pegasus_entailment': 0.5533628523349762, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4198895027624309, 'r1_recall': 0.628099173553719, 'r1_f1': 0.5033112582781457, 'pegasus_entailment': 0.7204168289899826, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5510204081632653, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.5654450261780105, 'pegasus_entailment': 0.6203324645757675, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6530612244897959, 'r1_recall': 0.48120300751879697, 'r1_f1': 0.5541125541125541, 'pegasus_entailment': 0.7693269610404968, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7019230769230769, 'r1_recall': 0.3945945945945946, 'r1_f1': 0.5051903114186851, 'pegasus_entailment': 0.6054031848907471, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3644859813084112, 'r1_recall': 0.6724137931034483, 'r1_f1': 0.4727272727272727, 'pegasus_entailment': 0.5255739882588386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39473684210526316, 'r1_recall': 0.5113636363636364, 'r1_f1': 0.44554455445544555, 'pegasus_entailment': 0.46424571610987186, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4782608695652174, 'r1_recall': 0.4731182795698925, 'r1_f1': 0.4756756756756757, 'pegasus_entailment': 0.3810370812813441, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53, 'r1_recall': 0.4690265486725664, 'r1_f1': 0.4976525821596244, 'pegasus_entailment': 0.7582129836082458, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5098039215686274, 'r1_recall': 0.65, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.6757595837116241, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.5436893203883496, 'pegasus_entailment': 0.5713955760002136, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6201550387596899, 'r1_recall': 0.3827751196172249, 'r1_f1': 0.47337278106508873, 'pegasus_entailment': 0.6067440658807755, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.660377358490566, 'r1_recall': 0.3867403314917127, 'r1_f1': 0.48780487804878053, 'pegasus_entailment': 0.44900578757127124, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3717948717948718, 'r1_recall': 0.4915254237288136, 'r1_f1': 0.4233576642335766, 'pegasus_entailment': 0.813797652721405, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7981651376146789, 'r1_recall': 0.5370370370370371, 'r1_f1': 0.6420664206642067, 'pegasus_entailment': 0.4584514629095793, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3923076923076923, 'r1_recall': 0.6219512195121951, 'r1_f1': 0.48113207547169806, 'pegasus_entailment': 0.37593673914670944, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43037974683544306, 'r1_recall': 0.3541666666666667, 'r1_f1': 0.3885714285714286, 'pegasus_entailment': 0.5583342090249062, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44881889763779526, 'r1_recall': 0.6195652173913043, 'r1_f1': 0.5205479452054794, 'pegasus_entailment': 0.4178726593963802, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7766990291262136, 'r1_recall': 0.41237113402061853, 'r1_f1': 0.5387205387205387, 'pegasus_entailment': 0.45479800179600716, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5370370370370371, 'r1_recall': 0.3493975903614458, 'r1_f1': 0.4233576642335767, 'pegasus_entailment': 0.41829054057598114, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33064516129032256, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.44808743169398907, 'pegasus_entailment': 0.7514328161875407, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6271186440677966, 'r1_recall': 0.4277456647398844, 'r1_f1': 0.5085910652920962, 'pegasus_entailment': 0.4022599846124649, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4626865671641791, 'r1_recall': 0.38271604938271603, 'r1_f1': 0.41891891891891897, 'pegasus_entailment': 0.6580566229919592, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5034965034965035, 'r1_recall': 0.48322147651006714, 'r1_f1': 0.49315068493150693, 'pegasus_entailment': 0.8055967092514038, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5747126436781609, 'r1_recall': 0.5376344086021505, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.27868172415765, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.33540372670807456, 'r1_f1': 0.4202334630350195, 'pegasus_entailment': 0.2320029828697443, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21739130434782608, 'r1_recall': 0.2631578947368421, 'r1_f1': 0.23809523809523808, 'pegasus_entailment': 0.9635570049285889, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 24, 'pegasus_ari': 35, 'pegasus_smog': 28}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5728155339805825, 'r1_recall': 0.5462962962962963, 'r1_f1': 0.5592417061611374, 'pegasus_entailment': 0.7289799526333809, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37572254335260113, 'r1_recall': 0.6310679611650486, 'r1_f1': 0.47101449275362317, 'pegasus_entailment': 0.869426429271698, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.654320987654321, 'r1_recall': 0.32515337423312884, 'r1_f1': 0.43442622950819676, 'pegasus_entailment': 0.6885570958256721, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5742574257425742, 'r1_recall': 0.5321100917431193, 'r1_f1': 0.5523809523809524, 'pegasus_entailment': 0.5509080678224564, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48863636363636365, 'r1_recall': 0.48863636363636365, 'r1_f1': 0.48863636363636365, 'pegasus_entailment': 0.4277232617139816, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43010752688172044, 'r1_recall': 0.26666666666666666, 'r1_f1': 0.3292181069958848, 'pegasus_entailment': 0.8380877176920573, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5089820359281437, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.5537459283387622, 'pegasus_entailment': 0.5460172792275747, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5080645161290323, 'r1_recall': 0.4228187919463087, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.6134821996092796, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48598130841121495, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5252525252525252, 'pegasus_entailment': 0.5923701326052347, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3805970149253731, 'r1_recall': 0.6623376623376623, 'r1_f1': 0.4834123222748815, 'pegasus_entailment': 0.5072733014822006, 'pegasus_flesch_kincaid': 33, 'pegasus_coleman_liau': 19, 'pegasus_ari': 41, 'pegasus_smog': 25}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39166666666666666, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.48704663212435234, 'pegasus_entailment': 0.620512424968183, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6896551724137931, 'r1_recall': 0.16304347826086957, 'r1_f1': 0.26373626373626374, 'pegasus_entailment': 0.5534291565418243, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.4909090909090909, 'r1_f1': 0.5167464114832535, 'pegasus_entailment': 0.6389245775838693, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5402298850574713, 'r1_recall': 0.3790322580645161, 'r1_f1': 0.44549763033175355, 'pegasus_entailment': 0.6536457240581512, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47468354430379744, 'r1_recall': 0.625, 'r1_f1': 0.539568345323741, 'pegasus_entailment': 0.5750852167606354, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7865168539325843, 'r1_recall': 0.2978723404255319, 'r1_f1': 0.4320987654320988, 'pegasus_entailment': 0.6572804339230061, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5100671140939598, 'r1_recall': 0.5, 'r1_f1': 0.5049833887043189, 'pegasus_entailment': 0.27998129092156887, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3089887640449438, 'r1_recall': 0.6395348837209303, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.528675944233934, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34408602150537637, 'r1_recall': 0.4266666666666667, 'r1_f1': 0.38095238095238104, 'pegasus_entailment': 0.6376828327775002, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41904761904761906, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.4512820512820513, 'pegasus_entailment': 0.9024880528450012, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6708860759493671, 'r1_recall': 0.3231707317073171, 'r1_f1': 0.43621399176954734, 'pegasus_entailment': 0.7083357274532318, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7829457364341085, 'r1_recall': 0.3519163763066202, 'r1_f1': 0.4855769230769231, 'pegasus_entailment': 0.41632277199200224, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6847826086956522, 'r1_recall': 0.35195530726256985, 'r1_f1': 0.46494464944649444, 'pegasus_entailment': 0.49718244187533855, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5752212389380531, 'r1_recall': 0.5701754385964912, 'r1_f1': 0.5726872246696035, 'pegasus_entailment': 0.6546744108200073, 'pegasus_flesch_kincaid': 52, 'pegasus_coleman_liau': 19, 'pegasus_ari': 64, 'pegasus_smog': 34}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6707317073170732, 'r1_recall': 0.4230769230769231, 'r1_f1': 0.5188679245283019, 'pegasus_entailment': 0.6752978463967642, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4661016949152542, 'r1_recall': 0.5288461538461539, 'r1_f1': 0.4954954954954955, 'pegasus_entailment': 0.3866795152425766, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3221476510067114, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.41201716738197425, 'pegasus_entailment': 0.9566343665122986, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6759259259259259, 'r1_recall': 0.4506172839506173, 'r1_f1': 0.5407407407407409, 'pegasus_entailment': 0.7148935596148173, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5897435897435898, 'r1_recall': 0.5974025974025974, 'r1_f1': 0.5935483870967742, 'pegasus_entailment': 0.4566979742376134, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.552, 'pegasus_entailment': 0.42761924816295505, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6133333333333333, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.6133333333333333, 'pegasus_entailment': 0.4594133794307709, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5688073394495413, 'r1_recall': 0.512396694214876, 'r1_f1': 0.5391304347826087, 'pegasus_entailment': 0.7448178589344024, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8082191780821918, 'r1_recall': 0.5315315315315315, 'r1_f1': 0.641304347826087, 'pegasus_entailment': 0.5455225699891647, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851063829787234, 'r1_recall': 0.3374233128834356, 'r1_f1': 0.42801556420233466, 'pegasus_entailment': 0.18151729305585226, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5779816513761468, 'r1_recall': 0.35795454545454547, 'r1_f1': 0.4421052631578947, 'pegasus_entailment': 0.3454425409436226, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5588235294117647, 'r1_recall': 0.7125, 'r1_f1': 0.6263736263736264, 'pegasus_entailment': 0.7891814609368643, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2636363636363636, 'r1_recall': 0.48333333333333334, 'r1_f1': 0.34117647058823525, 'pegasus_entailment': 0.6165966217716535, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 26}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4375, 'pegasus_entailment': 0.4352775923907757, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4426229508196721, 'r1_recall': 0.5510204081632653, 'r1_f1': 0.49090909090909085, 'pegasus_entailment': 0.33541417121887207, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5531914893617021, 'r1_recall': 0.6, 'r1_f1': 0.5756457564575646, 'pegasus_entailment': 0.617013406008482, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3047619047619048, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.42384105960264906, 'pegasus_entailment': 0.9890740911165873, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.675, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.5567010309278351, 'pegasus_entailment': 0.8306477467219034, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4672131147540984, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.4892703862660944, 'pegasus_entailment': 0.5148066524416208, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6938775510204082, 'r1_recall': 0.4657534246575342, 'r1_f1': 0.5573770491803278, 'pegasus_entailment': 0.4899275004863739, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.611764705882353, 'r1_recall': 0.6341463414634146, 'r1_f1': 0.6227544910179641, 'pegasus_entailment': 0.6797349055608114, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4621212121212121, 'r1_recall': 0.6931818181818182, 'r1_f1': 0.5545454545454546, 'pegasus_entailment': 0.7526635527610779, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5446428571428571, 'r1_recall': 0.6039603960396039, 'r1_f1': 0.5727699530516431, 'pegasus_entailment': 0.17453824058175088, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.472, 'r1_recall': 0.5462962962962963, 'r1_f1': 0.5064377682403434, 'pegasus_entailment': 0.2525451338539521, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2840909090909091, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.36764705882352944, 'pegasus_entailment': 0.27770412736572325, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5280898876404494, 'r1_recall': 0.47474747474747475, 'r1_f1': 0.5, 'pegasus_entailment': 0.584257165590922, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.56, 'r1_recall': 0.35443037974683544, 'r1_f1': 0.434108527131783, 'pegasus_entailment': 0.47310803333918255, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5140845070422535, 'r1_recall': 0.4620253164556962, 'r1_f1': 0.4866666666666667, 'pegasus_entailment': 0.48535676300525665, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5680473372781065, 'r1_recall': 0.49740932642487046, 'r1_f1': 0.5303867403314917, 'pegasus_entailment': 0.31199143330256146, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6885245901639344, 'r1_recall': 0.4, 'r1_f1': 0.5060240963855422, 'pegasus_entailment': 0.6027634143829346, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45569620253164556, 'r1_recall': 0.576, 'r1_f1': 0.5088339222614842, 'pegasus_entailment': 0.6013013064861298, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3409090909090909, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.3208227555733174, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3153153153153153, 'r1_recall': 0.5737704918032787, 'r1_f1': 0.40697674418604646, 'pegasus_entailment': 0.2494944843929261, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4657534246575342, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.5037037037037037, 'pegasus_entailment': 0.9451161424318949, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2702702702702703, 'r1_recall': 0.5084745762711864, 'r1_f1': 0.3529411764705882, 'pegasus_entailment': 0.2992536723613739, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4358974358974359, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.44155844155844154, 'pegasus_entailment': 0.3517903983592987, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4431818181818182, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.41711229946524064, 'pegasus_entailment': 0.6101228147745132, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2815533980582524, 'r1_recall': 0.725, 'r1_f1': 0.40559440559440557, 'pegasus_entailment': 0.6760659019152323, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4371584699453552, 'r1_recall': 0.4624277456647399, 'r1_f1': 0.44943820224719094, 'pegasus_entailment': 0.5536630700031916, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 25}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4351851851851852, 'r1_recall': 0.5875, 'r1_f1': 0.5, 'pegasus_entailment': 0.5107136726379394, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6224489795918368, 'r1_recall': 0.34269662921348315, 'r1_f1': 0.44202898550724645, 'pegasus_entailment': 0.5645067654550076, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7228915662650602, 'r1_recall': 0.37267080745341613, 'r1_f1': 0.49180327868852464, 'pegasus_entailment': 0.28952719643712044, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6076923076923076, 'r1_recall': 0.5895522388059702, 'r1_f1': 0.5984848484848485, 'pegasus_entailment': 0.20588585610191026, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 31, 'pegasus_smog': 26}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6875, 'r1_recall': 0.22633744855967078, 'r1_f1': 0.3405572755417957, 'pegasus_entailment': 0.5585938592751821, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4326923076923077, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.4838709677419355, 'pegasus_entailment': 0.6324315816164017, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 16, 'pegasus_ari': 31, 'pegasus_smog': 20}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49523809523809526, 'r1_recall': 0.34210526315789475, 'r1_f1': 0.4046692607003891, 'pegasus_entailment': 0.48075965978205204, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3211009174311927, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.3867403314917127, 'pegasus_entailment': 0.666877289613088, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5877862595419847, 'r1_recall': 0.3452914798206278, 'r1_f1': 0.4350282485875706, 'pegasus_entailment': 0.5783930346369743, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35714285714285715, 'r1_recall': 0.30973451327433627, 'r1_f1': 0.33175355450236965, 'pegasus_entailment': 0.316874402264754, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3402061855670103, 'r1_recall': 0.717391304347826, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.40247253281995654, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7555555555555555, 'r1_recall': 0.3756906077348066, 'r1_f1': 0.5018450184501846, 'pegasus_entailment': 0.330894747748971, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.686046511627907, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.4486692015209125, 'pegasus_entailment': 0.3104033973067999, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4236111111111111, 'r1_recall': 0.6354166666666666, 'r1_f1': 0.5083333333333334, 'pegasus_entailment': 0.6399297515551249, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6176470588235294, 'r1_recall': 0.43448275862068964, 'r1_f1': 0.5101214574898786, 'pegasus_entailment': 0.8030675768852233, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1450381679389313, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.23899371069182387, 'pegasus_entailment': 0.17203863114118575, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19310344827586207, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.27586206896551724, 'pegasus_entailment': 0.6303148925304413, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.68, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.6210045662100457, 'pegasus_entailment': 0.39496460537581396, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30952380952380953, 'r1_recall': 0.5492957746478874, 'r1_f1': 0.39593908629441626, 'pegasus_entailment': 0.3894849956035614, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.248, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.34444444444444444, 'pegasus_entailment': 0.7146193504333496, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3617021276595745, 'r1_recall': 0.41975308641975306, 'r1_f1': 0.38857142857142857, 'pegasus_entailment': 0.3070040214806795, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.611764705882353, 'r1_recall': 0.6419753086419753, 'r1_f1': 0.6265060240963856, 'pegasus_entailment': 0.8770049413045248, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5063291139240507, 'r1_recall': 0.4819277108433735, 'r1_f1': 0.49382716049382713, 'pegasus_entailment': 0.259297750541009, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5652173913043478, 'r1_recall': 0.46846846846846846, 'r1_f1': 0.5123152709359605, 'pegasus_entailment': 0.3363981540314853, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7961165048543689, 'r1_recall': 0.24404761904761904, 'r1_f1': 0.3735763097949886, 'pegasus_entailment': 0.5112008690834046, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.3108108108108108, 'r1_f1': 0.4207317073170732, 'pegasus_entailment': 0.4609153997153044, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47674418604651164, 'r1_recall': 0.5256410256410257, 'r1_f1': 0.5, 'pegasus_entailment': 0.5324264243245125, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5523809523809524, 'r1_recall': 0.5576923076923077, 'r1_f1': 0.5550239234449761, 'pegasus_entailment': 0.43314006303747493, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21965317919075145, 'r1_recall': 0.5205479452054794, 'r1_f1': 0.30894308943089427, 'pegasus_entailment': 0.5216895192861557, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3228346456692913, 'r1_recall': 0.6307692307692307, 'r1_f1': 0.4270833333333333, 'pegasus_entailment': 0.2945159201820691, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5921052631578947, 'r1_recall': 0.625, 'r1_f1': 0.6081081081081081, 'pegasus_entailment': 0.5674796203772227, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5487804878048781, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.5521472392638037, 'pegasus_entailment': 0.8695265799760818, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4375, 'r1_recall': 0.5526315789473685, 'r1_f1': 0.4883720930232558, 'pegasus_entailment': 0.8834349115689596, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42718446601941745, 'r1_recall': 0.5238095238095238, 'r1_f1': 0.4705882352941177, 'pegasus_entailment': 0.2228782958118245, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7254901960784313, 'r1_recall': 0.4713375796178344, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.7784717231988907, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6886792452830188, 'r1_recall': 0.5069444444444444, 'r1_f1': 0.584, 'pegasus_entailment': 0.5282692015171051, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3411764705882353, 'r1_recall': 0.30851063829787234, 'r1_f1': 0.32402234636871513, 'pegasus_entailment': 0.6005418747663498, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6483516483516484, 'r1_recall': 0.6178010471204188, 'r1_f1': 0.6327077747989276, 'pegasus_entailment': 0.4432292928298314, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3465346534653465, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.9816618164380392, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4492753623188406, 'r1_recall': 0.37349397590361444, 'r1_f1': 0.40789473684210525, 'pegasus_entailment': 0.9005027562379837, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7166666666666667, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.6231884057971016, 'pegasus_entailment': 0.6865303814411163, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 8}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44696969696969696, 'r1_recall': 0.7283950617283951, 'r1_f1': 0.5539906103286385, 'pegasus_entailment': 0.4352083284407854, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5310344827586206, 'r1_recall': 0.5620437956204379, 'r1_f1': 0.5460992907801417, 'pegasus_entailment': 0.7303782254457474, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3076923076923077, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.33333333333333337, 'pegasus_entailment': 0.6575305623312792, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32051282051282054, 'r1_recall': 0.423728813559322, 'r1_f1': 0.3649635036496351, 'pegasus_entailment': 0.46847159415483475, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.4701492537313433, 'r1_f1': 0.4980237154150198, 'pegasus_entailment': 0.5008024135604501, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.358974358974359, 'r1_f1': 0.4534412955465587, 'pegasus_entailment': 0.2949881562963128, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43119266055045874, 'r1_recall': 0.7230769230769231, 'r1_f1': 0.5402298850574713, 'pegasus_entailment': 0.7357929050922394, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4326923076923077, 'r1_recall': 0.5113636363636364, 'r1_f1': 0.46875, 'pegasus_entailment': 0.5529967024922371, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4946236559139785, 'r1_recall': 0.5476190476190477, 'r1_f1': 0.5197740112994351, 'pegasus_entailment': 0.6758133098483086, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3977272727272727, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.4242424242424242, 'pegasus_entailment': 0.5415948955342174, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33858267716535434, 'r1_recall': 0.5375, 'r1_f1': 0.41545893719806765, 'pegasus_entailment': 0.4993847645819187, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5035971223021583, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.4745762711864407, 'pegasus_entailment': 0.45366304895530146, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5063291139240507, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5161290322580646, 'pegasus_entailment': 0.25480619817972183, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3708609271523179, 'r1_recall': 0.6588235294117647, 'r1_f1': 0.47457627118644063, 'pegasus_entailment': 0.46662308648228645, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6730769230769231, 'r1_recall': 0.5343511450381679, 'r1_f1': 0.5957446808510639, 'pegasus_entailment': 0.45500591211020947, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4642857142857143, 'r1_recall': 0.36792452830188677, 'r1_f1': 0.4105263157894737, 'pegasus_entailment': 0.2987853630911559, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5939849624060151, 'r1_recall': 0.43169398907103823, 'r1_f1': 0.5, 'pegasus_entailment': 0.8131778538227081, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4880952380952381, 'r1_recall': 0.5394736842105263, 'r1_f1': 0.5125, 'pegasus_entailment': 0.34397818757376325, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5121951219512195, 'r1_recall': 0.45652173913043476, 'r1_f1': 0.48275862068965514, 'pegasus_entailment': 0.4509930331259966, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7520661157024794, 'r1_recall': 0.4212962962962963, 'r1_f1': 0.5400593471810089, 'pegasus_entailment': 0.2496687311679125, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5949367088607594, 'r1_recall': 0.46534653465346537, 'r1_f1': 0.5222222222222221, 'pegasus_entailment': 0.06338276776174705, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5119047619047619, 'r1_recall': 0.4387755102040816, 'r1_f1': 0.4725274725274725, 'pegasus_entailment': 0.18773385975509882, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5161290322580646, 'pegasus_entailment': 0.6153527131925026, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6990291262135923, 'r1_recall': 0.5413533834586466, 'r1_f1': 0.6101694915254237, 'pegasus_entailment': 0.2906938042433467, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.4, 'r1_f1': 0.4675324675324675, 'pegasus_entailment': 0.2651624729235967, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.3652173913043478, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.49146442785859107, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44329896907216493, 'r1_recall': 0.38738738738738737, 'r1_f1': 0.41346153846153844, 'pegasus_entailment': 0.696148137251536, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7528089887640449, 'r1_recall': 0.4855072463768116, 'r1_f1': 0.5903083700440528, 'pegasus_entailment': 0.6719439923763275, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21782178217821782, 'r1_recall': 0.44, 'r1_f1': 0.2913907284768212, 'pegasus_entailment': 0.32551082223653793, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26573426573426573, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.38190954773869346, 'pegasus_entailment': 0.25152797531336546, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22580645161290322, 'r1_recall': 0.2978723404255319, 'r1_f1': 0.2568807339449541, 'pegasus_entailment': 0.284672349691391, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4411764705882353, 'r1_recall': 0.4225352112676056, 'r1_f1': 0.43165467625899284, 'pegasus_entailment': 0.5144440829753876, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.3005464480874317, 'r1_f1': 0.40293040293040294, 'pegasus_entailment': 0.2458620723336935, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.514018691588785, 'r1_recall': 0.40145985401459855, 'r1_f1': 0.4508196721311475, 'pegasus_entailment': 0.8132250209649404, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 17}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6022727272727273, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.5921787709497207, 'pegasus_entailment': 0.7983407527208328, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5210084033613446, 'r1_recall': 0.46616541353383456, 'r1_f1': 0.49206349206349204, 'pegasus_entailment': 0.3848346810787916, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48333333333333334, 'r1_recall': 0.5304878048780488, 'r1_f1': 0.5058139534883721, 'pegasus_entailment': 0.2958300940692425, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6846153846153846, 'r1_recall': 0.4427860696517413, 'r1_f1': 0.5377643504531721, 'pegasus_entailment': 0.4883404541760683, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.3, 'r1_f1': 0.34285714285714286, 'pegasus_entailment': 0.5599430501461029, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.5625, 'r1_f1': 0.5590062111801242, 'pegasus_entailment': 0.5671789787709713, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33663366336633666, 'r1_recall': 0.4146341463414634, 'r1_f1': 0.37158469945355194, 'pegasus_entailment': 0.8419028123219808, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26666666666666666, 'r1_recall': 0.5, 'r1_f1': 0.3478260869565218, 'pegasus_entailment': 0.28081218898296356, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2857142857142857, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.3571428571428571, 'pegasus_entailment': 0.6898664496839046, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19607843137254902, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.29411764705882354, 'pegasus_entailment': 0.43534406144171955, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.375, 'r1_recall': 0.4342105263157895, 'r1_f1': 0.4024390243902439, 'pegasus_entailment': 0.5767182894051075, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6451612903225806, 'r1_recall': 0.32608695652173914, 'r1_f1': 0.4332129963898917, 'pegasus_entailment': 0.8045540452003479, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3402061855670103, 'r1_recall': 0.4925373134328358, 'r1_f1': 0.4024390243902439, 'pegasus_entailment': 0.34251442179083824, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6888888888888889, 'r1_recall': 0.36904761904761907, 'r1_f1': 0.4806201550387597, 'pegasus_entailment': 0.4161246486008167, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6320754716981132, 'r1_recall': 0.5075757575757576, 'r1_f1': 0.5630252100840336, 'pegasus_entailment': 0.32203347608447075, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7844827586206896, 'r1_recall': 0.5759493670886076, 'r1_f1': 0.6642335766423357, 'pegasus_entailment': 0.5782024264335632, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7647058823529411, 'r1_recall': 0.2195945945945946, 'r1_f1': 0.3412073490813648, 'pegasus_entailment': 0.43408970534801483, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.7272727272727273, 'r1_f1': 0.54421768707483, 'pegasus_entailment': 0.4875956103205681, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6481481481481481, 'r1_recall': 0.3553299492385787, 'r1_f1': 0.459016393442623, 'pegasus_entailment': 0.1930928498506546, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45588235294117646, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.484375, 'pegasus_entailment': 0.6408371962606907, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4961832061068702, 'r1_recall': 0.5284552845528455, 'r1_f1': 0.5118110236220472, 'pegasus_entailment': 0.7989411801099777, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5523809523809524, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5523809523809524, 'pegasus_entailment': 0.5678386330604553, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.775, 'r1_recall': 0.4732824427480916, 'r1_f1': 0.5876777251184834, 'pegasus_entailment': 0.4727054998278618, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3140495867768595, 'r1_recall': 0.5671641791044776, 'r1_f1': 0.4042553191489362, 'pegasus_entailment': 0.4419554229825735, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2894736842105263, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.3859649122807018, 'pegasus_entailment': 0.4621002972126007, 'pegasus_flesch_kincaid': 32, 'pegasus_coleman_liau': 21, 'pegasus_ari': 38, 'pegasus_smog': 26}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25806451612903225, 'r1_recall': 0.7017543859649122, 'r1_f1': 0.3773584905660377, 'pegasus_entailment': 0.616279861330986, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.5625, 'r1_f1': 0.5877551020408163, 'pegasus_entailment': 0.3008006915450096, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7818181818181819, 'r1_recall': 0.48314606741573035, 'r1_f1': 0.5972222222222223, 'pegasus_entailment': 0.55433922012647, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6333333333333333, 'r1_recall': 0.4662576687116564, 'r1_f1': 0.5371024734982333, 'pegasus_entailment': 0.726044887304306, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6415094339622641, 'r1_recall': 0.35233160621761656, 'r1_f1': 0.45484949832775917, 'pegasus_entailment': 0.6340672224760056, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4909090909090909, 'r1_recall': 0.5346534653465347, 'r1_f1': 0.5118483412322276, 'pegasus_entailment': 0.4082975375155608, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35947712418300654, 'r1_recall': 0.6547619047619048, 'r1_f1': 0.46413502109704646, 'pegasus_entailment': 0.4123345666698047, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.5, 'r1_f1': 0.4736842105263158, 'pegasus_entailment': 0.6782827149145305, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3380281690140845, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.39344262295081966, 'pegasus_entailment': 0.14754684269428253, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6267605633802817, 'r1_recall': 0.6013513513513513, 'r1_f1': 0.6137931034482759, 'pegasus_entailment': 0.5645301242669424, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.4580152671755725, 'r1_f1': 0.5286343612334802, 'pegasus_entailment': 0.560332209803164, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7121212121212122, 'r1_recall': 0.3983050847457627, 'r1_f1': 0.5108695652173914, 'pegasus_entailment': 0.9548970858256022, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7777777777777778, 'r1_recall': 0.3769230769230769, 'r1_f1': 0.5077720207253886, 'pegasus_entailment': 0.6044277374943098, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5408163265306123, 'r1_recall': 0.44537815126050423, 'r1_f1': 0.4884792626728111, 'pegasus_entailment': 0.4587773655851682, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7346938775510204, 'r1_recall': 0.5, 'r1_f1': 0.5950413223140496, 'pegasus_entailment': 0.7153411044273525, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5957446808510638, 'r1_recall': 0.6222222222222222, 'r1_f1': 0.608695652173913, 'pegasus_entailment': 0.3169755460694432, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45161290322580644, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.43579766536964976, 'pegasus_entailment': 0.3381445140577853, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6589147286821705, 'r1_recall': 0.4009433962264151, 'r1_f1': 0.4985337243401759, 'pegasus_entailment': 0.6678925057252248, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33766233766233766, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.3880597014925373, 'pegasus_entailment': 0.4067276641726494, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46511627906976744, 'r1_recall': 0.46875, 'r1_f1': 0.4669260700389105, 'pegasus_entailment': 0.45340456403791907, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34579439252336447, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.45121951219512196, 'pegasus_entailment': 0.5727633386850357, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7310924369747899, 'r1_recall': 0.45549738219895286, 'r1_f1': 0.5612903225806452, 'pegasus_entailment': 0.6220632692178091, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6333333333333333, 'r1_recall': 0.5170068027210885, 'r1_f1': 0.5692883895131086, 'pegasus_entailment': 0.38553042709827423, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45588235294117646, 'r1_recall': 0.4025974025974026, 'r1_f1': 0.42758620689655175, 'pegasus_entailment': 0.874851793050766, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36875, 'r1_recall': 0.7866666666666666, 'r1_f1': 0.5021276595744681, 'pegasus_entailment': 0.6777335129678249, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5984251968503937, 'r1_recall': 0.6608695652173913, 'r1_f1': 0.628099173553719, 'pegasus_entailment': 0.5237200796604157, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5945945945945946, 'r1_recall': 0.43137254901960786, 'r1_f1': 0.5000000000000001, 'pegasus_entailment': 0.6547691524028778, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5188679245283019, 'r1_recall': 0.5392156862745098, 'r1_f1': 0.5288461538461537, 'pegasus_entailment': 0.06418022233992815, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.445859872611465, 'pegasus_entailment': 0.4173084482550621, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3956043956043956, 'r1_recall': 0.5625, 'r1_f1': 0.4645161290322581, 'pegasus_entailment': 0.3455523768439889, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43, 'r1_recall': 0.5733333333333334, 'r1_f1': 0.49142857142857144, 'pegasus_entailment': 0.27242566586937755, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34513274336283184, 'r1_recall': 0.7358490566037735, 'r1_f1': 0.4698795180722891, 'pegasus_entailment': 0.86143858730793, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5670103092783505, 'r1_recall': 0.5913978494623656, 'r1_f1': 0.5789473684210525, 'pegasus_entailment': 0.6674053966999054, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43902439024390244, 'r1_recall': 0.6206896551724138, 'r1_f1': 0.5142857142857142, 'pegasus_entailment': 0.3770249326868604, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5431034482758621, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.5779816513761469, 'pegasus_entailment': 0.6137364953756332, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6296296296296297, 'r1_recall': 0.43037974683544306, 'r1_f1': 0.5112781954887219, 'pegasus_entailment': 0.5634314373135567, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3466666666666667, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.3939393939393939, 'pegasus_entailment': 0.4825938992823164, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5725190839694656, 'r1_recall': 0.5033557046979866, 'r1_f1': 0.5357142857142857, 'pegasus_entailment': 0.6616428891817728, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5316455696202531, 'r1_recall': 0.30656934306569344, 'r1_f1': 0.3888888888888889, 'pegasus_entailment': 0.6306249111890793, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6176470588235294, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.6268656716417911, 'pegasus_entailment': 0.21700024232268333, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5284552845528455, 'r1_recall': 0.5855855855855856, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.7940180897712708, 'pegasus_flesch_kincaid': 32, 'pegasus_coleman_liau': 20, 'pegasus_ari': 39, 'pegasus_smog': 28}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24285714285714285, 'r1_recall': 0.6375, 'r1_f1': 0.35172413793103446, 'pegasus_entailment': 0.9482558795383998, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.4409448818897638, 'r1_f1': 0.4534412955465587, 'pegasus_entailment': 0.8250105828046799, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7536231884057971, 'r1_recall': 0.5279187817258884, 'r1_f1': 0.6208955223880598, 'pegasus_entailment': 0.48445955770356314, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6890756302521008, 'r1_recall': 0.3374485596707819, 'r1_f1': 0.4530386740331492, 'pegasus_entailment': 0.31519676093012094, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.676056338028169, 'r1_recall': 0.34532374100719426, 'r1_f1': 0.45714285714285713, 'pegasus_entailment': 0.48386128908896353, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.031578947368421054, 'r1_recall': 0.0410958904109589, 'r1_f1': 0.03571428571428571, 'pegasus_entailment': 0.9542099833488464, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 1, 'pegasus_ari': 17, 'pegasus_smog': 8}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2828282828282828, 'r1_recall': 0.45901639344262296, 'r1_f1': 0.35, 'pegasus_entailment': 0.15300726937130094, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6875, 'r1_recall': 0.6395348837209303, 'r1_f1': 0.6626506024096386, 'pegasus_entailment': 0.6324207410216331, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4673913043478261, 'r1_recall': 0.581081081081081, 'r1_f1': 0.5180722891566265, 'pegasus_entailment': 0.2594465515576303, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5885714285714285, 'r1_recall': 0.5919540229885057, 'r1_f1': 0.5902578796561605, 'pegasus_entailment': 0.6316783428192139, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4827586206896552, 'r1_recall': 0.2916666666666667, 'r1_f1': 0.3636363636363637, 'pegasus_entailment': 0.3849963629618287, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7863247863247863, 'r1_recall': 0.4717948717948718, 'r1_f1': 0.5897435897435896, 'pegasus_entailment': 0.6674446687102318, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5531914893617021, 'r1_recall': 0.7123287671232876, 'r1_f1': 0.6227544910179641, 'pegasus_entailment': 0.49371232837438583, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49074074074074076, 'r1_recall': 0.7066666666666667, 'r1_f1': 0.5792349726775956, 'pegasus_entailment': 0.43740286622196434, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4830508474576271, 'r1_recall': 0.5, 'r1_f1': 0.49137931034482757, 'pegasus_entailment': 0.7744606733322144, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7398373983739838, 'r1_recall': 0.24202127659574468, 'r1_f1': 0.3647294589178357, 'pegasus_entailment': 0.580346517264843, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4857142857142857, 'r1_recall': 0.576271186440678, 'r1_f1': 0.5271317829457364, 'pegasus_entailment': 0.7218687931696574, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7397260273972602, 'r1_recall': 0.32142857142857145, 'r1_f1': 0.44813278008298757, 'pegasus_entailment': 0.6580447033047676, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47586206896551725, 'r1_recall': 0.5348837209302325, 'r1_f1': 0.5036496350364963, 'pegasus_entailment': 0.4769918170890638, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5109489051094891, 'r1_recall': 0.4697986577181208, 'r1_f1': 0.4895104895104895, 'pegasus_entailment': 0.7563707530498505, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6106194690265486, 'r1_recall': 0.40828402366863903, 'r1_f1': 0.48936170212765956, 'pegasus_entailment': 0.3965494744479656, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6696428571428571, 'r1_recall': 0.5725190839694656, 'r1_f1': 0.6172839506172839, 'pegasus_entailment': 0.7024544030427933, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4225352112676056, 'r1_recall': 0.24193548387096775, 'r1_f1': 0.3076923076923077, 'pegasus_entailment': 0.5976449449857076, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425531914893617, 'r1_recall': 0.7228915662650602, 'r1_f1': 0.5357142857142857, 'pegasus_entailment': 0.4587004162371159, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26373626373626374, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.36923076923076925, 'pegasus_entailment': 0.4108757358044386, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6756756756756757, 'r1_recall': 0.43103448275862066, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.26026322444279987, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6636363636363637, 'r1_recall': 0.3945945945945946, 'r1_f1': 0.49491525423728816, 'pegasus_entailment': 0.5605097077786922, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6417910447761194, 'r1_recall': 0.4479166666666667, 'r1_f1': 0.5276073619631902, 'pegasus_entailment': 0.9471827149391174, 'pegasus_flesch_kincaid': 37, 'pegasus_coleman_liau': 22, 'pegasus_ari': 44, 'pegasus_smog': 30}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7815126050420168, 'r1_recall': 0.24155844155844156, 'r1_f1': 0.369047619047619, 'pegasus_entailment': 0.329908254245917, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6770833333333334, 'r1_recall': 0.4513888888888889, 'r1_f1': 0.5416666666666666, 'pegasus_entailment': 0.5722659900784492, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2482758620689655, 'r1_recall': 0.5538461538461539, 'r1_f1': 0.34285714285714286, 'pegasus_entailment': 0.3597773537039757, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45555555555555555, 'r1_recall': 0.6833333333333333, 'r1_f1': 0.5466666666666666, 'pegasus_entailment': 0.26742803646872443, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44594594594594594, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.42580645161290326, 'pegasus_entailment': 0.2515876851975918, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5066666666666667, 'r1_recall': 0.36538461538461536, 'r1_f1': 0.4245810055865922, 'pegasus_entailment': 0.6934632062911987, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32558139534883723, 'r1_recall': 0.4883720930232558, 'r1_f1': 0.39069767441860465, 'pegasus_entailment': 0.6529766172170639, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.421875, 'r1_recall': 0.5192307692307693, 'r1_f1': 0.46551724137931033, 'pegasus_entailment': 0.40192589660485584, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5245901639344263, 'r1_recall': 0.3878787878787879, 'r1_f1': 0.445993031358885, 'pegasus_entailment': 0.6856850117444993, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4578313253012048, 'r1_recall': 0.6229508196721312, 'r1_f1': 0.5277777777777778, 'pegasus_entailment': 0.43050251858464134, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5857142857142857, 'r1_recall': 0.5466666666666666, 'r1_f1': 0.5655172413793104, 'pegasus_entailment': 0.5225172005593777, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5319148936170213, 'r1_recall': 0.5494505494505495, 'r1_f1': 0.5405405405405406, 'pegasus_entailment': 0.39293381075064343, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.544, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.53125, 'pegasus_entailment': 0.3526668002208074, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.52, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5445026178010471, 'pegasus_entailment': 0.6401330679655075, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.584070796460177, 'r1_recall': 0.6285714285714286, 'r1_f1': 0.6055045871559633, 'pegasus_entailment': 0.48934214242867063, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4375, 'r1_recall': 0.7671232876712328, 'r1_f1': 0.5572139303482587, 'pegasus_entailment': 0.4795444518327713, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5581395348837209, 'r1_recall': 0.384, 'r1_f1': 0.4549763033175356, 'pegasus_entailment': 0.25187146477401257, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5612244897959183, 'r1_recall': 0.4824561403508772, 'r1_f1': 0.5188679245283019, 'pegasus_entailment': 0.391675066947937, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35542168674698793, 'r1_recall': 0.6629213483146067, 'r1_f1': 0.4627450980392156, 'pegasus_entailment': 0.5033868892739216, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2, 'r1_recall': 0.32558139534883723, 'r1_f1': 0.24778761061946902, 'pegasus_entailment': 0.9248838722705841, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 15}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7075471698113207, 'r1_recall': 0.3393665158371041, 'r1_f1': 0.45871559633027525, 'pegasus_entailment': 0.5199355781078339, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6301369863013699, 'pegasus_entailment': 0.9620340764522552, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 22}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27835051546391754, 'r1_recall': 0.7297297297297297, 'r1_f1': 0.40298507462686567, 'pegasus_entailment': 0.3749085192879041, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 18}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2980132450331126, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.3862660944206009, 'pegasus_entailment': 0.6741462871432304, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47863247863247865, 'r1_recall': 0.5233644859813084, 'r1_f1': 0.5, 'pegasus_entailment': 0.6878381222486496, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2986111111111111, 'r1_recall': 0.5972222222222222, 'r1_f1': 0.39814814814814814, 'pegasus_entailment': 0.6571219086647033, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5638297872340425, 'r1_recall': 0.6022727272727273, 'r1_f1': 0.5824175824175825, 'pegasus_entailment': 0.48688208195380867, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 30, 'pegasus_smog': 20}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7, 'r1_recall': 0.550561797752809, 'r1_f1': 0.6163522012578616, 'pegasus_entailment': 0.41168683767318726, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2692307692307692, 'r1_recall': 0.5932203389830508, 'r1_f1': 0.3703703703703704, 'pegasus_entailment': 0.15530007786583155, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6741573033707865, 'r1_recall': 0.6060606060606061, 'r1_f1': 0.6382978723404256, 'pegasus_entailment': 0.776126429438591, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46551724137931033, 'r1_recall': 0.5625, 'r1_f1': 0.5094339622641509, 'pegasus_entailment': 0.6770926594734192, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41830065359477125, 'r1_recall': 0.6808510638297872, 'r1_f1': 0.5182186234817814, 'pegasus_entailment': 0.5247123266259829, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8616352201257862, 'r1_recall': 0.2624521072796935, 'r1_f1': 0.40234948604992654, 'pegasus_entailment': 0.565445890384061, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6524390243902439, 'r1_recall': 0.535, 'r1_f1': 0.5879120879120879, 'pegasus_entailment': 0.5532713415367263, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30357142857142855, 'r1_recall': 0.4358974358974359, 'r1_f1': 0.35789473684210527, 'pegasus_entailment': 0.11778875514864921, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6236559139784946, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5858585858585859, 'pegasus_entailment': 0.6512515544891357, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.4852941176470588, 'r1_f1': 0.4925373134328358, 'pegasus_entailment': 0.4438908211886883, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.48672566371681414, 'r1_f1': 0.5418719211822659, 'pegasus_entailment': 0.511633176356554, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47572815533980584, 'r1_recall': 0.5764705882352941, 'r1_f1': 0.5212765957446808, 'pegasus_entailment': 0.4667632281780243, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4186046511627907, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.47368421052631576, 'pegasus_entailment': 0.48165300861001015, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.4891304347826087, 'r1_f1': 0.5202312138728324, 'pegasus_entailment': 0.6083359532058239, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5274725274725275, 'r1_recall': 0.5783132530120482, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.33475450053811073, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6090909090909091, 'r1_recall': 0.5317460317460317, 'r1_f1': 0.5677966101694915, 'pegasus_entailment': 0.5171469151973724, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6206896551724138, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.4214533917605877, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5864661654135338, 'r1_recall': 0.484472049689441, 'r1_f1': 0.5306122448979592, 'pegasus_entailment': 0.5496786117553711, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42028985507246375, 'r1_recall': 0.5087719298245614, 'r1_f1': 0.46031746031746035, 'pegasus_entailment': 0.3604556878951068, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 13}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6204819277108434, 'r1_recall': 0.4557522123893805, 'r1_f1': 0.5255102040816326, 'pegasus_entailment': 0.6254832506179809, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3103448275862069, 'r1_recall': 0.6, 'r1_f1': 0.4090909090909091, 'pegasus_entailment': 0.19837059639394283, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5514018691588785, 'r1_recall': 0.5841584158415841, 'r1_f1': 0.5673076923076923, 'pegasus_entailment': 0.579101045926412, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3595505617977528, 'r1_recall': 0.6530612244897959, 'r1_f1': 0.463768115942029, 'pegasus_entailment': 0.6984294652938843, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.203125, 'r1_recall': 0.2826086956521739, 'r1_f1': 0.23636363636363636, 'pegasus_entailment': 0.8177447517712911, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6218487394957983, 'r1_recall': 0.5068493150684932, 'r1_f1': 0.5584905660377358, 'pegasus_entailment': 0.8368285894393921, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6459627329192547, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.5892351274787535, 'pegasus_entailment': 0.6935430586338043, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5254237288135594, 'r1_recall': 0.4189189189189189, 'r1_f1': 0.46616541353383456, 'pegasus_entailment': 0.34189148258883506, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4017857142857143, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.42654028436018965, 'pegasus_entailment': 0.4437068998813629, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5463917525773195, 'r1_recall': 0.6385542168674698, 'r1_f1': 0.5888888888888889, 'pegasus_entailment': 0.6052955587704977, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35772357723577236, 'r1_recall': 0.6197183098591549, 'r1_f1': 0.4536082474226804, 'pegasus_entailment': 0.4342086136341095, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.512396694214876, 'r1_recall': 0.5391304347826087, 'r1_f1': 0.5254237288135593, 'pegasus_entailment': 0.3408238925039768, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6296296296296297, 'r1_recall': 0.40476190476190477, 'r1_f1': 0.4927536231884058, 'pegasus_entailment': 0.28402944207191466, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29906542056074764, 'r1_recall': 0.6037735849056604, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.7132363468408585, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.42424242424242425, 'pegasus_entailment': 0.8700978010892868, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3923076923076923, 'r1_recall': 0.45132743362831856, 'r1_f1': 0.41975308641975306, 'pegasus_entailment': 0.4894271455705166, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39473684210526316, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.4864864864864865, 'pegasus_entailment': 0.4749680653214455, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5419354838709678, 'r1_recall': 0.3835616438356164, 'r1_f1': 0.4491978609625668, 'pegasus_entailment': 0.48808587789535524, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23076923076923078, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.3185840707964602, 'pegasus_entailment': 0.8682784835497538, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 21}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49019607843137253, 'r1_recall': 0.6024096385542169, 'r1_f1': 0.5405405405405406, 'pegasus_entailment': 0.49508877024054526, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3582089552238806, 'r1_recall': 0.4897959183673469, 'r1_f1': 0.4137931034482758, 'pegasus_entailment': 0.35937045365571973, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6493506493506493, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.6172839506172839, 'pegasus_entailment': 0.6865713596343994, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6379310344827587, 'r1_recall': 0.5736434108527132, 'r1_f1': 0.6040816326530614, 'pegasus_entailment': 0.6006013676524162, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.504950495049505, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.5425531914893617, 'pegasus_entailment': 0.8108405470848083, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6464646464646465, 'r1_recall': 0.48120300751879697, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.5616117380559444, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5945945945945946, 'r1_f1': 0.5432098765432098, 'pegasus_entailment': 0.17247513184944788, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4537037037037037, 'r1_recall': 0.5104166666666666, 'r1_f1': 0.4803921568627451, 'pegasus_entailment': 0.37727495771832764, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7176470588235294, 'r1_recall': 0.4357142857142857, 'r1_f1': 0.5422222222222223, 'pegasus_entailment': 0.8924940427144369, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46703296703296704, 'r1_recall': 0.5902777777777778, 'r1_f1': 0.5214723926380368, 'pegasus_entailment': 0.6907042860984802, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49504950495049505, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.5181347150259067, 'pegasus_entailment': 0.7772064805030823, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5542168674698795, 'r1_recall': 0.44660194174757284, 'r1_f1': 0.49462365591397855, 'pegasus_entailment': 0.712490051984787, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39473684210526316, 'r1_recall': 0.44776119402985076, 'r1_f1': 0.41958041958041953, 'pegasus_entailment': 0.4711893058071534, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4765625, 'r1_recall': 0.6703296703296703, 'r1_f1': 0.5570776255707763, 'pegasus_entailment': 0.7808398976922035, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.624, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5820895522388059, 'pegasus_entailment': 0.6613152585923672, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6739130434782609, 'r1_recall': 0.5081967213114754, 'r1_f1': 0.5794392523364487, 'pegasus_entailment': 0.4218052327632904, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6875, 'r1_recall': 0.463855421686747, 'r1_f1': 0.5539568345323741, 'pegasus_entailment': 0.36346298456192017, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5205479452054794, 'r1_recall': 0.6909090909090909, 'r1_f1': 0.59375, 'pegasus_entailment': 0.20500308523575464, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.6621621621621622, 'r1_f1': 0.547486033519553, 'pegasus_entailment': 0.5421691872179508, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5882352941176471, 'r1_recall': 0.3431372549019608, 'r1_f1': 0.43343653250773995, 'pegasus_entailment': 0.8909037113189697, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7094017094017094, 'r1_recall': 0.38425925925925924, 'r1_f1': 0.4984984984984985, 'pegasus_entailment': 0.38093746701876324, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4909090909090909, 'r1_recall': 0.4462809917355372, 'r1_f1': 0.4675324675324675, 'pegasus_entailment': 0.3786330081522465, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6422018348623854, 'r1_recall': 0.48951048951048953, 'r1_f1': 0.5555555555555556, 'pegasus_entailment': 0.1516966436058283, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42142857142857143, 'r1_recall': 0.6781609195402298, 'r1_f1': 0.5198237885462554, 'pegasus_entailment': 0.839323103427887, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41721854304635764, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.5206611570247935, 'pegasus_entailment': 0.8117801348368326, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3986013986013986, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.4653061224489796, 'pegasus_entailment': 0.3215726986527443, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5753424657534246, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.44919786096256686, 'pegasus_entailment': 0.26089430321007967, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5897435897435898, 'r1_recall': 0.46464646464646464, 'r1_f1': 0.519774011299435, 'pegasus_entailment': 0.21887610480189323, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3220338983050847, 'r1_recall': 0.42696629213483145, 'r1_f1': 0.3671497584541063, 'pegasus_entailment': 0.5952624082565308, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.675, 'r1_recall': 0.49693251533742333, 'r1_f1': 0.5724381625441696, 'pegasus_entailment': 0.3389609344303608, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.64, 'r1_recall': 0.26373626373626374, 'r1_f1': 0.37354085603112835, 'pegasus_entailment': 0.5633938908576965, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6935483870967742, 'r1_recall': 0.31272727272727274, 'r1_f1': 0.431077694235589, 'pegasus_entailment': 0.20300436913967132, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5789473684210527, 'r1_recall': 0.5045871559633027, 'r1_f1': 0.5392156862745099, 'pegasus_entailment': 0.6460630521178246, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26582278481012656, 'r1_recall': 0.3620689655172414, 'r1_f1': 0.3065693430656934, 'pegasus_entailment': 0.9707360565662384, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 17}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5813953488372093, 'r1_recall': 0.27624309392265195, 'r1_f1': 0.3745318352059925, 'pegasus_entailment': 0.688292404015859, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3445378151260504, 'r1_recall': 0.5324675324675324, 'r1_f1': 0.41836734693877553, 'pegasus_entailment': 0.4574697569012642, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32571428571428573, 'r1_recall': 0.7125, 'r1_f1': 0.4470588235294118, 'pegasus_entailment': 0.5455219112336636, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5934065934065934, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.5869565217391305, 'pegasus_entailment': 0.7388964220881462, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5096153846153846, 'r1_recall': 0.654320987654321, 'r1_f1': 0.572972972972973, 'pegasus_entailment': 0.5579134874045849, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5308641975308642, 'r1_recall': 0.4777777777777778, 'r1_f1': 0.5029239766081872, 'pegasus_entailment': 0.6428880492846171, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27956989247311825, 'r1_recall': 0.37681159420289856, 'r1_f1': 0.32098765432098764, 'pegasus_entailment': 0.4505146484589204, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3782051282051282, 'r1_recall': 0.6145833333333334, 'r1_f1': 0.46825396825396826, 'pegasus_entailment': 0.4413776679171456, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38, 'r1_recall': 0.59375, 'r1_f1': 0.46341463414634143, 'pegasus_entailment': 0.3738635601475835, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3968253968253968, 'r1_recall': 0.5494505494505495, 'r1_f1': 0.4608294930875576, 'pegasus_entailment': 0.6062497496604919, 'pegasus_flesch_kincaid': 31, 'pegasus_coleman_liau': 18, 'pegasus_ari': 39, 'pegasus_smog': 24}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44696969696969696, 'r1_recall': 0.6704545454545454, 'r1_f1': 0.5363636363636364, 'pegasus_entailment': 0.6399026811122894, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38524590163934425, 'r1_recall': 0.7580645161290323, 'r1_f1': 0.5108695652173914, 'pegasus_entailment': 0.5259238600730896, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5147058823529411, 'r1_recall': 0.6542056074766355, 'r1_f1': 0.5761316872427984, 'pegasus_entailment': 0.5157240554690361, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38028169014084506, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.40298507462686567, 'pegasus_entailment': 0.3669706713408232, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7920792079207921, 'r1_recall': 0.3018867924528302, 'r1_f1': 0.4371584699453552, 'pegasus_entailment': 0.4796195328235626, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36633663366336633, 'r1_recall': 0.578125, 'r1_f1': 0.4484848484848485, 'pegasus_entailment': 0.4862455949187279, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4148936170212766, 'r1_recall': 0.42391304347826086, 'r1_f1': 0.41935483870967744, 'pegasus_entailment': 0.8469926357269287, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.512396694214876, 'r1_recall': 0.62, 'r1_f1': 0.5610859728506787, 'pegasus_entailment': 0.5371859036386013, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4772727272727273, 'r1_recall': 0.45, 'r1_f1': 0.4632352941176471, 'pegasus_entailment': 0.7819550991058349, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5319148936170213, 'r1_recall': 0.5319148936170213, 'r1_f1': 0.5319148936170213, 'pegasus_entailment': 0.4124035630375147, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5816326530612245, 'r1_recall': 0.44881889763779526, 'r1_f1': 0.5066666666666667, 'pegasus_entailment': 0.7392638102173805, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3918918918918919, 'r1_recall': 0.4084507042253521, 'r1_f1': 0.4, 'pegasus_entailment': 0.59487184882164, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4409448818897638, 'r1_recall': 0.5957446808510638, 'r1_f1': 0.506787330316742, 'pegasus_entailment': 0.34745545871555805, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5263157894736842, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5, 'pegasus_entailment': 0.23872927762567997, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5348837209302325, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.575, 'pegasus_entailment': 0.3030800308721761, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4642857142857143, 'r1_recall': 0.582089552238806, 'r1_f1': 0.5165562913907285, 'pegasus_entailment': 0.6351023316383362, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.358974358974359, 'r1_recall': 0.4375, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.836095929145813, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5287356321839081, 'r1_recall': 0.2658959537572254, 'r1_f1': 0.3538461538461538, 'pegasus_entailment': 0.5277276933193207, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6261682242990654, 'r1_recall': 0.40606060606060607, 'r1_f1': 0.4926470588235294, 'pegasus_entailment': 0.42679300780097645, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6320754716981132, 'r1_recall': 0.6836734693877551, 'r1_f1': 0.6568627450980392, 'pegasus_entailment': 0.6183235887438059, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851063829787234, 'r1_recall': 0.29411764705882354, 'r1_f1': 0.3914590747330961, 'pegasus_entailment': 0.10104828886687756, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44871794871794873, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.4046242774566474, 'pegasus_entailment': 0.44852709472179414, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42424242424242425, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4912280701754386, 'pegasus_entailment': 0.6436878641446432, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40625, 'r1_recall': 0.4727272727272727, 'r1_f1': 0.43697478991596644, 'pegasus_entailment': 0.651074081659317, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22727272727272727, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.3289473684210526, 'pegasus_entailment': 0.37106930650770664, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4144144144144144, 'r1_recall': 0.647887323943662, 'r1_f1': 0.5054945054945055, 'pegasus_entailment': 0.9077486991882324, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32142857142857145, 'r1_recall': 0.5192307692307693, 'r1_f1': 0.39705882352941174, 'pegasus_entailment': 0.3618789967149496, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5072463768115942, 'r1_recall': 0.29914529914529914, 'r1_f1': 0.3763440860215054, 'pegasus_entailment': 0.4053036882542074, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6534653465346535, 'r1_recall': 0.5038167938931297, 'r1_f1': 0.5689655172413793, 'pegasus_entailment': 0.4550515413284302, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5405405405405406, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5063291139240507, 'pegasus_entailment': 0.5093708166386932, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 12}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6037735849056604, 'r1_recall': 0.35555555555555557, 'r1_f1': 0.44755244755244755, 'pegasus_entailment': 0.6055308878421783, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.5934065934065934, 'r1_f1': 0.5118483412322274, 'pegasus_entailment': 0.43761444091796875, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 25}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.51, 'r1_recall': 0.4636363636363636, 'r1_f1': 0.4857142857142857, 'pegasus_entailment': 0.5802631005644798, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 22}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5842696629213483, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.574585635359116, 'pegasus_entailment': 0.5011084030071894, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5058823529411764, 'r1_recall': 0.43, 'r1_f1': 0.46486486486486484, 'pegasus_entailment': 0.6636000603437424, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2708333333333333, 'r1_recall': 0.37681159420289856, 'r1_f1': 0.3151515151515151, 'pegasus_entailment': 0.6837629559449852, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5227272727272727, 'r1_recall': 0.5287356321839081, 'r1_f1': 0.5257142857142857, 'pegasus_entailment': 0.6650414168834686, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6203703703703703, 'r1_recall': 0.6568627450980392, 'r1_f1': 0.638095238095238, 'pegasus_entailment': 0.5822240188717842, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40298507462686567, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.49541284403669733, 'pegasus_entailment': 0.6191720366477966, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23255813953488372, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.2898550724637681, 'pegasus_entailment': 0.4679887555539608, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6237623762376238, 'r1_recall': 0.4405594405594406, 'r1_f1': 0.5163934426229508, 'pegasus_entailment': 0.7031949818134308, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5402298850574713, 'r1_recall': 0.5402298850574713, 'r1_f1': 0.5402298850574713, 'pegasus_entailment': 0.3125515356659889, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.4878048780487805, 'pegasus_entailment': 0.6433320247257749, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.39669421487603307, 'r1_f1': 0.45933014354066987, 'pegasus_entailment': 0.6853058040142059, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41379310344827586, 'r1_recall': 0.34615384615384615, 'r1_f1': 0.37696335078534027, 'pegasus_entailment': 0.3346194537977378, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47368421052631576, 'r1_recall': 0.2571428571428571, 'r1_f1': 0.3333333333333333, 'pegasus_entailment': 0.6736226181189219, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2892561983471074, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.36269430051813467, 'pegasus_entailment': 0.37788626505061984, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48598130841121495, 'r1_recall': 0.5842696629213483, 'r1_f1': 0.5306122448979592, 'pegasus_entailment': 0.29396875699361164, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1826086956521739, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.2625, 'pegasus_entailment': 0.6165829971432686, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45255474452554745, 'r1_recall': 0.6019417475728155, 'r1_f1': 0.5166666666666667, 'pegasus_entailment': 0.45390594253937405, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.13186813186813187, 'r1_recall': 0.34285714285714286, 'r1_f1': 0.1904761904761905, 'pegasus_entailment': 0.44790851697325706, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3472222222222222, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.42735042735042733, 'pegasus_entailment': 0.879147469997406, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22627737226277372, 'r1_recall': 0.7948717948717948, 'r1_f1': 0.3522727272727273, 'pegasus_entailment': 0.9510880907376608, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7647058823529411, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.48148148148148157, 'pegasus_entailment': 0.26776187121868134, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.6, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.8117288649082184, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32450331125827814, 'r1_recall': 0.5104166666666666, 'r1_f1': 0.3967611336032389, 'pegasus_entailment': 0.3928569592535496, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.532258064516129, 'r1_recall': 0.6055045871559633, 'r1_f1': 0.5665236051502146, 'pegasus_entailment': 0.35898205637931824, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.603448275862069, 'r1_recall': 0.5072463768115942, 'r1_f1': 0.5511811023622047, 'pegasus_entailment': 0.3799579789241155, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8791208791208791, 'r1_recall': 0.22727272727272727, 'r1_f1': 0.3611738148984198, 'pegasus_entailment': 0.9009361664454142, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4298245614035088, 'r1_recall': 0.44144144144144143, 'r1_f1': 0.4355555555555556, 'pegasus_entailment': 0.7416481897234917, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5212765957446809, 'r1_recall': 0.3288590604026846, 'r1_f1': 0.4032921810699589, 'pegasus_entailment': 0.6765744984149933, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7325581395348837, 'r1_recall': 0.4228187919463087, 'r1_f1': 0.5361702127659574, 'pegasus_entailment': 0.7686430931091308, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24691358024691357, 'r1_recall': 0.40816326530612246, 'r1_f1': 0.3076923076923077, 'pegasus_entailment': 0.199537156149745, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3884297520661157, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.48704663212435234, 'pegasus_entailment': 0.36349406590064365, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3602941176470588, 'r1_recall': 0.6049382716049383, 'r1_f1': 0.45161290322580644, 'pegasus_entailment': 0.48194907456636427, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8762886597938144, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.6882591093117408, 'pegasus_entailment': 0.5371608038743337, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4117647058823529, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.4605263157894737, 'pegasus_entailment': 0.5246486216783524, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7894736842105263, 'r1_recall': 0.5232558139534884, 'r1_f1': 0.6293706293706294, 'pegasus_entailment': 0.9063218633333842, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34965034965034963, 'r1_recall': 0.6756756756756757, 'r1_f1': 0.4608294930875576, 'pegasus_entailment': 0.7385792210698128, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5223880597014925, 'r1_recall': 0.43209876543209874, 'r1_f1': 0.47297297297297297, 'pegasus_entailment': 0.8222944339116415, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5603448275862069, 'r1_recall': 0.46099290780141844, 'r1_f1': 0.5058365758754862, 'pegasus_entailment': 0.5897003471851349, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3438914027149321, 'r1_recall': 0.5801526717557252, 'r1_f1': 0.4318181818181818, 'pegasus_entailment': 0.6571499332785606, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 20, 'pegasus_ari': 36, 'pegasus_smog': 25}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5975609756097561, 'r1_recall': 0.460093896713615, 'r1_f1': 0.519893899204244, 'pegasus_entailment': 0.5900787532329559, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5529411764705883, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.537142857142857, 'pegasus_entailment': 0.8222491343816122, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36470588235294116, 'r1_recall': 0.543859649122807, 'r1_f1': 0.4366197183098592, 'pegasus_entailment': 0.564756323893865, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.31746031746031744, 'r1_f1': 0.42105263157894735, 'pegasus_entailment': 0.5144186150282621, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6941176470588235, 'r1_recall': 0.19407894736842105, 'r1_f1': 0.3033419023136247, 'pegasus_entailment': 0.29711681852738064, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18840579710144928, 'r1_recall': 0.4126984126984127, 'r1_f1': 0.25870646766169153, 'pegasus_entailment': 0.5562828965485096, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40131578947368424, 'r1_recall': 0.6421052631578947, 'r1_f1': 0.4939271255060729, 'pegasus_entailment': 0.6066539287567139, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6782608695652174, 'r1_recall': 0.4936708860759494, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.43907816614955664, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2835820895522388, 'r1_recall': 0.3275862068965517, 'r1_f1': 0.304, 'pegasus_entailment': 0.3528770574678977, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7272727272727273, 'r1_recall': 0.35359116022099446, 'r1_f1': 0.4758364312267657, 'pegasus_entailment': 0.401650071144104, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.569620253164557, 'r1_recall': 0.31690140845070425, 'r1_f1': 0.40723981900452494, 'pegasus_entailment': 0.5625083049138387, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44761904761904764, 'r1_recall': 0.49473684210526314, 'r1_f1': 0.47000000000000003, 'pegasus_entailment': 0.29756504762917757, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5855855855855856, 'r1_recall': 0.37790697674418605, 'r1_f1': 0.45936395759717313, 'pegasus_entailment': 0.6312712550163269, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41509433962264153, 'r1_recall': 0.6197183098591549, 'r1_f1': 0.4971751412429378, 'pegasus_entailment': 0.5009271539747715, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7159090909090909, 'r1_recall': 0.30288461538461536, 'r1_f1': 0.42567567567567566, 'pegasus_entailment': 0.7563634117444357, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36464088397790057, 'r1_recall': 0.7096774193548387, 'r1_f1': 0.48175182481751827, 'pegasus_entailment': 0.6750149726867676, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36507936507936506, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.45771144278606957, 'pegasus_entailment': 0.6137096732854843, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46236559139784944, 'r1_recall': 0.6056338028169014, 'r1_f1': 0.524390243902439, 'pegasus_entailment': 0.3920397361119588, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5148514851485149, 'r1_recall': 0.5148514851485149, 'r1_f1': 0.5148514851485149, 'pegasus_entailment': 0.6513090133666992, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6938775510204082, 'r1_recall': 0.4927536231884058, 'r1_f1': 0.576271186440678, 'pegasus_entailment': 0.7587986886501312, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.4485981308411215, 'pegasus_entailment': 0.7946982562541962, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27058823529411763, 'r1_recall': 0.38333333333333336, 'r1_f1': 0.31724137931034485, 'pegasus_entailment': 0.32220791776974994, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8058252427184466, 'r1_recall': 0.46629213483146065, 'r1_f1': 0.590747330960854, 'pegasus_entailment': 0.7039458863437176, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44339622641509435, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.5251396648044692, 'pegasus_entailment': 0.4095403850078583, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4435483870967742, 'r1_recall': 0.7236842105263158, 'r1_f1': 0.55, 'pegasus_entailment': 0.21511110139545053, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5529411764705883, 'r1_recall': 0.5164835164835165, 'r1_f1': 0.5340909090909091, 'pegasus_entailment': 0.4883999414741993, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6228070175438597, 'r1_recall': 0.5916666666666667, 'r1_f1': 0.6068376068376069, 'pegasus_entailment': 0.565395787358284, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8145161290322581, 'r1_recall': 0.14326241134751774, 'r1_f1': 0.2436670687575392, 'pegasus_entailment': 0.719287283718586, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6363636363636364, 'r1_recall': 0.49295774647887325, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.5859746634960175, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.88, 'r1_recall': 0.4808743169398907, 'r1_f1': 0.6219081272084805, 'pegasus_entailment': 0.4208165916303794, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4015748031496063, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.4636363636363636, 'pegasus_entailment': 0.3654447728767991, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5929203539823009, 'r1_recall': 0.5775862068965517, 'r1_f1': 0.5851528384279475, 'pegasus_entailment': 0.5120957437902689, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4574468085106383, 'r1_recall': 0.6615384615384615, 'r1_f1': 0.540880503144654, 'pegasus_entailment': 0.32931030122563243, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48201438848920863, 'r1_recall': 0.4267515923566879, 'r1_f1': 0.4527027027027027, 'pegasus_entailment': 0.41376807913184166, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.20175438596491227, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.2839506172839506, 'pegasus_entailment': 0.39992243610322475, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4731182795698925, 'r1_recall': 0.4536082474226804, 'r1_f1': 0.46315789473684216, 'pegasus_entailment': 0.9707311391830444, 'pegasus_flesch_kincaid': 45, 'pegasus_coleman_liau': 20, 'pegasus_ari': 55, 'pegasus_smog': 32}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1743119266055046, 'r1_recall': 0.5428571428571428, 'r1_f1': 0.2638888888888889, 'pegasus_entailment': 0.4398182760924101, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43537414965986393, 'r1_recall': 0.6597938144329897, 'r1_f1': 0.5245901639344263, 'pegasus_entailment': 0.5514963768422604, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5178571428571429, 'r1_recall': 0.5132743362831859, 'r1_f1': 0.5155555555555555, 'pegasus_entailment': 0.67866450548172, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6363636363636364, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.5384615384615385, 'pegasus_entailment': 0.45638997317291796, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23232323232323232, 'r1_recall': 0.42592592592592593, 'r1_f1': 0.30065359477124176, 'pegasus_entailment': 0.39395245611667634, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5774647887323944, 'r1_recall': 0.41, 'r1_f1': 0.47953216374269003, 'pegasus_entailment': 0.8469030410051346, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.031578947368421054
MEAN
0.5039881876995551
MAX
0.88
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.0410958904109589
MEAN
0.5021844395657316
MAX
0.7971014492753623
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.03571428571428571
MEAN
0.4796578201394519
MAX
0.6995073891625615
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.06338276776174705
MEAN
0.5457424162566189
MAX
0.9890740911165873
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
17
MAX
52
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
1
MEAN
17
MAX
24
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
12
MEAN
21
MAX
64
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
8
MEAN
18
MAX
34
{}
