Entered file!
Imports done!
*** RUN *** 
eval_1d
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.547945205479452, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.4371584699453552, 'pegasus_entailment': 0.7116689880688986, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5826086956521739, 'r1_recall': 0.3872832369942196, 'r1_f1': 0.46527777777777773, 'pegasus_entailment': 0.666071243584156, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24468085106382978, 'r1_recall': 0.39655172413793105, 'r1_f1': 0.3026315789473684, 'pegasus_entailment': 0.4764786183834076, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6428571428571429, 'r1_recall': 0.4883720930232558, 'r1_f1': 0.5550660792951543, 'pegasus_entailment': 0.51149782538414, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7555555555555555, 'r1_recall': 0.39080459770114945, 'r1_f1': 0.5151515151515151, 'pegasus_entailment': 0.7247506678104401, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.36923076923076925, 'r1_f1': 0.384, 'pegasus_entailment': 0.7439693570137024, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16279069767441862, 'r1_recall': 0.4375, 'r1_f1': 0.23728813559322032, 'pegasus_entailment': 0.571635864675045, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.12871287128712872, 'r1_recall': 0.41935483870967744, 'r1_f1': 0.196969696969697, 'pegasus_entailment': 0.8996748725573221, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.524822695035461, 'r1_recall': 0.4966442953020134, 'r1_f1': 0.5103448275862068, 'pegasus_entailment': 0.3353196941316128, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5144927536231884, 'r1_recall': 0.5144927536231884, 'r1_f1': 0.5144927536231884, 'pegasus_entailment': 0.5298699789680541, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.504424778761062, 'r1_recall': 0.38, 'r1_f1': 0.43346007604562736, 'pegasus_entailment': 0.6447652479012808, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3939393939393939, 'r1_recall': 0.5462184873949579, 'r1_f1': 0.45774647887323944, 'pegasus_entailment': 0.621767240886887, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 18, 'pegasus_ari': 35, 'pegasus_smog': 25}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.504950495049505, 'r1_recall': 0.4766355140186916, 'r1_f1': 0.4903846153846154, 'pegasus_entailment': 0.6183358356356621, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4845360824742268, 'r1_recall': 0.5340909090909091, 'r1_f1': 0.5081081081081081, 'pegasus_entailment': 0.6060794070363045, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6301369863013698, 'r1_recall': 0.23958333333333334, 'r1_f1': 0.3471698113207547, 'pegasus_entailment': 0.4267313228920102, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23333333333333334, 'r1_recall': 0.3559322033898305, 'r1_f1': 0.28187919463087246, 'pegasus_entailment': 0.5041147880256176, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39325842696629215, 'r1_recall': 0.35353535353535354, 'r1_f1': 0.3723404255319149, 'pegasus_entailment': 0.7420316338539124, 'pegasus_flesch_kincaid': 44, 'pegasus_coleman_liau': 20, 'pegasus_ari': 53, 'pegasus_smog': 31}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.648936170212766, 'r1_recall': 0.20469798657718122, 'r1_f1': 0.31122448979591844, 'pegasus_entailment': 0.5728464722633362, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.2981366459627329, 'r1_f1': 0.401673640167364, 'pegasus_entailment': 0.18747738655656576, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.582089552238806, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.5064935064935066, 'pegasus_entailment': 0.59804967045784, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 13}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6818181818181818, 'r1_recall': 0.41208791208791207, 'r1_f1': 0.5136986301369862, 'pegasus_entailment': 0.6312385499477386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6511627906976745, 'r1_recall': 0.37333333333333335, 'r1_f1': 0.4745762711864407, 'pegasus_entailment': 0.38488870300352573, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5714285714285714, 'r1_recall': 0.48148148148148145, 'r1_f1': 0.5226130653266332, 'pegasus_entailment': 0.7772088348865509, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5073529411764706, 'r1_recall': 0.5073529411764706, 'r1_f1': 0.5073529411764706, 'pegasus_entailment': 0.3849626541137695, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3, 'r1_recall': 0.54, 'r1_f1': 0.3857142857142857, 'pegasus_entailment': 0.4759623795747757, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7446808510638298, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.6363636363636364, 'pegasus_entailment': 0.8032576590776443, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5036496350364964, 'r1_f1': 0.5018181818181818, 'pegasus_entailment': 0.42681920528411865, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6258992805755396, 'r1_recall': 0.3246268656716418, 'r1_f1': 0.4275184275184275, 'pegasus_entailment': 0.4240839838981628, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49382716049382713, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5095541401273886, 'pegasus_entailment': 0.4725390076637268, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37606837606837606, 'r1_recall': 0.3893805309734513, 'r1_f1': 0.382608695652174, 'pegasus_entailment': 0.8215039968490601, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2824858757062147, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.37878787878787873, 'pegasus_entailment': 0.5716495301042285, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5470085470085471, 'r1_recall': 0.31840796019900497, 'r1_f1': 0.4025157232704403, 'pegasus_entailment': 0.2915831238031387, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3387096774193548, 'r1_recall': 0.4077669902912621, 'r1_f1': 0.3700440528634361, 'pegasus_entailment': 0.8711265126864115, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5157894736842106, 'r1_recall': 0.5051546391752577, 'r1_f1': 0.5104166666666667, 'pegasus_entailment': 0.5728132635354996, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2945205479452055, 'r1_recall': 0.5119047619047619, 'r1_f1': 0.3739130434782609, 'pegasus_entailment': 0.5717255190014839, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47, 'r1_recall': 0.4051724137931034, 'r1_f1': 0.4351851851851852, 'pegasus_entailment': 0.5426786661148071, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.408, 'r1_recall': 0.7391304347826086, 'r1_f1': 0.5257731958762887, 'pegasus_entailment': 0.7366785705089569, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2866666666666667, 'r1_recall': 0.6323529411764706, 'r1_f1': 0.3944954128440367, 'pegasus_entailment': 0.5626005977392197, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2222222222222222, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.3137254901960784, 'pegasus_entailment': 0.3798774816095829, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5246913580246914, 'r1_recall': 0.5120481927710844, 'r1_f1': 0.5182926829268293, 'pegasus_entailment': 0.5699965804815292, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7375, 'r1_recall': 0.36875, 'r1_f1': 0.49166666666666664, 'pegasus_entailment': 0.4684705436229706, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.5384615384615385, 'pegasus_entailment': 0.25387746962951496, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3793103448275862, 'r1_recall': 0.4520547945205479, 'r1_f1': 0.4125, 'pegasus_entailment': 0.3860382284813871, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.5121951219512195, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.39695369228720667, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26153846153846155, 'r1_recall': 0.6538461538461539, 'r1_f1': 0.37362637362637363, 'pegasus_entailment': 0.7383989521435329, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5540540540540541, 'r1_recall': 0.2733333333333333, 'r1_f1': 0.36607142857142855, 'pegasus_entailment': 0.6690704226493835, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6530612244897959, 'r1_recall': 0.5423728813559322, 'r1_f1': 0.5925925925925926, 'pegasus_entailment': 0.6957162618637085, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.512396694214876, 'r1_recall': 0.5585585585585585, 'r1_f1': 0.5344827586206896, 'pegasus_entailment': 0.7408182203769684, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4857142857142857, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.5396825396825397, 'pegasus_entailment': 0.42992558777332307, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36879432624113473, 'r1_recall': 0.5, 'r1_f1': 0.42448979591836733, 'pegasus_entailment': 0.4041567100211978, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.325, 'r1_recall': 0.7027027027027027, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.5174738485366106, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24087591240875914, 'r1_recall': 0.6470588235294118, 'r1_f1': 0.35106382978723405, 'pegasus_entailment': 0.8186076964650836, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.5675675675675675, 'r1_f1': 0.42, 'pegasus_entailment': 0.7381453216075897, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 23, 'pegasus_ari': 33, 'pegasus_smog': 25}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.22598870056497175, 'r1_f1': 0.31746031746031744, 'pegasus_entailment': 0.3293006320794423, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.631578947368421, 'r1_recall': 0.47191011235955055, 'r1_f1': 0.540192926045016, 'pegasus_entailment': 0.4900782306989034, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2922077922077922, 'r1_recall': 0.625, 'r1_f1': 0.39823008849557523, 'pegasus_entailment': 0.4595879022963345, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4766355140186916, 'r1_recall': 0.20318725099601595, 'r1_f1': 0.28491620111731847, 'pegasus_entailment': 0.7187477648258209, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45121951219512196, 'r1_recall': 0.578125, 'r1_f1': 0.5068493150684932, 'pegasus_entailment': 0.4532991424202919, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5460526315789473, 'r1_recall': 0.6859504132231405, 'r1_f1': 0.608058608058608, 'pegasus_entailment': 0.7617147922515869, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5, 'pegasus_entailment': 0.7668958008289337, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 15}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.4659090909090909, 'r1_f1': 0.4823529411764706, 'pegasus_entailment': 0.7171827554702759, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34545454545454546, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.4175824175824176, 'pegasus_entailment': 0.3744451515376568, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4639175257731959, 'r1_recall': 0.26785714285714285, 'r1_f1': 0.33962264150943394, 'pegasus_entailment': 0.2699683606624603, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41836734693877553, 'r1_recall': 0.422680412371134, 'r1_f1': 0.4205128205128206, 'pegasus_entailment': 0.5383849591016769, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29245283018867924, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.4025974025974026, 'pegasus_entailment': 0.6155667205651602, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6071428571428571, 'r1_recall': 0.5354330708661418, 'r1_f1': 0.5690376569037657, 'pegasus_entailment': 0.8335050940513611, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5631067961165048, 'r1_recall': 0.5471698113207547, 'r1_f1': 0.5550239234449761, 'pegasus_entailment': 0.6384412571787834, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34615384615384615, 'r1_recall': 0.5625, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.5504471898078919, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4407894736842105, 'r1_recall': 0.5826086956521739, 'r1_f1': 0.50187265917603, 'pegasus_entailment': 0.5584174456695715, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7228915662650602, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.6486486486486487, 'pegasus_entailment': 0.5038634190956751, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6166666666666667, 'r1_recall': 0.4457831325301205, 'r1_f1': 0.5174825174825175, 'pegasus_entailment': 0.8910328596830368, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45977011494252873, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.5161290322580645, 'pegasus_entailment': 0.6448667496442795, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.5151515151515151, 'r1_f1': 0.45033112582781454, 'pegasus_entailment': 0.5673547200858593, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.515, 'r1_recall': 0.5421052631578948, 'r1_f1': 0.5282051282051282, 'pegasus_entailment': 0.6603145844170025, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21739130434782608, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.3004291845493562, 'pegasus_entailment': 0.6813492700457573, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35664335664335667, 'r1_recall': 0.6, 'r1_f1': 0.4473684210526316, 'pegasus_entailment': 0.4239334613084793, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3007518796992481, 'r1_recall': 0.625, 'r1_f1': 0.40609137055837563, 'pegasus_entailment': 0.272820907831192, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 13, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38144329896907214, 'r1_recall': 0.7115384615384616, 'r1_f1': 0.4966442953020133, 'pegasus_entailment': 0.34353720024228096, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3051948051948052, 'r1_recall': 0.5465116279069767, 'r1_f1': 0.3916666666666667, 'pegasus_entailment': 0.7291710178057352, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 25}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41379310344827586, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.4675324675324676, 'pegasus_entailment': 0.8551362603902817, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47191011235955055, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5029940119760479, 'pegasus_entailment': 0.5483718290925026, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6605504587155964, 'r1_recall': 0.6990291262135923, 'r1_f1': 0.6792452830188679, 'pegasus_entailment': 0.5104497194290161, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3111111111111111, 'r1_recall': 0.4307692307692308, 'r1_f1': 0.36129032258064514, 'pegasus_entailment': 0.7541700601577759, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3630573248407643, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.4672131147540984, 'pegasus_entailment': 0.6105150945484639, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5869565217391305, 'r1_f1': 0.54, 'pegasus_entailment': 0.5398991480469704, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25443786982248523, 'r1_recall': 0.4942528735632184, 'r1_f1': 0.3359375, 'pegasus_entailment': 0.4090337668146406, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1732283464566929, 'r1_recall': 0.28205128205128205, 'r1_f1': 0.21463414634146338, 'pegasus_entailment': 0.7124988079071045, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.256, 'r1_recall': 0.7111111111111111, 'r1_f1': 0.3764705882352941, 'pegasus_entailment': 0.7860204219818115, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5307692307692308, 'r1_recall': 0.3317307692307692, 'r1_f1': 0.40828402366863903, 'pegasus_entailment': 0.6264692395925522, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.32323232323232326, 'pegasus_entailment': 0.5654619783163071, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5975609756097561, 'r1_recall': 0.5104166666666666, 'r1_f1': 0.550561797752809, 'pegasus_entailment': 0.5928005456924439, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 26}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.514018691588785, 'r1_recall': 0.41044776119402987, 'r1_f1': 0.4564315352697096, 'pegasus_entailment': 0.51454296708107, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34782608695652173, 'r1_recall': 0.6575342465753424, 'r1_f1': 0.4549763033175355, 'pegasus_entailment': 0.5931411623954773, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5072463768115942, 'r1_recall': 0.5982905982905983, 'r1_f1': 0.5490196078431372, 'pegasus_entailment': 0.467057262857755, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3203125, 'r1_recall': 0.422680412371134, 'r1_f1': 0.3644444444444444, 'pegasus_entailment': 0.6108669877052307, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5096153846153846, 'r1_recall': 0.2994350282485876, 'r1_f1': 0.37722419928825623, 'pegasus_entailment': 0.5003048330545425, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4028776978417266, 'r1_recall': 0.5773195876288659, 'r1_f1': 0.4745762711864407, 'pegasus_entailment': 0.5175752103328705, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45925925925925926, 'r1_recall': 0.49206349206349204, 'r1_f1': 0.475095785440613, 'pegasus_entailment': 0.7741196274757385, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3025210084033613, 'r1_recall': 0.5538461538461539, 'r1_f1': 0.3913043478260869, 'pegasus_entailment': 0.6673876762390136, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47959183673469385, 'r1_recall': 0.41964285714285715, 'r1_f1': 0.4476190476190476, 'pegasus_entailment': 0.9206894189119339, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.20454545454545456, 'r1_recall': 0.4426229508196721, 'r1_f1': 0.2797927461139897, 'pegasus_entailment': 0.6652069061994552, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3879310344827586, 'r1_recall': 0.4787234042553192, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.7159821510314941, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.576271186440678, 'r1_recall': 0.591304347826087, 'r1_f1': 0.5836909871244637, 'pegasus_entailment': 0.7748668670654297, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5225225225225225, 'r1_recall': 0.5178571428571429, 'r1_f1': 0.5201793721973095, 'pegasus_entailment': 0.7319629490375519, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43243243243243246, 'r1_recall': 0.6, 'r1_f1': 0.5026178010471204, 'pegasus_entailment': 0.5530060082674026, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.6201550387596899, 'r1_f1': 0.5536332179930796, 'pegasus_entailment': 0.7374778240919113, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.296, 'r1_recall': 0.7184466019417476, 'r1_f1': 0.4192634560906516, 'pegasus_entailment': 0.6184001167615255, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5151515151515151, 'r1_recall': 0.425, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.3683085411787033, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4878048780487805, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5095541401273885, 'pegasus_entailment': 0.39486534893512726, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2956521739130435, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.38857142857142857, 'pegasus_entailment': 0.7879900097846985, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3063583815028902, 'r1_recall': 0.7681159420289855, 'r1_f1': 0.4380165289256198, 'pegasus_entailment': 0.5035060733556748, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5748031496062992, 'r1_recall': 0.5488721804511278, 'r1_f1': 0.5615384615384615, 'pegasus_entailment': 0.6030261609703302, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3445378151260504, 'r1_recall': 0.5189873417721519, 'r1_f1': 0.4141414141414141, 'pegasus_entailment': 0.7616279006004334, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5633802816901409, 'r1_recall': 0.449438202247191, 'r1_f1': 0.5000000000000001, 'pegasus_entailment': 0.3193804733455181, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45977011494252873, 'r1_recall': 0.3076923076923077, 'r1_f1': 0.3686635944700461, 'pegasus_entailment': 0.5721726516882578, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5869565217391305, 'r1_recall': 0.4550561797752809, 'r1_f1': 0.5126582278481013, 'pegasus_entailment': 0.7395468279719353, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7674418604651163, 'r1_recall': 0.375, 'r1_f1': 0.5038167938931298, 'pegasus_entailment': 0.4442046098411083, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6311475409836066, 'r1_recall': 0.5746268656716418, 'r1_f1': 0.6015625, 'pegasus_entailment': 0.6936100125312805, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5392156862745098, 'r1_recall': 0.5851063829787234, 'r1_f1': 0.5612244897959183, 'pegasus_entailment': 0.2846868534882863, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6868686868686869, 'r1_recall': 0.5354330708661418, 'r1_f1': 0.6017699115044248, 'pegasus_entailment': 0.4224584013223648, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5436893203883495, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.5863874345549738, 'pegasus_entailment': 0.6371643468737602, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5370370370370371, 'r1_recall': 0.5043478260869565, 'r1_f1': 0.5201793721973095, 'pegasus_entailment': 0.41023630897204083, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2677165354330709, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.3349753694581281, 'pegasus_entailment': 0.6029059052467346, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2054794520547945, 'r1_recall': 0.6976744186046512, 'r1_f1': 0.31746031746031744, 'pegasus_entailment': 0.64065982401371, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425531914893617, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.6639387965202331, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.576271186440678, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.5461847389558233, 'pegasus_entailment': 0.6153720915317535, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37209302325581395, 'r1_recall': 0.6, 'r1_f1': 0.45933014354066987, 'pegasus_entailment': 0.4895836357027292, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5714285714285714, 'r1_recall': 0.6495726495726496, 'r1_f1': 0.608, 'pegasus_entailment': 0.5050405144691468, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5181818181818182, 'r1_recall': 0.49137931034482757, 'r1_f1': 0.504424778761062, 'pegasus_entailment': 0.786547964811325, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2672413793103448, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.35428571428571426, 'pegasus_entailment': 0.5242541998624801, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5579710144927537, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.4709480122324159, 'pegasus_entailment': 0.7234940230846405, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44666666666666666, 'r1_recall': 0.5537190082644629, 'r1_f1': 0.49446494464944646, 'pegasus_entailment': 0.800745141506195, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6697247706422018, 'r1_recall': 0.47096774193548385, 'r1_f1': 0.553030303030303, 'pegasus_entailment': 0.8924667090177536, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4519774011299435, 'r1_recall': 0.49079754601226994, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.45416309460997584, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.373134328358209, 'r1_recall': 0.49504950495049505, 'r1_f1': 0.4255319148936171, 'pegasus_entailment': 0.7406548062960306, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4925373134328358, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5176470588235293, 'pegasus_entailment': 0.3950080027182897, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4305555555555556, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5232067510548523, 'pegasus_entailment': 0.5263183359056711, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6145833333333334, 'r1_recall': 0.44360902255639095, 'r1_f1': 0.5152838427947598, 'pegasus_entailment': 0.8071256875991821, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 23}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.34054054054054056, 'r1_f1': 0.4144736842105263, 'pegasus_entailment': 0.3922102339565754, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3625, 'r1_recall': 0.5, 'r1_f1': 0.42028985507246375, 'pegasus_entailment': 0.5195363561312357, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33884297520661155, 'r1_recall': 0.4659090909090909, 'r1_f1': 0.3923444976076555, 'pegasus_entailment': 0.5300447146097819, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 25}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.43010752688172044, 'r1_f1': 0.48484848484848486, 'pegasus_entailment': 0.6176441311836243, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4752475247524752, 'r1_recall': 0.4247787610619469, 'r1_f1': 0.4485981308411215, 'pegasus_entailment': 0.6222943812608719, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5571428571428572, 'r1_recall': 0.4875, 'r1_f1': 0.52, 'pegasus_entailment': 0.7359208265940348, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4482758620689655, 'r1_recall': 0.38613861386138615, 'r1_f1': 0.4148936170212766, 'pegasus_entailment': 0.26649039797484875, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6349206349206349, 'r1_recall': 0.3827751196172249, 'r1_f1': 0.47761194029850745, 'pegasus_entailment': 0.6817525699734688, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.3314917127071823, 'r1_f1': 0.4428044280442805, 'pegasus_entailment': 0.5896317005157471, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2727272727272727, 'r1_recall': 0.2033898305084746, 'r1_f1': 0.23300970873786409, 'pegasus_entailment': 0.812537670135498, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 23, 'pegasus_ari': 33, 'pegasus_smog': 22}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6526315789473685, 'r1_recall': 0.38271604938271603, 'r1_f1': 0.48249027237354086, 'pegasus_entailment': 0.49986863136291504, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4787234042553192, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.5113636363636364, 'pegasus_entailment': 0.32467150191466015, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36363636363636365, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.40552995391705066, 'pegasus_entailment': 0.43069726377725603, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5054945054945055, 'r1_recall': 0.5, 'r1_f1': 0.5027322404371585, 'pegasus_entailment': 0.5946051403880119, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6287878787878788, 'r1_recall': 0.42783505154639173, 'r1_f1': 0.50920245398773, 'pegasus_entailment': 0.40941788218915465, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.3313253012048193, 'r1_f1': 0.43307086614173235, 'pegasus_entailment': 0.4317089281976223, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.52, 'r1_recall': 0.6610169491525424, 'r1_f1': 0.582089552238806, 'pegasus_entailment': 0.4522808815042178, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.54, 'r1_recall': 0.4682080924855491, 'r1_f1': 0.5015479876160991, 'pegasus_entailment': 0.4464271391431491, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46987951807228917, 'r1_recall': 0.48148148148148145, 'r1_f1': 0.47560975609756095, 'pegasus_entailment': 0.42506975928942364, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5034965034965035, 'r1_recall': 0.48322147651006714, 'r1_f1': 0.49315068493150693, 'pegasus_entailment': 0.725921368598938, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5128205128205128, 'r1_recall': 0.6451612903225806, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.7128672748804092, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48695652173913045, 'r1_recall': 0.34782608695652173, 'r1_f1': 0.4057971014492754, 'pegasus_entailment': 0.6822736660639445, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.20535714285714285, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.30666666666666664, 'pegasus_entailment': 0.8111149370670319, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46601941747572817, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4549763033175355, 'pegasus_entailment': 0.7061222493648529, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46153846153846156, 'r1_recall': 0.4077669902912621, 'r1_f1': 0.4329896907216495, 'pegasus_entailment': 0.7908738702535629, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46511627906976744, 'r1_recall': 0.36809815950920244, 'r1_f1': 0.410958904109589, 'pegasus_entailment': 0.6973916962742805, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49514563106796117, 'r1_recall': 0.46788990825688076, 'r1_f1': 0.4811320754716981, 'pegasus_entailment': 0.6036132524410883, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5306122448979592, 'r1_recall': 0.4431818181818182, 'r1_f1': 0.4829721362229102, 'pegasus_entailment': 0.6931322485208511, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48514851485148514, 'r1_recall': 0.32666666666666666, 'r1_f1': 0.3904382470119522, 'pegasus_entailment': 0.503323882818222, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4818181818181818, 'r1_recall': 0.37857142857142856, 'r1_f1': 0.424, 'pegasus_entailment': 0.660187341272831, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5432098765432098, 'r1_recall': 0.2953020134228188, 'r1_f1': 0.3826086956521739, 'pegasus_entailment': 0.5758454352617264, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3027027027027027, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.4057971014492754, 'pegasus_entailment': 0.5372047856450081, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26436781609195403, 'r1_recall': 0.2987012987012987, 'r1_f1': 0.28048780487804875, 'pegasus_entailment': 0.754843125740687, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31125827814569534, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.41964285714285715, 'pegasus_entailment': 0.5616520285606384, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6774193548387096, 'r1_recall': 0.3423913043478261, 'r1_f1': 0.4548736462093863, 'pegasus_entailment': 0.6584490736325582, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45614035087719296, 'r1_recall': 0.4727272727272727, 'r1_f1': 0.46428571428571425, 'pegasus_entailment': 0.7437730828921, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2808219178082192, 'r1_recall': 0.33064516129032256, 'r1_f1': 0.30370370370370375, 'pegasus_entailment': 0.5543145500123501, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5739130434782609, 'r1_recall': 0.55, 'r1_f1': 0.5617021276595745, 'pegasus_entailment': 0.7211165428161621, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6091954022988506, 'r1_recall': 0.225531914893617, 'r1_f1': 0.32919254658385094, 'pegasus_entailment': 0.5291611790657044, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4338235294117647, 'r1_recall': 0.3881578947368421, 'r1_f1': 0.4097222222222222, 'pegasus_entailment': 0.4824587322771549, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.423728813559322, 'r1_recall': 0.5813953488372093, 'r1_f1': 0.4901960784313726, 'pegasus_entailment': 0.6929145753383636, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2830188679245283, 'r1_recall': 0.6, 'r1_f1': 0.3846153846153846, 'pegasus_entailment': 0.6125464833208493, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2971014492753623, 'r1_recall': 0.45555555555555555, 'r1_f1': 0.35964912280701755, 'pegasus_entailment': 0.4804466813802719, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6125, 'r1_recall': 0.29878048780487804, 'r1_f1': 0.4016393442622951, 'pegasus_entailment': 0.6480180323123932, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.524822695035461, 'r1_recall': 0.2578397212543554, 'r1_f1': 0.34579439252336447, 'pegasus_entailment': 0.8908912539482117, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6951219512195121, 'r1_recall': 0.31843575418994413, 'r1_f1': 0.4367816091954023, 'pegasus_entailment': 0.608722448348999, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.5470085470085471, 'pegasus_entailment': 0.6600356213748455, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5581395348837209, 'r1_recall': 0.36923076923076925, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.3789946486552556, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3422818791946309, 'r1_recall': 0.49038461538461536, 'r1_f1': 0.4031620553359684, 'pegasus_entailment': 0.6602086573839188, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3904109589041096, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.4956521739130435, 'pegasus_entailment': 0.672099158167839, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7375, 'r1_recall': 0.36419753086419754, 'r1_f1': 0.48760330578512395, 'pegasus_entailment': 0.5452903553843498, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4742268041237113, 'r1_recall': 0.5974025974025974, 'r1_f1': 0.5287356321839081, 'pegasus_entailment': 0.4157569818198681, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 21, 'pegasus_ari': 34, 'pegasus_smog': 25}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6842105263157895, 'r1_recall': 0.4513888888888889, 'r1_f1': 0.5439330543933054, 'pegasus_entailment': 0.42085585941094905, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4485981308411215, 'r1_recall': 0.64, 'r1_f1': 0.5274725274725275, 'pegasus_entailment': 0.545948455731074, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.49586776859504134, 'r1_f1': 0.5529953917050691, 'pegasus_entailment': 0.7921659052371979, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5714285714285714, 'r1_recall': 0.6126126126126126, 'r1_f1': 0.591304347826087, 'pegasus_entailment': 0.7504397034645081, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49640287769784175, 'r1_recall': 0.4233128834355828, 'r1_f1': 0.45695364238410596, 'pegasus_entailment': 0.7153758406639099, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5877192982456141, 'r1_recall': 0.3806818181818182, 'r1_f1': 0.4620689655172414, 'pegasus_entailment': 0.3903159573674202, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39344262295081966, 'r1_recall': 0.6, 'r1_f1': 0.4752475247524752, 'pegasus_entailment': 0.28559451308101413, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2698412698412698, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.3655913978494623, 'pegasus_entailment': 0.3103298656642437, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3425925925925926, 'r1_recall': 0.6166666666666667, 'r1_f1': 0.4404761904761905, 'pegasus_entailment': 0.4848189353942871, 'pegasus_flesch_kincaid': 50, 'pegasus_coleman_liau': 18, 'pegasus_ari': 61, 'pegasus_smog': 32}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4774774774774775, 'r1_recall': 0.5408163265306123, 'r1_f1': 0.5071770334928231, 'pegasus_entailment': 0.7443739771842957, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.574468085106383, 'r1_recall': 0.6230769230769231, 'r1_f1': 0.5977859778597786, 'pegasus_entailment': 0.6611455952127775, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.203125, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.2988505747126437, 'pegasus_entailment': 0.5538761019706726, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5227272727272727, 'r1_recall': 0.40350877192982454, 'r1_f1': 0.4554455445544554, 'pegasus_entailment': 0.36638781676689786, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29518072289156627, 'r1_recall': 0.44144144144144143, 'r1_f1': 0.3537906137184115, 'pegasus_entailment': 0.4632329111918807, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5982142857142857, 'r1_recall': 0.3059360730593607, 'r1_f1': 0.40483383685800606, 'pegasus_entailment': 0.2933636959642172, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4016393442622951, 'r1_recall': 0.5975609756097561, 'r1_f1': 0.4803921568627451, 'pegasus_entailment': 0.5571486130356789, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3983739837398374, 'r1_recall': 0.5568181818181818, 'r1_f1': 0.46445497630331756, 'pegasus_entailment': 0.8623994588851929, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46308724832214765, 'r1_recall': 0.6831683168316832, 'r1_f1': 0.552, 'pegasus_entailment': 0.5113308224827051, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43609022556390975, 'r1_recall': 0.5370370370370371, 'r1_f1': 0.48132780082987553, 'pegasus_entailment': 0.5684201642870903, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1875, 'r1_recall': 0.4375, 'r1_f1': 0.2625, 'pegasus_entailment': 0.6938558034598827, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4392523364485981, 'r1_recall': 0.47474747474747475, 'r1_f1': 0.4563106796116505, 'pegasus_entailment': 0.5661094225943089, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44886363636363635, 'r1_recall': 0.5, 'r1_f1': 0.47305389221556887, 'pegasus_entailment': 0.7008199453353882, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4452054794520548, 'r1_recall': 0.41139240506329117, 'r1_f1': 0.4276315789473685, 'pegasus_entailment': 0.6863609671592712, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6559139784946236, 'r1_recall': 0.3160621761658031, 'r1_f1': 0.42657342657342656, 'pegasus_entailment': 0.42242670655250547, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5544554455445545, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5436893203883496, 'pegasus_entailment': 0.7149469455083212, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.475, 'r1_recall': 0.456, 'r1_f1': 0.46530612244897956, 'pegasus_entailment': 0.4130570888519287, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.216, 'r1_recall': 0.5192307692307693, 'r1_f1': 0.3050847457627119, 'pegasus_entailment': 0.31399669237434863, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25384615384615383, 'r1_recall': 0.5409836065573771, 'r1_f1': 0.3455497382198953, 'pegasus_entailment': 0.4061473372081916, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3425925925925926, 'r1_recall': 0.5967741935483871, 'r1_f1': 0.43529411764705883, 'pegasus_entailment': 0.42968251183629036, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23529411764705882, 'r1_recall': 0.4067796610169492, 'r1_f1': 0.2981366459627329, 'pegasus_entailment': 0.16883782390505075, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.41025641025641024, 'pegasus_entailment': 0.5562919874986013, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3305084745762712, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.3594470046082949, 'pegasus_entailment': 0.5275392060478529, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.17272727272727273, 'r1_recall': 0.475, 'r1_f1': 0.25333333333333335, 'pegasus_entailment': 0.5863654613494873, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4330357142857143, 'r1_recall': 0.5606936416184971, 'r1_f1': 0.48866498740554154, 'pegasus_entailment': 0.8049858212471008, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53125, 'r1_recall': 0.6375, 'r1_f1': 0.5795454545454545, 'pegasus_entailment': 0.397839680314064, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5886524822695035, 'r1_recall': 0.46629213483146065, 'r1_f1': 0.5203761755485893, 'pegasus_entailment': 0.4493711863954862, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6697247706422018, 'r1_recall': 0.453416149068323, 'r1_f1': 0.5407407407407407, 'pegasus_entailment': 0.6970231980085373, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5648148148148148, 'r1_recall': 0.4552238805970149, 'r1_f1': 0.5041322314049587, 'pegasus_entailment': 0.5876177151997884, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6697247706422018, 'r1_recall': 0.3004115226337449, 'r1_f1': 0.41477272727272724, 'pegasus_entailment': 0.3861895650625229, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3048780487804878, 'r1_recall': 0.3048780487804878, 'r1_f1': 0.3048780487804878, 'pegasus_entailment': 0.7048590257763863, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.580952380952381, 'r1_recall': 0.40131578947368424, 'r1_f1': 0.47470817120622577, 'pegasus_entailment': 0.8373359888792038, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35051546391752575, 'r1_recall': 0.4722222222222222, 'r1_f1': 0.40236686390532544, 'pegasus_entailment': 0.4483148315921426, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6857142857142857, 'r1_recall': 0.21524663677130046, 'r1_f1': 0.3276450511945393, 'pegasus_entailment': 0.4516259394586086, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2375, 'r1_recall': 0.168141592920354, 'r1_f1': 0.1968911917098446, 'pegasus_entailment': 0.3563977329370876, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2909090909090909, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.41025641025641024, 'pegasus_entailment': 0.6249985750764608, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5238095238095238, 'r1_recall': 0.30386740331491713, 'r1_f1': 0.38461538461538464, 'pegasus_entailment': 0.8131734132766724, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6363636363636364, 'r1_recall': 0.3163841807909605, 'r1_f1': 0.4226415094339622, 'pegasus_entailment': 0.43622495234012604, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4409448818897638, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.5022421524663677, 'pegasus_entailment': 0.7008512347936631, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6436781609195402, 'r1_recall': 0.38620689655172413, 'r1_f1': 0.48275862068965514, 'pegasus_entailment': 0.33684495091438293, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.10526315789473684, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.17777777777777778, 'pegasus_entailment': 0.5961997985839844, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24242424242424243, 'r1_recall': 0.41379310344827586, 'r1_f1': 0.3057324840764331, 'pegasus_entailment': 0.6260488331317902, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6309523809523809, 'r1_recall': 0.44537815126050423, 'r1_f1': 0.5221674876847291, 'pegasus_entailment': 0.29404733267923194, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21428571428571427, 'r1_recall': 0.5070422535211268, 'r1_f1': 0.30125523012552297, 'pegasus_entailment': 0.4928355866244861, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3218390804597701, 'r1_recall': 0.509090909090909, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.25126622058451176, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24675324675324675, 'r1_recall': 0.4691358024691358, 'r1_f1': 0.3234042553191489, 'pegasus_entailment': 0.703338885307312, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5700934579439252, 'r1_recall': 0.7530864197530864, 'r1_f1': 0.648936170212766, 'pegasus_entailment': 0.3494804981164634, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5058823529411764, 'r1_recall': 0.5180722891566265, 'r1_f1': 0.511904761904762, 'pegasus_entailment': 0.6397628635168076, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5869565217391305, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.5320197044334976, 'pegasus_entailment': 0.3808538168668747, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7209302325581395, 'r1_recall': 0.18452380952380953, 'r1_f1': 0.29383886255924174, 'pegasus_entailment': 0.4750573579221964, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5772357723577236, 'r1_recall': 0.31981981981981983, 'r1_f1': 0.41159420289855075, 'pegasus_entailment': 0.681549894809723, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2727272727272727, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.3620689655172414, 'pegasus_entailment': 0.6950721542040507, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5773195876288659, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5572139303482586, 'pegasus_entailment': 0.29879713207483294, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 12}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3047619047619048, 'r1_recall': 0.4383561643835616, 'r1_f1': 0.3595505617977528, 'pegasus_entailment': 0.4709047647193074, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4583333333333333, 'r1_recall': 0.5076923076923077, 'r1_f1': 0.48175182481751827, 'pegasus_entailment': 0.4379807114601135, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5584415584415584, 'r1_recall': 0.5972222222222222, 'r1_f1': 0.5771812080536912, 'pegasus_entailment': 0.44652173947542906, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4153846153846154, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5118483412322276, 'pegasus_entailment': 0.5173580825328827, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2857142857142857, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.38260869565217387, 'pegasus_entailment': 0.6125749170780181, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.4891304347826087, 'pegasus_entailment': 0.6169806718826294, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6097560975609756, 'r1_recall': 0.47770700636942676, 'r1_f1': 0.5357142857142857, 'pegasus_entailment': 0.4588583083823323, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.725, 'r1_recall': 0.4027777777777778, 'r1_f1': 0.5178571428571429, 'pegasus_entailment': 0.2857955666258931, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3898305084745763, 'r1_recall': 0.48936170212765956, 'r1_f1': 0.4339622641509434, 'pegasus_entailment': 0.6756517201662063, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6326530612244898, 'r1_recall': 0.32460732984293195, 'r1_f1': 0.4290657439446367, 'pegasus_entailment': 0.41943716009457904, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.304, 'r1_recall': 0.7755102040816326, 'r1_f1': 0.43678160919540227, 'pegasus_entailment': 0.7031233504414558, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37755102040816324, 'r1_recall': 0.4457831325301205, 'r1_f1': 0.4088397790055249, 'pegasus_entailment': 0.8282516151666641, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5599999999999999, 'pegasus_entailment': 0.3364373904963334, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 14}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39, 'r1_recall': 0.48148148148148145, 'r1_f1': 0.43093922651933697, 'pegasus_entailment': 0.5574856884777546, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.39416058394160586, 'r1_f1': 0.47577092511013214, 'pegasus_entailment': 0.6311478540301323, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1958762886597938, 'r1_recall': 0.4318181818181818, 'r1_f1': 0.2695035460992908, 'pegasus_entailment': 0.6988627115885416, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2524271844660194, 'r1_recall': 0.4406779661016949, 'r1_f1': 0.3209876543209876, 'pegasus_entailment': 0.6130781273047129, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45588235294117646, 'r1_recall': 0.4626865671641791, 'r1_f1': 0.45925925925925926, 'pegasus_entailment': 0.7218033224344254, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6756756756756757, 'r1_recall': 0.32051282051282054, 'r1_f1': 0.4347826086956522, 'pegasus_entailment': 0.4399121527870496, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.384, 'r1_recall': 0.7384615384615385, 'r1_f1': 0.505263157894737, 'pegasus_entailment': 0.5392576642334461, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3888888888888889, 'r1_recall': 0.3181818181818182, 'r1_f1': 0.35000000000000003, 'pegasus_entailment': 0.8124988675117493, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37362637362637363, 'r1_recall': 0.40476190476190477, 'r1_f1': 0.38857142857142857, 'pegasus_entailment': 0.6156468316912651, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38372093023255816, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.40490797546012264, 'pegasus_entailment': 0.5343942095836004, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31756756756756754, 'r1_recall': 0.5875, 'r1_f1': 0.41228070175438597, 'pegasus_entailment': 0.4919295385479927, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5096774193548387, 'r1_recall': 0.5064102564102564, 'r1_f1': 0.5080385852090031, 'pegasus_entailment': 0.4051272187914167, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31451612903225806, 'r1_recall': 0.5131578947368421, 'r1_f1': 0.39, 'pegasus_entailment': 0.30577885508537295, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40476190476190477, 'r1_recall': 0.6, 'r1_f1': 0.4834123222748815, 'pegasus_entailment': 0.49239592254161835, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48091603053435117, 'r1_recall': 0.48091603053435117, 'r1_f1': 0.48091603053435117, 'pegasus_entailment': 0.6837172359228134, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.336, 'r1_recall': 0.39622641509433965, 'r1_f1': 0.3636363636363637, 'pegasus_entailment': 0.3431853324174881, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5345911949685535, 'r1_recall': 0.4644808743169399, 'r1_f1': 0.4970760233918129, 'pegasus_entailment': 0.4944487636288007, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5176470588235295, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.5465838509316772, 'pegasus_entailment': 0.6787532195448875, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3586206896551724, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.43881856540084385, 'pegasus_entailment': 0.4574415609240532, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7216494845360825, 'r1_recall': 0.32407407407407407, 'r1_f1': 0.4472843450479233, 'pegasus_entailment': 0.6681190431118011, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4891304347826087, 'r1_recall': 0.44554455445544555, 'r1_f1': 0.46632124352331605, 'pegasus_entailment': 0.5070118783041835, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6029411764705882, 'r1_recall': 0.41836734693877553, 'r1_f1': 0.49397590361445787, 'pegasus_entailment': 0.3384382873773575, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.573170731707317, 'r1_recall': 0.6714285714285714, 'r1_f1': 0.6184210526315789, 'pegasus_entailment': 0.5352461735407511, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4520547945205479, 'r1_recall': 0.49624060150375937, 'r1_f1': 0.4731182795698925, 'pegasus_entailment': 0.5840541243553161, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4251968503937008, 'r1_recall': 0.6, 'r1_f1': 0.4976958525345623, 'pegasus_entailment': 0.6737633407115936, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45098039215686275, 'r1_recall': 0.4, 'r1_f1': 0.423963133640553, 'pegasus_entailment': 0.6542875568072001, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3007518796992481, 'r1_recall': 0.36036036036036034, 'r1_f1': 0.32786885245901637, 'pegasus_entailment': 0.5377448126673698, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.65, 'r1_recall': 0.37681159420289856, 'r1_f1': 0.47706422018348627, 'pegasus_entailment': 0.6357953250408173, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16748768472906403, 'r1_recall': 0.68, 'r1_f1': 0.26877470355731226, 'pegasus_entailment': 0.48896451741456987, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2727272727272727, 'r1_recall': 0.6964285714285714, 'r1_f1': 0.39195979899497485, 'pegasus_entailment': 0.4615897759795189, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16161616161616163, 'r1_recall': 0.3404255319148936, 'r1_f1': 0.21917808219178087, 'pegasus_entailment': 0.4808129258453846, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 16, 'pegasus_ari': 30, 'pegasus_smog': 19}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4235294117647059, 'r1_recall': 0.5070422535211268, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.7542008757591248, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6637168141592921, 'r1_recall': 0.4098360655737705, 'r1_f1': 0.5067567567567567, 'pegasus_entailment': 0.71630380153656, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5684210526315789, 'r1_recall': 0.39416058394160586, 'r1_f1': 0.4655172413793104, 'pegasus_entailment': 0.49078149497509005, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5142857142857142, 'r1_recall': 0.3956043956043956, 'r1_f1': 0.4472049689440994, 'pegasus_entailment': 0.6528112689654032, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4878048780487805, 'r1_recall': 0.45112781954887216, 'r1_f1': 0.46874999999999994, 'pegasus_entailment': 0.3158726617693901, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5915492957746479, 'r1_recall': 0.5121951219512195, 'r1_f1': 0.5490196078431372, 'pegasus_entailment': 0.5081589102745057, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8207547169811321, 'r1_recall': 0.43283582089552236, 'r1_f1': 0.5667752442996743, 'pegasus_entailment': 0.7945481836795807, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 24}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4067796610169492, 'r1_recall': 0.48, 'r1_f1': 0.44036697247706424, 'pegasus_entailment': 0.49912766367197037, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5212765957446809, 'r1_recall': 0.6125, 'r1_f1': 0.5632183908045978, 'pegasus_entailment': 0.6049029141664505, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40476190476190477, 'r1_recall': 0.4146341463414634, 'r1_f1': 0.4096385542168674, 'pegasus_entailment': 0.22438185413678488, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2, 'r1_recall': 0.5, 'r1_f1': 0.28571428571428575, 'pegasus_entailment': 0.766668975353241, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24285714285714285, 'r1_recall': 0.5396825396825397, 'r1_f1': 0.33497536945812806, 'pegasus_entailment': 0.7683663964271545, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18627450980392157, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.27941176470588236, 'pegasus_entailment': 0.5201807200908661, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25757575757575757, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.32692307692307687, 'pegasus_entailment': 0.4407361877150834, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.635036496350365, 'r1_recall': 0.47282608695652173, 'r1_f1': 0.5420560747663552, 'pegasus_entailment': 0.6604075481494268, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3368421052631579, 'r1_recall': 0.47761194029850745, 'r1_f1': 0.3950617283950617, 'pegasus_entailment': 0.7328931868076325, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5594405594405595, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5144694533762059, 'pegasus_entailment': 0.4193584465732177, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5221238938053098, 'r1_recall': 0.44696969696969696, 'r1_f1': 0.48163265306122455, 'pegasus_entailment': 0.7172692894935608, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.627906976744186, 'r1_recall': 0.34177215189873417, 'r1_f1': 0.4426229508196721, 'pegasus_entailment': 0.6216167435050011, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6538461538461539, 'r1_recall': 0.34459459459459457, 'r1_f1': 0.45132743362831856, 'pegasus_entailment': 0.707441379626592, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3225806451612903, 'r1_recall': 0.7272727272727273, 'r1_f1': 0.446927374301676, 'pegasus_entailment': 0.293211130425334, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.36548223350253806, 'r1_f1': 0.4324324324324324, 'pegasus_entailment': 0.4395460090599954, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.375, 'r1_recall': 0.7, 'r1_f1': 0.48837209302325574, 'pegasus_entailment': 0.5344156235456466, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5102040816326531, 'r1_recall': 0.4065040650406504, 'r1_f1': 0.45248868778280543, 'pegasus_entailment': 0.6704647898674011, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5596330275229358, 'r1_recall': 0.580952380952381, 'r1_f1': 0.5700934579439252, 'pegasus_entailment': 0.6977772315343221, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6027397260273972, 'r1_recall': 0.33587786259541985, 'r1_f1': 0.43137254901960786, 'pegasus_entailment': 0.47894929721951485, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2807017543859649, 'r1_recall': 0.47761194029850745, 'r1_f1': 0.3535911602209944, 'pegasus_entailment': 0.5192745253443718, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21875, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.32258064516129037, 'pegasus_entailment': 0.685415044426918, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29245283018867924, 'r1_recall': 0.543859649122807, 'r1_f1': 0.3803680981595092, 'pegasus_entailment': 0.6760816693305969, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5595238095238095, 'r1_recall': 0.3671875, 'r1_f1': 0.44339622641509435, 'pegasus_entailment': 0.3888249769806862, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5258620689655172, 'r1_recall': 0.34269662921348315, 'r1_f1': 0.41496598639455784, 'pegasus_entailment': 0.48170930785792215, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5871559633027523, 'r1_recall': 0.39263803680981596, 'r1_f1': 0.4705882352941177, 'pegasus_entailment': 0.5319487094879151, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6052631578947368, 'r1_recall': 0.35751295336787564, 'r1_f1': 0.4495114006514658, 'pegasus_entailment': 0.6319346725940704, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4166666666666667, 'r1_recall': 0.594059405940594, 'r1_f1': 0.489795918367347, 'pegasus_entailment': 0.47162246108055117, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30864197530864196, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.4065040650406504, 'pegasus_entailment': 0.40167891383171084, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24675324675324675, 'r1_recall': 0.4222222222222222, 'r1_f1': 0.3114754098360656, 'pegasus_entailment': 0.7202855587005615, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2653061224489796, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.348993288590604, 'pegasus_entailment': 0.6181944496929646, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5463917525773195, 'r1_recall': 0.3581081081081081, 'r1_f1': 0.43265306122448977, 'pegasus_entailment': 0.3857880290597677, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5384615384615384, 'r1_recall': 0.42748091603053434, 'r1_f1': 0.4765957446808511, 'pegasus_entailment': 0.32279550035794574, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.488, 'r1_recall': 0.5169491525423728, 'r1_f1': 0.5020576131687242, 'pegasus_entailment': 0.5819950153430303, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5511811023622047, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5447470817120622, 'pegasus_entailment': 0.5098807513713837, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46788990825688076, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.4473684210526315, 'pegasus_entailment': 0.28940185136161745, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7604166666666666, 'r1_recall': 0.5069444444444444, 'r1_f1': 0.6083333333333333, 'pegasus_entailment': 0.739960769812266, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43157894736842106, 'r1_recall': 0.45555555555555555, 'r1_f1': 0.44324324324324327, 'pegasus_entailment': 0.6064335763454437, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41739130434782606, 'r1_recall': 0.3609022556390977, 'r1_f1': 0.3870967741935483, 'pegasus_entailment': 0.2101848628371954, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.65, 'r1_recall': 0.36792452830188677, 'r1_f1': 0.46987951807228917, 'pegasus_entailment': 0.6918951719999313, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2534246575342466, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.36453201970443355, 'pegasus_entailment': 0.6658226698637009, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4146341463414634, 'r1_recall': 0.3984375, 'r1_f1': 0.4063745019920319, 'pegasus_entailment': 0.6162566343943278, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36363636363636365, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.4413793103448276, 'pegasus_entailment': 0.35630643367767334, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5272727272727272, 'r1_recall': 0.3036649214659686, 'r1_f1': 0.3853820598006644, 'pegasus_entailment': 0.6042539402842522, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5533980582524272, 'r1_recall': 0.3877551020408163, 'r1_f1': 0.456, 'pegasus_entailment': 0.43803736101835966, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.512, 'r1_recall': 0.4155844155844156, 'r1_f1': 0.45878136200716846, 'pegasus_entailment': 0.5577546606461207, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3089887640449438, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.4347826086956522, 'pegasus_entailment': 0.6603837410608927, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5775862068965517, 'r1_recall': 0.5826086956521739, 'r1_f1': 0.58008658008658, 'pegasus_entailment': 0.6201486065983772, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6344086021505376, 'r1_recall': 0.38562091503267976, 'r1_f1': 0.4796747967479675, 'pegasus_entailment': 0.5493087247014046, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3816793893129771, 'r1_recall': 0.49019607843137253, 'r1_f1': 0.4291845493562232, 'pegasus_entailment': 0.5180387228727341, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3409090909090909, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.4137931034482758, 'pegasus_entailment': 0.7145083174109459, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4606741573033708, 'r1_recall': 0.640625, 'r1_f1': 0.5359477124183006, 'pegasus_entailment': 0.670559361577034, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23857868020304568, 'r1_recall': 0.6266666666666667, 'r1_f1': 0.34558823529411764, 'pegasus_entailment': 0.6280752662569284, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28368794326241137, 'r1_recall': 0.7547169811320755, 'r1_f1': 0.4123711340206186, 'pegasus_entailment': 0.534083272020022, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5666666666666667, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.5573770491803278, 'pegasus_entailment': 0.8108065724372864, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5822784810126582, 'r1_recall': 0.7931034482758621, 'r1_f1': 0.6715328467153284, 'pegasus_entailment': 0.44513995945453644, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6265060240963856, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.5621621621621622, 'pegasus_entailment': 0.2821234464645386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48, 'r1_recall': 0.45569620253164556, 'r1_f1': 0.4675324675324675, 'pegasus_entailment': 0.44530246903498966, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2740740740740741, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.3854166666666667, 'pegasus_entailment': 0.6374925002455711, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5959595959595959, 'r1_recall': 0.3959731543624161, 'r1_f1': 0.4758064516129032, 'pegasus_entailment': 0.4386082887649536, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5161290322580645, 'r1_recall': 0.23357664233576642, 'r1_f1': 0.32160804020100503, 'pegasus_entailment': 0.5920418679714203, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 14, 'pegasus_ari': 11, 'pegasus_smog': 14}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28104575163398693, 'r1_recall': 0.6515151515151515, 'r1_f1': 0.3926940639269406, 'pegasus_entailment': 0.5055662453174591, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5813953488372093, 'r1_recall': 0.45045045045045046, 'r1_f1': 0.5076142131979695, 'pegasus_entailment': 0.45006218925118446, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33540372670807456, 'r1_recall': 0.675, 'r1_f1': 0.4481327800829876, 'pegasus_entailment': 0.7553877085447311, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6195652173913043, 'r1_recall': 0.44881889763779526, 'r1_f1': 0.5205479452054794, 'pegasus_entailment': 0.46628549706656486, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6615384615384615, 'r1_recall': 0.4365482233502538, 'r1_f1': 0.5259938837920489, 'pegasus_entailment': 0.6508480608463287, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6627218934911243, 'r1_recall': 0.4609053497942387, 'r1_f1': 0.5436893203883496, 'pegasus_entailment': 0.6355108966430029, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7247706422018348, 'r1_recall': 0.5683453237410072, 'r1_f1': 0.6370967741935485, 'pegasus_entailment': 0.3063703626394272, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1724137931034483, 'r1_recall': 0.0684931506849315, 'r1_f1': 0.09803921568627451, 'pegasus_entailment': 0.08133979141712189, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 11, 'pegasus_ari': 16, 'pegasus_smog': 8}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19852941176470587, 'r1_recall': 0.4426229508196721, 'r1_f1': 0.27411167512690354, 'pegasus_entailment': 0.5723375957459211, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4830508474576271, 'r1_recall': 0.6627906976744186, 'r1_f1': 0.5588235294117647, 'pegasus_entailment': 0.6243046298623085, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43023255813953487, 'r1_recall': 0.5, 'r1_f1': 0.46249999999999997, 'pegasus_entailment': 0.7014586329460144, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5548387096774193, 'r1_recall': 0.4942528735632184, 'r1_f1': 0.5227963525835866, 'pegasus_entailment': 0.5570059610264642, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4864864864864865, 'r1_recall': 0.375, 'r1_f1': 0.42352941176470593, 'pegasus_entailment': 0.44925788044929504, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5982905982905983, 'r1_recall': 0.358974358974359, 'r1_f1': 0.44871794871794873, 'pegasus_entailment': 0.44696809649467467, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47115384615384615, 'r1_recall': 0.6712328767123288, 'r1_f1': 0.5536723163841807, 'pegasus_entailment': 0.1730489529669285, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3700787401574803, 'r1_recall': 0.6266666666666667, 'r1_f1': 0.46534653465346537, 'pegasus_entailment': 0.8026982545852661, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42748091603053434, 'r1_recall': 0.49122807017543857, 'r1_f1': 0.4571428571428571, 'pegasus_entailment': 0.5805051997303963, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.78, 'r1_recall': 0.2074468085106383, 'r1_f1': 0.3277310924369748, 'pegasus_entailment': 0.5183591842651367, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3488372093023256, 'r1_recall': 0.5084745762711864, 'r1_f1': 0.41379310344827586, 'pegasus_entailment': 0.4261971712112427, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5957446808510638, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.42748091603053434, 'pegasus_entailment': 0.5643905594944953, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4240506329113924, 'r1_recall': 0.5193798449612403, 'r1_f1': 0.46689895470383275, 'pegasus_entailment': 0.4299915835261345, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5259259259259259, 'r1_recall': 0.47651006711409394, 'r1_f1': 0.5, 'pegasus_entailment': 0.6951553851366044, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5462184873949579, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.4513888888888889, 'pegasus_entailment': 0.4005549311637878, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44, 'r1_recall': 0.5038167938931297, 'r1_f1': 0.4697508896797153, 'pegasus_entailment': 0.4290229491889477, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3821138211382114, 'r1_recall': 0.3790322580645161, 'r1_f1': 0.3805668016194332, 'pegasus_entailment': 0.6183282807469368, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37254901960784315, 'r1_recall': 0.4578313253012048, 'r1_f1': 0.41081081081081083, 'pegasus_entailment': 0.3118539661169052, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26666666666666666, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.37209302325581395, 'pegasus_entailment': 0.3601117208600044, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 22}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5393258426966292, 'r1_recall': 0.41379310344827586, 'r1_f1': 0.4682926829268293, 'pegasus_entailment': 0.5379602372646332, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5688073394495413, 'r1_recall': 0.33513513513513515, 'r1_f1': 0.4217687074829932, 'pegasus_entailment': 0.47055692970752716, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5638297872340425, 'r1_recall': 0.5520833333333334, 'r1_f1': 0.5578947368421052, 'pegasus_entailment': 0.6123773604631424, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6353591160220995, 'r1_recall': 0.2987012987012987, 'r1_f1': 0.40636042402826855, 'pegasus_entailment': 0.5042361037598716, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5773195876288659, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.46473029045643155, 'pegasus_entailment': 0.502325713634491, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24113475177304963, 'r1_recall': 0.5230769230769231, 'r1_f1': 0.3300970873786408, 'pegasus_entailment': 0.5170303791761398, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28421052631578947, 'r1_recall': 0.45, 'r1_f1': 0.34838709677419355, 'pegasus_entailment': 0.78828364610672, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25, 'r1_recall': 0.4567901234567901, 'r1_f1': 0.3231441048034934, 'pegasus_entailment': 0.49398232872287434, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.3076923076923077, 'r1_f1': 0.380952380952381, 'pegasus_entailment': 0.5669788718223572, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2727272727272727, 'r1_recall': 0.313953488372093, 'r1_f1': 0.2918918918918919, 'pegasus_entailment': 0.5214952670037747, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5169491525423728, 'r1_recall': 0.391025641025641, 'r1_f1': 0.44525547445255476, 'pegasus_entailment': 0.6584614098072052, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5648854961832062, 'r1_recall': 0.4484848484848485, 'r1_f1': 0.5, 'pegasus_entailment': 0.6986455321311951, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24812030075187969, 'r1_recall': 0.5409836065573771, 'r1_f1': 0.3402061855670103, 'pegasus_entailment': 0.7827723026275635, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6239316239316239, 'r1_recall': 0.4866666666666667, 'r1_f1': 0.5468164794007491, 'pegasus_entailment': 0.5591140190760294, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3416666666666667, 'r1_recall': 0.45054945054945056, 'r1_f1': 0.38862559241706157, 'pegasus_entailment': 0.22658791323192418, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4140127388535032, 'r1_recall': 0.4961832061068702, 'r1_f1': 0.45138888888888895, 'pegasus_entailment': 0.3161278005157198, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3888888888888889, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.4765957446808511, 'pegasus_entailment': 0.5501415090901511, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53, 'r1_recall': 0.5047619047619047, 'r1_f1': 0.5170731707317073, 'pegasus_entailment': 0.5645731464028358, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45555555555555555, 'r1_recall': 0.5616438356164384, 'r1_f1': 0.5030674846625767, 'pegasus_entailment': 0.5850240443833172, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46875, 'r1_recall': 0.36, 'r1_f1': 0.40723981900452483, 'pegasus_entailment': 0.2724561234936118, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7341772151898734, 'r1_recall': 0.5087719298245614, 'r1_f1': 0.6010362694300517, 'pegasus_entailment': 0.24136992155884704, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40298507462686567, 'r1_recall': 0.6067415730337079, 'r1_f1': 0.4843049327354261, 'pegasus_entailment': 0.5236648801714182, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18269230769230768, 'r1_recall': 0.4418604651162791, 'r1_f1': 0.2585034013605442, 'pegasus_entailment': 0.3015216131461784, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5666666666666667, 'r1_recall': 0.3076923076923077, 'r1_f1': 0.3988269794721408, 'pegasus_entailment': 0.23440367628687195, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4631578947368421, 'r1_recall': 0.3893805309734513, 'r1_f1': 0.4230769230769231, 'pegasus_entailment': 0.3314610403031111, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.09502262443438914, 'r1_recall': 0.5675675675675675, 'r1_f1': 0.1627906976744186, 'pegasus_entailment': 0.6604368627071381, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 25}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36666666666666664, 'r1_recall': 0.5365853658536586, 'r1_f1': 0.4356435643564356, 'pegasus_entailment': 0.522095238789916, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33879781420765026, 'r1_recall': 0.5794392523364486, 'r1_f1': 0.4275862068965517, 'pegasus_entailment': 0.5271476097404957, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3291139240506329, 'r1_recall': 0.7222222222222222, 'r1_f1': 0.4521739130434782, 'pegasus_entailment': 0.9195612788200378, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5098039215686274, 'r1_recall': 0.5909090909090909, 'r1_f1': 0.5473684210526317, 'pegasus_entailment': 0.7777872085571289, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35507246376811596, 'r1_recall': 0.550561797752809, 'r1_f1': 0.43171806167400884, 'pegasus_entailment': 0.29178259428590536, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23118279569892472, 'r1_recall': 0.7288135593220338, 'r1_f1': 0.3510204081632653, 'pegasus_entailment': 0.5840718746185303, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5588235294117647, 'r1_recall': 0.5757575757575758, 'r1_f1': 0.5671641791044776, 'pegasus_entailment': 0.5058976233005523, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45714285714285713, 'r1_recall': 0.5, 'r1_f1': 0.4776119402985075, 'pegasus_entailment': 0.6712418496608734, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49557522123893805, 'r1_recall': 0.5957446808510638, 'r1_f1': 0.5410628019323672, 'pegasus_entailment': 0.5382455835739771, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8623853211009175, 'r1_recall': 0.18007662835249041, 'r1_f1': 0.2979397781299524, 'pegasus_entailment': 0.7702000141143799, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5648148148148148, 'r1_recall': 0.305, 'r1_f1': 0.396103896103896, 'pegasus_entailment': 0.5489356338977813, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32075471698113206, 'r1_recall': 0.4358974358974359, 'r1_f1': 0.3695652173913044, 'pegasus_entailment': 0.20209923386573792, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.594059405940594, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5825242718446602, 'pegasus_entailment': 0.6056196987628937, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 15, 'pegasus_ari': 30, 'pegasus_smog': 18}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.68, 'r1_recall': 0.375, 'r1_f1': 0.48341232227488146, 'pegasus_entailment': 0.6298333555459976, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5523809523809524, 'r1_recall': 0.5132743362831859, 'r1_f1': 0.5321100917431192, 'pegasus_entailment': 0.37211183831095695, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3253968253968254, 'r1_recall': 0.4823529411764706, 'r1_f1': 0.38862559241706157, 'pegasus_entailment': 0.8184705575307211, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 17}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49206349206349204, 'r1_recall': 0.4696969696969697, 'r1_f1': 0.48062015503875966, 'pegasus_entailment': 0.8625607093175253, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3983050847457627, 'r1_recall': 0.5108695652173914, 'r1_f1': 0.44761904761904764, 'pegasus_entailment': 0.3551782116293907, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4305555555555556, 'r1_recall': 0.37349397590361444, 'r1_f1': 0.4, 'pegasus_entailment': 0.512772424146533, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5783132530120482, 'r1_recall': 0.38095238095238093, 'r1_f1': 0.4593301435406698, 'pegasus_entailment': 0.4366057999432087, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5373134328358209, 'r1_recall': 0.35294117647058826, 'r1_f1': 0.4260355029585799, 'pegasus_entailment': 0.32485433916250867, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6022727272727273, 'r1_recall': 0.32919254658385094, 'r1_f1': 0.42570281124497994, 'pegasus_entailment': 0.6036211550235748, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 13}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2716049382716049, 'r1_recall': 0.38596491228070173, 'r1_f1': 0.3188405797101449, 'pegasus_entailment': 0.3073163108589749, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5238095238095238, 'r1_recall': 0.24336283185840707, 'r1_f1': 0.33232628398791547, 'pegasus_entailment': 0.36981090903282166, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25757575757575757, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.3541666666666667, 'pegasus_entailment': 0.515577665397099, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5161290322580645, 'r1_recall': 0.4752475247524752, 'r1_f1': 0.4948453608247423, 'pegasus_entailment': 0.778304323554039, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21333333333333335, 'r1_recall': 0.6530612244897959, 'r1_f1': 0.32160804020100503, 'pegasus_entailment': 0.5626005977392197, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.17307692307692307, 'r1_recall': 0.391304347826087, 'r1_f1': 0.24, 'pegasus_entailment': 0.635090458393097, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5503875968992248, 'r1_recall': 0.4863013698630137, 'r1_f1': 0.5163636363636362, 'pegasus_entailment': 0.6277516335248947, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4896907216494845, 'r1_recall': 0.4947916666666667, 'r1_f1': 0.49222797927461137, 'pegasus_entailment': 0.5997907902513232, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35772357723577236, 'r1_recall': 0.5945945945945946, 'r1_f1': 0.44670050761421315, 'pegasus_entailment': 0.7011303380131721, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5342465753424658, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.4534883720930233, 'pegasus_entailment': 0.4836561568081379, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4132231404958678, 'r1_recall': 0.6024096385542169, 'r1_f1': 0.49019607843137253, 'pegasus_entailment': 0.713262935479482, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36885245901639346, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.46632124352331605, 'pegasus_entailment': 0.3511446602642536, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38461538461538464, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.4577464788732394, 'pegasus_entailment': 0.43072380423545836, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6055045871559633, 'r1_recall': 0.39285714285714285, 'r1_f1': 0.4765342960288808, 'pegasus_entailment': 0.35578487114980817, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.211864406779661, 'r1_recall': 0.4716981132075472, 'r1_f1': 0.29239766081871343, 'pegasus_entailment': 0.6503561623394489, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5241935483870968, 'r1_recall': 0.6018518518518519, 'r1_f1': 0.560344827586207, 'pegasus_entailment': 0.4592871852219105, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4883720930232558, 'r1_recall': 0.18584070796460178, 'r1_f1': 0.2692307692307692, 'pegasus_entailment': 0.9004939595858256, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 23, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2808219178082192, 'r1_recall': 0.5774647887323944, 'r1_f1': 0.3778801843317972, 'pegasus_entailment': 0.6243804216384887, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5798319327731093, 'r1_recall': 0.3150684931506849, 'r1_f1': 0.40828402366863903, 'pegasus_entailment': 0.6257137656211853, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.08333333333333333, 'r1_recall': 0.3142857142857143, 'r1_f1': 0.13173652694610777, 'pegasus_entailment': 0.4705091789364815, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5486725663716814, 'r1_recall': 0.7469879518072289, 'r1_f1': 0.6326530612244897, 'pegasus_entailment': 0.5454468727111816, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1793103448275862, 'r1_recall': 0.5306122448979592, 'r1_f1': 0.26804123711340205, 'pegasus_entailment': 0.4943750949576497, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7181818181818181, 'r1_recall': 0.4647058823529412, 'r1_f1': 0.5642857142857143, 'pegasus_entailment': 0.5297838164493441, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5158730158730159, 'r1_recall': 0.5038759689922481, 'r1_f1': 0.5098039215686275, 'pegasus_entailment': 0.833868658542633, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3885350318471338, 'r1_recall': 0.7011494252873564, 'r1_f1': 0.5, 'pegasus_entailment': 0.7619022093713284, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45081967213114754, 'r1_recall': 0.41353383458646614, 'r1_f1': 0.4313725490196078, 'pegasus_entailment': 0.5617232844233513, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40310077519379844, 'r1_recall': 0.46846846846846846, 'r1_f1': 0.43333333333333335, 'pegasus_entailment': 0.4036387659609318, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28484848484848485, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.36015325670498083, 'pegasus_entailment': 0.4838643968105316, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5104895104895105, 'r1_recall': 0.5214285714285715, 'r1_f1': 0.5159010600706714, 'pegasus_entailment': 0.45109667629003525, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4491525423728814, 'r1_recall': 0.3680555555555556, 'r1_f1': 0.4045801526717558, 'pegasus_entailment': 0.40409862250089645, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.569620253164557, 'r1_recall': 0.4891304347826087, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.7325196489691734, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3893129770992366, 'r1_recall': 0.49514563106796117, 'r1_f1': 0.4358974358974359, 'pegasus_entailment': 0.766289214293162, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3493975903614458, 'r1_recall': 0.43283582089552236, 'r1_f1': 0.38666666666666666, 'pegasus_entailment': 0.4960238039493561, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38461538461538464, 'r1_recall': 0.6043956043956044, 'r1_f1': 0.47008547008547, 'pegasus_entailment': 0.467092901468277, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6923076923076923, 'r1_recall': 0.4405594405594406, 'r1_f1': 0.5384615384615384, 'pegasus_entailment': 0.38784564062953, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5959595959595959, 'r1_recall': 0.48360655737704916, 'r1_f1': 0.5339366515837105, 'pegasus_entailment': 0.3378147780895233, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5952380952380952, 'r1_recall': 0.45180722891566266, 'r1_f1': 0.5136986301369864, 'pegasus_entailment': 0.48454082012176514, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37, 'r1_recall': 0.6727272727272727, 'r1_f1': 0.4774193548387097, 'pegasus_entailment': 0.2868343472480774, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3541666666666667, 'r1_recall': 0.4594594594594595, 'r1_f1': 0.4000000000000001, 'pegasus_entailment': 0.3542625233530998, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5730994152046783, 'r1_recall': 0.4803921568627451, 'r1_f1': 0.5226666666666667, 'pegasus_entailment': 0.6547221839427948, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.25925925925925924, 'r1_f1': 0.37333333333333335, 'pegasus_entailment': 0.15764727319280306, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5196850393700787, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.532258064516129, 'pegasus_entailment': 0.6101354598999024, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4090909090909091, 'r1_recall': 0.4405594405594406, 'r1_f1': 0.42424242424242425, 'pegasus_entailment': 0.23069642271314347, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34459459459459457, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.43404255319148927, 'pegasus_entailment': 0.48367043149967986, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49107142857142855, 'r1_recall': 0.6043956043956044, 'r1_f1': 0.541871921182266, 'pegasus_entailment': 0.5939199229081472, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5698924731182796, 'r1_recall': 0.5196078431372549, 'r1_f1': 0.5435897435897437, 'pegasus_entailment': 0.443744283169508, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4049586776859504, 'r1_recall': 0.4298245614035088, 'r1_f1': 0.41702127659574467, 'pegasus_entailment': 0.47696413695812223, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5054945054945055, 'r1_recall': 0.46464646464646464, 'r1_f1': 0.4842105263157894, 'pegasus_entailment': 0.47815547604113817, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2708333333333333, 'r1_recall': 0.43820224719101125, 'r1_f1': 0.33476394849785407, 'pegasus_entailment': 0.43160770693793893, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6853932584269663, 'r1_recall': 0.37423312883435583, 'r1_f1': 0.48412698412698413, 'pegasus_entailment': 0.2894093990325928, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5737704918032787, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.46052631578947373, 'pegasus_entailment': 0.3677360676229, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.64, 'r1_recall': 0.23272727272727273, 'r1_f1': 0.3413333333333333, 'pegasus_entailment': 0.5252489211658636, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5324675324675324, 'r1_recall': 0.3761467889908257, 'r1_f1': 0.4408602150537634, 'pegasus_entailment': 0.8363401492436727, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16071428571428573, 'r1_recall': 0.3103448275862069, 'r1_f1': 0.21176470588235297, 'pegasus_entailment': 0.3457467663101852, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5130434782608696, 'r1_recall': 0.3259668508287293, 'r1_f1': 0.39864864864864863, 'pegasus_entailment': 0.5790630280971527, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2891566265060241, 'r1_recall': 0.6233766233766234, 'r1_f1': 0.3950617283950617, 'pegasus_entailment': 0.4495223253965378, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.366412213740458, 'r1_recall': 0.6, 'r1_f1': 0.4549763033175355, 'pegasus_entailment': 0.5585023403167725, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5465116279069767, 'r1_recall': 0.5053763440860215, 'r1_f1': 0.5251396648044693, 'pegasus_entailment': 0.4892889693379402, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3216374269005848, 'r1_recall': 0.6790123456790124, 'r1_f1': 0.4365079365079365, 'pegasus_entailment': 0.6020141541957855, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47474747474747475, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.4973544973544973, 'pegasus_entailment': 0.5774325355887413, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24705882352941178, 'r1_recall': 0.30434782608695654, 'r1_f1': 0.27272727272727276, 'pegasus_entailment': 0.5491951256990433, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3979591836734694, 'r1_recall': 0.40625, 'r1_f1': 0.40206185567010305, 'pegasus_entailment': 0.3117429297417402, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22435897435897437, 'r1_recall': 0.546875, 'r1_f1': 0.31818181818181823, 'pegasus_entailment': 0.642843212400164, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41025641025641024, 'r1_recall': 0.5274725274725275, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.7249060869216919, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 20, 'pegasus_ari': 38, 'pegasus_smog': 25}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47115384615384615, 'r1_recall': 0.5568181818181818, 'r1_f1': 0.5104166666666667, 'pegasus_entailment': 0.5920843213796616, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37168141592920356, 'r1_recall': 0.6774193548387096, 'r1_f1': 0.48, 'pegasus_entailment': 0.3228264699379603, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53125, 'r1_recall': 0.6355140186915887, 'r1_f1': 0.5787234042553191, 'pegasus_entailment': 0.7505555152893066, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2727272727272727, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.3468208092485549, 'pegasus_entailment': 0.35186103731393814, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.78125, 'r1_recall': 0.2830188679245283, 'r1_f1': 0.41551246537396125, 'pegasus_entailment': 0.7326204776763916, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3008130081300813, 'r1_recall': 0.578125, 'r1_f1': 0.39572192513368987, 'pegasus_entailment': 0.3624199390411377, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45161290322580644, 'r1_recall': 0.45652173913043476, 'r1_f1': 0.4540540540540541, 'pegasus_entailment': 0.6767552196979523, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6176470588235294, 'r1_recall': 0.42, 'r1_f1': 0.5, 'pegasus_entailment': 0.7729672193527222, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4652777777777778, 'r1_recall': 0.4785714285714286, 'r1_f1': 0.471830985915493, 'pegasus_entailment': 0.5225115306675434, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5581395348837209, 'r1_recall': 0.5106382978723404, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.5854346267879009, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5277777777777778, 'r1_recall': 0.5984251968503937, 'r1_f1': 0.5608856088560885, 'pegasus_entailment': 0.576496496796608, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31496062992125984, 'r1_recall': 0.5633802816901409, 'r1_f1': 0.40404040404040403, 'pegasus_entailment': 0.5607479453086853, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3893129770992366, 'r1_recall': 0.5425531914893617, 'r1_f1': 0.4533333333333333, 'pegasus_entailment': 0.5509363561868668, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35294117647058826, 'r1_recall': 0.5, 'r1_f1': 0.41379310344827586, 'pegasus_entailment': 0.6331271901726723, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3697478991596639, 'r1_recall': 0.5945945945945946, 'r1_f1': 0.45595854922279794, 'pegasus_entailment': 0.5842207372188568, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 23}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36082474226804123, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.42682926829268286, 'pegasus_entailment': 0.3910604566335678, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28888888888888886, 'r1_recall': 0.40625, 'r1_f1': 0.3376623376623376, 'pegasus_entailment': 0.2925424873828888, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44, 'r1_recall': 0.3179190751445087, 'r1_f1': 0.36912751677852357, 'pegasus_entailment': 0.38132974079677034, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5357142857142857, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.43321299638989175, 'pegasus_entailment': 0.6007225438952446, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49557522123893805, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5308056872037914, 'pegasus_entailment': 0.39308541143933934, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6103896103896104, 'r1_recall': 0.25133689839572193, 'r1_f1': 0.3560606060606061, 'pegasus_entailment': 0.6237019201119741, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4375, 'r1_recall': 0.5157894736842106, 'r1_f1': 0.47342995169082125, 'pegasus_entailment': 0.15538834314793348, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3548387096774194, 'r1_recall': 0.6111111111111112, 'r1_f1': 0.4489795918367347, 'pegasus_entailment': 0.3531760280020535, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36470588235294116, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.44285714285714284, 'pegasus_entailment': 0.6270374283194542, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16847826086956522, 'r1_recall': 0.7380952380952381, 'r1_f1': 0.2743362831858407, 'pegasus_entailment': 0.5591985821723938, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3474576271186441, 'r1_recall': 0.5774647887323944, 'r1_f1': 0.43386243386243384, 'pegasus_entailment': 0.6284926608204842, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2682926829268293, 'r1_recall': 0.6346153846153846, 'r1_f1': 0.37714285714285717, 'pegasus_entailment': 0.5059975783030192, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3893805309734513, 'r1_recall': 0.37606837606837606, 'r1_f1': 0.382608695652174, 'pegasus_entailment': 0.544543232768774, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5565217391304348, 'r1_recall': 0.48854961832061067, 'r1_f1': 0.5203252032520325, 'pegasus_entailment': 0.676344707608223, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32679738562091504, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.4219409282700422, 'pegasus_entailment': 0.3517763428390026, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4883720930232558, 'r1_recall': 0.35, 'r1_f1': 0.4077669902912621, 'pegasus_entailment': 0.49714462757110595, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4019607843137255, 'r1_recall': 0.45054945054945056, 'r1_f1': 0.42487046632124353, 'pegasus_entailment': 0.6447470684846243, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37681159420289856, 'r1_recall': 0.4727272727272727, 'r1_f1': 0.41935483870967744, 'pegasus_entailment': 0.7809694111347198, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5053763440860215, 'r1_recall': 0.5108695652173914, 'r1_f1': 0.508108108108108, 'pegasus_entailment': 0.5922582944234213, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46153846153846156, 'r1_recall': 0.42, 'r1_f1': 0.4397905759162304, 'pegasus_entailment': 0.7536548872788748, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.358695652173913, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.4099378881987578, 'pegasus_entailment': 0.7042716344197592, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5376344086021505, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.5570486970245838, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3617021276595745, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.3469387755102041, 'pegasus_entailment': 0.7273746579885483, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4205607476635514, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.47120418848167533, 'pegasus_entailment': 0.8186355630556742, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1744186046511628, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.26785714285714285, 'pegasus_entailment': 0.6965209186077118, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6883116883116883, 'r1_recall': 0.3706293706293706, 'r1_f1': 0.48181818181818176, 'pegasus_entailment': 0.6517106592655182, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45535714285714285, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.5125628140703518, 'pegasus_entailment': 0.7101704776287079, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3153153153153153, 'r1_recall': 0.6481481481481481, 'r1_f1': 0.42424242424242425, 'pegasus_entailment': 0.4265016441543897, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5638297872340425, 'r1_recall': 0.4380165289256198, 'r1_f1': 0.4930232558139534, 'pegasus_entailment': 0.5597939218084017, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33695652173913043, 'r1_recall': 0.2980769230769231, 'r1_f1': 0.31632653061224486, 'pegasus_entailment': 0.28346450813114643, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24855491329479767, 'r1_recall': 0.6142857142857143, 'r1_f1': 0.35390946502057613, 'pegasus_entailment': 0.7210965553919474, 'pegasus_flesch_kincaid': 31, 'pegasus_coleman_liau': 19, 'pegasus_ari': 36, 'pegasus_smog': 26}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38461538461538464, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.4, 'pegasus_entailment': 0.3473808616399765, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3900709219858156, 'r1_recall': 0.6179775280898876, 'r1_f1': 0.4782608695652174, 'pegasus_entailment': 0.5744590684771538, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.17777777777777778, 'r1_recall': 0.35555555555555557, 'r1_f1': 0.23703703703703705, 'pegasus_entailment': 0.5580895096063614, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5213675213675214, 'r1_recall': 0.5922330097087378, 'r1_f1': 0.5545454545454545, 'pegasus_entailment': 0.5001824796199799, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.10084033613445378, 'r1_recall': 0.34285714285714286, 'r1_f1': 0.15584415584415587, 'pegasus_entailment': 0.6785400450229645, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3118279569892473, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.42028985507246375, 'pegasus_entailment': 0.6629041910171509, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30303030303030304, 'r1_recall': 0.7692307692307693, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.37704103253781796, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45098039215686275, 'r1_recall': 0.3108108108108108, 'r1_f1': 0.368, 'pegasus_entailment': 0.3386633090674877, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6447368421052632, 'r1_recall': 0.4260869565217391, 'r1_f1': 0.5130890052356022, 'pegasus_entailment': 0.39899813880523044, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.589041095890411, 'r1_recall': 0.4479166666666667, 'r1_f1': 0.5088757396449705, 'pegasus_entailment': 0.5281783975660801, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.6422018348623854, 'r1_f1': 0.5622489959839357, 'pegasus_entailment': 0.5147545430809259, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6551724137931034, 'r1_recall': 0.41304347826086957, 'r1_f1': 0.5066666666666666, 'pegasus_entailment': 0.4817139506340027, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8555555555555555, 'r1_recall': 0.21875, 'r1_f1': 0.34841628959276016, 'pegasus_entailment': 0.8089087903499603, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3225806451612903, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.4040404040404041, 'pegasus_entailment': 0.6430126011371613, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5975609756097561, 'r1_recall': 0.3288590604026846, 'r1_f1': 0.4242424242424243, 'pegasus_entailment': 0.7270730286836624, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.37583892617449666, 'r1_f1': 0.4571428571428572, 'pegasus_entailment': 0.6248853951692581, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2235294117647059, 'r1_recall': 0.3877551020408163, 'r1_f1': 0.28358208955223885, 'pegasus_entailment': 0.5479617317517599, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27325581395348836, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.38524590163934425, 'pegasus_entailment': 0.5382859706878662, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 22}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.4368932038834952, 'pegasus_entailment': 0.7412221307555834, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6821705426356589, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.6308243727598566, 'pegasus_entailment': 0.697112786769867, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.411214953271028, 'r1_recall': 0.6567164179104478, 'r1_f1': 0.5057471264367815, 'pegasus_entailment': 0.4630494648590684, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7227722772277227, 'r1_recall': 0.42441860465116277, 'r1_f1': 0.5347985347985347, 'pegasus_entailment': 0.49379144608974457, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32323232323232326, 'r1_recall': 0.43243243243243246, 'r1_f1': 0.3699421965317919, 'pegasus_entailment': 0.488835205634435, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.4691358024691358, 'r1_f1': 0.3897435897435897, 'pegasus_entailment': 0.793456494808197, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5363636363636364, 'r1_recall': 0.41843971631205673, 'r1_f1': 0.47011952191235057, 'pegasus_entailment': 0.8380859891573588, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4444444444444444, 'r1_recall': 0.42748091603053434, 'r1_f1': 0.43579766536964976, 'pegasus_entailment': 0.6536489129066467, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6213592233009708, 'r1_recall': 0.3004694835680751, 'r1_f1': 0.4050632911392405, 'pegasus_entailment': 0.6893047317862511, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 21}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3717948717948718, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.47154471544715454, 'pegasus_entailment': 0.5126483082771301, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5588235294117647, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.608, 'pegasus_entailment': 0.21815470606088638, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5032679738562091, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.4502923976608187, 'pegasus_entailment': 0.44607687890529635, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.61, 'r1_recall': 0.20065789473684212, 'r1_f1': 0.30198019801980197, 'pegasus_entailment': 0.41280115619301794, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30666666666666664, 'r1_recall': 0.36507936507936506, 'r1_f1': 0.33333333333333326, 'pegasus_entailment': 0.37576694786548615, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.427536231884058, 'r1_recall': 0.6210526315789474, 'r1_f1': 0.5064377682403434, 'pegasus_entailment': 0.47248690128326415, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5961538461538461, 'r1_recall': 0.3924050632911392, 'r1_f1': 0.47328244274809156, 'pegasus_entailment': 0.3918276329835256, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30434782608695654, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.3733333333333333, 'pegasus_entailment': 0.7349880337715149, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6619718309859155, 'r1_recall': 0.2596685082872928, 'r1_f1': 0.373015873015873, 'pegasus_entailment': 0.6812121629714966, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 13}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4953271028037383, 'r1_recall': 0.3732394366197183, 'r1_f1': 0.42570281124497994, 'pegasus_entailment': 0.4854816819541156, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4946236559139785, 'r1_recall': 0.4842105263157895, 'r1_f1': 0.4893617021276596, 'pegasus_entailment': 0.49585745483636856, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5409836065573771, 'r1_recall': 0.38372093023255816, 'r1_f1': 0.44897959183673475, 'pegasus_entailment': 0.6189742162823677, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2348993288590604, 'r1_recall': 0.49295774647887325, 'r1_f1': 0.3181818181818182, 'pegasus_entailment': 0.7055622488260269, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7741935483870968, 'r1_recall': 0.34615384615384615, 'r1_f1': 0.47840531561461797, 'pegasus_entailment': 0.5573438704013824, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4632352941176471, 'r1_recall': 0.6774193548387096, 'r1_f1': 0.5502183406113537, 'pegasus_entailment': 0.8109116355578104, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 19}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.308411214953271, 'r1_recall': 0.44, 'r1_f1': 0.3626373626373626, 'pegasus_entailment': 0.7793782353401184, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5494505494505495, 'r1_recall': 0.704225352112676, 'r1_f1': 0.6172839506172839, 'pegasus_entailment': 0.40902961492538453, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49333333333333335, 'r1_recall': 0.36633663366336633, 'r1_f1': 0.42045454545454547, 'pegasus_entailment': 0.42507406510412693, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.684931506849315, 'r1_recall': 0.4830917874396135, 'r1_f1': 0.56657223796034, 'pegasus_entailment': 0.7533052325248718, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36363636363636365, 'r1_recall': 0.5490196078431373, 'r1_f1': 0.43750000000000006, 'pegasus_entailment': 0.517834797501564, 'pegasus_flesch_kincaid': 36, 'pegasus_coleman_liau': 17, 'pegasus_ari': 45, 'pegasus_smog': 24}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2857142857142857, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.37209302325581395, 'pegasus_entailment': 0.7366804281870524, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.5112359550561798, 'r1_f1': 0.5449101796407186, 'pegasus_entailment': 0.5300587763388952, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4358974358974359, 'r1_recall': 0.4657534246575342, 'r1_f1': 0.45033112582781454, 'pegasus_entailment': 0.3838203027844429, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2891566265060241, 'r1_recall': 0.631578947368421, 'r1_f1': 0.396694214876033, 'pegasus_entailment': 0.6430477897326151, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5526315789473685, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.6146341463414634, 'pegasus_entailment': 0.5911403894424438, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49056603773584906, 'r1_recall': 0.43333333333333335, 'r1_f1': 0.46017699115044247, 'pegasus_entailment': 0.6605715692043305, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7967479674796748, 'r1_recall': 0.13900709219858157, 'r1_f1': 0.23671497584541065, 'pegasus_entailment': 0.6277537435526028, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5764705882352941, 'r1_recall': 0.34507042253521125, 'r1_f1': 0.4317180616740088, 'pegasus_entailment': 0.6852381378412247, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6019417475728155, 'r1_recall': 0.33879781420765026, 'r1_f1': 0.4335664335664336, 'pegasus_entailment': 0.5498359426856041, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4528301886792453, 'r1_recall': 0.5161290322580645, 'r1_f1': 0.4824120603015076, 'pegasus_entailment': 0.5069712121039629, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43023255813953487, 'r1_recall': 0.6379310344827587, 'r1_f1': 0.5138888888888888, 'pegasus_entailment': 0.44695581775158644, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43564356435643564, 'r1_recall': 0.676923076923077, 'r1_f1': 0.5301204819277109, 'pegasus_entailment': 0.43928880989551544, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.532258064516129, 'r1_recall': 0.42038216560509556, 'r1_f1': 0.4697508896797153, 'pegasus_entailment': 0.6035769134759903, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23469387755102042, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.31506849315068497, 'pegasus_entailment': 0.552516108751297, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4157303370786517, 'r1_recall': 0.38144329896907214, 'r1_f1': 0.3978494623655914, 'pegasus_entailment': 0.5251320004463196, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.2782608695652174, 'pegasus_entailment': 0.2869273377582431, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5257731958762887, 'r1_f1': 0.5125628140703519, 'pegasus_entailment': 0.9068611413240433, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42592592592592593, 'r1_recall': 0.40707964601769914, 'r1_f1': 0.416289592760181, 'pegasus_entailment': 0.4760657008155249, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6629213483146067, 'r1_recall': 0.43703703703703706, 'r1_f1': 0.5267857142857143, 'pegasus_entailment': 0.19977375073358417, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2535211267605634, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.288, 'pegasus_entailment': 0.3666082337498665, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.368, 'r1_recall': 0.46, 'r1_f1': 0.4088888888888889, 'pegasus_entailment': 0.7696442246437073, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.08333333333333333
MEAN
0.45368173308715803
MAX
0.8623853211009175
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.0684931506849315
MEAN
0.4819224673736361
MAX
0.7931034482758621
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.09803921568627451
MEAN
0.4417281715412319
MAX
0.6792452830188679
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.08133979141712189
MEAN
0.5551492355504287
MAX
0.9206894189119339
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
17
MAX
50
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
11
MEAN
17
MAX
23
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
11
MEAN
20
MAX
61
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
8
MEAN
18
MAX
32
{}
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4084507042253521, 'r1_recall': 0.5272727272727272, 'r1_f1': 0.46031746031746035, 'pegasus_entailment': 0.7724915146827698, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6593406593406593, 'r1_recall': 0.3468208092485549, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.6576289087533951, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.4724409448818897, 'pegasus_entailment': 0.5390811171382666, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7349397590361446, 'r1_recall': 0.4728682170542636, 'r1_f1': 0.5754716981132076, 'pegasus_entailment': 0.4870912486997743, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7029702970297029, 'r1_recall': 0.40804597701149425, 'r1_f1': 0.5163636363636364, 'pegasus_entailment': 0.4424409940838814, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4178082191780822, 'r1_recall': 0.46923076923076923, 'r1_f1': 0.4420289855072464, 'pegasus_entailment': 0.3408838614821434, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16666666666666666, 'r1_recall': 0.375, 'r1_f1': 0.23076923076923078, 'pegasus_entailment': 0.28631126740947366, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22772277227722773, 'r1_recall': 0.7419354838709677, 'r1_f1': 0.3484848484848485, 'pegasus_entailment': 0.5533858048729599, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7415730337078652, 'r1_recall': 0.4429530201342282, 'r1_f1': 0.5546218487394958, 'pegasus_entailment': 0.47559825237840414, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6428571428571429, 'r1_recall': 0.5869565217391305, 'r1_f1': 0.6136363636363638, 'pegasus_entailment': 0.6252761855721474, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7027027027027027, 'r1_recall': 0.3466666666666667, 'r1_f1': 0.46428571428571436, 'pegasus_entailment': 0.516546007245779, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5892857142857143, 'r1_recall': 0.5546218487394958, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.889235277970632, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7887323943661971, 'r1_recall': 0.5233644859813084, 'r1_f1': 0.6292134831460674, 'pegasus_entailment': 0.7453572247177362, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5873015873015873, 'r1_recall': 0.42045454545454547, 'r1_f1': 0.4900662251655629, 'pegasus_entailment': 0.7580639521280924, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8701298701298701, 'r1_recall': 0.3489583333333333, 'r1_f1': 0.4981412639405205, 'pegasus_entailment': 0.655083179473877, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21052631578947367, 'r1_recall': 0.2033898305084746, 'r1_f1': 0.20689655172413796, 'pegasus_entailment': 0.6182583371798197, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4722222222222222, 'r1_recall': 0.3434343434343434, 'r1_f1': 0.39766081871345027, 'pegasus_entailment': 0.6825147171815237, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7951807228915663, 'r1_recall': 0.2214765100671141, 'r1_f1': 0.3464566929133859, 'pegasus_entailment': 0.38432972878217697, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6639344262295082, 'r1_recall': 0.5031055900621118, 'r1_f1': 0.5724381625441696, 'pegasus_entailment': 0.42666998878121376, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5494505494505495, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.5617977528089888, 'pegasus_entailment': 0.5804827511310577, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6194690265486725, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.47457627118644063, 'pegasus_entailment': 0.4292094074189663, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5693430656934306, 'r1_recall': 0.52, 'r1_f1': 0.5435540069686411, 'pegasus_entailment': 0.6179236595829328, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3963963963963964, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.4018264840182648, 'pegasus_entailment': 0.69203253587087, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 26}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6810344827586207, 'r1_recall': 0.5808823529411765, 'r1_f1': 0.626984126984127, 'pegasus_entailment': 0.5345117092132569, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3723404255319149, 'r1_recall': 0.7, 'r1_f1': 0.48611111111111105, 'pegasus_entailment': 0.6895427651082476, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6201117318435754, 'r1_recall': 0.5873015873015873, 'r1_f1': 0.6032608695652174, 'pegasus_entailment': 0.482532124966383, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5811965811965812, 'r1_recall': 0.49635036496350365, 'r1_f1': 0.5354330708661418, 'pegasus_entailment': 0.5321875838562846, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8620689655172413, 'r1_recall': 0.2798507462686567, 'r1_f1': 0.4225352112676056, 'pegasus_entailment': 0.6074931671222051, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42592592592592593, 'r1_recall': 0.3026315789473684, 'r1_f1': 0.3538461538461538, 'pegasus_entailment': 0.8554395437240601, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 12, 'pegasus_ari': 12, 'pegasus_smog': 11}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40404040404040403, 'r1_recall': 0.35398230088495575, 'r1_f1': 0.3773584905660377, 'pegasus_entailment': 0.5586630403995514, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 15, 'pegasus_ari': 30, 'pegasus_smog': 19}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4818181818181818, 'r1_recall': 0.6091954022988506, 'r1_f1': 0.5380710659898478, 'pegasus_entailment': 0.7331172972917557, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5688073394495413, 'r1_recall': 0.30845771144278605, 'r1_f1': 0.4, 'pegasus_entailment': 0.5389385223388672, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2708333333333333, 'r1_recall': 0.3786407766990291, 'r1_f1': 0.3157894736842105, 'pegasus_entailment': 0.6817261576652527, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6268656716417911, 'r1_recall': 0.4329896907216495, 'r1_f1': 0.5121951219512195, 'pegasus_entailment': 0.4571133553981781, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42016806722689076, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.49261083743842365, 'pegasus_entailment': 0.24310313016176224, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44, 'r1_recall': 0.5689655172413793, 'r1_f1': 0.49624060150375937, 'pegasus_entailment': 0.5995419124762217, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 16, 'pegasus_ari': 31, 'pegasus_smog': 22}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4824561403508772, 'r1_recall': 0.7971014492753623, 'r1_f1': 0.6010928961748634, 'pegasus_entailment': 0.3558418992906809, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3392857142857143, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.4222222222222223, 'pegasus_entailment': 0.7086844330769964, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2158273381294964, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.32608695652173914, 'pegasus_entailment': 0.5585499167442322, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5027027027027027, 'r1_recall': 0.5602409638554217, 'r1_f1': 0.5299145299145298, 'pegasus_entailment': 0.5907276675105095, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7029702970297029, 'r1_recall': 0.44375, 'r1_f1': 0.5440613026819924, 'pegasus_entailment': 0.6363784652203321, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5967741935483871, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.5323741007194245, 'pegasus_entailment': 0.6368355502684911, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5733333333333334, 'r1_recall': 0.589041095890411, 'r1_f1': 0.5810810810810811, 'pegasus_entailment': 0.4572935209920009, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8, 'r1_recall': 0.5203252032520326, 'r1_f1': 0.6305418719211824, 'pegasus_entailment': 0.8583741585413615, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3684210526315789, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.4046242774566474, 'pegasus_entailment': 0.6639065742492676, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4692737430167598, 'r1_recall': 0.56, 'r1_f1': 0.5106382978723405, 'pegasus_entailment': 0.47598588466644287, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.61, 'r1_recall': 0.5169491525423728, 'r1_f1': 0.5596330275229358, 'pegasus_entailment': 0.5543049506377429, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.7027027027027027, 'r1_f1': 0.5098039215686274, 'pegasus_entailment': 0.7242395494665418, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3708609271523179, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.47659574468085103, 'pegasus_entailment': 0.554472331268092, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3983739837398374, 'r1_recall': 0.47115384615384615, 'r1_f1': 0.4317180616740089, 'pegasus_entailment': 0.49961447566747663, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3082706766917293, 'r1_recall': 0.5540540540540541, 'r1_f1': 0.3961352657004831, 'pegasus_entailment': 0.5740776658058167, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24427480916030533, 'r1_recall': 0.6274509803921569, 'r1_f1': 0.3516483516483516, 'pegasus_entailment': 0.6189645236978928, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35537190082644626, 'r1_recall': 0.581081081081081, 'r1_f1': 0.441025641025641, 'pegasus_entailment': 0.4952914547175169, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.3107344632768362, 'r1_f1': 0.4119850187265918, 'pegasus_entailment': 0.2732164611419042, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6642857142857143, 'r1_recall': 0.5224719101123596, 'r1_f1': 0.5849056603773586, 'pegasus_entailment': 0.3126731589436531, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42727272727272725, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.5164835164835165, 'pegasus_entailment': 0.5515370219945908, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6196319018404908, 'r1_recall': 0.40239043824701193, 'r1_f1': 0.48792270531400955, 'pegasus_entailment': 0.5853856280446053, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39090909090909093, 'r1_recall': 0.671875, 'r1_f1': 0.4942528735632184, 'pegasus_entailment': 0.5879095159471035, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.6115702479338843, 'r1_f1': 0.6379310344827586, 'pegasus_entailment': 0.44853512570261955, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5918367346938775, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.30873304853836697, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42391304347826086, 'r1_recall': 0.4431818181818182, 'r1_f1': 0.4333333333333333, 'pegasus_entailment': 0.8287956515947977, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4358974358974359, 'r1_recall': 0.4722222222222222, 'r1_f1': 0.45333333333333337, 'pegasus_entailment': 0.3628084361553192, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5268817204301075, 'r1_recall': 0.2916666666666667, 'r1_f1': 0.3754789272030651, 'pegasus_entailment': 0.6636510118842125, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3894736842105263, 'r1_recall': 0.38144329896907214, 'r1_f1': 0.38541666666666663, 'pegasus_entailment': 0.6726335237423579, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30526315789473685, 'r1_recall': 0.6041666666666666, 'r1_f1': 0.4055944055944056, 'pegasus_entailment': 0.26413025458653766, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7254901960784313, 'r1_recall': 0.5826771653543307, 'r1_f1': 0.6462882096069869, 'pegasus_entailment': 0.5024576857686043, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31794871794871793, 'r1_recall': 0.5849056603773585, 'r1_f1': 0.4119601328903654, 'pegasus_entailment': 0.9247671961784363, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 24}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4097222222222222, 'r1_recall': 0.6145833333333334, 'r1_f1': 0.49166666666666664, 'pegasus_entailment': 0.3526182036846876, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6082474226804123, 'r1_recall': 0.5130434782608696, 'r1_f1': 0.5566037735849056, 'pegasus_entailment': 0.2738933617947623, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7230769230769231, 'r1_recall': 0.46078431372549017, 'r1_f1': 0.562874251497006, 'pegasus_entailment': 0.6452730645736059, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4327485380116959, 'r1_recall': 0.4457831325301205, 'r1_f1': 0.4391691394658754, 'pegasus_entailment': 0.6009947001934052, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2971014492753623, 'r1_recall': 0.6029411764705882, 'r1_f1': 0.3980582524271844, 'pegasus_entailment': 0.4221682965755463, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2972972972972973, 'r1_recall': 0.5, 'r1_f1': 0.3728813559322034, 'pegasus_entailment': 0.2889961926266551, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6638655462184874, 'r1_recall': 0.41578947368421054, 'r1_f1': 0.511326860841424, 'pegasus_entailment': 0.6325911656022072, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25280898876404495, 'r1_recall': 0.625, 'r1_f1': 0.36, 'pegasus_entailment': 0.24065336678177118, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.379746835443038, 'r1_recall': 0.7058823529411765, 'r1_f1': 0.49382716049382724, 'pegasus_entailment': 0.3533804578972714, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29357798165137616, 'r1_recall': 0.5, 'r1_f1': 0.36994219653179194, 'pegasus_entailment': 0.9561551511287689, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5818181818181818, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5981308411214953, 'pegasus_entailment': 0.49981139476100606, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5181818181818182, 'r1_recall': 0.6627906976744186, 'r1_f1': 0.5816326530612245, 'pegasus_entailment': 0.5459788478910923, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5223880597014925, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.5223880597014925, 'pegasus_entailment': 0.8432019501924515, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5180722891566265, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.5341614906832298, 'pegasus_entailment': 0.29760339111089706, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.71, 'r1_recall': 0.6893203883495146, 'r1_f1': 0.6995073891625615, 'pegasus_entailment': 0.3805353989203771, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.43243243243243246, 'pegasus_entailment': 0.44439053535461426, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.527027027027027, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.48447204968944096, 'pegasus_entailment': 0.9556332528591156, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5309734513274337, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.5853658536585366, 'pegasus_entailment': 0.4753687207897504, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3619047619047619, 'r1_recall': 0.4367816091954023, 'r1_f1': 0.39583333333333337, 'pegasus_entailment': 0.7331586927175522, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2716049382716049, 'r1_recall': 0.28205128205128205, 'r1_f1': 0.27672955974842767, 'pegasus_entailment': 0.42119892438252765, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2719298245614035, 'r1_recall': 0.6888888888888889, 'r1_f1': 0.389937106918239, 'pegasus_entailment': 0.8661567717790604, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7634408602150538, 'r1_recall': 0.34134615384615385, 'r1_f1': 0.4717607973421926, 'pegasus_entailment': 0.4846502721309662, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47191011235955055, 'r1_recall': 0.6, 'r1_f1': 0.5283018867924529, 'pegasus_entailment': 0.22750169615028426, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.5729166666666666, 'r1_f1': 0.5641025641025641, 'pegasus_entailment': 0.8042283654212952, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 33, 'pegasus_smog': 27}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425, 'r1_recall': 0.3805970149253731, 'r1_f1': 0.4015748031496063, 'pegasus_entailment': 0.42347376700490713, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 13}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31343283582089554, 'r1_recall': 0.5753424657534246, 'r1_f1': 0.4057971014492754, 'pegasus_entailment': 0.4569806487299502, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5094339622641509, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.484304932735426, 'pegasus_entailment': 0.44477460446069017, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.15463917525773196, 'r1_f1': 0.2307692307692308, 'pegasus_entailment': 0.9775312542915344, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4424778761061947, 'r1_recall': 0.5649717514124294, 'r1_f1': 0.4962779156327544, 'pegasus_entailment': 0.6841746978461742, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47572815533980584, 'r1_recall': 0.5051546391752577, 'r1_f1': 0.49, 'pegasus_entailment': 0.4672451963027318, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5306122448979592, 'r1_recall': 0.4126984126984127, 'r1_f1': 0.4642857142857143, 'pegasus_entailment': 0.7804876963297526, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3490566037735849, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.4327485380116959, 'pegasus_entailment': 0.6252047084271908, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3867924528301887, 'r1_recall': 0.36607142857142855, 'r1_f1': 0.37614678899082565, 'pegasus_entailment': 0.5853602214095494, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37681159420289856, 'r1_recall': 0.4262295081967213, 'r1_f1': 0.4, 'pegasus_entailment': 0.22727882644782463, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4639175257731959, 'r1_recall': 0.4787234042553192, 'r1_f1': 0.47120418848167545, 'pegasus_entailment': 0.7710384353995323, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5233644859813084, 'r1_recall': 0.48695652173913045, 'r1_f1': 0.5045045045045046, 'pegasus_entailment': 0.8629238605499268, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.547945205479452, 'r1_recall': 0.35714285714285715, 'r1_f1': 0.4324324324324324, 'pegasus_entailment': 0.7307569682598114, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3505747126436782, 'r1_recall': 0.7625, 'r1_f1': 0.4803149606299212, 'pegasus_entailment': 0.6758878976106644, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6710526315789473, 'r1_recall': 0.3953488372093023, 'r1_f1': 0.49756097560975604, 'pegasus_entailment': 0.44810023307800295, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49166666666666664, 'r1_recall': 0.5728155339805825, 'r1_f1': 0.5291479820627802, 'pegasus_entailment': 0.7231589108705521, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6979166666666666, 'r1_recall': 0.41875, 'r1_f1': 0.5234375, 'pegasus_entailment': 0.45678095519542694, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3790322580645161, 'r1_recall': 0.6266666666666667, 'r1_f1': 0.4723618090452261, 'pegasus_entailment': 0.6298145682667382, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34375, 'r1_recall': 0.55, 'r1_f1': 0.42307692307692313, 'pegasus_entailment': 0.6714966495831808, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.6040268456375839, 'pegasus_entailment': 0.927316352725029, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6020408163265306, 'r1_recall': 0.44360902255639095, 'r1_f1': 0.5108225108225107, 'pegasus_entailment': 0.22826587967574596, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7213114754098361, 'r1_recall': 0.5569620253164557, 'r1_f1': 0.6285714285714286, 'pegasus_entailment': 0.4885687637142837, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46956521739130436, 'r1_recall': 0.6067415730337079, 'r1_f1': 0.5294117647058824, 'pegasus_entailment': 0.6052300110459328, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.46923076923076923, 'r1_f1': 0.48412698412698413, 'pegasus_entailment': 0.6423696019919589, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851851851851851, 'r1_recall': 0.4438202247191011, 'r1_f1': 0.5047923322683706, 'pegasus_entailment': 0.6357724666595459, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7575757575757576, 'r1_recall': 0.42613636363636365, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.7660873532295227, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 19, 'pegasus_ari': 33, 'pegasus_smog': 23}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5841584158415841, 'r1_recall': 0.44029850746268656, 'r1_f1': 0.502127659574468, 'pegasus_entailment': 0.4436695694923401, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5092592592592593, 'r1_recall': 0.5851063829787234, 'r1_f1': 0.5445544554455446, 'pegasus_entailment': 0.5841448467690498, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6923076923076923, 'r1_recall': 0.3543307086614173, 'r1_f1': 0.46874999999999994, 'pegasus_entailment': 0.8002045949300131, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4766355140186916, 'r1_recall': 0.5795454545454546, 'r1_f1': 0.5230769230769231, 'pegasus_entailment': 0.7382049262523651, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5365853658536586, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.5546218487394958, 'pegasus_entailment': 0.7433254917462667, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 19}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39814814814814814, 'r1_recall': 0.5657894736842105, 'r1_f1': 0.46739130434782605, 'pegasus_entailment': 0.6243456929922104, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23232323232323232, 'r1_recall': 0.5348837209302325, 'r1_f1': 0.32394366197183094, 'pegasus_entailment': 0.45122377946972847, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7555555555555555, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.6732673267326731, 'pegasus_entailment': 0.9478484193483988, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5419847328244275, 'r1_recall': 0.5419847328244275, 'r1_f1': 0.5419847328244275, 'pegasus_entailment': 0.4712727442383766, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26, 'r1_recall': 0.65, 'r1_f1': 0.37142857142857144, 'pegasus_entailment': 0.47108266362920403, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.552, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.5702479338842975, 'pegasus_entailment': 0.9169735511144003, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 15, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5035460992907801, 'r1_recall': 0.6120689655172413, 'r1_f1': 0.5525291828793774, 'pegasus_entailment': 0.5796971842646599, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5256410256410257, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.5985401459854015, 'pegasus_entailment': 0.5310210337241491, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6834532374100719, 'r1_recall': 0.5026455026455027, 'r1_f1': 0.5792682926829269, 'pegasus_entailment': 0.1277024628361687, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.5950413223140496, 'r1_f1': 0.5255474452554746, 'pegasus_entailment': 0.9823962251345316, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 25}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.578125, 'r1_recall': 0.4774193548387097, 'r1_f1': 0.5229681978798586, 'pegasus_entailment': 0.8744952082633972, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6583333333333333, 'r1_recall': 0.48466257668711654, 'r1_f1': 0.5583038869257951, 'pegasus_entailment': 0.6053387373685837, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.475, 'r1_recall': 0.5643564356435643, 'r1_f1': 0.5158371040723981, 'pegasus_entailment': 0.5533628523349762, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4198895027624309, 'r1_recall': 0.628099173553719, 'r1_f1': 0.5033112582781457, 'pegasus_entailment': 0.7204168289899826, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5510204081632653, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.5654450261780105, 'pegasus_entailment': 0.6203324645757675, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6530612244897959, 'r1_recall': 0.48120300751879697, 'r1_f1': 0.5541125541125541, 'pegasus_entailment': 0.7693269610404968, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7019230769230769, 'r1_recall': 0.3945945945945946, 'r1_f1': 0.5051903114186851, 'pegasus_entailment': 0.6054031848907471, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3644859813084112, 'r1_recall': 0.6724137931034483, 'r1_f1': 0.4727272727272727, 'pegasus_entailment': 0.5255739882588386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39473684210526316, 'r1_recall': 0.5113636363636364, 'r1_f1': 0.44554455445544555, 'pegasus_entailment': 0.46424571610987186, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4782608695652174, 'r1_recall': 0.4731182795698925, 'r1_f1': 0.4756756756756757, 'pegasus_entailment': 0.3810370812813441, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53, 'r1_recall': 0.4690265486725664, 'r1_f1': 0.4976525821596244, 'pegasus_entailment': 0.7582129836082458, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5098039215686274, 'r1_recall': 0.65, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.6757595837116241, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.5436893203883496, 'pegasus_entailment': 0.5713955760002136, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6201550387596899, 'r1_recall': 0.3827751196172249, 'r1_f1': 0.47337278106508873, 'pegasus_entailment': 0.6067440658807755, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.660377358490566, 'r1_recall': 0.3867403314917127, 'r1_f1': 0.48780487804878053, 'pegasus_entailment': 0.44900578757127124, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3717948717948718, 'r1_recall': 0.4915254237288136, 'r1_f1': 0.4233576642335766, 'pegasus_entailment': 0.813797652721405, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7981651376146789, 'r1_recall': 0.5370370370370371, 'r1_f1': 0.6420664206642067, 'pegasus_entailment': 0.4584514629095793, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3923076923076923, 'r1_recall': 0.6219512195121951, 'r1_f1': 0.48113207547169806, 'pegasus_entailment': 0.37593673914670944, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43037974683544306, 'r1_recall': 0.3541666666666667, 'r1_f1': 0.3885714285714286, 'pegasus_entailment': 0.5583342090249062, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44881889763779526, 'r1_recall': 0.6195652173913043, 'r1_f1': 0.5205479452054794, 'pegasus_entailment': 0.4178726593963802, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7766990291262136, 'r1_recall': 0.41237113402061853, 'r1_f1': 0.5387205387205387, 'pegasus_entailment': 0.45479800179600716, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5370370370370371, 'r1_recall': 0.3493975903614458, 'r1_f1': 0.4233576642335767, 'pegasus_entailment': 0.41829054057598114, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33064516129032256, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.44808743169398907, 'pegasus_entailment': 0.7514328161875407, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6271186440677966, 'r1_recall': 0.4277456647398844, 'r1_f1': 0.5085910652920962, 'pegasus_entailment': 0.4022599846124649, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4626865671641791, 'r1_recall': 0.38271604938271603, 'r1_f1': 0.41891891891891897, 'pegasus_entailment': 0.6580566229919592, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5034965034965035, 'r1_recall': 0.48322147651006714, 'r1_f1': 0.49315068493150693, 'pegasus_entailment': 0.8055967092514038, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5747126436781609, 'r1_recall': 0.5376344086021505, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.27868172415765, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.33540372670807456, 'r1_f1': 0.4202334630350195, 'pegasus_entailment': 0.2320029828697443, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21739130434782608, 'r1_recall': 0.2631578947368421, 'r1_f1': 0.23809523809523808, 'pegasus_entailment': 0.9635570049285889, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 24, 'pegasus_ari': 35, 'pegasus_smog': 28}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5728155339805825, 'r1_recall': 0.5462962962962963, 'r1_f1': 0.5592417061611374, 'pegasus_entailment': 0.7289799526333809, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37572254335260113, 'r1_recall': 0.6310679611650486, 'r1_f1': 0.47101449275362317, 'pegasus_entailment': 0.869426429271698, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.654320987654321, 'r1_recall': 0.32515337423312884, 'r1_f1': 0.43442622950819676, 'pegasus_entailment': 0.6885570958256721, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5742574257425742, 'r1_recall': 0.5321100917431193, 'r1_f1': 0.5523809523809524, 'pegasus_entailment': 0.5509080678224564, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48863636363636365, 'r1_recall': 0.48863636363636365, 'r1_f1': 0.48863636363636365, 'pegasus_entailment': 0.4277232617139816, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43010752688172044, 'r1_recall': 0.26666666666666666, 'r1_f1': 0.3292181069958848, 'pegasus_entailment': 0.8380877176920573, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5089820359281437, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.5537459283387622, 'pegasus_entailment': 0.5460172792275747, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5080645161290323, 'r1_recall': 0.4228187919463087, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.6134821996092796, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48598130841121495, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5252525252525252, 'pegasus_entailment': 0.5923701326052347, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3805970149253731, 'r1_recall': 0.6623376623376623, 'r1_f1': 0.4834123222748815, 'pegasus_entailment': 0.5072733014822006, 'pegasus_flesch_kincaid': 33, 'pegasus_coleman_liau': 19, 'pegasus_ari': 41, 'pegasus_smog': 25}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39166666666666666, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.48704663212435234, 'pegasus_entailment': 0.620512424968183, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6896551724137931, 'r1_recall': 0.16304347826086957, 'r1_f1': 0.26373626373626374, 'pegasus_entailment': 0.5534291565418243, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.4909090909090909, 'r1_f1': 0.5167464114832535, 'pegasus_entailment': 0.6389245775838693, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5402298850574713, 'r1_recall': 0.3790322580645161, 'r1_f1': 0.44549763033175355, 'pegasus_entailment': 0.6536457240581512, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47468354430379744, 'r1_recall': 0.625, 'r1_f1': 0.539568345323741, 'pegasus_entailment': 0.5750852167606354, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7865168539325843, 'r1_recall': 0.2978723404255319, 'r1_f1': 0.4320987654320988, 'pegasus_entailment': 0.6572804339230061, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5100671140939598, 'r1_recall': 0.5, 'r1_f1': 0.5049833887043189, 'pegasus_entailment': 0.27998129092156887, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3089887640449438, 'r1_recall': 0.6395348837209303, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.528675944233934, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34408602150537637, 'r1_recall': 0.4266666666666667, 'r1_f1': 0.38095238095238104, 'pegasus_entailment': 0.6376828327775002, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41904761904761906, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.4512820512820513, 'pegasus_entailment': 0.9024880528450012, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6708860759493671, 'r1_recall': 0.3231707317073171, 'r1_f1': 0.43621399176954734, 'pegasus_entailment': 0.7083357274532318, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7829457364341085, 'r1_recall': 0.3519163763066202, 'r1_f1': 0.4855769230769231, 'pegasus_entailment': 0.41632277199200224, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6847826086956522, 'r1_recall': 0.35195530726256985, 'r1_f1': 0.46494464944649444, 'pegasus_entailment': 0.49718244187533855, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5752212389380531, 'r1_recall': 0.5701754385964912, 'r1_f1': 0.5726872246696035, 'pegasus_entailment': 0.6546744108200073, 'pegasus_flesch_kincaid': 52, 'pegasus_coleman_liau': 19, 'pegasus_ari': 64, 'pegasus_smog': 34}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6707317073170732, 'r1_recall': 0.4230769230769231, 'r1_f1': 0.5188679245283019, 'pegasus_entailment': 0.6752978463967642, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4661016949152542, 'r1_recall': 0.5288461538461539, 'r1_f1': 0.4954954954954955, 'pegasus_entailment': 0.3866795152425766, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3221476510067114, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.41201716738197425, 'pegasus_entailment': 0.9566343665122986, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6759259259259259, 'r1_recall': 0.4506172839506173, 'r1_f1': 0.5407407407407409, 'pegasus_entailment': 0.7148935596148173, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5897435897435898, 'r1_recall': 0.5974025974025974, 'r1_f1': 0.5935483870967742, 'pegasus_entailment': 0.4566979742376134, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.552, 'pegasus_entailment': 0.42761924816295505, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6133333333333333, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.6133333333333333, 'pegasus_entailment': 0.4594133794307709, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5688073394495413, 'r1_recall': 0.512396694214876, 'r1_f1': 0.5391304347826087, 'pegasus_entailment': 0.7448178589344024, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8082191780821918, 'r1_recall': 0.5315315315315315, 'r1_f1': 0.641304347826087, 'pegasus_entailment': 0.5455225699891647, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851063829787234, 'r1_recall': 0.3374233128834356, 'r1_f1': 0.42801556420233466, 'pegasus_entailment': 0.18151729305585226, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5779816513761468, 'r1_recall': 0.35795454545454547, 'r1_f1': 0.4421052631578947, 'pegasus_entailment': 0.3454425409436226, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5588235294117647, 'r1_recall': 0.7125, 'r1_f1': 0.6263736263736264, 'pegasus_entailment': 0.7891814609368643, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2636363636363636, 'r1_recall': 0.48333333333333334, 'r1_f1': 0.34117647058823525, 'pegasus_entailment': 0.6165966217716535, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 26}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4375, 'pegasus_entailment': 0.4352775923907757, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4426229508196721, 'r1_recall': 0.5510204081632653, 'r1_f1': 0.49090909090909085, 'pegasus_entailment': 0.33541417121887207, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5531914893617021, 'r1_recall': 0.6, 'r1_f1': 0.5756457564575646, 'pegasus_entailment': 0.617013406008482, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3047619047619048, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.42384105960264906, 'pegasus_entailment': 0.9890740911165873, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.675, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.5567010309278351, 'pegasus_entailment': 0.8306477467219034, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4672131147540984, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.4892703862660944, 'pegasus_entailment': 0.5148066524416208, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6938775510204082, 'r1_recall': 0.4657534246575342, 'r1_f1': 0.5573770491803278, 'pegasus_entailment': 0.4899275004863739, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.611764705882353, 'r1_recall': 0.6341463414634146, 'r1_f1': 0.6227544910179641, 'pegasus_entailment': 0.6797349055608114, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4621212121212121, 'r1_recall': 0.6931818181818182, 'r1_f1': 0.5545454545454546, 'pegasus_entailment': 0.7526635527610779, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5446428571428571, 'r1_recall': 0.6039603960396039, 'r1_f1': 0.5727699530516431, 'pegasus_entailment': 0.17453824058175088, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.472, 'r1_recall': 0.5462962962962963, 'r1_f1': 0.5064377682403434, 'pegasus_entailment': 0.2525451338539521, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2840909090909091, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.36764705882352944, 'pegasus_entailment': 0.27770412736572325, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5280898876404494, 'r1_recall': 0.47474747474747475, 'r1_f1': 0.5, 'pegasus_entailment': 0.584257165590922, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.56, 'r1_recall': 0.35443037974683544, 'r1_f1': 0.434108527131783, 'pegasus_entailment': 0.47310803333918255, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5140845070422535, 'r1_recall': 0.4620253164556962, 'r1_f1': 0.4866666666666667, 'pegasus_entailment': 0.48535676300525665, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5680473372781065, 'r1_recall': 0.49740932642487046, 'r1_f1': 0.5303867403314917, 'pegasus_entailment': 0.31199143330256146, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6885245901639344, 'r1_recall': 0.4, 'r1_f1': 0.5060240963855422, 'pegasus_entailment': 0.6027634143829346, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45569620253164556, 'r1_recall': 0.576, 'r1_f1': 0.5088339222614842, 'pegasus_entailment': 0.6013013064861298, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3409090909090909, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.3208227555733174, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3153153153153153, 'r1_recall': 0.5737704918032787, 'r1_f1': 0.40697674418604646, 'pegasus_entailment': 0.2494944843929261, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4657534246575342, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.5037037037037037, 'pegasus_entailment': 0.9451161424318949, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2702702702702703, 'r1_recall': 0.5084745762711864, 'r1_f1': 0.3529411764705882, 'pegasus_entailment': 0.2992536723613739, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4358974358974359, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.44155844155844154, 'pegasus_entailment': 0.3517903983592987, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4431818181818182, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.41711229946524064, 'pegasus_entailment': 0.6101228147745132, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2815533980582524, 'r1_recall': 0.725, 'r1_f1': 0.40559440559440557, 'pegasus_entailment': 0.6760659019152323, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4371584699453552, 'r1_recall': 0.4624277456647399, 'r1_f1': 0.44943820224719094, 'pegasus_entailment': 0.5536630700031916, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 25}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4351851851851852, 'r1_recall': 0.5875, 'r1_f1': 0.5, 'pegasus_entailment': 0.5107136726379394, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6224489795918368, 'r1_recall': 0.34269662921348315, 'r1_f1': 0.44202898550724645, 'pegasus_entailment': 0.5645067654550076, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7228915662650602, 'r1_recall': 0.37267080745341613, 'r1_f1': 0.49180327868852464, 'pegasus_entailment': 0.28952719643712044, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6076923076923076, 'r1_recall': 0.5895522388059702, 'r1_f1': 0.5984848484848485, 'pegasus_entailment': 0.20588585610191026, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 31, 'pegasus_smog': 26}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6875, 'r1_recall': 0.22633744855967078, 'r1_f1': 0.3405572755417957, 'pegasus_entailment': 0.5585938592751821, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4326923076923077, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.4838709677419355, 'pegasus_entailment': 0.6324315816164017, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 16, 'pegasus_ari': 31, 'pegasus_smog': 20}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49523809523809526, 'r1_recall': 0.34210526315789475, 'r1_f1': 0.4046692607003891, 'pegasus_entailment': 0.48075965978205204, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3211009174311927, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.3867403314917127, 'pegasus_entailment': 0.666877289613088, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5877862595419847, 'r1_recall': 0.3452914798206278, 'r1_f1': 0.4350282485875706, 'pegasus_entailment': 0.5783930346369743, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35714285714285715, 'r1_recall': 0.30973451327433627, 'r1_f1': 0.33175355450236965, 'pegasus_entailment': 0.316874402264754, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3402061855670103, 'r1_recall': 0.717391304347826, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.40247253281995654, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7555555555555555, 'r1_recall': 0.3756906077348066, 'r1_f1': 0.5018450184501846, 'pegasus_entailment': 0.330894747748971, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.686046511627907, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.4486692015209125, 'pegasus_entailment': 0.3104033973067999, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4236111111111111, 'r1_recall': 0.6354166666666666, 'r1_f1': 0.5083333333333334, 'pegasus_entailment': 0.6399297515551249, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6176470588235294, 'r1_recall': 0.43448275862068964, 'r1_f1': 0.5101214574898786, 'pegasus_entailment': 0.8030675768852233, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1450381679389313, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.23899371069182387, 'pegasus_entailment': 0.17203863114118575, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19310344827586207, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.27586206896551724, 'pegasus_entailment': 0.6303148925304413, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.68, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.6210045662100457, 'pegasus_entailment': 0.39496460537581396, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30952380952380953, 'r1_recall': 0.5492957746478874, 'r1_f1': 0.39593908629441626, 'pegasus_entailment': 0.3894849956035614, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.248, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.34444444444444444, 'pegasus_entailment': 0.7146193504333496, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3617021276595745, 'r1_recall': 0.41975308641975306, 'r1_f1': 0.38857142857142857, 'pegasus_entailment': 0.3070040214806795, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.611764705882353, 'r1_recall': 0.6419753086419753, 'r1_f1': 0.6265060240963856, 'pegasus_entailment': 0.8770049413045248, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5063291139240507, 'r1_recall': 0.4819277108433735, 'r1_f1': 0.49382716049382713, 'pegasus_entailment': 0.259297750541009, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5652173913043478, 'r1_recall': 0.46846846846846846, 'r1_f1': 0.5123152709359605, 'pegasus_entailment': 0.3363981540314853, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7961165048543689, 'r1_recall': 0.24404761904761904, 'r1_f1': 0.3735763097949886, 'pegasus_entailment': 0.5112008690834046, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.3108108108108108, 'r1_f1': 0.4207317073170732, 'pegasus_entailment': 0.4609153997153044, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47674418604651164, 'r1_recall': 0.5256410256410257, 'r1_f1': 0.5, 'pegasus_entailment': 0.5324264243245125, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5523809523809524, 'r1_recall': 0.5576923076923077, 'r1_f1': 0.5550239234449761, 'pegasus_entailment': 0.43314006303747493, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21965317919075145, 'r1_recall': 0.5205479452054794, 'r1_f1': 0.30894308943089427, 'pegasus_entailment': 0.5216895192861557, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3228346456692913, 'r1_recall': 0.6307692307692307, 'r1_f1': 0.4270833333333333, 'pegasus_entailment': 0.2945159201820691, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5921052631578947, 'r1_recall': 0.625, 'r1_f1': 0.6081081081081081, 'pegasus_entailment': 0.5674796203772227, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5487804878048781, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.5521472392638037, 'pegasus_entailment': 0.8695265799760818, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4375, 'r1_recall': 0.5526315789473685, 'r1_f1': 0.4883720930232558, 'pegasus_entailment': 0.8834349115689596, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42718446601941745, 'r1_recall': 0.5238095238095238, 'r1_f1': 0.4705882352941177, 'pegasus_entailment': 0.2228782958118245, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7254901960784313, 'r1_recall': 0.4713375796178344, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.7784717231988907, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6886792452830188, 'r1_recall': 0.5069444444444444, 'r1_f1': 0.584, 'pegasus_entailment': 0.5282692015171051, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3411764705882353, 'r1_recall': 0.30851063829787234, 'r1_f1': 0.32402234636871513, 'pegasus_entailment': 0.6005418747663498, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6483516483516484, 'r1_recall': 0.6178010471204188, 'r1_f1': 0.6327077747989276, 'pegasus_entailment': 0.4432292928298314, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3465346534653465, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.9816618164380392, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4492753623188406, 'r1_recall': 0.37349397590361444, 'r1_f1': 0.40789473684210525, 'pegasus_entailment': 0.9005027562379837, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7166666666666667, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.6231884057971016, 'pegasus_entailment': 0.6865303814411163, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 8}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44696969696969696, 'r1_recall': 0.7283950617283951, 'r1_f1': 0.5539906103286385, 'pegasus_entailment': 0.4352083284407854, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5310344827586206, 'r1_recall': 0.5620437956204379, 'r1_f1': 0.5460992907801417, 'pegasus_entailment': 0.7303782254457474, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3076923076923077, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.33333333333333337, 'pegasus_entailment': 0.6575305623312792, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32051282051282054, 'r1_recall': 0.423728813559322, 'r1_f1': 0.3649635036496351, 'pegasus_entailment': 0.46847159415483475, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.4701492537313433, 'r1_f1': 0.4980237154150198, 'pegasus_entailment': 0.5008024135604501, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.358974358974359, 'r1_f1': 0.4534412955465587, 'pegasus_entailment': 0.2949881562963128, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43119266055045874, 'r1_recall': 0.7230769230769231, 'r1_f1': 0.5402298850574713, 'pegasus_entailment': 0.7357929050922394, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4326923076923077, 'r1_recall': 0.5113636363636364, 'r1_f1': 0.46875, 'pegasus_entailment': 0.5529967024922371, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4946236559139785, 'r1_recall': 0.5476190476190477, 'r1_f1': 0.5197740112994351, 'pegasus_entailment': 0.6758133098483086, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3977272727272727, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.4242424242424242, 'pegasus_entailment': 0.5415948955342174, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33858267716535434, 'r1_recall': 0.5375, 'r1_f1': 0.41545893719806765, 'pegasus_entailment': 0.4993847645819187, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5035971223021583, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.4745762711864407, 'pegasus_entailment': 0.45366304895530146, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5063291139240507, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5161290322580646, 'pegasus_entailment': 0.25480619817972183, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3708609271523179, 'r1_recall': 0.6588235294117647, 'r1_f1': 0.47457627118644063, 'pegasus_entailment': 0.46662308648228645, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6730769230769231, 'r1_recall': 0.5343511450381679, 'r1_f1': 0.5957446808510639, 'pegasus_entailment': 0.45500591211020947, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4642857142857143, 'r1_recall': 0.36792452830188677, 'r1_f1': 0.4105263157894737, 'pegasus_entailment': 0.2987853630911559, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5939849624060151, 'r1_recall': 0.43169398907103823, 'r1_f1': 0.5, 'pegasus_entailment': 0.8131778538227081, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4880952380952381, 'r1_recall': 0.5394736842105263, 'r1_f1': 0.5125, 'pegasus_entailment': 0.34397818757376325, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5121951219512195, 'r1_recall': 0.45652173913043476, 'r1_f1': 0.48275862068965514, 'pegasus_entailment': 0.4509930331259966, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7520661157024794, 'r1_recall': 0.4212962962962963, 'r1_f1': 0.5400593471810089, 'pegasus_entailment': 0.2496687311679125, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5949367088607594, 'r1_recall': 0.46534653465346537, 'r1_f1': 0.5222222222222221, 'pegasus_entailment': 0.06338276776174705, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5119047619047619, 'r1_recall': 0.4387755102040816, 'r1_f1': 0.4725274725274725, 'pegasus_entailment': 0.18773385975509882, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5161290322580646, 'pegasus_entailment': 0.6153527131925026, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6990291262135923, 'r1_recall': 0.5413533834586466, 'r1_f1': 0.6101694915254237, 'pegasus_entailment': 0.2906938042433467, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.4, 'r1_f1': 0.4675324675324675, 'pegasus_entailment': 0.2651624729235967, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.3652173913043478, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.49146442785859107, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44329896907216493, 'r1_recall': 0.38738738738738737, 'r1_f1': 0.41346153846153844, 'pegasus_entailment': 0.696148137251536, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7528089887640449, 'r1_recall': 0.4855072463768116, 'r1_f1': 0.5903083700440528, 'pegasus_entailment': 0.6719439923763275, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21782178217821782, 'r1_recall': 0.44, 'r1_f1': 0.2913907284768212, 'pegasus_entailment': 0.32551082223653793, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26573426573426573, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.38190954773869346, 'pegasus_entailment': 0.25152797531336546, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22580645161290322, 'r1_recall': 0.2978723404255319, 'r1_f1': 0.2568807339449541, 'pegasus_entailment': 0.284672349691391, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4411764705882353, 'r1_recall': 0.4225352112676056, 'r1_f1': 0.43165467625899284, 'pegasus_entailment': 0.5144440829753876, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.3005464480874317, 'r1_f1': 0.40293040293040294, 'pegasus_entailment': 0.2458620723336935, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.514018691588785, 'r1_recall': 0.40145985401459855, 'r1_f1': 0.4508196721311475, 'pegasus_entailment': 0.8132250209649404, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 17}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6022727272727273, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.5921787709497207, 'pegasus_entailment': 0.7983407527208328, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5210084033613446, 'r1_recall': 0.46616541353383456, 'r1_f1': 0.49206349206349204, 'pegasus_entailment': 0.3848346810787916, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48333333333333334, 'r1_recall': 0.5304878048780488, 'r1_f1': 0.5058139534883721, 'pegasus_entailment': 0.2958300940692425, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6846153846153846, 'r1_recall': 0.4427860696517413, 'r1_f1': 0.5377643504531721, 'pegasus_entailment': 0.4883404541760683, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.3, 'r1_f1': 0.34285714285714286, 'pegasus_entailment': 0.5599430501461029, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.5625, 'r1_f1': 0.5590062111801242, 'pegasus_entailment': 0.5671789787709713, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33663366336633666, 'r1_recall': 0.4146341463414634, 'r1_f1': 0.37158469945355194, 'pegasus_entailment': 0.8419028123219808, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26666666666666666, 'r1_recall': 0.5, 'r1_f1': 0.3478260869565218, 'pegasus_entailment': 0.28081218898296356, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2857142857142857, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.3571428571428571, 'pegasus_entailment': 0.6898664496839046, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19607843137254902, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.29411764705882354, 'pegasus_entailment': 0.43534406144171955, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.375, 'r1_recall': 0.4342105263157895, 'r1_f1': 0.4024390243902439, 'pegasus_entailment': 0.5767182894051075, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6451612903225806, 'r1_recall': 0.32608695652173914, 'r1_f1': 0.4332129963898917, 'pegasus_entailment': 0.8045540452003479, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3402061855670103, 'r1_recall': 0.4925373134328358, 'r1_f1': 0.4024390243902439, 'pegasus_entailment': 0.34251442179083824, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6888888888888889, 'r1_recall': 0.36904761904761907, 'r1_f1': 0.4806201550387597, 'pegasus_entailment': 0.4161246486008167, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6320754716981132, 'r1_recall': 0.5075757575757576, 'r1_f1': 0.5630252100840336, 'pegasus_entailment': 0.32203347608447075, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7844827586206896, 'r1_recall': 0.5759493670886076, 'r1_f1': 0.6642335766423357, 'pegasus_entailment': 0.5782024264335632, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7647058823529411, 'r1_recall': 0.2195945945945946, 'r1_f1': 0.3412073490813648, 'pegasus_entailment': 0.43408970534801483, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.7272727272727273, 'r1_f1': 0.54421768707483, 'pegasus_entailment': 0.4875956103205681, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6481481481481481, 'r1_recall': 0.3553299492385787, 'r1_f1': 0.459016393442623, 'pegasus_entailment': 0.1930928498506546, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45588235294117646, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.484375, 'pegasus_entailment': 0.6408371962606907, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4961832061068702, 'r1_recall': 0.5284552845528455, 'r1_f1': 0.5118110236220472, 'pegasus_entailment': 0.7989411801099777, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5523809523809524, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5523809523809524, 'pegasus_entailment': 0.5678386330604553, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.775, 'r1_recall': 0.4732824427480916, 'r1_f1': 0.5876777251184834, 'pegasus_entailment': 0.4727054998278618, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3140495867768595, 'r1_recall': 0.5671641791044776, 'r1_f1': 0.4042553191489362, 'pegasus_entailment': 0.4419554229825735, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2894736842105263, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.3859649122807018, 'pegasus_entailment': 0.4621002972126007, 'pegasus_flesch_kincaid': 32, 'pegasus_coleman_liau': 21, 'pegasus_ari': 38, 'pegasus_smog': 26}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25806451612903225, 'r1_recall': 0.7017543859649122, 'r1_f1': 0.3773584905660377, 'pegasus_entailment': 0.616279861330986, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.5625, 'r1_f1': 0.5877551020408163, 'pegasus_entailment': 0.3008006915450096, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7818181818181819, 'r1_recall': 0.48314606741573035, 'r1_f1': 0.5972222222222223, 'pegasus_entailment': 0.55433922012647, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6333333333333333, 'r1_recall': 0.4662576687116564, 'r1_f1': 0.5371024734982333, 'pegasus_entailment': 0.726044887304306, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6415094339622641, 'r1_recall': 0.35233160621761656, 'r1_f1': 0.45484949832775917, 'pegasus_entailment': 0.6340672224760056, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4909090909090909, 'r1_recall': 0.5346534653465347, 'r1_f1': 0.5118483412322276, 'pegasus_entailment': 0.4082975375155608, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35947712418300654, 'r1_recall': 0.6547619047619048, 'r1_f1': 0.46413502109704646, 'pegasus_entailment': 0.4123345666698047, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.5, 'r1_f1': 0.4736842105263158, 'pegasus_entailment': 0.6782827149145305, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3380281690140845, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.39344262295081966, 'pegasus_entailment': 0.14754684269428253, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6267605633802817, 'r1_recall': 0.6013513513513513, 'r1_f1': 0.6137931034482759, 'pegasus_entailment': 0.5645301242669424, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.4580152671755725, 'r1_f1': 0.5286343612334802, 'pegasus_entailment': 0.560332209803164, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7121212121212122, 'r1_recall': 0.3983050847457627, 'r1_f1': 0.5108695652173914, 'pegasus_entailment': 0.9548970858256022, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7777777777777778, 'r1_recall': 0.3769230769230769, 'r1_f1': 0.5077720207253886, 'pegasus_entailment': 0.6044277374943098, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5408163265306123, 'r1_recall': 0.44537815126050423, 'r1_f1': 0.4884792626728111, 'pegasus_entailment': 0.4587773655851682, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7346938775510204, 'r1_recall': 0.5, 'r1_f1': 0.5950413223140496, 'pegasus_entailment': 0.7153411044273525, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5957446808510638, 'r1_recall': 0.6222222222222222, 'r1_f1': 0.608695652173913, 'pegasus_entailment': 0.3169755460694432, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45161290322580644, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.43579766536964976, 'pegasus_entailment': 0.3381445140577853, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6589147286821705, 'r1_recall': 0.4009433962264151, 'r1_f1': 0.4985337243401759, 'pegasus_entailment': 0.6678925057252248, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33766233766233766, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.3880597014925373, 'pegasus_entailment': 0.4067276641726494, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46511627906976744, 'r1_recall': 0.46875, 'r1_f1': 0.4669260700389105, 'pegasus_entailment': 0.45340456403791907, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34579439252336447, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.45121951219512196, 'pegasus_entailment': 0.5727633386850357, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7310924369747899, 'r1_recall': 0.45549738219895286, 'r1_f1': 0.5612903225806452, 'pegasus_entailment': 0.6220632692178091, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6333333333333333, 'r1_recall': 0.5170068027210885, 'r1_f1': 0.5692883895131086, 'pegasus_entailment': 0.38553042709827423, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45588235294117646, 'r1_recall': 0.4025974025974026, 'r1_f1': 0.42758620689655175, 'pegasus_entailment': 0.874851793050766, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36875, 'r1_recall': 0.7866666666666666, 'r1_f1': 0.5021276595744681, 'pegasus_entailment': 0.6777335129678249, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5984251968503937, 'r1_recall': 0.6608695652173913, 'r1_f1': 0.628099173553719, 'pegasus_entailment': 0.5237200796604157, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5945945945945946, 'r1_recall': 0.43137254901960786, 'r1_f1': 0.5000000000000001, 'pegasus_entailment': 0.6547691524028778, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5188679245283019, 'r1_recall': 0.5392156862745098, 'r1_f1': 0.5288461538461537, 'pegasus_entailment': 0.06418022233992815, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.445859872611465, 'pegasus_entailment': 0.4173084482550621, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3956043956043956, 'r1_recall': 0.5625, 'r1_f1': 0.4645161290322581, 'pegasus_entailment': 0.3455523768439889, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43, 'r1_recall': 0.5733333333333334, 'r1_f1': 0.49142857142857144, 'pegasus_entailment': 0.27242566586937755, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34513274336283184, 'r1_recall': 0.7358490566037735, 'r1_f1': 0.4698795180722891, 'pegasus_entailment': 0.86143858730793, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5670103092783505, 'r1_recall': 0.5913978494623656, 'r1_f1': 0.5789473684210525, 'pegasus_entailment': 0.6674053966999054, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43902439024390244, 'r1_recall': 0.6206896551724138, 'r1_f1': 0.5142857142857142, 'pegasus_entailment': 0.3770249326868604, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5431034482758621, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.5779816513761469, 'pegasus_entailment': 0.6137364953756332, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6296296296296297, 'r1_recall': 0.43037974683544306, 'r1_f1': 0.5112781954887219, 'pegasus_entailment': 0.5634314373135567, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3466666666666667, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.3939393939393939, 'pegasus_entailment': 0.4825938992823164, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5725190839694656, 'r1_recall': 0.5033557046979866, 'r1_f1': 0.5357142857142857, 'pegasus_entailment': 0.6616428891817728, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5316455696202531, 'r1_recall': 0.30656934306569344, 'r1_f1': 0.3888888888888889, 'pegasus_entailment': 0.6306249111890793, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6176470588235294, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.6268656716417911, 'pegasus_entailment': 0.21700024232268333, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5284552845528455, 'r1_recall': 0.5855855855855856, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.7940180897712708, 'pegasus_flesch_kincaid': 32, 'pegasus_coleman_liau': 20, 'pegasus_ari': 39, 'pegasus_smog': 28}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24285714285714285, 'r1_recall': 0.6375, 'r1_f1': 0.35172413793103446, 'pegasus_entailment': 0.9482558795383998, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.4409448818897638, 'r1_f1': 0.4534412955465587, 'pegasus_entailment': 0.8250105828046799, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7536231884057971, 'r1_recall': 0.5279187817258884, 'r1_f1': 0.6208955223880598, 'pegasus_entailment': 0.48445955770356314, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6890756302521008, 'r1_recall': 0.3374485596707819, 'r1_f1': 0.4530386740331492, 'pegasus_entailment': 0.31519676093012094, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.676056338028169, 'r1_recall': 0.34532374100719426, 'r1_f1': 0.45714285714285713, 'pegasus_entailment': 0.48386128908896353, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.031578947368421054, 'r1_recall': 0.0410958904109589, 'r1_f1': 0.03571428571428571, 'pegasus_entailment': 0.9542099833488464, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 1, 'pegasus_ari': 17, 'pegasus_smog': 8}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2828282828282828, 'r1_recall': 0.45901639344262296, 'r1_f1': 0.35, 'pegasus_entailment': 0.15300726937130094, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6875, 'r1_recall': 0.6395348837209303, 'r1_f1': 0.6626506024096386, 'pegasus_entailment': 0.6324207410216331, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4673913043478261, 'r1_recall': 0.581081081081081, 'r1_f1': 0.5180722891566265, 'pegasus_entailment': 0.2594465515576303, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5885714285714285, 'r1_recall': 0.5919540229885057, 'r1_f1': 0.5902578796561605, 'pegasus_entailment': 0.6316783428192139, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4827586206896552, 'r1_recall': 0.2916666666666667, 'r1_f1': 0.3636363636363637, 'pegasus_entailment': 0.3849963629618287, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7863247863247863, 'r1_recall': 0.4717948717948718, 'r1_f1': 0.5897435897435896, 'pegasus_entailment': 0.6674446687102318, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5531914893617021, 'r1_recall': 0.7123287671232876, 'r1_f1': 0.6227544910179641, 'pegasus_entailment': 0.49371232837438583, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49074074074074076, 'r1_recall': 0.7066666666666667, 'r1_f1': 0.5792349726775956, 'pegasus_entailment': 0.43740286622196434, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4830508474576271, 'r1_recall': 0.5, 'r1_f1': 0.49137931034482757, 'pegasus_entailment': 0.7744606733322144, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7398373983739838, 'r1_recall': 0.24202127659574468, 'r1_f1': 0.3647294589178357, 'pegasus_entailment': 0.580346517264843, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4857142857142857, 'r1_recall': 0.576271186440678, 'r1_f1': 0.5271317829457364, 'pegasus_entailment': 0.7218687931696574, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7397260273972602, 'r1_recall': 0.32142857142857145, 'r1_f1': 0.44813278008298757, 'pegasus_entailment': 0.6580447033047676, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47586206896551725, 'r1_recall': 0.5348837209302325, 'r1_f1': 0.5036496350364963, 'pegasus_entailment': 0.4769918170890638, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5109489051094891, 'r1_recall': 0.4697986577181208, 'r1_f1': 0.4895104895104895, 'pegasus_entailment': 0.7563707530498505, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6106194690265486, 'r1_recall': 0.40828402366863903, 'r1_f1': 0.48936170212765956, 'pegasus_entailment': 0.3965494744479656, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6696428571428571, 'r1_recall': 0.5725190839694656, 'r1_f1': 0.6172839506172839, 'pegasus_entailment': 0.7024544030427933, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4225352112676056, 'r1_recall': 0.24193548387096775, 'r1_f1': 0.3076923076923077, 'pegasus_entailment': 0.5976449449857076, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425531914893617, 'r1_recall': 0.7228915662650602, 'r1_f1': 0.5357142857142857, 'pegasus_entailment': 0.4587004162371159, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26373626373626374, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.36923076923076925, 'pegasus_entailment': 0.4108757358044386, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6756756756756757, 'r1_recall': 0.43103448275862066, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.26026322444279987, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6636363636363637, 'r1_recall': 0.3945945945945946, 'r1_f1': 0.49491525423728816, 'pegasus_entailment': 0.5605097077786922, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6417910447761194, 'r1_recall': 0.4479166666666667, 'r1_f1': 0.5276073619631902, 'pegasus_entailment': 0.9471827149391174, 'pegasus_flesch_kincaid': 37, 'pegasus_coleman_liau': 22, 'pegasus_ari': 44, 'pegasus_smog': 30}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7815126050420168, 'r1_recall': 0.24155844155844156, 'r1_f1': 0.369047619047619, 'pegasus_entailment': 0.329908254245917, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6770833333333334, 'r1_recall': 0.4513888888888889, 'r1_f1': 0.5416666666666666, 'pegasus_entailment': 0.5722659900784492, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2482758620689655, 'r1_recall': 0.5538461538461539, 'r1_f1': 0.34285714285714286, 'pegasus_entailment': 0.3597773537039757, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45555555555555555, 'r1_recall': 0.6833333333333333, 'r1_f1': 0.5466666666666666, 'pegasus_entailment': 0.26742803646872443, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44594594594594594, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.42580645161290326, 'pegasus_entailment': 0.2515876851975918, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5066666666666667, 'r1_recall': 0.36538461538461536, 'r1_f1': 0.4245810055865922, 'pegasus_entailment': 0.6934632062911987, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32558139534883723, 'r1_recall': 0.4883720930232558, 'r1_f1': 0.39069767441860465, 'pegasus_entailment': 0.6529766172170639, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.421875, 'r1_recall': 0.5192307692307693, 'r1_f1': 0.46551724137931033, 'pegasus_entailment': 0.40192589660485584, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5245901639344263, 'r1_recall': 0.3878787878787879, 'r1_f1': 0.445993031358885, 'pegasus_entailment': 0.6856850117444993, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4578313253012048, 'r1_recall': 0.6229508196721312, 'r1_f1': 0.5277777777777778, 'pegasus_entailment': 0.43050251858464134, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5857142857142857, 'r1_recall': 0.5466666666666666, 'r1_f1': 0.5655172413793104, 'pegasus_entailment': 0.5225172005593777, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5319148936170213, 'r1_recall': 0.5494505494505495, 'r1_f1': 0.5405405405405406, 'pegasus_entailment': 0.39293381075064343, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.544, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.53125, 'pegasus_entailment': 0.3526668002208074, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.52, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5445026178010471, 'pegasus_entailment': 0.6401330679655075, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.584070796460177, 'r1_recall': 0.6285714285714286, 'r1_f1': 0.6055045871559633, 'pegasus_entailment': 0.48934214242867063, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4375, 'r1_recall': 0.7671232876712328, 'r1_f1': 0.5572139303482587, 'pegasus_entailment': 0.4795444518327713, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5581395348837209, 'r1_recall': 0.384, 'r1_f1': 0.4549763033175356, 'pegasus_entailment': 0.25187146477401257, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5612244897959183, 'r1_recall': 0.4824561403508772, 'r1_f1': 0.5188679245283019, 'pegasus_entailment': 0.391675066947937, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35542168674698793, 'r1_recall': 0.6629213483146067, 'r1_f1': 0.4627450980392156, 'pegasus_entailment': 0.5033868892739216, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2, 'r1_recall': 0.32558139534883723, 'r1_f1': 0.24778761061946902, 'pegasus_entailment': 0.9248838722705841, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 15}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7075471698113207, 'r1_recall': 0.3393665158371041, 'r1_f1': 0.45871559633027525, 'pegasus_entailment': 0.5199355781078339, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6301369863013699, 'pegasus_entailment': 0.9620340764522552, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 22}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27835051546391754, 'r1_recall': 0.7297297297297297, 'r1_f1': 0.40298507462686567, 'pegasus_entailment': 0.3749085192879041, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 18}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2980132450331126, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.3862660944206009, 'pegasus_entailment': 0.6741462871432304, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47863247863247865, 'r1_recall': 0.5233644859813084, 'r1_f1': 0.5, 'pegasus_entailment': 0.6878381222486496, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2986111111111111, 'r1_recall': 0.5972222222222222, 'r1_f1': 0.39814814814814814, 'pegasus_entailment': 0.6571219086647033, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5638297872340425, 'r1_recall': 0.6022727272727273, 'r1_f1': 0.5824175824175825, 'pegasus_entailment': 0.48688208195380867, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 30, 'pegasus_smog': 20}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7, 'r1_recall': 0.550561797752809, 'r1_f1': 0.6163522012578616, 'pegasus_entailment': 0.41168683767318726, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2692307692307692, 'r1_recall': 0.5932203389830508, 'r1_f1': 0.3703703703703704, 'pegasus_entailment': 0.15530007786583155, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6741573033707865, 'r1_recall': 0.6060606060606061, 'r1_f1': 0.6382978723404256, 'pegasus_entailment': 0.776126429438591, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46551724137931033, 'r1_recall': 0.5625, 'r1_f1': 0.5094339622641509, 'pegasus_entailment': 0.6770926594734192, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41830065359477125, 'r1_recall': 0.6808510638297872, 'r1_f1': 0.5182186234817814, 'pegasus_entailment': 0.5247123266259829, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8616352201257862, 'r1_recall': 0.2624521072796935, 'r1_f1': 0.40234948604992654, 'pegasus_entailment': 0.565445890384061, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6524390243902439, 'r1_recall': 0.535, 'r1_f1': 0.5879120879120879, 'pegasus_entailment': 0.5532713415367263, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30357142857142855, 'r1_recall': 0.4358974358974359, 'r1_f1': 0.35789473684210527, 'pegasus_entailment': 0.11778875514864921, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6236559139784946, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5858585858585859, 'pegasus_entailment': 0.6512515544891357, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.4852941176470588, 'r1_f1': 0.4925373134328358, 'pegasus_entailment': 0.4438908211886883, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.48672566371681414, 'r1_f1': 0.5418719211822659, 'pegasus_entailment': 0.511633176356554, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47572815533980584, 'r1_recall': 0.5764705882352941, 'r1_f1': 0.5212765957446808, 'pegasus_entailment': 0.4667632281780243, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4186046511627907, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.47368421052631576, 'pegasus_entailment': 0.48165300861001015, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.4891304347826087, 'r1_f1': 0.5202312138728324, 'pegasus_entailment': 0.6083359532058239, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5274725274725275, 'r1_recall': 0.5783132530120482, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.33475450053811073, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6090909090909091, 'r1_recall': 0.5317460317460317, 'r1_f1': 0.5677966101694915, 'pegasus_entailment': 0.5171469151973724, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6206896551724138, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.4214533917605877, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5864661654135338, 'r1_recall': 0.484472049689441, 'r1_f1': 0.5306122448979592, 'pegasus_entailment': 0.5496786117553711, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42028985507246375, 'r1_recall': 0.5087719298245614, 'r1_f1': 0.46031746031746035, 'pegasus_entailment': 0.3604556878951068, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 13}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6204819277108434, 'r1_recall': 0.4557522123893805, 'r1_f1': 0.5255102040816326, 'pegasus_entailment': 0.6254832506179809, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3103448275862069, 'r1_recall': 0.6, 'r1_f1': 0.4090909090909091, 'pegasus_entailment': 0.19837059639394283, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5514018691588785, 'r1_recall': 0.5841584158415841, 'r1_f1': 0.5673076923076923, 'pegasus_entailment': 0.579101045926412, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3595505617977528, 'r1_recall': 0.6530612244897959, 'r1_f1': 0.463768115942029, 'pegasus_entailment': 0.6984294652938843, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.203125, 'r1_recall': 0.2826086956521739, 'r1_f1': 0.23636363636363636, 'pegasus_entailment': 0.8177447517712911, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6218487394957983, 'r1_recall': 0.5068493150684932, 'r1_f1': 0.5584905660377358, 'pegasus_entailment': 0.8368285894393921, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6459627329192547, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.5892351274787535, 'pegasus_entailment': 0.6935430586338043, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5254237288135594, 'r1_recall': 0.4189189189189189, 'r1_f1': 0.46616541353383456, 'pegasus_entailment': 0.34189148258883506, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4017857142857143, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.42654028436018965, 'pegasus_entailment': 0.4437068998813629, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5463917525773195, 'r1_recall': 0.6385542168674698, 'r1_f1': 0.5888888888888889, 'pegasus_entailment': 0.6052955587704977, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35772357723577236, 'r1_recall': 0.6197183098591549, 'r1_f1': 0.4536082474226804, 'pegasus_entailment': 0.4342086136341095, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.512396694214876, 'r1_recall': 0.5391304347826087, 'r1_f1': 0.5254237288135593, 'pegasus_entailment': 0.3408238925039768, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6296296296296297, 'r1_recall': 0.40476190476190477, 'r1_f1': 0.4927536231884058, 'pegasus_entailment': 0.28402944207191466, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29906542056074764, 'r1_recall': 0.6037735849056604, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.7132363468408585, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.42424242424242425, 'pegasus_entailment': 0.8700978010892868, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3923076923076923, 'r1_recall': 0.45132743362831856, 'r1_f1': 0.41975308641975306, 'pegasus_entailment': 0.4894271455705166, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39473684210526316, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.4864864864864865, 'pegasus_entailment': 0.4749680653214455, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5419354838709678, 'r1_recall': 0.3835616438356164, 'r1_f1': 0.4491978609625668, 'pegasus_entailment': 0.48808587789535524, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23076923076923078, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.3185840707964602, 'pegasus_entailment': 0.8682784835497538, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 21}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49019607843137253, 'r1_recall': 0.6024096385542169, 'r1_f1': 0.5405405405405406, 'pegasus_entailment': 0.49508877024054526, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3582089552238806, 'r1_recall': 0.4897959183673469, 'r1_f1': 0.4137931034482758, 'pegasus_entailment': 0.35937045365571973, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6493506493506493, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.6172839506172839, 'pegasus_entailment': 0.6865713596343994, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6379310344827587, 'r1_recall': 0.5736434108527132, 'r1_f1': 0.6040816326530614, 'pegasus_entailment': 0.6006013676524162, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.504950495049505, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.5425531914893617, 'pegasus_entailment': 0.8108405470848083, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6464646464646465, 'r1_recall': 0.48120300751879697, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.5616117380559444, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5945945945945946, 'r1_f1': 0.5432098765432098, 'pegasus_entailment': 0.17247513184944788, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4537037037037037, 'r1_recall': 0.5104166666666666, 'r1_f1': 0.4803921568627451, 'pegasus_entailment': 0.37727495771832764, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7176470588235294, 'r1_recall': 0.4357142857142857, 'r1_f1': 0.5422222222222223, 'pegasus_entailment': 0.8924940427144369, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46703296703296704, 'r1_recall': 0.5902777777777778, 'r1_f1': 0.5214723926380368, 'pegasus_entailment': 0.6907042860984802, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49504950495049505, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.5181347150259067, 'pegasus_entailment': 0.7772064805030823, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5542168674698795, 'r1_recall': 0.44660194174757284, 'r1_f1': 0.49462365591397855, 'pegasus_entailment': 0.712490051984787, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39473684210526316, 'r1_recall': 0.44776119402985076, 'r1_f1': 0.41958041958041953, 'pegasus_entailment': 0.4711893058071534, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4765625, 'r1_recall': 0.6703296703296703, 'r1_f1': 0.5570776255707763, 'pegasus_entailment': 0.7808398976922035, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.624, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5820895522388059, 'pegasus_entailment': 0.6613152585923672, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6739130434782609, 'r1_recall': 0.5081967213114754, 'r1_f1': 0.5794392523364487, 'pegasus_entailment': 0.4218052327632904, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6875, 'r1_recall': 0.463855421686747, 'r1_f1': 0.5539568345323741, 'pegasus_entailment': 0.36346298456192017, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5205479452054794, 'r1_recall': 0.6909090909090909, 'r1_f1': 0.59375, 'pegasus_entailment': 0.20500308523575464, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.6621621621621622, 'r1_f1': 0.547486033519553, 'pegasus_entailment': 0.5421691872179508, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5882352941176471, 'r1_recall': 0.3431372549019608, 'r1_f1': 0.43343653250773995, 'pegasus_entailment': 0.8909037113189697, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7094017094017094, 'r1_recall': 0.38425925925925924, 'r1_f1': 0.4984984984984985, 'pegasus_entailment': 0.38093746701876324, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4909090909090909, 'r1_recall': 0.4462809917355372, 'r1_f1': 0.4675324675324675, 'pegasus_entailment': 0.3786330081522465, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6422018348623854, 'r1_recall': 0.48951048951048953, 'r1_f1': 0.5555555555555556, 'pegasus_entailment': 0.1516966436058283, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42142857142857143, 'r1_recall': 0.6781609195402298, 'r1_f1': 0.5198237885462554, 'pegasus_entailment': 0.839323103427887, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41721854304635764, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.5206611570247935, 'pegasus_entailment': 0.8117801348368326, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3986013986013986, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.4653061224489796, 'pegasus_entailment': 0.3215726986527443, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5753424657534246, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.44919786096256686, 'pegasus_entailment': 0.26089430321007967, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5897435897435898, 'r1_recall': 0.46464646464646464, 'r1_f1': 0.519774011299435, 'pegasus_entailment': 0.21887610480189323, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3220338983050847, 'r1_recall': 0.42696629213483145, 'r1_f1': 0.3671497584541063, 'pegasus_entailment': 0.5952624082565308, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.675, 'r1_recall': 0.49693251533742333, 'r1_f1': 0.5724381625441696, 'pegasus_entailment': 0.3389609344303608, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.64, 'r1_recall': 0.26373626373626374, 'r1_f1': 0.37354085603112835, 'pegasus_entailment': 0.5633938908576965, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6935483870967742, 'r1_recall': 0.31272727272727274, 'r1_f1': 0.431077694235589, 'pegasus_entailment': 0.20300436913967132, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5789473684210527, 'r1_recall': 0.5045871559633027, 'r1_f1': 0.5392156862745099, 'pegasus_entailment': 0.6460630521178246, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26582278481012656, 'r1_recall': 0.3620689655172414, 'r1_f1': 0.3065693430656934, 'pegasus_entailment': 0.9707360565662384, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 17}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5813953488372093, 'r1_recall': 0.27624309392265195, 'r1_f1': 0.3745318352059925, 'pegasus_entailment': 0.688292404015859, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3445378151260504, 'r1_recall': 0.5324675324675324, 'r1_f1': 0.41836734693877553, 'pegasus_entailment': 0.4574697569012642, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32571428571428573, 'r1_recall': 0.7125, 'r1_f1': 0.4470588235294118, 'pegasus_entailment': 0.5455219112336636, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5934065934065934, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.5869565217391305, 'pegasus_entailment': 0.7388964220881462, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5096153846153846, 'r1_recall': 0.654320987654321, 'r1_f1': 0.572972972972973, 'pegasus_entailment': 0.5579134874045849, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5308641975308642, 'r1_recall': 0.4777777777777778, 'r1_f1': 0.5029239766081872, 'pegasus_entailment': 0.6428880492846171, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27956989247311825, 'r1_recall': 0.37681159420289856, 'r1_f1': 0.32098765432098764, 'pegasus_entailment': 0.4505146484589204, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3782051282051282, 'r1_recall': 0.6145833333333334, 'r1_f1': 0.46825396825396826, 'pegasus_entailment': 0.4413776679171456, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38, 'r1_recall': 0.59375, 'r1_f1': 0.46341463414634143, 'pegasus_entailment': 0.3738635601475835, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3968253968253968, 'r1_recall': 0.5494505494505495, 'r1_f1': 0.4608294930875576, 'pegasus_entailment': 0.6062497496604919, 'pegasus_flesch_kincaid': 31, 'pegasus_coleman_liau': 18, 'pegasus_ari': 39, 'pegasus_smog': 24}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44696969696969696, 'r1_recall': 0.6704545454545454, 'r1_f1': 0.5363636363636364, 'pegasus_entailment': 0.6399026811122894, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38524590163934425, 'r1_recall': 0.7580645161290323, 'r1_f1': 0.5108695652173914, 'pegasus_entailment': 0.5259238600730896, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5147058823529411, 'r1_recall': 0.6542056074766355, 'r1_f1': 0.5761316872427984, 'pegasus_entailment': 0.5157240554690361, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38028169014084506, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.40298507462686567, 'pegasus_entailment': 0.3669706713408232, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7920792079207921, 'r1_recall': 0.3018867924528302, 'r1_f1': 0.4371584699453552, 'pegasus_entailment': 0.4796195328235626, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36633663366336633, 'r1_recall': 0.578125, 'r1_f1': 0.4484848484848485, 'pegasus_entailment': 0.4862455949187279, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4148936170212766, 'r1_recall': 0.42391304347826086, 'r1_f1': 0.41935483870967744, 'pegasus_entailment': 0.8469926357269287, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.512396694214876, 'r1_recall': 0.62, 'r1_f1': 0.5610859728506787, 'pegasus_entailment': 0.5371859036386013, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4772727272727273, 'r1_recall': 0.45, 'r1_f1': 0.4632352941176471, 'pegasus_entailment': 0.7819550991058349, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5319148936170213, 'r1_recall': 0.5319148936170213, 'r1_f1': 0.5319148936170213, 'pegasus_entailment': 0.4124035630375147, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5816326530612245, 'r1_recall': 0.44881889763779526, 'r1_f1': 0.5066666666666667, 'pegasus_entailment': 0.7392638102173805, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3918918918918919, 'r1_recall': 0.4084507042253521, 'r1_f1': 0.4, 'pegasus_entailment': 0.59487184882164, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4409448818897638, 'r1_recall': 0.5957446808510638, 'r1_f1': 0.506787330316742, 'pegasus_entailment': 0.34745545871555805, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5263157894736842, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5, 'pegasus_entailment': 0.23872927762567997, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5348837209302325, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.575, 'pegasus_entailment': 0.3030800308721761, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4642857142857143, 'r1_recall': 0.582089552238806, 'r1_f1': 0.5165562913907285, 'pegasus_entailment': 0.6351023316383362, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.358974358974359, 'r1_recall': 0.4375, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.836095929145813, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5287356321839081, 'r1_recall': 0.2658959537572254, 'r1_f1': 0.3538461538461538, 'pegasus_entailment': 0.5277276933193207, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6261682242990654, 'r1_recall': 0.40606060606060607, 'r1_f1': 0.4926470588235294, 'pegasus_entailment': 0.42679300780097645, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6320754716981132, 'r1_recall': 0.6836734693877551, 'r1_f1': 0.6568627450980392, 'pegasus_entailment': 0.6183235887438059, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851063829787234, 'r1_recall': 0.29411764705882354, 'r1_f1': 0.3914590747330961, 'pegasus_entailment': 0.10104828886687756, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44871794871794873, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.4046242774566474, 'pegasus_entailment': 0.44852709472179414, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42424242424242425, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4912280701754386, 'pegasus_entailment': 0.6436878641446432, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40625, 'r1_recall': 0.4727272727272727, 'r1_f1': 0.43697478991596644, 'pegasus_entailment': 0.651074081659317, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22727272727272727, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.3289473684210526, 'pegasus_entailment': 0.37106930650770664, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4144144144144144, 'r1_recall': 0.647887323943662, 'r1_f1': 0.5054945054945055, 'pegasus_entailment': 0.9077486991882324, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32142857142857145, 'r1_recall': 0.5192307692307693, 'r1_f1': 0.39705882352941174, 'pegasus_entailment': 0.3618789967149496, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5072463768115942, 'r1_recall': 0.29914529914529914, 'r1_f1': 0.3763440860215054, 'pegasus_entailment': 0.4053036882542074, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6534653465346535, 'r1_recall': 0.5038167938931297, 'r1_f1': 0.5689655172413793, 'pegasus_entailment': 0.4550515413284302, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5405405405405406, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5063291139240507, 'pegasus_entailment': 0.5093708166386932, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 12}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6037735849056604, 'r1_recall': 0.35555555555555557, 'r1_f1': 0.44755244755244755, 'pegasus_entailment': 0.6055308878421783, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.5934065934065934, 'r1_f1': 0.5118483412322274, 'pegasus_entailment': 0.43761444091796875, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 25}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.51, 'r1_recall': 0.4636363636363636, 'r1_f1': 0.4857142857142857, 'pegasus_entailment': 0.5802631005644798, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 22}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5842696629213483, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.574585635359116, 'pegasus_entailment': 0.5011084030071894, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5058823529411764, 'r1_recall': 0.43, 'r1_f1': 0.46486486486486484, 'pegasus_entailment': 0.6636000603437424, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2708333333333333, 'r1_recall': 0.37681159420289856, 'r1_f1': 0.3151515151515151, 'pegasus_entailment': 0.6837629559449852, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5227272727272727, 'r1_recall': 0.5287356321839081, 'r1_f1': 0.5257142857142857, 'pegasus_entailment': 0.6650414168834686, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6203703703703703, 'r1_recall': 0.6568627450980392, 'r1_f1': 0.638095238095238, 'pegasus_entailment': 0.5822240188717842, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40298507462686567, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.49541284403669733, 'pegasus_entailment': 0.6191720366477966, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23255813953488372, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.2898550724637681, 'pegasus_entailment': 0.4679887555539608, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6237623762376238, 'r1_recall': 0.4405594405594406, 'r1_f1': 0.5163934426229508, 'pegasus_entailment': 0.7031949818134308, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5402298850574713, 'r1_recall': 0.5402298850574713, 'r1_f1': 0.5402298850574713, 'pegasus_entailment': 0.3125515356659889, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.4878048780487805, 'pegasus_entailment': 0.6433320247257749, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.39669421487603307, 'r1_f1': 0.45933014354066987, 'pegasus_entailment': 0.6853058040142059, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41379310344827586, 'r1_recall': 0.34615384615384615, 'r1_f1': 0.37696335078534027, 'pegasus_entailment': 0.3346194537977378, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47368421052631576, 'r1_recall': 0.2571428571428571, 'r1_f1': 0.3333333333333333, 'pegasus_entailment': 0.6736226181189219, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2892561983471074, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.36269430051813467, 'pegasus_entailment': 0.37788626505061984, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48598130841121495, 'r1_recall': 0.5842696629213483, 'r1_f1': 0.5306122448979592, 'pegasus_entailment': 0.29396875699361164, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1826086956521739, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.2625, 'pegasus_entailment': 0.6165829971432686, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45255474452554745, 'r1_recall': 0.6019417475728155, 'r1_f1': 0.5166666666666667, 'pegasus_entailment': 0.45390594253937405, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.13186813186813187, 'r1_recall': 0.34285714285714286, 'r1_f1': 0.1904761904761905, 'pegasus_entailment': 0.44790851697325706, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3472222222222222, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.42735042735042733, 'pegasus_entailment': 0.879147469997406, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22627737226277372, 'r1_recall': 0.7948717948717948, 'r1_f1': 0.3522727272727273, 'pegasus_entailment': 0.9510880907376608, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7647058823529411, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.48148148148148157, 'pegasus_entailment': 0.26776187121868134, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.6, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.8117288649082184, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32450331125827814, 'r1_recall': 0.5104166666666666, 'r1_f1': 0.3967611336032389, 'pegasus_entailment': 0.3928569592535496, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.532258064516129, 'r1_recall': 0.6055045871559633, 'r1_f1': 0.5665236051502146, 'pegasus_entailment': 0.35898205637931824, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.603448275862069, 'r1_recall': 0.5072463768115942, 'r1_f1': 0.5511811023622047, 'pegasus_entailment': 0.3799579789241155, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8791208791208791, 'r1_recall': 0.22727272727272727, 'r1_f1': 0.3611738148984198, 'pegasus_entailment': 0.9009361664454142, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4298245614035088, 'r1_recall': 0.44144144144144143, 'r1_f1': 0.4355555555555556, 'pegasus_entailment': 0.7416481897234917, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5212765957446809, 'r1_recall': 0.3288590604026846, 'r1_f1': 0.4032921810699589, 'pegasus_entailment': 0.6765744984149933, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7325581395348837, 'r1_recall': 0.4228187919463087, 'r1_f1': 0.5361702127659574, 'pegasus_entailment': 0.7686430931091308, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24691358024691357, 'r1_recall': 0.40816326530612246, 'r1_f1': 0.3076923076923077, 'pegasus_entailment': 0.199537156149745, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3884297520661157, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.48704663212435234, 'pegasus_entailment': 0.36349406590064365, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3602941176470588, 'r1_recall': 0.6049382716049383, 'r1_f1': 0.45161290322580644, 'pegasus_entailment': 0.48194907456636427, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8762886597938144, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.6882591093117408, 'pegasus_entailment': 0.5371608038743337, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4117647058823529, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.4605263157894737, 'pegasus_entailment': 0.5246486216783524, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7894736842105263, 'r1_recall': 0.5232558139534884, 'r1_f1': 0.6293706293706294, 'pegasus_entailment': 0.9063218633333842, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34965034965034963, 'r1_recall': 0.6756756756756757, 'r1_f1': 0.4608294930875576, 'pegasus_entailment': 0.7385792210698128, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5223880597014925, 'r1_recall': 0.43209876543209874, 'r1_f1': 0.47297297297297297, 'pegasus_entailment': 0.8222944339116415, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5603448275862069, 'r1_recall': 0.46099290780141844, 'r1_f1': 0.5058365758754862, 'pegasus_entailment': 0.5897003471851349, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3438914027149321, 'r1_recall': 0.5801526717557252, 'r1_f1': 0.4318181818181818, 'pegasus_entailment': 0.6571499332785606, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 20, 'pegasus_ari': 36, 'pegasus_smog': 25}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5975609756097561, 'r1_recall': 0.460093896713615, 'r1_f1': 0.519893899204244, 'pegasus_entailment': 0.5900787532329559, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5529411764705883, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.537142857142857, 'pegasus_entailment': 0.8222491343816122, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36470588235294116, 'r1_recall': 0.543859649122807, 'r1_f1': 0.4366197183098592, 'pegasus_entailment': 0.564756323893865, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.31746031746031744, 'r1_f1': 0.42105263157894735, 'pegasus_entailment': 0.5144186150282621, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6941176470588235, 'r1_recall': 0.19407894736842105, 'r1_f1': 0.3033419023136247, 'pegasus_entailment': 0.29711681852738064, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18840579710144928, 'r1_recall': 0.4126984126984127, 'r1_f1': 0.25870646766169153, 'pegasus_entailment': 0.5562828965485096, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40131578947368424, 'r1_recall': 0.6421052631578947, 'r1_f1': 0.4939271255060729, 'pegasus_entailment': 0.6066539287567139, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6782608695652174, 'r1_recall': 0.4936708860759494, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.43907816614955664, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2835820895522388, 'r1_recall': 0.3275862068965517, 'r1_f1': 0.304, 'pegasus_entailment': 0.3528770574678977, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7272727272727273, 'r1_recall': 0.35359116022099446, 'r1_f1': 0.4758364312267657, 'pegasus_entailment': 0.401650071144104, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.569620253164557, 'r1_recall': 0.31690140845070425, 'r1_f1': 0.40723981900452494, 'pegasus_entailment': 0.5625083049138387, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44761904761904764, 'r1_recall': 0.49473684210526314, 'r1_f1': 0.47000000000000003, 'pegasus_entailment': 0.29756504762917757, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5855855855855856, 'r1_recall': 0.37790697674418605, 'r1_f1': 0.45936395759717313, 'pegasus_entailment': 0.6312712550163269, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41509433962264153, 'r1_recall': 0.6197183098591549, 'r1_f1': 0.4971751412429378, 'pegasus_entailment': 0.5009271539747715, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7159090909090909, 'r1_recall': 0.30288461538461536, 'r1_f1': 0.42567567567567566, 'pegasus_entailment': 0.7563634117444357, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36464088397790057, 'r1_recall': 0.7096774193548387, 'r1_f1': 0.48175182481751827, 'pegasus_entailment': 0.6750149726867676, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36507936507936506, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.45771144278606957, 'pegasus_entailment': 0.6137096732854843, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46236559139784944, 'r1_recall': 0.6056338028169014, 'r1_f1': 0.524390243902439, 'pegasus_entailment': 0.3920397361119588, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5148514851485149, 'r1_recall': 0.5148514851485149, 'r1_f1': 0.5148514851485149, 'pegasus_entailment': 0.6513090133666992, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6938775510204082, 'r1_recall': 0.4927536231884058, 'r1_f1': 0.576271186440678, 'pegasus_entailment': 0.7587986886501312, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.4485981308411215, 'pegasus_entailment': 0.7946982562541962, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27058823529411763, 'r1_recall': 0.38333333333333336, 'r1_f1': 0.31724137931034485, 'pegasus_entailment': 0.32220791776974994, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8058252427184466, 'r1_recall': 0.46629213483146065, 'r1_f1': 0.590747330960854, 'pegasus_entailment': 0.7039458863437176, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44339622641509435, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.5251396648044692, 'pegasus_entailment': 0.4095403850078583, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4435483870967742, 'r1_recall': 0.7236842105263158, 'r1_f1': 0.55, 'pegasus_entailment': 0.21511110139545053, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5529411764705883, 'r1_recall': 0.5164835164835165, 'r1_f1': 0.5340909090909091, 'pegasus_entailment': 0.4883999414741993, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6228070175438597, 'r1_recall': 0.5916666666666667, 'r1_f1': 0.6068376068376069, 'pegasus_entailment': 0.565395787358284, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8145161290322581, 'r1_recall': 0.14326241134751774, 'r1_f1': 0.2436670687575392, 'pegasus_entailment': 0.719287283718586, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6363636363636364, 'r1_recall': 0.49295774647887325, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.5859746634960175, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.88, 'r1_recall': 0.4808743169398907, 'r1_f1': 0.6219081272084805, 'pegasus_entailment': 0.4208165916303794, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4015748031496063, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.4636363636363636, 'pegasus_entailment': 0.3654447728767991, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5929203539823009, 'r1_recall': 0.5775862068965517, 'r1_f1': 0.5851528384279475, 'pegasus_entailment': 0.5120957437902689, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4574468085106383, 'r1_recall': 0.6615384615384615, 'r1_f1': 0.540880503144654, 'pegasus_entailment': 0.32931030122563243, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48201438848920863, 'r1_recall': 0.4267515923566879, 'r1_f1': 0.4527027027027027, 'pegasus_entailment': 0.41376807913184166, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.20175438596491227, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.2839506172839506, 'pegasus_entailment': 0.39992243610322475, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4731182795698925, 'r1_recall': 0.4536082474226804, 'r1_f1': 0.46315789473684216, 'pegasus_entailment': 0.9707311391830444, 'pegasus_flesch_kincaid': 45, 'pegasus_coleman_liau': 20, 'pegasus_ari': 55, 'pegasus_smog': 32}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1743119266055046, 'r1_recall': 0.5428571428571428, 'r1_f1': 0.2638888888888889, 'pegasus_entailment': 0.4398182760924101, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43537414965986393, 'r1_recall': 0.6597938144329897, 'r1_f1': 0.5245901639344263, 'pegasus_entailment': 0.5514963768422604, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5178571428571429, 'r1_recall': 0.5132743362831859, 'r1_f1': 0.5155555555555555, 'pegasus_entailment': 0.67866450548172, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6363636363636364, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.5384615384615385, 'pegasus_entailment': 0.45638997317291796, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23232323232323232, 'r1_recall': 0.42592592592592593, 'r1_f1': 0.30065359477124176, 'pegasus_entailment': 0.39395245611667634, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5774647887323944, 'r1_recall': 0.41, 'r1_f1': 0.47953216374269003, 'pegasus_entailment': 0.8469030410051346, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.031578947368421054
MEAN
0.5039881876995551
MAX
0.88
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.0410958904109589
MEAN
0.5021844395657316
MAX
0.7971014492753623
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.03571428571428571
MEAN
0.4796578201394519
MAX
0.6995073891625615
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.06338276776174705
MEAN
0.5457424162566189
MAX
0.9890740911165873
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
17
MAX
52
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
1
MEAN
17
MAX
24
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
12
MEAN
21
MAX
64
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
8
MEAN
18
MAX
34
{}
