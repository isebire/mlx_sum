Entered file!
Imports done!
*** RUN *** 
eval_2cB
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
** Loading results csv
*** Analysing case 0
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.21 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3439153439153439, 'r1_recall': 0.5909090909090909, 'r1_f1': 0.4347826086956522, 'r2_precision': 0.13829787234042554, 'r2_recall': 0.23853211009174313, 'r2_f1': 0.1750841750841751, 'rL_precision': 0.17989417989417988, 'rL_recall': 0.3090909090909091, 'rL_f1': 0.22742474916387959, 'bs_precision': 0.2876920700073242, 'bs_recall': 0.4163723886013031, 'bs_f1': 0.35075151920318604, 'bs_mnli_precision': 0.6104393005371094, 'bs_mnli_recall': 0.674125611782074, 'bs_mnli_f1': 0.6407036781311035, 'unique_bigram_ratio': 0.9513513513513514, 'nid': -0.21926917980407268, 'grammatical_errors': 0, 'pegasus_entailment': 0.6246168434619903, 'gold_entailment': 0.5025635659694672, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 1
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.84 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5393258426966292, 'r1_recall': 0.5549132947976878, 'r1_f1': 0.5470085470085471, 'r2_precision': 0.192090395480226, 'r2_recall': 0.19767441860465115, 'r2_f1': 0.19484240687679083, 'rL_precision': 0.2303370786516854, 'rL_recall': 0.23699421965317918, 'rL_f1': 0.2336182336182336, 'bs_precision': 0.46164780855178833, 'bs_recall': 0.3750818371772766, 'bs_f1': 0.4188603460788727, 'bs_mnli_precision': 0.6957768201828003, 'bs_mnli_recall': 0.6568459868431091, 'bs_mnli_f1': 0.6757512092590332, 'unique_bigram_ratio': 0.9479768786127167, 'nid': -0.24348192654249456, 'grammatical_errors': 0, 'pegasus_entailment': 0.5586648366103569, 'gold_entailment': 0.530137801276786, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 2
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.46 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.17408906882591094, 'r1_recall': 0.7413793103448276, 'r1_f1': 0.28196721311475414, 'r2_precision': 0.044715447154471545, 'r2_recall': 0.19298245614035087, 'r2_f1': 0.07260726072607261, 'rL_precision': 0.0931174089068826, 'rL_recall': 0.39655172413793105, 'rL_f1': 0.15081967213114755, 'bs_precision': 0.05506843328475952, 'bs_recall': 0.3663308918476105, 'bs_f1': 0.19019095599651337, 'bs_mnli_precision': 0.5183224081993103, 'bs_mnli_recall': 0.6941607594490051, 'bs_mnli_f1': 0.59349125623703, 'unique_bigram_ratio': 0.9163179916317992, 'nid': -0.2151435724690025, 'grammatical_errors': 3, 'pegasus_entailment': 0.2790211966261268, 'gold_entailment': 0.21996606141328812, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 3
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.70 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5633802816901409, 'r1_recall': 0.6201550387596899, 'r1_f1': 0.5904059040590407, 'r2_precision': 0.3049645390070922, 'r2_recall': 0.3359375, 'r2_f1': 0.3197026022304833, 'rL_precision': 0.39436619718309857, 'rL_recall': 0.43410852713178294, 'rL_f1': 0.41328413284132837, 'bs_precision': 0.43820303678512573, 'bs_recall': 0.4797927141189575, 'bs_f1': 0.4605107605457306, 'bs_mnli_precision': 0.7083921432495117, 'bs_mnli_recall': 0.7467939853668213, 'bs_mnli_f1': 0.7270863652229309, 'unique_bigram_ratio': 0.9424460431654677, 'nid': -0.2474858323461815, 'grammatical_errors': 2, 'pegasus_entailment': 0.36257986202836034, 'gold_entailment': 0.16659018630161881, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 4
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.05 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5054347826086957, 'r1_recall': 0.5344827586206896, 'r1_f1': 0.5195530726256984, 'r2_precision': 0.1912568306010929, 'r2_recall': 0.2023121387283237, 'r2_f1': 0.19662921348314608, 'rL_precision': 0.2717391304347826, 'rL_recall': 0.28735632183908044, 'rL_f1': 0.27932960893854747, 'bs_precision': 0.3193645179271698, 'bs_recall': 0.39873892068862915, 'bs_f1': 0.35991883277893066, 'bs_mnli_precision': 0.6459283232688904, 'bs_mnli_recall': 0.6760998368263245, 'bs_mnli_f1': 0.6606698036193848, 'unique_bigram_ratio': 0.9385474860335196, 'nid': -0.22193453047163425, 'grammatical_errors': 3, 'pegasus_entailment': 0.5147622355393001, 'gold_entailment': 0.19450564309954643, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 5
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.11 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.358695652173913, 'r1_recall': 0.5076923076923077, 'r1_f1': 0.4203821656050955, 'r2_precision': 0.1092896174863388, 'r2_recall': 0.15503875968992248, 'r2_f1': 0.1282051282051282, 'rL_precision': 0.19021739130434784, 'rL_recall': 0.2692307692307692, 'rL_f1': 0.2229299363057325, 'bs_precision': 0.28936484456062317, 'bs_recall': 0.3167906403541565, 'bs_f1': 0.30529263615608215, 'bs_mnli_precision': 0.6323120594024658, 'bs_mnli_recall': 0.6448824405670166, 'bs_mnli_f1': 0.6385353803634644, 'unique_bigram_ratio': 0.9213483146067416, 'nid': -0.21100636097938574, 'grammatical_errors': 0, 'pegasus_entailment': 0.36981236934661865, 'gold_entailment': 0.22012584060430526, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 6
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 67.79 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.11904761904761904, 'r1_recall': 0.625, 'r1_f1': 0.19999999999999998, 'r2_precision': 0.03592814371257485, 'r2_recall': 0.1935483870967742, 'r2_f1': 0.0606060606060606, 'rL_precision': 0.08333333333333333, 'rL_recall': 0.4375, 'rL_f1': 0.13999999999999999, 'bs_precision': 0.1126842200756073, 'bs_recall': 0.4329347014427185, 'bs_f1': 0.2521131932735443, 'bs_mnli_precision': 0.5220118761062622, 'bs_mnli_recall': 0.6984384059906006, 'bs_mnli_f1': 0.59747314453125, 'unique_bigram_ratio': 0.9503105590062112, 'nid': -0.23129756562496873, 'grammatical_errors': 0, 'pegasus_entailment': 0.4495976982372148, 'gold_entailment': 0.2981189365188281, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 7
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 82.75 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2523364485981308, 'r1_recall': 0.8709677419354839, 'r1_f1': 0.3913043478260869, 'r2_precision': 0.14150943396226415, 'r2_recall': 0.5, 'r2_f1': 0.22058823529411764, 'rL_precision': 0.205607476635514, 'rL_recall': 0.7096774193548387, 'rL_f1': 0.3188405797101449, 'bs_precision': 0.26523980498313904, 'bs_recall': 0.6571482419967651, 'bs_f1': 0.433388352394104, 'bs_mnli_precision': 0.6046789884567261, 'bs_mnli_recall': 0.8229594230651855, 'bs_mnli_f1': 0.6971321105957031, 'unique_bigram_ratio': 0.9702970297029703, 'nid': -0.2924157198059718, 'grammatical_errors': 0, 'pegasus_entailment': 0.7031989892323812, 'gold_entailment': 0.615858256816864, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 8
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.64 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5637583892617449, 'r1_recall': 0.5637583892617449, 'r1_f1': 0.5637583892617449, 'r2_precision': 0.3581081081081081, 'r2_recall': 0.3581081081081081, 'r2_f1': 0.3581081081081081, 'rL_precision': 0.4161073825503356, 'rL_recall': 0.4161073825503356, 'rL_f1': 0.4161073825503356, 'bs_precision': 0.4343584179878235, 'bs_recall': 0.4474567174911499, 'bs_f1': 0.44278407096862793, 'bs_mnli_precision': 0.7034344673156738, 'bs_mnli_recall': 0.7072523832321167, 'bs_mnli_f1': 0.7053382396697998, 'unique_bigram_ratio': 0.9586206896551724, 'nid': -0.24980982832622733, 'grammatical_errors': 2, 'pegasus_entailment': 0.4771806014080842, 'gold_entailment': 0.5682932532259396, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 9
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.10 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4742857142857143, 'r1_recall': 0.6014492753623188, 'r1_f1': 0.5303514376996805, 'r2_precision': 0.21264367816091953, 'r2_recall': 0.27007299270072993, 'r2_f1': 0.23794212218649516, 'rL_precision': 0.26857142857142857, 'rL_recall': 0.34057971014492755, 'rL_f1': 0.3003194888178914, 'bs_precision': 0.295916885137558, 'bs_recall': 0.3517988622188568, 'bs_f1': 0.3254918158054352, 'bs_mnli_precision': 0.6414248943328857, 'bs_mnli_recall': 0.6500431895256042, 'bs_mnli_f1': 0.6457052826881409, 'unique_bigram_ratio': 0.9590643274853801, 'nid': -0.20342580377586472, 'grammatical_errors': 3, 'pegasus_entailment': 0.5306134058960846, 'gold_entailment': 0.3026285966237386, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 10
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.27 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5259259259259259, 'r1_recall': 0.47333333333333333, 'r1_f1': 0.49824561403508766, 'r2_precision': 0.27611940298507465, 'r2_recall': 0.2483221476510067, 'r2_f1': 0.26148409893992935, 'rL_precision': 0.2740740740740741, 'rL_recall': 0.24666666666666667, 'rL_f1': 0.2596491228070175, 'bs_precision': 0.3683875501155853, 'bs_recall': 0.37161633372306824, 'bs_f1': 0.3721524178981781, 'bs_mnli_precision': 0.6757460832595825, 'bs_mnli_recall': 0.6587662696838379, 'bs_mnli_f1': 0.6671481728553772, 'unique_bigram_ratio': 0.9699248120300752, 'nid': -0.29475655899782227, 'grammatical_errors': 1, 'pegasus_entailment': 0.5483212545514107, 'gold_entailment': 0.3703038364648819, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 11
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.60 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3697916666666667, 'r1_recall': 0.5966386554621849, 'r1_f1': 0.4565916398713827, 'r2_precision': 0.15706806282722513, 'r2_recall': 0.2542372881355932, 'r2_f1': 0.1941747572815534, 'rL_precision': 0.234375, 'rL_recall': 0.37815126050420167, 'rL_f1': 0.28938906752411575, 'bs_precision': 0.2928301990032196, 'bs_recall': 0.41617101430892944, 'bs_f1': 0.35350197553634644, 'bs_mnli_precision': 0.6326399445533752, 'bs_mnli_recall': 0.6989296078681946, 'bs_mnli_f1': 0.6641347408294678, 'unique_bigram_ratio': 0.9513513513513514, 'nid': -0.21412427155342684, 'grammatical_errors': 1, 'pegasus_entailment': 0.7100017219781876, 'gold_entailment': 0.5938594102859497, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 12
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 75.02 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5803571428571429, 'r1_recall': 0.6074766355140186, 'r1_f1': 0.5936073059360729, 'r2_precision': 0.3153153153153153, 'r2_recall': 0.330188679245283, 'r2_f1': 0.3225806451612903, 'rL_precision': 0.41964285714285715, 'rL_recall': 0.4392523364485981, 'rL_f1': 0.4292237442922374, 'bs_precision': 0.5068466067314148, 'bs_recall': 0.5000762343406677, 'bs_f1': 0.5051498413085938, 'bs_mnli_precision': 0.736810564994812, 'bs_mnli_recall': 0.7322697639465332, 'bs_mnli_f1': 0.7345331311225891, 'unique_bigram_ratio': 0.9541284403669725, 'nid': -0.259359837709362, 'grammatical_errors': 0, 'pegasus_entailment': 0.45506381392478945, 'gold_entailment': 0.4696320965886116, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 13
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 68.57 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.40707964601769914, 'r1_recall': 0.5227272727272727, 'r1_f1': 0.4577114427860697, 'r2_precision': 0.19642857142857142, 'r2_recall': 0.25287356321839083, 'r2_f1': 0.22110552763819097, 'rL_precision': 0.3008849557522124, 'rL_recall': 0.38636363636363635, 'rL_f1': 0.3383084577114428, 'bs_precision': 0.41433945298194885, 'bs_recall': 0.46095073223114014, 'bs_f1': 0.4391379952430725, 'bs_mnli_precision': 0.6875382661819458, 'bs_mnli_recall': 0.6976823806762695, 'bs_mnli_f1': 0.6925731897354126, 'unique_bigram_ratio': 0.9814814814814815, 'nid': -0.2848228132375923, 'grammatical_errors': 2, 'pegasus_entailment': 0.5087304592132569, 'gold_entailment': 0.28962519268194836, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 14
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.49 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.3802083333333333, 'r1_f1': 0.43195266272189353, 'r2_precision': 0.2, 'r2_recall': 0.1518324607329843, 'r2_f1': 0.17261904761904762, 'rL_precision': 0.3150684931506849, 'rL_recall': 0.23958333333333334, 'rL_f1': 0.27218934911242604, 'bs_precision': 0.29882046580314636, 'bs_recall': 0.22937551140785217, 'bs_f1': 0.2655179500579834, 'bs_mnli_precision': 0.6354538798332214, 'bs_mnli_recall': 0.6106808185577393, 'bs_mnli_f1': 0.6228210926055908, 'unique_bigram_ratio': 0.9929577464788732, 'nid': -0.260161276517513, 'grammatical_errors': 1, 'pegasus_entailment': 0.30898111760616304, 'gold_entailment': 0.16758272604783997, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 15
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.36 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.15346534653465346, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.2375478927203065, 'r2_precision': 0.03482587064676617, 'r2_recall': 0.1206896551724138, 'r2_f1': 0.05405405405405405, 'rL_precision': 0.0891089108910891, 'rL_recall': 0.3050847457627119, 'rL_f1': 0.13793103448275862, 'bs_precision': 0.06192345917224884, 'bs_recall': 0.3145204484462738, 'bs_f1': 0.17537344992160797, 'bs_mnli_precision': 0.5053694248199463, 'bs_mnli_recall': 0.62736976146698, 'bs_mnli_f1': 0.5597996711730957, 'unique_bigram_ratio': 0.9246231155778895, 'nid': -0.2250166217082048, 'grammatical_errors': 4, 'pegasus_entailment': 0.263176498003304, 'gold_entailment': 0.31833145022392273, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 16
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.69 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.23, 'r1_recall': 0.46464646464646464, 'r1_f1': 0.3076923076923077, 'r2_precision': 0.05527638190954774, 'r2_recall': 0.11224489795918367, 'r2_f1': 0.07407407407407408, 'rL_precision': 0.115, 'rL_recall': 0.23232323232323232, 'rL_f1': 0.15384615384615385, 'bs_precision': 0.1387307494878769, 'bs_recall': 0.26632314920425415, 'bs_f1': 0.2013181746006012, 'bs_mnli_precision': 0.5420453548431396, 'bs_mnli_recall': 0.6268537044525146, 'bs_mnli_f1': 0.5813729166984558, 'unique_bigram_ratio': 0.9381443298969072, 'nid': -0.23283277784197853, 'grammatical_errors': 1, 'pegasus_entailment': 0.7929341912269592, 'gold_entailment': 0.44362615297238034, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 17
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 35.91 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.7, 'r1_recall': 0.3053691275167785, 'r1_f1': 0.4252336448598131, 'r2_precision': 0.2868217054263566, 'r2_recall': 0.12457912457912458, 'r2_f1': 0.17370892018779344, 'rL_precision': 0.36923076923076925, 'rL_recall': 0.1610738255033557, 'rL_f1': 0.22429906542056074, 'bs_precision': 0.4488864541053772, 'bs_recall': 0.22570961713790894, 'bs_f1': 0.32894259691238403, 'bs_mnli_precision': 0.7072386145591736, 'bs_mnli_recall': 0.5864689350128174, 'bs_mnli_f1': 0.6412166953086853, 'unique_bigram_ratio': 0.9838709677419355, 'nid': -0.2545416050437479, 'grammatical_errors': 2, 'pegasus_entailment': 0.4586848855018616, 'gold_entailment': 0.2495304487645626, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 18
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.17 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.47878787878787876, 'r1_recall': 0.4906832298136646, 'r1_f1': 0.48466257668711654, 'r2_precision': 0.21951219512195122, 'r2_recall': 0.225, 'r2_f1': 0.22222222222222224, 'rL_precision': 0.23030303030303031, 'rL_recall': 0.2360248447204969, 'rL_f1': 0.2331288343558282, 'bs_precision': 0.28055402636528015, 'bs_recall': 0.23461885750293732, 'bs_f1': 0.25964218378067017, 'bs_mnli_precision': 0.6322649717330933, 'bs_mnli_recall': 0.6037864089012146, 'bs_mnli_f1': 0.6176976561546326, 'unique_bigram_ratio': 0.949685534591195, 'nid': -0.24430559169449428, 'grammatical_errors': 0, 'pegasus_entailment': 0.3995065023856504, 'gold_entailment': 0.1585101628942149, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 19
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 75.07 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5135135135135135, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.5757575757575758, 'r2_precision': 0.2545454545454545, 'r2_recall': 0.32558139534883723, 'r2_f1': 0.2857142857142857, 'rL_precision': 0.36036036036036034, 'rL_recall': 0.45977011494252873, 'rL_f1': 0.40404040404040403, 'bs_precision': 0.5004924535751343, 'bs_recall': 0.5589333176612854, 'bs_f1': 0.5306922197341919, 'bs_mnli_precision': 0.7370073795318604, 'bs_mnli_recall': 0.7774415612220764, 'bs_mnli_f1': 0.7566847205162048, 'unique_bigram_ratio': 0.9719626168224299, 'nid': -0.2725974691099162, 'grammatical_errors': 0, 'pegasus_entailment': 0.3482562378048897, 'gold_entailment': 0.34125813841819763, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 20
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.54 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5976331360946746, 'r1_recall': 0.554945054945055, 'r1_f1': 0.5754985754985756, 'r2_precision': 0.2916666666666667, 'r2_recall': 0.27071823204419887, 'r2_f1': 0.2808022922636103, 'rL_precision': 0.34911242603550297, 'rL_recall': 0.3241758241758242, 'rL_f1': 0.3361823361823362, 'bs_precision': 0.42646780610084534, 'bs_recall': 0.4334337115287781, 'bs_f1': 0.43188896775245667, 'bs_mnli_precision': 0.6836628317832947, 'bs_mnli_recall': 0.6942036151885986, 'bs_mnli_f1': 0.6888929009437561, 'unique_bigram_ratio': 0.9696969696969697, 'nid': -0.23959290595425764, 'grammatical_errors': 3, 'pegasus_entailment': 0.5764685620864233, 'gold_entailment': 0.3787737637758255, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 21
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.26 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5070422535211268, 'r1_recall': 0.48, 'r1_f1': 0.4931506849315068, 'r2_precision': 0.2695035460992908, 'r2_recall': 0.2550335570469799, 'r2_f1': 0.26206896551724135, 'rL_precision': 0.33098591549295775, 'rL_recall': 0.31333333333333335, 'rL_f1': 0.3219178082191781, 'bs_precision': 0.32624492049217224, 'bs_recall': 0.2828948497772217, 'bs_f1': 0.30653566122055054, 'bs_mnli_precision': 0.6390072107315063, 'bs_mnli_recall': 0.6273934245109558, 'bs_mnli_f1': 0.6331470608711243, 'unique_bigram_ratio': 0.9416058394160584, 'nid': -0.21064099073798803, 'grammatical_errors': 0, 'pegasus_entailment': 0.4722054104010264, 'gold_entailment': 0.20837022612492243, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 22
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.54 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.427536231884058, 'r1_recall': 0.5462962962962963, 'r1_f1': 0.4796747967479675, 'r2_precision': 0.21897810218978103, 'r2_recall': 0.2803738317757009, 'r2_f1': 0.2459016393442623, 'rL_precision': 0.3115942028985507, 'rL_recall': 0.39814814814814814, 'rL_f1': 0.3495934959349593, 'bs_precision': 0.30091288685798645, 'bs_recall': 0.35456332564353943, 'bs_f1': 0.3294137716293335, 'bs_mnli_precision': 0.6269262433052063, 'bs_mnli_recall': 0.6535540819168091, 'bs_mnli_f1': 0.6399632692337036, 'unique_bigram_ratio': 0.9318181818181818, 'nid': -0.25023792367006203, 'grammatical_errors': 2, 'pegasus_entailment': 0.6096753239631653, 'gold_entailment': 0.38158789835870266, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 23
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.33 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5735294117647058, 'r1_f1': 0.5342465753424658, 'r2_precision': 0.21935483870967742, 'r2_recall': 0.2518518518518518, 'r2_f1': 0.23448275862068965, 'rL_precision': 0.30128205128205127, 'rL_recall': 0.34558823529411764, 'rL_f1': 0.3219178082191781, 'bs_precision': 0.29707950353622437, 'bs_recall': 0.34826135635375977, 'bs_f1': 0.32441672682762146, 'bs_mnli_precision': 0.6366392374038696, 'bs_mnli_recall': 0.679760217666626, 'bs_mnli_f1': 0.6574934720993042, 'unique_bigram_ratio': 0.9477124183006536, 'nid': -0.24784768919952493, 'grammatical_errors': 0, 'pegasus_entailment': 0.4678747405608495, 'gold_entailment': 0.1915984395891428, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 24
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 74.02 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24793388429752067, 'r1_recall': 0.6, 'r1_f1': 0.3508771929824562, 'r2_precision': 0.10833333333333334, 'r2_recall': 0.2653061224489796, 'r2_f1': 0.15384615384615385, 'rL_precision': 0.15702479338842976, 'rL_recall': 0.38, 'rL_f1': 0.2222222222222222, 'bs_precision': 0.22750651836395264, 'bs_recall': 0.3883068561553955, 'bs_f1': 0.3046042323112488, 'bs_mnli_precision': 0.5790554285049438, 'bs_mnli_recall': 0.6783718466758728, 'bs_mnli_f1': 0.6247915029525757, 'unique_bigram_ratio': 0.9736842105263158, 'nid': -0.29636322508899915, 'grammatical_errors': 1, 'pegasus_entailment': 0.32435607314109804, 'gold_entailment': 0.43734486401081085, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.87 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5405405405405405, 'r2_precision': 0.35664335664335667, 'r2_recall': 0.2712765957446808, 'r2_f1': 0.30815709969788524, 'rL_precision': 0.4652777777777778, 'rL_recall': 0.3544973544973545, 'rL_f1': 0.4024024024024023, 'bs_precision': 0.4421161413192749, 'bs_recall': 0.435340940952301, 'bs_f1': 0.4406377077102661, 'bs_mnli_precision': 0.7077686190605164, 'bs_mnli_recall': 0.7030961513519287, 'bs_mnli_f1': 0.7054246068000793, 'unique_bigram_ratio': 0.9857142857142858, 'nid': -0.29613685046585503, 'grammatical_errors': 4, 'pegasus_entailment': 0.5432842671871185, 'gold_entailment': 0.5087024971842766, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 26
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.67 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.489247311827957, 'r1_recall': 0.6642335766423357, 'r1_f1': 0.5634674922600619, 'r2_precision': 0.22162162162162163, 'r2_recall': 0.3014705882352941, 'r2_f1': 0.25545171339563866, 'rL_precision': 0.3225806451612903, 'rL_recall': 0.43795620437956206, 'rL_f1': 0.37151702786377705, 'bs_precision': 0.4064016342163086, 'bs_recall': 0.43399563431739807, 'bs_f1': 0.4220271706581116, 'bs_mnli_precision': 0.6844141483306885, 'bs_mnli_recall': 0.7022759318351746, 'bs_mnli_f1': 0.6932299733161926, 'unique_bigram_ratio': 0.9395604395604396, 'nid': -0.21196672136456818, 'grammatical_errors': 0, 'pegasus_entailment': 0.4694148004055023, 'gold_entailment': 0.2360549122095108, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 27
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 39.88 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.608433734939759, 'r1_recall': 0.376865671641791, 'r1_f1': 0.4654377880184331, 'r2_precision': 0.24242424242424243, 'r2_recall': 0.149812734082397, 'r2_f1': 0.18518518518518517, 'rL_precision': 0.3313253012048193, 'rL_recall': 0.20522388059701493, 'rL_f1': 0.2534562211981567, 'bs_precision': 0.3262575566768646, 'bs_recall': 0.25494569540023804, 'bs_f1': 0.2918985188007355, 'bs_mnli_precision': 0.6340513229370117, 'bs_mnli_recall': 0.6039454340934753, 'bs_mnli_f1': 0.6186322569847107, 'unique_bigram_ratio': 0.9743589743589743, 'nid': -0.27371085484259505, 'grammatical_errors': 0, 'pegasus_entailment': 0.3337811291217804, 'gold_entailment': 0.21804510802030563, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 28
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 69.29 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.32857142857142857, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.4259259259259259, 'r2_precision': 0.17985611510791366, 'r2_recall': 0.3333333333333333, 'r2_f1': 0.23364485981308414, 'rL_precision': 0.22142857142857142, 'rL_recall': 0.40789473684210525, 'rL_f1': 0.28703703703703703, 'bs_precision': 0.3197038769721985, 'bs_recall': 0.37387943267822266, 'bs_f1': 0.3484002649784088, 'bs_mnli_precision': 0.6454759836196899, 'bs_mnli_recall': 0.68864905834198, 'bs_mnli_f1': 0.6663639545440674, 'unique_bigram_ratio': 0.9632352941176471, 'nid': -0.257254706420321, 'grammatical_errors': 1, 'pegasus_entailment': 0.48544643446803093, 'gold_entailment': 0.1516748278712233, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 29
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.72 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.27358490566037735, 'r1_recall': 0.5132743362831859, 'r1_f1': 0.35692307692307695, 'r2_precision': 0.07582938388625593, 'r2_recall': 0.14285714285714285, 'r2_f1': 0.09907120743034055, 'rL_precision': 0.15566037735849056, 'rL_recall': 0.2920353982300885, 'rL_f1': 0.20307692307692304, 'bs_precision': 0.1672380566596985, 'bs_recall': 0.31451380252838135, 'bs_f1': 0.2384176105260849, 'bs_mnli_precision': 0.5559000372886658, 'bs_mnli_recall': 0.6126877069473267, 'bs_mnli_f1': 0.5829141139984131, 'unique_bigram_ratio': 0.9423076923076923, 'nid': -0.20184891707356467, 'grammatical_errors': 1, 'pegasus_entailment': 0.463329258064429, 'gold_entailment': 0.40236485563218594, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 30
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.49 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2896174863387978, 'r1_recall': 0.6091954022988506, 'r1_f1': 0.3925925925925926, 'r2_precision': 0.12087912087912088, 'r2_recall': 0.2558139534883721, 'r2_f1': 0.16417910447761194, 'rL_precision': 0.21311475409836064, 'rL_recall': 0.4482758620689655, 'rL_f1': 0.28888888888888886, 'bs_precision': 0.20094315707683563, 'bs_recall': 0.40131205320358276, 'bs_f1': 0.29466527700424194, 'bs_mnli_precision': 0.5614774823188782, 'bs_mnli_recall': 0.6718239784240723, 'bs_mnli_f1': 0.6117143034934998, 'unique_bigram_ratio': 0.9553072625698324, 'nid': -0.24559189269061465, 'grammatical_errors': 4, 'pegasus_entailment': 0.47025749683380125, 'gold_entailment': 0.2990163365999858, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 31
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.90 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4385026737967914, 'r1_recall': 0.4079601990049751, 'r1_f1': 0.4226804123711341, 'r2_precision': 0.17204301075268819, 'r2_recall': 0.16, 'r2_f1': 0.1658031088082902, 'rL_precision': 0.25668449197860965, 'rL_recall': 0.23880597014925373, 'rL_f1': 0.24742268041237114, 'bs_precision': 0.2909441590309143, 'bs_recall': 0.2224036008119583, 'bs_f1': 0.2581401765346527, 'bs_mnli_precision': 0.6290764212608337, 'bs_mnli_recall': 0.5800668001174927, 'bs_mnli_f1': 0.6035783886909485, 'unique_bigram_ratio': 0.9234972677595629, 'nid': -0.17251067098839767, 'grammatical_errors': 1, 'pegasus_entailment': 0.44304268434643745, 'gold_entailment': 0.39933426181475323, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 32
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.75 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.34265734265734266, 'r1_recall': 0.47572815533980584, 'r1_f1': 0.39837398373983735, 'r2_precision': 0.09859154929577464, 'r2_recall': 0.13725490196078433, 'r2_f1': 0.11475409836065574, 'rL_precision': 0.1888111888111888, 'rL_recall': 0.2621359223300971, 'rL_f1': 0.21951219512195122, 'bs_precision': 0.3008415400981903, 'bs_recall': 0.3464404046535492, 'bs_f1': 0.32550138235092163, 'bs_mnli_precision': 0.6062355041503906, 'bs_mnli_recall': 0.6192430257797241, 'bs_mnli_f1': 0.6126702427864075, 'unique_bigram_ratio': 0.9565217391304348, 'nid': -0.2780734536999703, 'grammatical_errors': 1, 'pegasus_entailment': 0.6406753242015839, 'gold_entailment': 0.2712821923196316, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 33
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.85 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3179190751445087, 'r1_recall': 0.5670103092783505, 'r1_f1': 0.4074074074074074, 'r2_precision': 0.14534883720930233, 'r2_recall': 0.2604166666666667, 'r2_f1': 0.1865671641791045, 'rL_precision': 0.2023121387283237, 'rL_recall': 0.36082474226804123, 'rL_f1': 0.2592592592592593, 'bs_precision': 0.3465663492679596, 'bs_recall': 0.4879172742366791, 'bs_f1': 0.4152372181415558, 'bs_mnli_precision': 0.6481876373291016, 'bs_mnli_recall': 0.7029113173484802, 'bs_mnli_f1': 0.6744411587715149, 'unique_bigram_ratio': 0.9470588235294117, 'nid': -0.2491530184527535, 'grammatical_errors': 4, 'pegasus_entailment': 0.665702298283577, 'gold_entailment': 0.5204540888468424, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 34
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.87 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2823529411764706, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.3779527559055118, 'r2_precision': 0.15976331360946747, 'r2_recall': 0.3253012048192771, 'r2_f1': 0.2142857142857143, 'rL_precision': 0.16470588235294117, 'rL_recall': 0.3333333333333333, 'rL_f1': 0.2204724409448819, 'bs_precision': 0.2769011855125427, 'bs_recall': 0.45082008838653564, 'bs_f1': 0.3597159683704376, 'bs_mnli_precision': 0.5967205762863159, 'bs_mnli_recall': 0.690912127494812, 'bs_mnli_f1': 0.6403712630271912, 'unique_bigram_ratio': 0.9085365853658537, 'nid': -0.21285137599947834, 'grammatical_errors': 1, 'pegasus_entailment': 0.43248824384063483, 'gold_entailment': 0.3567475924889247, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 35
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 70.82 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.46835443037974683, 'r1_recall': 0.31896551724137934, 'r1_f1': 0.3794871794871795, 'r2_precision': 0.19230769230769232, 'r2_recall': 0.13043478260869565, 'r2_f1': 0.15544041450777202, 'rL_precision': 0.31645569620253167, 'rL_recall': 0.21551724137931033, 'rL_f1': 0.2564102564102564, 'bs_precision': 0.30545899271965027, 'bs_recall': 0.18957743048667908, 'bs_f1': 0.24699057638645172, 'bs_mnli_precision': 0.6296837329864502, 'bs_mnli_recall': 0.5625048279762268, 'bs_mnli_f1': 0.5942016243934631, 'unique_bigram_ratio': 0.9868421052631579, 'nid': -0.2893666411839213, 'grammatical_errors': 2, 'pegasus_entailment': 0.4114907644689083, 'gold_entailment': 0.43042004108428955, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 36
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.20 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2843601895734597, 'r1_recall': 0.8695652173913043, 'r1_f1': 0.4285714285714286, 'r2_precision': 0.1761904761904762, 'r2_recall': 0.5441176470588235, 'r2_f1': 0.2661870503597122, 'rL_precision': 0.1895734597156398, 'rL_recall': 0.5797101449275363, 'rL_f1': 0.2857142857142857, 'bs_precision': 0.24216797947883606, 'bs_recall': 0.4927709698677063, 'bs_f1': 0.3565562069416046, 'bs_mnli_precision': 0.5903062224388123, 'bs_mnli_recall': 0.7180043458938599, 'bs_mnli_f1': 0.6479232907295227, 'unique_bigram_ratio': 0.9471153846153846, 'nid': -0.2355785522131002, 'grammatical_errors': 8, 'pegasus_entailment': 0.599288871511817, 'gold_entailment': 0.7589377959569296, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 37
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 59.20 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.26582278481012656, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.3716814159292035, 'r2_precision': 0.10828025477707007, 'r2_recall': 0.2537313432835821, 'r2_f1': 0.15178571428571427, 'rL_precision': 0.21518987341772153, 'rL_recall': 0.5, 'rL_f1': 0.3008849557522124, 'bs_precision': 0.2853313088417053, 'bs_recall': 0.46964287757873535, 'bs_f1': 0.37259870767593384, 'bs_mnli_precision': 0.5976012945175171, 'bs_mnli_recall': 0.681922197341919, 'bs_mnli_f1': 0.636983335018158, 'unique_bigram_ratio': 0.974025974025974, 'nid': -0.24228299132211895, 'grammatical_errors': 1, 'pegasus_entailment': 0.5860827362630516, 'gold_entailment': 0.13734645769000053, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 38
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 59.55 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.147239263803681, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.23076923076923078, 'r2_precision': 0.030864197530864196, 'r2_recall': 0.11363636363636363, 'r2_f1': 0.04854368932038835, 'rL_precision': 0.09815950920245399, 'rL_recall': 0.35555555555555557, 'rL_f1': 0.15384615384615385, 'bs_precision': 0.13860398530960083, 'bs_recall': 0.36007145047187805, 'bs_f1': 0.24057252705097198, 'bs_mnli_precision': 0.508074164390564, 'bs_mnli_recall': 0.6502218246459961, 'bs_mnli_f1': 0.5704257488250732, 'unique_bigram_ratio': 0.9490445859872612, 'nid': -0.23066588811421407, 'grammatical_errors': 0, 'pegasus_entailment': 0.6772181491057078, 'gold_entailment': 0.6519759744405746, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 39
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.19 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5170068027210885, 'r1_recall': 0.4578313253012048, 'r1_f1': 0.48562300319488816, 'r2_precision': 0.21232876712328766, 'r2_recall': 0.18787878787878787, 'r2_f1': 0.19935691318327975, 'rL_precision': 0.3197278911564626, 'rL_recall': 0.28313253012048195, 'rL_f1': 0.30031948881789133, 'bs_precision': 0.38173848390579224, 'bs_recall': 0.29701560735702515, 'bs_f1': 0.3401089608669281, 'bs_mnli_precision': 0.6776643395423889, 'bs_mnli_recall': 0.6412093639373779, 'bs_mnli_f1': 0.6589330434799194, 'unique_bigram_ratio': 0.9790209790209791, 'nid': -0.25107824872561424, 'grammatical_errors': 0, 'pegasus_entailment': 0.5582686334848403, 'gold_entailment': 0.17253870964050294, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 40
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.02 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5266272189349113, 'r1_recall': 0.55625, 'r1_f1': 0.5410334346504558, 'r2_precision': 0.22023809523809523, 'r2_recall': 0.23270440251572327, 'r2_f1': 0.22629969418960244, 'rL_precision': 0.33136094674556216, 'rL_recall': 0.35, 'rL_f1': 0.3404255319148936, 'bs_precision': 0.42619040608406067, 'bs_recall': 0.3874123990535736, 'bs_f1': 0.40852707624435425, 'bs_mnli_precision': 0.6815920472145081, 'bs_mnli_recall': 0.6630496978759766, 'bs_mnli_f1': 0.6721930503845215, 'unique_bigram_ratio': 0.9390243902439024, 'nid': -0.23364702183979214, 'grammatical_errors': 0, 'pegasus_entailment': 0.6421930768660137, 'gold_entailment': 0.4372316598892212, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 41
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.92 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3023255813953488, 'r1_recall': 0.6753246753246753, 'r1_f1': 0.41767068273092367, 'r2_precision': 0.14619883040935672, 'r2_recall': 0.32894736842105265, 'r2_f1': 0.20242914979757085, 'rL_precision': 0.22674418604651161, 'rL_recall': 0.5064935064935064, 'rL_f1': 0.3132530120481928, 'bs_precision': 0.31541553139686584, 'bs_recall': 0.500514805316925, 'bs_f1': 0.40308678150177, 'bs_mnli_precision': 0.6221106052398682, 'bs_mnli_recall': 0.7184854745864868, 'bs_mnli_f1': 0.6668338775634766, 'unique_bigram_ratio': 0.9397590361445783, 'nid': -0.19065396749473185, 'grammatical_errors': 1, 'pegasus_entailment': 0.40730786323547363, 'gold_entailment': 0.330745667219162, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 42
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 59.53 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3076923076923077, 'r1_recall': 0.6027397260273972, 'r1_f1': 0.40740740740740744, 'r2_precision': 0.13380281690140844, 'r2_recall': 0.2638888888888889, 'r2_f1': 0.17757009345794392, 'rL_precision': 0.16083916083916083, 'rL_recall': 0.3150684931506849, 'rL_f1': 0.21296296296296297, 'bs_precision': 0.24940212070941925, 'bs_recall': 0.47979623079299927, 'bs_f1': 0.35569214820861816, 'bs_mnli_precision': 0.5739482641220093, 'bs_mnli_recall': 0.7000554800033569, 'bs_mnli_f1': 0.6307604908943176, 'unique_bigram_ratio': 0.9712230215827338, 'nid': -0.2781630094288028, 'grammatical_errors': 4, 'pegasus_entailment': 0.42134826704859735, 'gold_entailment': 0.199818664851288, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 43
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.59 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3802083333333333, 'r1_recall': 0.5934959349593496, 'r1_f1': 0.4634920634920635, 'r2_precision': 0.20418848167539266, 'r2_recall': 0.319672131147541, 'r2_f1': 0.24920127795527153, 'rL_precision': 0.25, 'rL_recall': 0.3902439024390244, 'rL_f1': 0.3047619047619048, 'bs_precision': 0.39219754934310913, 'bs_recall': 0.4371963441371918, 'bs_f1': 0.4162901043891907, 'bs_mnli_precision': 0.6818913221359253, 'bs_mnli_recall': 0.7072360515594482, 'bs_mnli_f1': 0.694332480430603, 'unique_bigram_ratio': 0.9157894736842105, 'nid': -0.2109823845389509, 'grammatical_errors': 0, 'pegasus_entailment': 0.5724555055300394, 'gold_entailment': 0.05904622686405977, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 44
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 40.78 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.1550632911392405, 'r1_recall': 0.6282051282051282, 'r1_f1': 0.24873096446700507, 'r2_precision': 0.06031746031746032, 'r2_recall': 0.24675324675324675, 'r2_f1': 0.09693877551020409, 'rL_precision': 0.10126582278481013, 'rL_recall': 0.41025641025641024, 'rL_f1': 0.16243654822335027, 'bs_precision': 0.11385500431060791, 'bs_recall': 0.4226004183292389, 'bs_f1': 0.249092236161232, 'bs_mnli_precision': 0.5266000628471375, 'bs_mnli_recall': 0.6914699077606201, 'bs_mnli_f1': 0.5978770852088928, 'unique_bigram_ratio': 0.8726114649681529, 'nid': -0.14727829932579106, 'grammatical_errors': 1, 'pegasus_entailment': 0.5177536650250355, 'gold_entailment': 0.18417415767908096, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 45
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.71 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5403225806451613, 'r1_recall': 0.44666666666666666, 'r1_f1': 0.48905109489051096, 'r2_precision': 0.24390243902439024, 'r2_recall': 0.20134228187919462, 'r2_f1': 0.22058823529411764, 'rL_precision': 0.28225806451612906, 'rL_recall': 0.23333333333333334, 'rL_f1': 0.25547445255474455, 'bs_precision': 0.35836854577064514, 'bs_recall': 0.3476436734199524, 'bs_f1': 0.3551931381225586, 'bs_mnli_precision': 0.6479533910751343, 'bs_mnli_recall': 0.6385238170623779, 'bs_mnli_f1': 0.6432040333747864, 'unique_bigram_ratio': 0.9421487603305785, 'nid': -0.24312198272126406, 'grammatical_errors': 2, 'pegasus_entailment': 0.5878407303243876, 'gold_entailment': 0.5623835057020188, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 46
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.53 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3632286995515695, 'r1_recall': 0.6864406779661016, 'r1_f1': 0.47507331378299117, 'r2_precision': 0.22072072072072071, 'r2_recall': 0.4188034188034188, 'r2_f1': 0.28908554572271383, 'rL_precision': 0.2914798206278027, 'rL_recall': 0.5508474576271186, 'rL_f1': 0.38123167155425214, 'bs_precision': 0.3441651165485382, 'bs_recall': 0.4968486726284027, 'bs_f1': 0.4178374409675598, 'bs_mnli_precision': 0.6583459973335266, 'bs_mnli_recall': 0.7402238249778748, 'bs_mnli_f1': 0.6968882083892822, 'unique_bigram_ratio': 0.9248826291079812, 'nid': -0.19391023464376733, 'grammatical_errors': 0, 'pegasus_entailment': 0.3744816239923239, 'gold_entailment': 0.3067900389432907, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 47
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.56 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.37185929648241206, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.47741935483870973, 'r2_precision': 0.13131313131313133, 'r2_recall': 0.23636363636363636, 'r2_f1': 0.16883116883116883, 'rL_precision': 0.2562814070351759, 'rL_recall': 0.4594594594594595, 'rL_f1': 0.3290322580645161, 'bs_precision': 0.3527325689792633, 'bs_recall': 0.5006973147392273, 'bs_f1': 0.42432865500450134, 'bs_mnli_precision': 0.63742995262146, 'bs_mnli_recall': 0.7188771963119507, 'bs_mnli_f1': 0.6757081151008606, 'unique_bigram_ratio': 0.949238578680203, 'nid': -0.24951833990978067, 'grammatical_errors': 2, 'pegasus_entailment': 0.5711157268711499, 'gold_entailment': 0.4139849580824375, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 48
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 66.08 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3695652173913043, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.45945945945945943, 'r2_precision': 0.13138686131386862, 'r2_recall': 0.21686746987951808, 'r2_f1': 0.16363636363636366, 'rL_precision': 0.2391304347826087, 'rL_recall': 0.39285714285714285, 'rL_f1': 0.2972972972972973, 'bs_precision': 0.3275669813156128, 'bs_recall': 0.4499320983886719, 'bs_f1': 0.3877730071544647, 'bs_mnli_precision': 0.6396220922470093, 'bs_mnli_recall': 0.705433189868927, 'bs_mnli_f1': 0.6709175705909729, 'unique_bigram_ratio': 0.948905109489051, 'nid': -0.2166090116084598, 'grammatical_errors': 6, 'pegasus_entailment': 0.5983299485274723, 'gold_entailment': 0.6384464701016744, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 49
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 39.93 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.23103448275862068, 'r1_recall': 0.6442307692307693, 'r1_f1': 0.3401015228426396, 'r2_precision': 0.09688581314878893, 'r2_recall': 0.27184466019417475, 'r2_f1': 0.14285714285714288, 'rL_precision': 0.13793103448275862, 'rL_recall': 0.38461538461538464, 'rL_f1': 0.20304568527918782, 'bs_precision': 0.19993643462657928, 'bs_recall': 0.4130835235118866, 'bs_f1': 0.29891252517700195, 'bs_mnli_precision': 0.5747785568237305, 'bs_mnli_recall': 0.6760013103485107, 'bs_mnli_f1': 0.6212940812110901, 'unique_bigram_ratio': 0.9298245614035088, 'nid': -0.21499574569309154, 'grammatical_errors': 3, 'pegasus_entailment': 0.6045472081750631, 'gold_entailment': 0.46713072061538696, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 50
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.68 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.32894736842105265, 'r1_recall': 0.6756756756756757, 'r1_f1': 0.4424778761061947, 'r2_precision': 0.09933774834437085, 'r2_recall': 0.2054794520547945, 'r2_f1': 0.13392857142857142, 'rL_precision': 0.2236842105263158, 'rL_recall': 0.4594594594594595, 'rL_f1': 0.3008849557522124, 'bs_precision': 0.20223022997379303, 'bs_recall': 0.35234102606773376, 'bs_f1': 0.2746792733669281, 'bs_mnli_precision': 0.5867261290550232, 'bs_mnli_recall': 0.6930304765701294, 'bs_mnli_f1': 0.6354632377624512, 'unique_bigram_ratio': 0.9455782312925171, 'nid': -0.21499561789585075, 'grammatical_errors': 5, 'pegasus_entailment': 0.28355177817866206, 'gold_entailment': 0.6451673209667206, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 51
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.53 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.1875, 'r1_recall': 0.7058823529411765, 'r1_f1': 0.2962962962962963, 'r2_precision': 0.07329842931937172, 'r2_recall': 0.28, 'r2_f1': 0.1161825726141079, 'rL_precision': 0.11458333333333333, 'rL_recall': 0.43137254901960786, 'rL_f1': 0.1810699588477366, 'bs_precision': 0.09746141731739044, 'bs_recall': 0.33465421199798584, 'bs_f1': 0.20532743632793427, 'bs_mnli_precision': 0.5195139646530151, 'bs_mnli_recall': 0.6755716800689697, 'bs_mnli_f1': 0.5873535871505737, 'unique_bigram_ratio': 0.9444444444444444, 'nid': -0.23784489066815784, 'grammatical_errors': 0, 'pegasus_entailment': 0.3112127206155232, 'gold_entailment': 0.3413532506674528, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 52
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.41 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.21658986175115208, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.32302405498281783, 'r2_precision': 0.12962962962962962, 'r2_recall': 0.3835616438356164, 'r2_f1': 0.19377162629757785, 'rL_precision': 0.17050691244239632, 'rL_recall': 0.5, 'rL_f1': 0.2542955326460481, 'bs_precision': 0.22769108414649963, 'bs_recall': 0.4929894804954529, 'bs_f1': 0.34778591990470886, 'bs_mnli_precision': 0.555073618888855, 'bs_mnli_recall': 0.7275747656822205, 'bs_mnli_f1': 0.6297245621681213, 'unique_bigram_ratio': 0.9339622641509434, 'nid': -0.20975214423566024, 'grammatical_errors': 0, 'pegasus_entailment': 0.5407650896481105, 'gold_entailment': 0.15212789488335451, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 53
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.55 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5967741935483871, 'r1_recall': 0.4180790960451977, 'r1_f1': 0.4916943521594684, 'r2_precision': 0.2032520325203252, 'r2_recall': 0.14204545454545456, 'r2_f1': 0.16722408026755853, 'rL_precision': 0.3467741935483871, 'rL_recall': 0.24293785310734464, 'rL_f1': 0.28571428571428575, 'bs_precision': 0.41566699743270874, 'bs_recall': 0.3233140707015991, 'bs_f1': 0.36987748742103577, 'bs_mnli_precision': 0.6749143600463867, 'bs_mnli_recall': 0.632632851600647, 'bs_mnli_f1': 0.6530900001525879, 'unique_bigram_ratio': 0.9666666666666667, 'nid': -0.25791672212275873, 'grammatical_errors': 0, 'pegasus_entailment': 0.31599472016096114, 'gold_entailment': 0.2275938421487808, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 54
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.73 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5233160621761658, 'r1_recall': 0.5674157303370787, 'r1_f1': 0.5444743935309972, 'r2_precision': 0.21875, 'r2_recall': 0.23728813559322035, 'r2_f1': 0.22764227642276422, 'rL_precision': 0.3005181347150259, 'rL_recall': 0.3258426966292135, 'rL_f1': 0.31266846361185985, 'bs_precision': 0.33240634202957153, 'bs_recall': 0.3559693992137909, 'bs_f1': 0.34631022810935974, 'bs_mnli_precision': 0.6268232464790344, 'bs_mnli_recall': 0.6522181034088135, 'bs_mnli_f1': 0.6392685770988464, 'unique_bigram_ratio': 0.9572192513368984, 'nid': -0.22310043367616528, 'grammatical_errors': 2, 'pegasus_entailment': 0.3604812042787671, 'gold_entailment': 0.2307035710130419, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 55
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.62 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2604166666666667, 'r1_recall': 0.6944444444444444, 'r1_f1': 0.3787878787878788, 'r2_precision': 0.14659685863874344, 'r2_recall': 0.39436619718309857, 'r2_f1': 0.21374045801526717, 'rL_precision': 0.16666666666666666, 'rL_recall': 0.4444444444444444, 'rL_f1': 0.24242424242424243, 'bs_precision': 0.27486732602119446, 'bs_recall': 0.4787188470363617, 'bs_f1': 0.3703366816043854, 'bs_mnli_precision': 0.6095696091651917, 'bs_mnli_recall': 0.7127423882484436, 'bs_mnli_f1': 0.657131016254425, 'unique_bigram_ratio': 0.956989247311828, 'nid': -0.23206791578464148, 'grammatical_errors': 4, 'pegasus_entailment': 0.5099130982998759, 'gold_entailment': 0.4871969322363536, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 56
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 43.04 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5260115606936416, 'r1_recall': 0.36254980079681276, 'r1_f1': 0.42924528301886794, 'r2_precision': 0.1686046511627907, 'r2_recall': 0.116, 'r2_f1': 0.13744075829383887, 'rL_precision': 0.2658959537572254, 'rL_recall': 0.18326693227091634, 'rL_f1': 0.21698113207547168, 'bs_precision': 0.26714178919792175, 'bs_recall': 0.16867296397686005, 'bs_f1': 0.21827983856201172, 'bs_mnli_precision': 0.6191281676292419, 'bs_mnli_recall': 0.5527670383453369, 'bs_mnli_f1': 0.5840686559677124, 'unique_bigram_ratio': 0.9285714285714286, 'nid': -0.2067751728399636, 'grammatical_errors': 1, 'pegasus_entailment': 0.3403125873633793, 'gold_entailment': 0.25700175965374167, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 57
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 70.07 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3230769230769231, 'r1_recall': 0.65625, 'r1_f1': 0.43298969072164956, 'r2_precision': 0.13178294573643412, 'r2_recall': 0.2698412698412698, 'r2_f1': 0.17708333333333334, 'rL_precision': 0.2153846153846154, 'rL_recall': 0.4375, 'rL_f1': 0.28865979381443296, 'bs_precision': 0.31920865178108215, 'bs_recall': 0.5454824566841125, 'bs_f1': 0.4241732060909271, 'bs_mnli_precision': 0.6105016469955444, 'bs_mnli_recall': 0.7243286371231079, 'bs_mnli_f1': 0.66256183385849, 'unique_bigram_ratio': 0.9763779527559056, 'nid': -0.2678272648195994, 'grammatical_errors': 3, 'pegasus_entailment': 0.5127660214900971, 'gold_entailment': 0.5561618655920029, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 58
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.19 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3669724770642202, 'r1_recall': 0.6611570247933884, 'r1_f1': 0.47197640117994105, 'r2_precision': 0.15207373271889402, 'r2_recall': 0.275, 'r2_f1': 0.19584569732937687, 'rL_precision': 0.19724770642201836, 'rL_recall': 0.35537190082644626, 'rL_f1': 0.2536873156342183, 'bs_precision': 0.24965932965278625, 'bs_recall': 0.4458608031272888, 'bs_f1': 0.3418387174606323, 'bs_mnli_precision': 0.6210671663284302, 'bs_mnli_recall': 0.7020190954208374, 'bs_mnli_f1': 0.6590666174888611, 'unique_bigram_ratio': 0.9154929577464789, 'nid': -0.2133386605430323, 'grammatical_errors': 2, 'pegasus_entailment': 0.44893676321953535, 'gold_entailment': 0.3055337122641504, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 59
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.15 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3096446700507614, 'r1_recall': 0.580952380952381, 'r1_f1': 0.4039735099337748, 'r2_precision': 0.12244897959183673, 'r2_recall': 0.23076923076923078, 'r2_f1': 0.16, 'rL_precision': 0.17766497461928935, 'rL_recall': 0.3333333333333333, 'rL_f1': 0.23178807947019867, 'bs_precision': 0.3067846894264221, 'bs_recall': 0.39216017723083496, 'bs_f1': 0.3501524031162262, 'bs_mnli_precision': 0.631139874458313, 'bs_mnli_recall': 0.6832447648048401, 'bs_mnli_f1': 0.656159520149231, 'unique_bigram_ratio': 0.9578947368421052, 'nid': -0.2333205515968395, 'grammatical_errors': 1, 'pegasus_entailment': 0.7057989711562792, 'gold_entailment': 0.3831447809934616, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 60
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.26 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3179190751445087, 'r1_recall': 0.625, 'r1_f1': 0.421455938697318, 'r2_precision': 0.11046511627906977, 'r2_recall': 0.21839080459770116, 'r2_f1': 0.14671814671814673, 'rL_precision': 0.1907514450867052, 'rL_recall': 0.375, 'rL_f1': 0.25287356321839083, 'bs_precision': 0.2882062792778015, 'bs_recall': 0.474208801984787, 'bs_f1': 0.3761990964412689, 'bs_mnli_precision': 0.6198434829711914, 'bs_mnli_recall': 0.6925148963928223, 'bs_mnli_f1': 0.654167115688324, 'unique_bigram_ratio': 0.9470588235294117, 'nid': -0.23593588829258993, 'grammatical_errors': 2, 'pegasus_entailment': 0.598917230963707, 'gold_entailment': 0.5266511738300323, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 61
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.54 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2702702702702703, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.36363636363636365, 'r2_precision': 0.07482993197278912, 'r2_recall': 0.15492957746478872, 'r2_f1': 0.10091743119266054, 'rL_precision': 0.1554054054054054, 'rL_recall': 0.3194444444444444, 'rL_f1': 0.2090909090909091, 'bs_precision': 0.25726914405822754, 'bs_recall': 0.35261213779449463, 'bs_f1': 0.30531641840934753, 'bs_mnli_precision': 0.5652291774749756, 'bs_mnli_recall': 0.6059924364089966, 'bs_mnli_f1': 0.5849014520645142, 'unique_bigram_ratio': 0.9795918367346939, 'nid': -0.2722769169424273, 'grammatical_errors': 3, 'pegasus_entailment': 0.6953004002571106, 'gold_entailment': 0.5339830964803696, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 24, 'pegasus_ari': 30, 'pegasus_smog': 25}
*** Analysing case 62
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 59.11 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.57, 'r1_recall': 0.3392857142857143, 'r1_f1': 0.4253731343283582, 'r2_precision': 0.1717171717171717, 'r2_recall': 0.10179640718562874, 'r2_f1': 0.12781954887218044, 'rL_precision': 0.33, 'rL_recall': 0.19642857142857142, 'rL_f1': 0.2462686567164179, 'bs_precision': 0.2945418059825897, 'bs_recall': 0.25819727778434753, 'bs_f1': 0.2785465717315674, 'bs_mnli_precision': 0.6260266900062561, 'bs_mnli_recall': 0.6082810163497925, 'bs_mnli_f1': 0.6170262694358826, 'unique_bigram_ratio': 0.968421052631579, 'nid': -0.2595755415111596, 'grammatical_errors': 0, 'pegasus_entailment': 0.3179932937026024, 'gold_entailment': 0.13130065146833658, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 63
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 77.18 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.43564356435643564, 'r1_recall': 0.4536082474226804, 'r1_f1': 0.4444444444444444, 'r2_precision': 0.17, 'r2_recall': 0.17708333333333334, 'r2_f1': 0.17346938775510207, 'rL_precision': 0.26732673267326734, 'rL_recall': 0.27835051546391754, 'rL_f1': 0.27272727272727276, 'bs_precision': 0.4409969449043274, 'bs_recall': 0.44891732931137085, 'bs_f1': 0.4468412697315216, 'bs_mnli_precision': 0.6952915191650391, 'bs_mnli_recall': 0.7070711851119995, 'bs_mnli_f1': 0.7011318802833557, 'unique_bigram_ratio': 0.9591836734693877, 'nid': -0.2898631879516831, 'grammatical_errors': 0, 'pegasus_entailment': 0.845883771777153, 'gold_entailment': 0.5351754228274027, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 64
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.24 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.22285714285714286, 'r1_recall': 0.8125, 'r1_f1': 0.34977578475336324, 'r2_precision': 0.12643678160919541, 'r2_recall': 0.46808510638297873, 'r2_f1': 0.19909502262443443, 'rL_precision': 0.17142857142857143, 'rL_recall': 0.625, 'rL_f1': 0.26905829596412556, 'bs_precision': 0.27347511053085327, 'bs_recall': 0.6410097479820251, 'bs_f1': 0.432942271232605, 'bs_mnli_precision': 0.6018996834754944, 'bs_mnli_recall': 0.8115745782852173, 'bs_mnli_f1': 0.691185474395752, 'unique_bigram_ratio': 0.9642857142857143, 'nid': -0.2697751441233447, 'grammatical_errors': 1, 'pegasus_entailment': 0.584470774446215, 'gold_entailment': 0.5196386873722076, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 65
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.34 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.45549738219895286, 'r1_recall': 0.6850393700787402, 'r1_f1': 0.5471698113207547, 'r2_precision': 0.21052631578947367, 'r2_recall': 0.31746031746031744, 'r2_f1': 0.25316455696202533, 'rL_precision': 0.29842931937172773, 'rL_recall': 0.44881889763779526, 'rL_f1': 0.3584905660377358, 'bs_precision': 0.39506796002388, 'bs_recall': 0.4977566599845886, 'bs_f1': 0.44624224305152893, 'bs_mnli_precision': 0.6668450832366943, 'bs_mnli_recall': 0.7337281107902527, 'bs_mnli_f1': 0.6986896395683289, 'unique_bigram_ratio': 0.9728260869565217, 'nid': -0.24692544344546952, 'grammatical_errors': 2, 'pegasus_entailment': 0.6281415410339832, 'gold_entailment': 0.48142219334840775, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 23}
*** Analysing case 66
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 66.32 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4732824427480916, 'r1_recall': 0.5849056603773585, 'r1_f1': 0.5232067510548523, 'r2_precision': 0.2692307692307692, 'r2_recall': 0.3333333333333333, 'r2_f1': 0.2978723404255319, 'rL_precision': 0.37404580152671757, 'rL_recall': 0.46226415094339623, 'rL_f1': 0.4135021097046413, 'bs_precision': 0.5272501111030579, 'bs_recall': 0.5107835531234741, 'bs_f1': 0.5206109285354614, 'bs_mnli_precision': 0.7210978269577026, 'bs_mnli_recall': 0.7323834300041199, 'bs_mnli_f1': 0.7266968488693237, 'unique_bigram_ratio': 0.9444444444444444, 'nid': -0.22499413186180228, 'grammatical_errors': 0, 'pegasus_entailment': 0.7467272639274597, 'gold_entailment': 0.5383912026882172, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 67
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.80 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4172661870503597, 'r1_recall': 0.6041666666666666, 'r1_f1': 0.49361702127659574, 'r2_precision': 0.2536231884057971, 'r2_recall': 0.3684210526315789, 'r2_f1': 0.3004291845493562, 'rL_precision': 0.34532374100719426, 'rL_recall': 0.5, 'rL_f1': 0.4085106382978723, 'bs_precision': 0.40053537487983704, 'bs_recall': 0.5075767040252686, 'bs_f1': 0.4536949396133423, 'bs_mnli_precision': 0.6652506589889526, 'bs_mnli_recall': 0.7278961539268494, 'bs_mnli_f1': 0.6951649785041809, 'unique_bigram_ratio': 0.9635036496350365, 'nid': -0.23080955476550336, 'grammatical_errors': 1, 'pegasus_entailment': 0.4911653231829405, 'gold_entailment': 0.342523642629385, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 68
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.50 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.5478260869565217, 'r1_f1': 0.4809160305343511, 'r2_precision': 0.22602739726027396, 'r2_recall': 0.2894736842105263, 'r2_f1': 0.25384615384615383, 'rL_precision': 0.3333333333333333, 'rL_recall': 0.4260869565217391, 'rL_f1': 0.3740458015267175, 'bs_precision': 0.3881780803203583, 'bs_recall': 0.38867199420928955, 'bs_f1': 0.3905147612094879, 'bs_mnli_precision': 0.6728833317756653, 'bs_mnli_recall': 0.688125491142273, 'bs_mnli_f1': 0.6804190278053284, 'unique_bigram_ratio': 0.965034965034965, 'nid': -0.2519552948074921, 'grammatical_errors': 0, 'pegasus_entailment': 0.5638345001886288, 'gold_entailment': 0.26250718037287396, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 69
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.36 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.45394736842105265, 'r1_recall': 0.6764705882352942, 'r1_f1': 0.5433070866141733, 'r2_precision': 0.25165562913907286, 'r2_recall': 0.37623762376237624, 'r2_f1': 0.30158730158730157, 'rL_precision': 0.2894736842105263, 'rL_recall': 0.43137254901960786, 'rL_f1': 0.3464566929133858, 'bs_precision': 0.3562591075897217, 'bs_recall': 0.4668828845024109, 'bs_f1': 0.4111221730709076, 'bs_mnli_precision': 0.6789951324462891, 'bs_mnli_recall': 0.7408995032310486, 'bs_mnli_f1': 0.7085978388786316, 'unique_bigram_ratio': 0.9527027027027027, 'nid': -0.24661245643268215, 'grammatical_errors': 2, 'pegasus_entailment': 0.4798692181706429, 'gold_entailment': 0.2607724815607071, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 70
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.59 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.47391304347826085, 'r1_recall': 0.6566265060240963, 'r1_f1': 0.5505050505050505, 'r2_precision': 0.22707423580786026, 'r2_recall': 0.3151515151515151, 'r2_f1': 0.2639593908629442, 'rL_precision': 0.2956521739130435, 'rL_recall': 0.40963855421686746, 'rL_f1': 0.34343434343434337, 'bs_precision': 0.4063907265663147, 'bs_recall': 0.4420531094074249, 'bs_f1': 0.4259355664253235, 'bs_mnli_precision': 0.6843522191047668, 'bs_mnli_recall': 0.6995257139205933, 'bs_mnli_f1': 0.6918557286262512, 'unique_bigram_ratio': 0.9103139013452914, 'nid': -0.21953482231636823, 'grammatical_errors': 1, 'pegasus_entailment': 0.6942923702299595, 'gold_entailment': 0.5014013573527336, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 71
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.30 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.25609756097560976, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.36206896551724144, 'r2_precision': 0.08588957055214724, 'r2_recall': 0.208955223880597, 'r2_f1': 0.12173913043478261, 'rL_precision': 0.1524390243902439, 'rL_recall': 0.36764705882352944, 'rL_f1': 0.21551724137931033, 'bs_precision': 0.2631135880947113, 'bs_recall': 0.4127516448497772, 'bs_f1': 0.3354129493236542, 'bs_mnli_precision': 0.5879713296890259, 'bs_mnli_recall': 0.6892212629318237, 'bs_mnli_f1': 0.6345829963684082, 'unique_bigram_ratio': 0.9487179487179487, 'nid': -0.23841104945275426, 'grammatical_errors': 0, 'pegasus_entailment': 0.49067629048866884, 'gold_entailment': 0.35188440419733524, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 72
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 80.38 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.36, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.43373493975903615, 'r2_precision': 0.1414141414141414, 'r2_recall': 0.2153846153846154, 'r2_f1': 0.17073170731707316, 'rL_precision': 0.23, 'rL_recall': 0.3484848484848485, 'rL_f1': 0.27710843373493976, 'bs_precision': 0.21531075239181519, 'bs_recall': 0.39059317111968994, 'bs_f1': 0.298570841550827, 'bs_mnli_precision': 0.6015051603317261, 'bs_mnli_recall': 0.6770095825195312, 'bs_mnli_f1': 0.6370278596878052, 'unique_bigram_ratio': 0.9690721649484536, 'nid': -0.2925060436680851, 'grammatical_errors': 2, 'pegasus_entailment': 0.36720180213451387, 'gold_entailment': 0.42149341851472855, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 73
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.16 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5359116022099447, 'r1_recall': 0.5105263157894737, 'r1_f1': 0.522911051212938, 'r2_precision': 0.2722222222222222, 'r2_recall': 0.25925925925925924, 'r2_f1': 0.26558265582655827, 'rL_precision': 0.3149171270718232, 'rL_recall': 0.3, 'rL_f1': 0.307277628032345, 'bs_precision': 0.4167547821998596, 'bs_recall': 0.4256400167942047, 'bs_f1': 0.4231592118740082, 'bs_mnli_precision': 0.6815752387046814, 'bs_mnli_recall': 0.6805570125579834, 'bs_mnli_f1': 0.6810656785964966, 'unique_bigram_ratio': 0.9829545454545454, 'nid': -0.270585011175716, 'grammatical_errors': 1, 'pegasus_entailment': 0.48718574217387606, 'gold_entailment': 0.24047964035222927, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 74
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 39.98 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.12589928057553956, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.2, 'r2_precision': 0.02888086642599278, 'r2_recall': 0.11267605633802817, 'r2_f1': 0.04597701149425287, 'rL_precision': 0.07913669064748201, 'rL_recall': 0.3055555555555556, 'rL_f1': 0.1257142857142857, 'bs_precision': 0.07277515530586243, 'bs_recall': 0.2773122191429138, 'bs_f1': 0.16748319566249847, 'bs_mnli_precision': 0.4931468367576599, 'bs_mnli_recall': 0.5967090725898743, 'bs_mnli_f1': 0.540007472038269, 'unique_bigram_ratio': 0.9442379182156134, 'nid': -0.26343295021062385, 'grammatical_errors': 1, 'pegasus_entailment': 0.4625131839886308, 'gold_entailment': 0.20593036338686943, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 75
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.44 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2848101265822785, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.37037037037037035, 'r2_precision': 0.10828025477707007, 'r2_recall': 0.20238095238095238, 'r2_f1': 0.14107883817427386, 'rL_precision': 0.18354430379746836, 'rL_recall': 0.3411764705882353, 'rL_f1': 0.23868312757201648, 'bs_precision': 0.24878275394439697, 'bs_recall': 0.3870644271373749, 'bs_f1': 0.31609880924224854, 'bs_mnli_precision': 0.6053026914596558, 'bs_mnli_recall': 0.6936244368553162, 'bs_mnli_f1': 0.6464608311653137, 'unique_bigram_ratio': 0.9342105263157895, 'nid': -0.23633200392967413, 'grammatical_errors': 1, 'pegasus_entailment': 0.5919082569224494, 'gold_entailment': 0.5485700726509094, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 76
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.61 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.18106995884773663, 'r1_recall': 0.6875, 'r1_f1': 0.2866449511400651, 'r2_precision': 0.09090909090909091, 'r2_recall': 0.3492063492063492, 'r2_f1': 0.1442622950819672, 'rL_precision': 0.13168724279835392, 'rL_recall': 0.5, 'rL_f1': 0.20846905537459284, 'bs_precision': 0.15667887032032013, 'bs_recall': 0.44561317563056946, 'bs_f1': 0.2851363718509674, 'bs_mnli_precision': 0.5549237728118896, 'bs_mnli_recall': 0.6965584754943848, 'bs_mnli_f1': 0.6177265048027039, 'unique_bigram_ratio': 0.9227467811158798, 'nid': -0.22192926762833198, 'grammatical_errors': 7, 'pegasus_entailment': 0.4675938418755929, 'gold_entailment': 0.28516495414078236, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 77
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 67.59 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2714285714285714, 'r1_recall': 0.7307692307692307, 'r1_f1': 0.39583333333333326, 'r2_precision': 0.15827338129496402, 'r2_recall': 0.43137254901960786, 'r2_f1': 0.23157894736842105, 'rL_precision': 0.19285714285714287, 'rL_recall': 0.5192307692307693, 'rL_f1': 0.28125000000000006, 'bs_precision': 0.30101126432418823, 'bs_recall': 0.5593218803405762, 'bs_f1': 0.41891393065452576, 'bs_mnli_precision': 0.6090532541275024, 'bs_mnli_recall': 0.755791187286377, 'bs_mnli_f1': 0.6745341420173645, 'unique_bigram_ratio': 0.9253731343283582, 'nid': -0.22660198572323043, 'grammatical_errors': 0, 'pegasus_entailment': 0.5264825920263926, 'gold_entailment': 0.5872446199258169, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 78
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.11 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.23897058823529413, 'r1_recall': 0.7558139534883721, 'r1_f1': 0.36312849162011174, 'r2_precision': 0.14022140221402213, 'r2_recall': 0.4470588235294118, 'r2_f1': 0.21348314606741572, 'rL_precision': 0.16544117647058823, 'rL_recall': 0.5232558139534884, 'rL_f1': 0.25139664804469275, 'bs_precision': 0.23111999034881592, 'bs_recall': 0.46242836117744446, 'bs_f1': 0.3376707136631012, 'bs_mnli_precision': 0.5794752240180969, 'bs_mnli_recall': 0.7416945099830627, 'bs_mnli_f1': 0.6506258845329285, 'unique_bigram_ratio': 0.9427480916030534, 'nid': -0.2254465012893887, 'grammatical_errors': 1, 'pegasus_entailment': 0.6934034585952759, 'gold_entailment': 0.5945173650979996, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 17, 'pegasus_ari': 33, 'pegasus_smog': 24}
*** Analysing case 79
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.44 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.32, 'r1_recall': 0.7164179104477612, 'r1_f1': 0.4423963133640553, 'r2_precision': 0.18791946308724833, 'r2_recall': 0.42424242424242425, 'r2_f1': 0.26046511627906976, 'rL_precision': 0.21333333333333335, 'rL_recall': 0.47761194029850745, 'rL_f1': 0.2949308755760369, 'bs_precision': 0.32106611132621765, 'bs_recall': 0.5725134015083313, 'bs_f1': 0.43633514642715454, 'bs_mnli_precision': 0.6331137418746948, 'bs_mnli_recall': 0.7557206153869629, 'bs_mnli_f1': 0.6890052556991577, 'unique_bigram_ratio': 0.9857142857142858, 'nid': -0.2750652710047372, 'grammatical_errors': 1, 'pegasus_entailment': 0.6943076167787824, 'gold_entailment': 0.30196914573510486, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 80
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 79.14 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.44761904761904764, 'r1_recall': 0.6025641025641025, 'r1_f1': 0.5136612021857923, 'r2_precision': 0.20192307692307693, 'r2_recall': 0.2727272727272727, 'r2_f1': 0.23204419889502761, 'rL_precision': 0.3142857142857143, 'rL_recall': 0.4230769230769231, 'rL_f1': 0.360655737704918, 'bs_precision': 0.5351784229278564, 'bs_recall': 0.5495286583900452, 'bs_f1': 0.5438796877861023, 'bs_mnli_precision': 0.7250226736068726, 'bs_mnli_recall': 0.7515798807144165, 'bs_mnli_f1': 0.7380624413490295, 'unique_bigram_ratio': 0.9900990099009901, 'nid': -0.27649665430811887, 'grammatical_errors': 0, 'pegasus_entailment': 0.594948124885559, 'gold_entailment': 0.5953201701243719, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 81
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.85 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6274509803921569, 'r1_recall': 0.6213592233009708, 'r1_f1': 0.624390243902439, 'r2_precision': 0.38613861386138615, 'r2_recall': 0.38235294117647056, 'r2_f1': 0.3842364532019704, 'rL_precision': 0.46078431372549017, 'rL_recall': 0.4563106796116505, 'rL_f1': 0.4585365853658537, 'bs_precision': 0.5941022038459778, 'bs_recall': 0.5902420282363892, 'bs_f1': 0.5935631990432739, 'bs_mnli_precision': 0.7811177968978882, 'bs_mnli_recall': 0.7695262432098389, 'bs_mnli_f1': 0.7752787470817566, 'unique_bigram_ratio': 0.96, 'nid': -0.2610215763529986, 'grammatical_errors': 1, 'pegasus_entailment': 0.28913659043610096, 'gold_entailment': 0.24590027332305908, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 82
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.06 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2062780269058296, 'r1_recall': 0.7076923076923077, 'r1_f1': 0.3194444444444445, 'r2_precision': 0.1036036036036036, 'r2_recall': 0.359375, 'r2_f1': 0.16083916083916083, 'rL_precision': 0.17040358744394618, 'rL_recall': 0.5846153846153846, 'rL_f1': 0.2638888888888889, 'bs_precision': 0.23184004426002502, 'bs_recall': 0.5181745886802673, 'bs_f1': 0.36018234491348267, 'bs_mnli_precision': 0.5893276929855347, 'bs_mnli_recall': 0.7206771373748779, 'bs_mnli_f1': 0.6484174132347107, 'unique_bigram_ratio': 0.958139534883721, 'nid': -0.2376010969913489, 'grammatical_errors': 1, 'pegasus_entailment': 0.6958730043843389, 'gold_entailment': 0.6785010993480682, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 83
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.42 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2871287128712871, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.40138408304498274, 'r2_precision': 0.13432835820895522, 'r2_recall': 0.313953488372093, 'r2_f1': 0.1881533101045296, 'rL_precision': 0.19801980198019803, 'rL_recall': 0.45977011494252873, 'rL_f1': 0.2768166089965398, 'bs_precision': 0.22447194159030914, 'bs_recall': 0.39213016629219055, 'bs_f1': 0.30450597405433655, 'bs_mnli_precision': 0.5902226567268372, 'bs_mnli_recall': 0.6888787150382996, 'bs_mnli_f1': 0.6357460618019104, 'unique_bigram_ratio': 0.934010152284264, 'nid': -0.22482526600398023, 'grammatical_errors': 3, 'pegasus_entailment': 0.6273867360183171, 'gold_entailment': 0.358562837044398, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 84
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.09 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.35714285714285715, 'r1_recall': 0.7065217391304348, 'r1_f1': 0.4744525547445255, 'r2_precision': 0.20994475138121546, 'r2_recall': 0.4175824175824176, 'r2_f1': 0.27941176470588236, 'rL_precision': 0.26373626373626374, 'rL_recall': 0.5217391304347826, 'rL_f1': 0.3503649635036496, 'bs_precision': 0.35644716024398804, 'bs_recall': 0.5747475624084473, 'bs_f1': 0.45825275778770447, 'bs_mnli_precision': 0.6622886061668396, 'bs_mnli_recall': 0.7773314714431763, 'bs_mnli_f1': 0.715213418006897, 'unique_bigram_ratio': 0.9550561797752809, 'nid': -0.2480607266843684, 'grammatical_errors': 1, 'pegasus_entailment': 0.4468181026833398, 'gold_entailment': 0.4144515562802553, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 85
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 38.51 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.22362869198312235, 'r1_recall': 0.6091954022988506, 'r1_f1': 0.3271604938271605, 'r2_precision': 0.09745762711864407, 'r2_recall': 0.26744186046511625, 'r2_f1': 0.14285714285714285, 'rL_precision': 0.1308016877637131, 'rL_recall': 0.3563218390804598, 'rL_f1': 0.19135802469135804, 'bs_precision': 0.23674526810646057, 'bs_recall': 0.3646720349788666, 'bs_f1': 0.2994871735572815, 'bs_mnli_precision': 0.6015481948852539, 'bs_mnli_recall': 0.6657214760780334, 'bs_mnli_f1': 0.6320100426673889, 'unique_bigram_ratio': 0.9342105263157895, 'nid': -0.19921896340402334, 'grammatical_errors': 6, 'pegasus_entailment': 0.22296197298500273, 'gold_entailment': 0.14247221909463406, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 86
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.29 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.16911764705882354, 'r1_recall': 0.2948717948717949, 'r1_f1': 0.21495327102803738, 'r2_precision': 0.022222222222222223, 'r2_recall': 0.03896103896103896, 'r2_f1': 0.028301886792452827, 'rL_precision': 0.10294117647058823, 'rL_recall': 0.1794871794871795, 'rL_f1': 0.13084112149532712, 'bs_precision': 0.08996067941188812, 'bs_recall': 0.2007800042629242, 'bs_f1': 0.14514844119548798, 'bs_mnli_precision': 0.5301616787910461, 'bs_mnli_recall': 0.5648910999298096, 'bs_mnli_f1': 0.5469757318496704, 'unique_bigram_ratio': 0.9850746268656716, 'nid': -0.2527401142504253, 'grammatical_errors': 1, 'pegasus_entailment': 0.5120101521412531, 'gold_entailment': 0.2731717452406883, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 87
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 68.26 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.22666666666666666, 'r1_recall': 0.7555555555555555, 'r1_f1': 0.3487179487179487, 'r2_precision': 0.10738255033557047, 'r2_recall': 0.36363636363636365, 'r2_f1': 0.16580310880829013, 'rL_precision': 0.15333333333333332, 'rL_recall': 0.5111111111111111, 'rL_f1': 0.23589743589743586, 'bs_precision': 0.2665387690067291, 'bs_recall': 0.5975984930992126, 'bs_f1': 0.4123636782169342, 'bs_mnli_precision': 0.6047770380973816, 'bs_mnli_recall': 0.7748050689697266, 'bs_mnli_f1': 0.6793134212493896, 'unique_bigram_ratio': 0.9726027397260274, 'nid': -0.26061331119334796, 'grammatical_errors': 0, 'pegasus_entailment': 0.5872066702161517, 'gold_entailment': 0.6215670704841614, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 88
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.22 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5469613259668509, 'r1_recall': 0.47596153846153844, 'r1_f1': 0.5089974293059127, 'r2_precision': 0.20555555555555555, 'r2_recall': 0.178743961352657, 'r2_f1': 0.19121447028423774, 'rL_precision': 0.32044198895027626, 'rL_recall': 0.27884615384615385, 'rL_f1': 0.2982005141388175, 'bs_precision': 0.3598319888114929, 'bs_recall': 0.33379194140434265, 'bs_f1': 0.348901629447937, 'bs_mnli_precision': 0.6520299911499023, 'bs_mnli_recall': 0.6419667601585388, 'bs_mnli_f1': 0.6469591856002808, 'unique_bigram_ratio': 0.9659090909090909, 'nid': -0.23923727861711708, 'grammatical_errors': 5, 'pegasus_entailment': 0.1546163267145554, 'gold_entailment': 0.12092549465079275, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 89
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 72.59 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2767857142857143, 'r1_recall': 0.44285714285714284, 'r1_f1': 0.34065934065934067, 'r2_precision': 0.04504504504504504, 'r2_recall': 0.07246376811594203, 'r2_f1': 0.05555555555555555, 'rL_precision': 0.16071428571428573, 'rL_recall': 0.2571428571428571, 'rL_f1': 0.1978021978021978, 'bs_precision': 0.2958277761936188, 'bs_recall': 0.34491193294525146, 'bs_f1': 0.3221685290336609, 'bs_mnli_precision': 0.6106149554252625, 'bs_mnli_recall': 0.6229036450386047, 'bs_mnli_f1': 0.6166980862617493, 'unique_bigram_ratio': 0.9811320754716981, 'nid': -0.26731130618232046, 'grammatical_errors': 0, 'pegasus_entailment': 0.38744628926118213, 'gold_entailment': 0.09303888554374377, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 90
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.21 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5988023952095808, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.5571030640668523, 'r2_precision': 0.18674698795180722, 'r2_recall': 0.16230366492146597, 'r2_f1': 0.17366946778711484, 'rL_precision': 0.31736526946107785, 'rL_recall': 0.2760416666666667, 'rL_f1': 0.29526462395543174, 'bs_precision': 0.45316240191459656, 'bs_recall': 0.39278537034988403, 'bs_f1': 0.4242230951786041, 'bs_mnli_precision': 0.6931415796279907, 'bs_mnli_recall': 0.6698668599128723, 'bs_mnli_f1': 0.681305468082428, 'unique_bigram_ratio': 0.9567901234567902, 'nid': -0.23989584641057937, 'grammatical_errors': 3, 'pegasus_entailment': 0.7714458465576172, 'gold_entailment': 0.4902607910335064, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 91
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.01 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.39204545454545453, 'r1_recall': 0.5149253731343284, 'r1_f1': 0.4451612903225806, 'r2_precision': 0.16, 'r2_recall': 0.21052631578947367, 'r2_f1': 0.1818181818181818, 'rL_precision': 0.20454545454545456, 'rL_recall': 0.26865671641791045, 'rL_f1': 0.23225806451612901, 'bs_precision': 0.3146003484725952, 'bs_recall': 0.32645317912101746, 'bs_f1': 0.3228176534175873, 'bs_mnli_precision': 0.645709753036499, 'bs_mnli_recall': 0.6436271071434021, 'bs_mnli_f1': 0.6446667313575745, 'unique_bigram_ratio': 0.9415204678362573, 'nid': -0.2424867595122593, 'grammatical_errors': 1, 'pegasus_entailment': 0.5122976217951093, 'gold_entailment': 0.5248376607894898, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 92
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.73 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2056451612903226, 'r1_recall': 0.6986301369863014, 'r1_f1': 0.31775700934579443, 'r2_precision': 0.1214574898785425, 'r2_recall': 0.4166666666666667, 'r2_f1': 0.18808777429467083, 'rL_precision': 0.14112903225806453, 'rL_recall': 0.4794520547945205, 'rL_f1': 0.2180685358255452, 'bs_precision': 0.17320291697978973, 'bs_recall': 0.5313814878463745, 'bs_f1': 0.3274596333503723, 'bs_mnli_precision': 0.5562646389007568, 'bs_mnli_recall': 0.7422163486480713, 'bs_mnli_f1': 0.6359257102012634, 'unique_bigram_ratio': 0.9411764705882353, 'nid': -0.22351564856093686, 'grammatical_errors': 6, 'pegasus_entailment': 0.7021361078534808, 'gold_entailment': 0.6050263345241547, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 93
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.98 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4357142857142857, 'r1_recall': 0.5213675213675214, 'r1_f1': 0.4747081712062257, 'r2_precision': 0.26618705035971224, 'r2_recall': 0.31896551724137934, 'r2_f1': 0.2901960784313726, 'rL_precision': 0.2714285714285714, 'rL_recall': 0.3247863247863248, 'rL_f1': 0.29571984435797666, 'bs_precision': 0.45501863956451416, 'bs_recall': 0.4725549817085266, 'bs_f1': 0.46555933356285095, 'bs_mnli_precision': 0.6872286796569824, 'bs_mnli_recall': 0.6752011775970459, 'bs_mnli_f1': 0.6811618208885193, 'unique_bigram_ratio': 0.9626865671641791, 'nid': -0.24864317379537182, 'grammatical_errors': 1, 'pegasus_entailment': 0.5328221246600151, 'gold_entailment': 0.48013214270273846, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 94
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.94 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24358974358974358, 'r1_recall': 0.5876288659793815, 'r1_f1': 0.3444108761329305, 'r2_precision': 0.08583690987124463, 'r2_recall': 0.20833333333333334, 'r2_f1': 0.12158054711246202, 'rL_precision': 0.1282051282051282, 'rL_recall': 0.30927835051546393, 'rL_f1': 0.18126888217522658, 'bs_precision': 0.20366171002388, 'bs_recall': 0.41048353910446167, 'bs_f1': 0.3000604212284088, 'bs_mnli_precision': 0.5868608951568604, 'bs_mnli_recall': 0.6760679483413696, 'bs_mnli_f1': 0.6283138394355774, 'unique_bigram_ratio': 0.9118942731277533, 'nid': -0.22823263945257732, 'grammatical_errors': 3, 'pegasus_entailment': 0.3091919157757527, 'gold_entailment': 0.19341377541422844, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 95
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.10 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.41116751269035534, 'r1_recall': 0.4576271186440678, 'r1_f1': 0.4331550802139037, 'r2_precision': 0.1377551020408163, 'r2_recall': 0.1534090909090909, 'r2_f1': 0.14516129032258063, 'rL_precision': 0.23857868020304568, 'rL_recall': 0.2655367231638418, 'rL_f1': 0.2513368983957219, 'bs_precision': 0.2737717032432556, 'bs_recall': 0.2992314398288727, 'bs_f1': 0.2887939512729645, 'bs_mnli_precision': 0.6076051592826843, 'bs_mnli_recall': 0.6283777952194214, 'bs_mnli_f1': 0.6178169846534729, 'unique_bigram_ratio': 0.9368421052631579, 'nid': -0.20496672920946502, 'grammatical_errors': 2, 'pegasus_entailment': 0.6696493551135063, 'gold_entailment': 0.3726605785389741, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 96
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 73.24 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4462809917355372, 'r1_recall': 0.5567010309278351, 'r1_f1': 0.4954128440366972, 'r2_precision': 0.24166666666666667, 'r2_recall': 0.3020833333333333, 'r2_f1': 0.2685185185185185, 'rL_precision': 0.3140495867768595, 'rL_recall': 0.3917525773195876, 'rL_f1': 0.3486238532110092, 'bs_precision': 0.39605340361595154, 'bs_recall': 0.424277126789093, 'bs_f1': 0.412019819021225, 'bs_mnli_precision': 0.6698013544082642, 'bs_mnli_recall': 0.6978031992912292, 'bs_mnli_f1': 0.6835156083106995, 'unique_bigram_ratio': 0.9491525423728814, 'nid': -0.22094428757521167, 'grammatical_errors': 2, 'pegasus_entailment': 0.5173112414777279, 'gold_entailment': 0.20278062857687473, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 97
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.79 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3686868686868687, 'r1_recall': 0.5793650793650794, 'r1_f1': 0.4506172839506173, 'r2_precision': 0.13705583756345177, 'r2_recall': 0.216, 'r2_f1': 0.16770186335403725, 'rL_precision': 0.19696969696969696, 'rL_recall': 0.30952380952380953, 'rL_f1': 0.24074074074074073, 'bs_precision': 0.2527572810649872, 'bs_recall': 0.3833385109901428, 'bs_f1': 0.31667280197143555, 'bs_mnli_precision': 0.6067987680435181, 'bs_mnli_recall': 0.6680846214294434, 'bs_mnli_f1': 0.6359686255455017, 'unique_bigram_ratio': 0.9481865284974094, 'nid': -0.23727885049572928, 'grammatical_errors': 0, 'pegasus_entailment': 0.4958966581949166, 'gold_entailment': 0.4636237493583134, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 98
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.50 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.21875, 'r1_recall': 0.7538461538461538, 'r1_f1': 0.3391003460207612, 'r2_precision': 0.08968609865470852, 'r2_recall': 0.3125, 'r2_f1': 0.13937282229965156, 'rL_precision': 0.15178571428571427, 'rL_recall': 0.5230769230769231, 'rL_f1': 0.2352941176470588, 'bs_precision': 0.26855504512786865, 'bs_recall': 0.4952791929244995, 'bs_f1': 0.3734542727470398, 'bs_mnli_precision': 0.5988901853561401, 'bs_mnli_recall': 0.7302376627922058, 'bs_mnli_f1': 0.6580739617347717, 'unique_bigram_ratio': 0.9457013574660633, 'nid': -0.25148833368206436, 'grammatical_errors': 3, 'pegasus_entailment': 0.6355643691495061, 'gold_entailment': 0.3708880866567294, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 99
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.91 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3262411347517731, 'r1_recall': 0.4107142857142857, 'r1_f1': 0.36363636363636365, 'r2_precision': 0.07857142857142857, 'r2_recall': 0.0990990990990991, 'r2_f1': 0.08764940239043825, 'rL_precision': 0.19148936170212766, 'rL_recall': 0.24107142857142858, 'rL_f1': 0.21343873517786563, 'bs_precision': 0.20212899148464203, 'bs_recall': 0.21949097514152527, 'bs_f1': 0.21343369781970978, 'bs_mnli_precision': 0.5900176167488098, 'bs_mnli_recall': 0.6061871647834778, 'bs_mnli_f1': 0.5979930758476257, 'unique_bigram_ratio': 0.9782608695652174, 'nid': -0.23321084345740273, 'grammatical_errors': 3, 'pegasus_entailment': 0.4221296314150095, 'gold_entailment': 0.24039181872891882, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 100
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.70 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.19875776397515527, 'r1_recall': 0.5245901639344263, 'r1_f1': 0.28828828828828823, 'r2_precision': 0.05625, 'r2_recall': 0.15, 'r2_f1': 0.08181818181818183, 'rL_precision': 0.11801242236024845, 'rL_recall': 0.3114754098360656, 'rL_f1': 0.17117117117117117, 'bs_precision': 0.17303819954395294, 'bs_recall': 0.32783666253089905, 'bs_f1': 0.24746674299240112, 'bs_mnli_precision': 0.5520449280738831, 'bs_mnli_recall': 0.6465333104133606, 'bs_mnli_f1': 0.5955647230148315, 'unique_bigram_ratio': 0.9354838709677419, 'nid': -0.25617924666866276, 'grammatical_errors': 4, 'pegasus_entailment': 0.3358490904793143, 'gold_entailment': 0.06103094667196274, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 101
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 67.87 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4094488188976378, 'r1_recall': 0.5531914893617021, 'r1_f1': 0.47058823529411764, 'r2_precision': 0.11904761904761904, 'r2_recall': 0.16129032258064516, 'r2_f1': 0.136986301369863, 'rL_precision': 0.2440944881889764, 'rL_recall': 0.32978723404255317, 'rL_f1': 0.28054298642533937, 'bs_precision': 0.30232614278793335, 'bs_recall': 0.40835312008857727, 'bs_f1': 0.355175644159317, 'bs_mnli_precision': 0.60886549949646, 'bs_mnli_recall': 0.664567768573761, 'bs_mnli_f1': 0.6354984045028687, 'unique_bigram_ratio': 0.9758064516129032, 'nid': -0.28736361702132873, 'grammatical_errors': 0, 'pegasus_entailment': 0.3968605436384678, 'gold_entailment': 0.28202853351831436, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 102
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.58 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.31640625, 'r1_recall': 0.7043478260869566, 'r1_f1': 0.43665768194070087, 'r2_precision': 0.17254901960784313, 'r2_recall': 0.38596491228070173, 'r2_f1': 0.23848238482384826, 'rL_precision': 0.21484375, 'rL_recall': 0.4782608695652174, 'rL_f1': 0.29649595687331537, 'bs_precision': 0.2897745668888092, 'bs_recall': 0.5542476177215576, 'bs_f1': 0.4100590646266937, 'bs_mnli_precision': 0.6189115047454834, 'bs_mnli_recall': 0.7420394420623779, 'bs_mnli_f1': 0.6749056577682495, 'unique_bigram_ratio': 0.9437751004016064, 'nid': -0.19840374755627765, 'grammatical_errors': 2, 'pegasus_entailment': 0.618750641743342, 'gold_entailment': 0.45435090735554695, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 103
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.72 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3693181818181818, 'r1_recall': 0.5803571428571429, 'r1_f1': 0.4513888888888889, 'r2_precision': 0.15428571428571428, 'r2_recall': 0.24324324324324326, 'r2_f1': 0.18881118881118877, 'rL_precision': 0.23295454545454544, 'rL_recall': 0.36607142857142855, 'rL_f1': 0.2847222222222222, 'bs_precision': 0.3407845199108124, 'bs_recall': 0.44111523032188416, 'bs_f1': 0.39097344875335693, 'bs_mnli_precision': 0.6506192684173584, 'bs_mnli_recall': 0.707878828048706, 'bs_mnli_f1': 0.6780423521995544, 'unique_bigram_ratio': 0.9532163742690059, 'nid': -0.21086134288085923, 'grammatical_errors': 1, 'pegasus_entailment': 0.6990829280444554, 'gold_entailment': 0.5298281113306681, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 104
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.98 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.25870646766169153, 'r1_recall': 0.65, 'r1_f1': 0.3701067615658363, 'r2_precision': 0.135, 'r2_recall': 0.34177215189873417, 'r2_f1': 0.1935483870967742, 'rL_precision': 0.21393034825870647, 'rL_recall': 0.5375, 'rL_f1': 0.3060498220640569, 'bs_precision': 0.32865989208221436, 'bs_recall': 0.5595210790634155, 'bs_f1': 0.4355608820915222, 'bs_mnli_precision': 0.6178566217422485, 'bs_mnli_recall': 0.7601715326309204, 'bs_mnli_f1': 0.681665301322937, 'unique_bigram_ratio': 0.9679144385026738, 'nid': -0.2463942149716909, 'grammatical_errors': 3, 'pegasus_entailment': 0.5303841293272045, 'gold_entailment': 0.2945236237719655, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 105
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.36 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.352, 'r1_recall': 0.6821705426356589, 'r1_f1': 0.46437994722955145, 'r2_precision': 0.13253012048192772, 'r2_recall': 0.2578125, 'r2_f1': 0.17506631299734748, 'rL_precision': 0.192, 'rL_recall': 0.37209302325581395, 'rL_f1': 0.2532981530343008, 'bs_precision': 0.31632155179977417, 'bs_recall': 0.4686433970928192, 'bs_f1': 0.38982465863227844, 'bs_mnli_precision': 0.6263293027877808, 'bs_mnli_recall': 0.7092350125312805, 'bs_mnli_f1': 0.6652089357376099, 'unique_bigram_ratio': 0.9512195121951219, 'nid': -0.23044404394891105, 'grammatical_errors': 2, 'pegasus_entailment': 0.5646000541746616, 'gold_entailment': 0.3414716236293316, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 106
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.06 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4028436018957346, 'r1_recall': 0.8252427184466019, 'r1_f1': 0.5414012738853504, 'r2_precision': 0.21904761904761905, 'r2_recall': 0.45098039215686275, 'r2_f1': 0.2948717948717948, 'rL_precision': 0.26540284360189575, 'rL_recall': 0.5436893203883495, 'rL_f1': 0.35668789808917195, 'bs_precision': 0.36280176043510437, 'bs_recall': 0.622131884098053, 'bs_f1': 0.48152387142181396, 'bs_mnli_precision': 0.6321008205413818, 'bs_mnli_recall': 0.7810416221618652, 'bs_mnli_f1': 0.698722243309021, 'unique_bigram_ratio': 0.9609756097560975, 'nid': -0.24582692261902994, 'grammatical_errors': 2, 'pegasus_entailment': 0.4912258442491293, 'gold_entailment': 0.4420250281691551, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 107
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.56 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4444444444444444, 'r1_recall': 0.525, 'r1_f1': 0.4813753581661891, 'r2_precision': 0.16489361702127658, 'r2_recall': 0.1949685534591195, 'r2_f1': 0.17867435158501438, 'rL_precision': 0.24338624338624337, 'rL_recall': 0.2875, 'rL_f1': 0.2636103151862464, 'bs_precision': 0.2841636836528778, 'bs_recall': 0.3543024957180023, 'bs_f1': 0.3204899728298187, 'bs_mnli_precision': 0.635830283164978, 'bs_mnli_recall': 0.6607736945152283, 'bs_mnli_f1': 0.6480621099472046, 'unique_bigram_ratio': 0.9402173913043478, 'nid': -0.22686349866025401, 'grammatical_errors': 0, 'pegasus_entailment': 0.4072286146027701, 'gold_entailment': 0.6526487339287996, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 108
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.70 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.32098765432098764, 'r1_recall': 0.6933333333333334, 'r1_f1': 0.43881856540084385, 'r2_precision': 0.18012422360248448, 'r2_recall': 0.3918918918918919, 'r2_f1': 0.2468085106382979, 'rL_precision': 0.19753086419753085, 'rL_recall': 0.4266666666666667, 'rL_f1': 0.270042194092827, 'bs_precision': 0.25556832551956177, 'bs_recall': 0.5025482773780823, 'bs_f1': 0.36860236525535583, 'bs_mnli_precision': 0.5986239314079285, 'bs_mnli_recall': 0.7287126779556274, 'bs_mnli_f1': 0.6572934985160828, 'unique_bigram_ratio': 0.9430379746835443, 'nid': -0.2315658009133006, 'grammatical_errors': 4, 'pegasus_entailment': 0.26775409653782845, 'gold_entailment': 0.02063418086618185, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 109
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.06 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.17672413793103448, 'r1_recall': 0.6833333333333333, 'r1_f1': 0.2808219178082192, 'r2_precision': 0.06060606060606061, 'r2_recall': 0.23728813559322035, 'r2_f1': 0.09655172413793105, 'rL_precision': 0.08620689655172414, 'rL_recall': 0.3333333333333333, 'rL_f1': 0.136986301369863, 'bs_precision': 0.027084169909358025, 'bs_recall': 0.3329445421695709, 'bs_f1': 0.15972797572612762, 'bs_mnli_precision': 0.4795406460762024, 'bs_mnli_recall': 0.6428095102310181, 'bs_mnli_f1': 0.5492996573448181, 'unique_bigram_ratio': 0.9244444444444444, 'nid': -0.22664480690697242, 'grammatical_errors': 4, 'pegasus_entailment': 0.7398824223450252, 'gold_entailment': 0.427563801407814, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 110
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.16 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.23728813559322035, 'r1_recall': 0.8115942028985508, 'r1_f1': 0.36721311475409835, 'r2_precision': 0.14893617021276595, 'r2_recall': 0.5147058823529411, 'r2_f1': 0.231023102310231, 'rL_precision': 0.1652542372881356, 'rL_recall': 0.5652173913043478, 'rL_f1': 0.2557377049180328, 'bs_precision': 0.23854796588420868, 'bs_recall': 0.6306412816047668, 'bs_f1': 0.4062275290489197, 'bs_mnli_precision': 0.5704874992370605, 'bs_mnli_recall': 0.796668529510498, 'bs_mnli_f1': 0.6648684144020081, 'unique_bigram_ratio': 0.9515418502202643, 'nid': -0.22623570517904823, 'grammatical_errors': 2, 'pegasus_entailment': 0.5178413242101669, 'gold_entailment': 0.4077516744534175, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 111
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.07 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.49645390070921985, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5109489051094891, 'r2_precision': 0.2642857142857143, 'r2_recall': 0.2803030303030303, 'r2_f1': 0.2720588235294118, 'rL_precision': 0.2978723404255319, 'rL_recall': 0.3157894736842105, 'rL_f1': 0.30656934306569344, 'bs_precision': 0.44493070244789124, 'bs_recall': 0.41744858026504517, 'bs_f1': 0.4329851269721985, 'bs_mnli_precision': 0.699569821357727, 'bs_mnli_recall': 0.6893447637557983, 'bs_mnli_f1': 0.6944196224212646, 'unique_bigram_ratio': 0.9485294117647058, 'nid': -0.22372879072640495, 'grammatical_errors': 2, 'pegasus_entailment': 0.34627565058569115, 'gold_entailment': 0.558576320608457, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 112
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.51 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.32335329341317365, 'r1_recall': 0.6835443037974683, 'r1_f1': 0.43902439024390244, 'r2_precision': 0.1686746987951807, 'r2_recall': 0.358974358974359, 'r2_f1': 0.2295081967213115, 'rL_precision': 0.2155688622754491, 'rL_recall': 0.45569620253164556, 'rL_f1': 0.2926829268292683, 'bs_precision': 0.3086688816547394, 'bs_recall': 0.4416896104812622, 'bs_f1': 0.3736517131328583, 'bs_mnli_precision': 0.6296242475509644, 'bs_mnli_recall': 0.6939777135848999, 'bs_mnli_f1': 0.6602365374565125, 'unique_bigram_ratio': 0.9622641509433962, 'nid': -0.26222666830324504, 'grammatical_errors': 0, 'pegasus_entailment': 0.43567776307463646, 'gold_entailment': 0.41504740715026855, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 113
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 41.01 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24381625441696114, 'r1_recall': 0.7752808988764045, 'r1_f1': 0.3709677419354839, 'r2_precision': 0.12411347517730496, 'r2_recall': 0.3977272727272727, 'r2_f1': 0.18918918918918917, 'rL_precision': 0.14487632508833923, 'rL_recall': 0.4606741573033708, 'rL_f1': 0.22043010752688172, 'bs_precision': 0.1613539308309555, 'bs_recall': 0.4728395938873291, 'bs_f1': 0.2983470857143402, 'bs_mnli_precision': 0.5492275357246399, 'bs_mnli_recall': 0.709505021572113, 'bs_mnli_f1': 0.6191620230674744, 'unique_bigram_ratio': 0.9205776173285198, 'nid': -0.2140095476877315, 'grammatical_errors': 3, 'pegasus_entailment': 0.5093141076239672, 'gold_entailment': 0.3151111304759979, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 114
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.37 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3696969696969697, 'r1_recall': 0.46923076923076923, 'r1_f1': 0.4135593220338983, 'r2_precision': 0.08536585365853659, 'r2_recall': 0.10852713178294573, 'r2_f1': 0.09556313993174062, 'rL_precision': 0.19393939393939394, 'rL_recall': 0.24615384615384617, 'rL_f1': 0.21694915254237285, 'bs_precision': 0.26519399881362915, 'bs_recall': 0.2653331458568573, 'bs_f1': 0.2677743136882782, 'bs_mnli_precision': 0.609575629234314, 'bs_mnli_recall': 0.6295005083084106, 'bs_mnli_f1': 0.619377851486206, 'unique_bigram_ratio': 0.9620253164556962, 'nid': -0.26372159405351714, 'grammatical_errors': 5, 'pegasus_entailment': 0.34495989978313446, 'gold_entailment': 0.318079457928737, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 115
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.83 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5688622754491018, 'r1_recall': 0.5337078651685393, 'r1_f1': 0.5507246376811594, 'r2_precision': 0.2469879518072289, 'r2_recall': 0.23163841807909605, 'r2_f1': 0.239067055393586, 'rL_precision': 0.3473053892215569, 'rL_recall': 0.3258426966292135, 'rL_f1': 0.33623188405797105, 'bs_precision': 0.48334237933158875, 'bs_recall': 0.396003782749176, 'bs_f1': 0.44009435176849365, 'bs_mnli_precision': 0.7173704504966736, 'bs_mnli_recall': 0.6859793663024902, 'bs_mnli_f1': 0.7013238072395325, 'unique_bigram_ratio': 0.9506172839506173, 'nid': -0.27448126101996606, 'grammatical_errors': 2, 'pegasus_entailment': 0.7980922341346741, 'gold_entailment': 0.6778367204325539, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 116
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.44 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.696969696969697, 'r1_recall': 0.39204545454545453, 'r1_f1': 0.5018181818181818, 'r2_precision': 0.3163265306122449, 'r2_recall': 0.17714285714285713, 'r2_f1': 0.2271062271062271, 'rL_precision': 0.43434343434343436, 'rL_recall': 0.24431818181818182, 'rL_f1': 0.31272727272727274, 'bs_precision': 0.49328023195266724, 'bs_recall': 0.32165950536727905, 'bs_f1': 0.4035719931125641, 'bs_mnli_precision': 0.7187047004699707, 'bs_mnli_recall': 0.6319159269332886, 'bs_mnli_f1': 0.6725218892097473, 'unique_bigram_ratio': 0.9895833333333334, 'nid': -0.27423217035077063, 'grammatical_errors': 1, 'pegasus_entailment': 0.6070100627839565, 'gold_entailment': 0.2957775273493358, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 117
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.80 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.52, 'r1_recall': 0.582089552238806, 'r1_f1': 0.5492957746478873, 'r2_precision': 0.2214765100671141, 'r2_recall': 0.24812030075187969, 'r2_f1': 0.23404255319148937, 'rL_precision': 0.32, 'rL_recall': 0.3582089552238806, 'rL_f1': 0.3380281690140845, 'bs_precision': 0.44504567980766296, 'bs_recall': 0.4573231339454651, 'bs_f1': 0.45303013920783997, 'bs_mnli_precision': 0.6962937712669373, 'bs_mnli_recall': 0.7155131697654724, 'bs_mnli_f1': 0.7057726383209229, 'unique_bigram_ratio': 0.952054794520548, 'nid': -0.22906654828205175, 'grammatical_errors': 2, 'pegasus_entailment': 0.596158180385828, 'gold_entailment': 0.5226981540520986, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 118
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.65 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.26582278481012656, 'r1_recall': 0.6702127659574468, 'r1_f1': 0.3806646525679758, 'r2_precision': 0.1271186440677966, 'r2_recall': 0.3225806451612903, 'r2_f1': 0.182370820668693, 'rL_precision': 0.18143459915611815, 'rL_recall': 0.4574468085106383, 'rL_f1': 0.2598187311178248, 'bs_precision': 0.21038775146007538, 'bs_recall': 0.48127004504203796, 'bs_f1': 0.332507461309433, 'bs_mnli_precision': 0.5775805711746216, 'bs_mnli_recall': 0.7204207181930542, 'bs_mnli_f1': 0.6411411166191101, 'unique_bigram_ratio': 0.9513274336283186, 'nid': -0.2500864002735821, 'grammatical_errors': 7, 'pegasus_entailment': 0.2866873755119741, 'gold_entailment': 0.11518060509115458, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 119
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.59 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4936708860759494, 'r1_recall': 0.6141732283464567, 'r1_f1': 0.5473684210526316, 'r2_precision': 0.28662420382165604, 'r2_recall': 0.35714285714285715, 'r2_f1': 0.31802120141342755, 'rL_precision': 0.2721518987341772, 'rL_recall': 0.33858267716535434, 'rL_f1': 0.30175438596491233, 'bs_precision': 0.49752768874168396, 'bs_recall': 0.5074058771133423, 'bs_f1': 0.5041482448577881, 'bs_mnli_precision': 0.7155133485794067, 'bs_mnli_recall': 0.7294000387191772, 'bs_mnli_f1': 0.7223899960517883, 'unique_bigram_ratio': 0.9548387096774194, 'nid': -0.22882725098962098, 'grammatical_errors': 3, 'pegasus_entailment': 0.38340961188077927, 'gold_entailment': 0.5271761885711125, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 120
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.12 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.27419354838709675, 'r1_recall': 0.7727272727272727, 'r1_f1': 0.4047619047619047, 'r2_precision': 0.16194331983805668, 'r2_recall': 0.45977011494252873, 'r2_f1': 0.23952095808383236, 'rL_precision': 0.2056451612903226, 'rL_recall': 0.5795454545454546, 'rL_f1': 0.3035714285714286, 'bs_precision': 0.2995566427707672, 'bs_recall': 0.5336106419563293, 'bs_f1': 0.4076211452484131, 'bs_mnli_precision': 0.6257563829421997, 'bs_mnli_recall': 0.7479382753372192, 'bs_mnli_f1': 0.6814136505126953, 'unique_bigram_ratio': 0.9338842975206612, 'nid': -0.23386706560539294, 'grammatical_errors': 1, 'pegasus_entailment': 0.7192911952733994, 'gold_entailment': 0.4233737736940384, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 121
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.10 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.49295774647887325, 'r1_recall': 0.6086956521739131, 'r1_f1': 0.5447470817120623, 'r2_precision': 0.2127659574468085, 'r2_recall': 0.2631578947368421, 'r2_f1': 0.2352941176470588, 'rL_precision': 0.30985915492957744, 'rL_recall': 0.3826086956521739, 'rL_f1': 0.34241245136186765, 'bs_precision': 0.4045666456222534, 'bs_recall': 0.4445493221282959, 'bs_f1': 0.4262053966522217, 'bs_mnli_precision': 0.6633013486862183, 'bs_mnli_recall': 0.6778077483177185, 'bs_mnli_f1': 0.6704761385917664, 'unique_bigram_ratio': 0.9784172661870504, 'nid': -0.2512062740470875, 'grammatical_errors': 1, 'pegasus_entailment': 0.3975750058889389, 'gold_entailment': 0.29076578486710786, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 122
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 67.76 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.27692307692307694, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.3495145631067961, 'r2_precision': 0.09302325581395349, 'r2_recall': 0.16, 'r2_f1': 0.11764705882352942, 'rL_precision': 0.18461538461538463, 'rL_recall': 0.3157894736842105, 'rL_f1': 0.23300970873786409, 'bs_precision': 0.2077295184135437, 'bs_recall': 0.4327499270439148, 'bs_f1': 0.31158706545829773, 'bs_mnli_precision': 0.5847159028053284, 'bs_mnli_recall': 0.6861671805381775, 'bs_mnli_f1': 0.631392240524292, 'unique_bigram_ratio': 0.9920634920634921, 'nid': -0.30304207495142266, 'grammatical_errors': 1, 'pegasus_entailment': 0.692436546087265, 'gold_entailment': 0.5156548420588175, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 123
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.47 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.17647058823529413, 'r1_recall': 0.7674418604651163, 'r1_f1': 0.28695652173913044, 'r2_precision': 0.053763440860215055, 'r2_recall': 0.23809523809523808, 'r2_f1': 0.08771929824561403, 'rL_precision': 0.10160427807486631, 'rL_recall': 0.4418604651162791, 'rL_f1': 0.16521739130434784, 'bs_precision': 0.11330719292163849, 'bs_recall': 0.39455482363700867, 'bs_f1': 0.2382887750864029, 'bs_mnli_precision': 0.5332814455032349, 'bs_mnli_recall': 0.6702340841293335, 'bs_mnli_f1': 0.5939655900001526, 'unique_bigram_ratio': 0.9662921348314607, 'nid': -0.25656587783890905, 'grammatical_errors': 0, 'pegasus_entailment': 0.6169668659567833, 'gold_entailment': 0.5252911671996117, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 124
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.30 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.22439024390243903, 'r1_recall': 0.8214285714285714, 'r1_f1': 0.35249042145593873, 'r2_precision': 0.12254901960784313, 'r2_recall': 0.45454545454545453, 'r2_f1': 0.19305019305019305, 'rL_precision': 0.15609756097560976, 'rL_recall': 0.5714285714285714, 'rL_f1': 0.24521072796934865, 'bs_precision': 0.27576202154159546, 'bs_recall': 0.6042810678482056, 'bs_f1': 0.4207538068294525, 'bs_mnli_precision': 0.5892842411994934, 'bs_mnli_recall': 0.7607794404029846, 'bs_mnli_f1': 0.6641395092010498, 'unique_bigram_ratio': 0.9597989949748744, 'nid': -0.2376020926846465, 'grammatical_errors': 1, 'pegasus_entailment': 0.4932024968521936, 'gold_entailment': 0.6746587753295898, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 125
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.04 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.45145631067961167, 'r1_recall': 0.7099236641221374, 'r1_f1': 0.5519287833827893, 'r2_precision': 0.22439024390243903, 'r2_recall': 0.35384615384615387, 'r2_f1': 0.2746268656716418, 'rL_precision': 0.2912621359223301, 'rL_recall': 0.4580152671755725, 'rL_f1': 0.35608308605341243, 'bs_precision': 0.4345239996910095, 'bs_recall': 0.5440943241119385, 'bs_f1': 0.48878347873687744, 'bs_mnli_precision': 0.6879075169563293, 'bs_mnli_recall': 0.7466520667076111, 'bs_mnli_f1': 0.7160770297050476, 'unique_bigram_ratio': 0.9313725490196079, 'nid': -0.22125520697067724, 'grammatical_errors': 0, 'pegasus_entailment': 0.4293173361155722, 'gold_entailment': 0.24431789852678776, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 126
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.82 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.30113636363636365, 'r1_recall': 0.6625, 'r1_f1': 0.4140625, 'r2_precision': 0.17714285714285713, 'r2_recall': 0.3924050632911392, 'r2_f1': 0.24409448818897633, 'rL_precision': 0.2159090909090909, 'rL_recall': 0.475, 'rL_f1': 0.296875, 'bs_precision': 0.26423996686935425, 'bs_recall': 0.5700870156288147, 'bs_f1': 0.4004591703414917, 'bs_mnli_precision': 0.609664261341095, 'bs_mnli_recall': 0.7732857465744019, 'bs_mnli_f1': 0.6817957162857056, 'unique_bigram_ratio': 0.953757225433526, 'nid': -0.22220707552387675, 'grammatical_errors': 3, 'pegasus_entailment': 0.5205435891236577, 'gold_entailment': 0.3561509723464648, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 127
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 69.96 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5691056910569106, 'r1_recall': 0.5982905982905983, 'r1_f1': 0.5833333333333334, 'r2_precision': 0.319672131147541, 'r2_recall': 0.33620689655172414, 'r2_f1': 0.3277310924369748, 'rL_precision': 0.3902439024390244, 'rL_recall': 0.41025641025641024, 'rL_f1': 0.4, 'bs_precision': 0.4937124252319336, 'bs_recall': 0.5141088366508484, 'bs_f1': 0.5055274963378906, 'bs_mnli_precision': 0.736068069934845, 'bs_mnli_recall': 0.7431809902191162, 'bs_mnli_f1': 0.7396075129508972, 'unique_bigram_ratio': 0.9576271186440678, 'nid': -0.26347007565564806, 'grammatical_errors': 2, 'pegasus_entailment': 0.5105259567499161, 'gold_entailment': 0.285223330060641, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 128
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.24 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.39880952380952384, 'r1_recall': 0.5775862068965517, 'r1_f1': 0.47183098591549294, 'r2_precision': 0.19161676646706588, 'r2_recall': 0.2782608695652174, 'r2_f1': 0.22695035460992907, 'rL_precision': 0.23809523809523808, 'rL_recall': 0.3448275862068966, 'rL_f1': 0.2816901408450704, 'bs_precision': 0.3652344048023224, 'bs_recall': 0.4524933397769928, 'bs_f1': 0.40934959053993225, 'bs_mnli_precision': 0.6477725505828857, 'bs_mnli_recall': 0.6951043605804443, 'bs_mnli_f1': 0.6706042885780334, 'unique_bigram_ratio': 0.9631901840490797, 'nid': -0.25389726038166316, 'grammatical_errors': 2, 'pegasus_entailment': 0.6288644274075826, 'gold_entailment': 0.3925587385892868, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 129
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.26 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.25882352941176473, 'r1_recall': 0.7457627118644068, 'r1_f1': 0.3842794759825328, 'r2_precision': 0.13609467455621302, 'r2_recall': 0.39655172413793105, 'r2_f1': 0.2026431718061674, 'rL_precision': 0.17647058823529413, 'rL_recall': 0.5084745762711864, 'rL_f1': 0.26200873362445415, 'bs_precision': 0.2963113486766815, 'bs_recall': 0.5540758371353149, 'bs_f1': 0.4139616787433624, 'bs_mnli_precision': 0.6217312216758728, 'bs_mnli_recall': 0.7594913840293884, 'bs_mnli_f1': 0.6837413311004639, 'unique_bigram_ratio': 0.9698795180722891, 'nid': -0.28760381474934404, 'grammatical_errors': 3, 'pegasus_entailment': 0.6029897872358561, 'gold_entailment': 0.4638199508190155, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 130
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.68 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.46190476190476193, 'r1_recall': 0.5132275132275133, 'r1_f1': 0.4862155388471178, 'r2_precision': 0.20095693779904306, 'r2_recall': 0.22340425531914893, 'r2_f1': 0.21158690176322417, 'rL_precision': 0.23809523809523808, 'rL_recall': 0.26455026455026454, 'rL_f1': 0.25062656641604014, 'bs_precision': 0.3323100209236145, 'bs_recall': 0.34520506858825684, 'bs_f1': 0.34098127484321594, 'bs_mnli_precision': 0.6449621915817261, 'bs_mnli_recall': 0.6537866592407227, 'bs_mnli_f1': 0.6493444442749023, 'unique_bigram_ratio': 0.9516908212560387, 'nid': -0.25419486041082595, 'grammatical_errors': 0, 'pegasus_entailment': 0.44726063311100006, 'gold_entailment': 0.25559459486976266, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 131
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.85 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3838383838383838, 'r1_recall': 0.628099173553719, 'r1_f1': 0.47648902821316613, 'r2_precision': 0.2131979695431472, 'r2_recall': 0.35, 'r2_f1': 0.26498422712933756, 'rL_precision': 0.25252525252525254, 'rL_recall': 0.4132231404958678, 'rL_f1': 0.31347962382445144, 'bs_precision': 0.3253630995750427, 'bs_recall': 0.44264599680900574, 'bs_f1': 0.3832823634147644, 'bs_mnli_precision': 0.6472734212875366, 'bs_mnli_recall': 0.6907625794410706, 'bs_mnli_f1': 0.6683112382888794, 'unique_bigram_ratio': 0.9790575916230366, 'nid': -0.2566474464538331, 'grammatical_errors': 0, 'pegasus_entailment': 0.6645926982164383, 'gold_entailment': 0.5371513764063517, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 132
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.18 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5902777777777778, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.5685618729096991, 'r2_precision': 0.34265734265734266, 'r2_recall': 0.3181818181818182, 'r2_f1': 0.32996632996632996, 'rL_precision': 0.4513888888888889, 'rL_recall': 0.41935483870967744, 'rL_f1': 0.4347826086956522, 'bs_precision': 0.4163050353527069, 'bs_recall': 0.4096946120262146, 'bs_f1': 0.4149971902370453, 'bs_mnli_precision': 0.7156389951705933, 'bs_mnli_recall': 0.7235222458839417, 'bs_mnli_f1': 0.7195589542388916, 'unique_bigram_ratio': 0.9710144927536232, 'nid': -0.2679612738006556, 'grammatical_errors': 3, 'pegasus_entailment': 0.7268501460552216, 'gold_entailment': 0.6020671855658293, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 133
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.05 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4583333333333333, 'r1_recall': 0.6073619631901841, 'r1_f1': 0.5224274406332454, 'r2_precision': 0.22325581395348837, 'r2_recall': 0.2962962962962963, 'r2_f1': 0.2546419098143236, 'rL_precision': 0.25462962962962965, 'rL_recall': 0.3374233128834356, 'rL_f1': 0.2902374670184697, 'bs_precision': 0.3875032961368561, 'bs_recall': 0.4326018691062927, 'bs_f1': 0.41165825724601746, 'bs_mnli_precision': 0.656169593334198, 'bs_mnli_recall': 0.7083141207695007, 'bs_mnli_f1': 0.6812455058097839, 'unique_bigram_ratio': 0.9523809523809523, 'nid': -0.2303370704267833, 'grammatical_errors': 2, 'pegasus_entailment': 0.4811639537413915, 'gold_entailment': 0.3585795784989993, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 134
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 33.19 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.16756756756756758, 'r1_recall': 0.6138613861386139, 'r1_f1': 0.26326963906581746, 'r2_precision': 0.06775067750677506, 'r2_recall': 0.25, 'r2_f1': 0.10660980810234541, 'rL_precision': 0.0972972972972973, 'rL_recall': 0.3564356435643564, 'rL_f1': 0.15286624203821655, 'bs_precision': 0.10268799960613251, 'bs_recall': 0.3314765989780426, 'bs_f1': 0.20729364454746246, 'bs_mnli_precision': 0.5207363963127136, 'bs_mnli_recall': 0.6327911615371704, 'bs_mnli_f1': 0.5713212490081787, 'unique_bigram_ratio': 0.9301675977653632, 'nid': -0.20992561932375753, 'grammatical_errors': 9, 'pegasus_entailment': 0.2494370390016299, 'gold_entailment': 0.21495582349598408, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 135
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 38.36 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.26973684210526316, 'r1_recall': 0.6776859504132231, 'r1_f1': 0.3858823529411765, 'r2_precision': 0.1254125412541254, 'r2_recall': 0.31666666666666665, 'r2_f1': 0.17966903073286053, 'rL_precision': 0.15789473684210525, 'rL_recall': 0.39669421487603307, 'rL_f1': 0.22588235294117645, 'bs_precision': 0.20995578169822693, 'bs_recall': 0.4264649450778961, 'bs_f1': 0.31036096811294556, 'bs_mnli_precision': 0.5771154761314392, 'bs_mnli_recall': 0.7092806100845337, 'bs_mnli_f1': 0.6364086866378784, 'unique_bigram_ratio': 0.9264214046822743, 'nid': -0.18664007832867524, 'grammatical_errors': 10, 'pegasus_entailment': 0.4800891652703285, 'gold_entailment': 0.22186595341190696, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 136
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 68.11 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.47107438016528924, 'r1_recall': 0.6129032258064516, 'r1_f1': 0.5327102803738318, 'r2_precision': 0.275, 'r2_recall': 0.358695652173913, 'r2_f1': 0.3113207547169812, 'rL_precision': 0.32231404958677684, 'rL_recall': 0.41935483870967744, 'rL_f1': 0.3644859813084112, 'bs_precision': 0.44547271728515625, 'bs_recall': 0.5564643740653992, 'bs_f1': 0.500364363193512, 'bs_mnli_precision': 0.6973718404769897, 'bs_mnli_recall': 0.7659497261047363, 'bs_mnli_f1': 0.7300539016723633, 'unique_bigram_ratio': 0.9913793103448276, 'nid': -0.31505202316683234, 'grammatical_errors': 2, 'pegasus_entailment': 0.5960080329095945, 'gold_entailment': 0.25386528577655554, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 137
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.16 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.47878787878787876, 'r1_recall': 0.5939849624060151, 'r1_f1': 0.5302013422818792, 'r2_precision': 0.2682926829268293, 'r2_recall': 0.3333333333333333, 'r2_f1': 0.2972972972972973, 'rL_precision': 0.3212121212121212, 'rL_recall': 0.39849624060150374, 'rL_f1': 0.35570469798657717, 'bs_precision': 0.43663299083709717, 'bs_recall': 0.39192846417427063, 'bs_f1': 0.4158838391304016, 'bs_mnli_precision': 0.6659354567527771, 'bs_mnli_recall': 0.683289110660553, 'bs_mnli_f1': 0.6745007038116455, 'unique_bigram_ratio': 0.9119496855345912, 'nid': -0.1939670025322333, 'grammatical_errors': 1, 'pegasus_entailment': 0.7005748391151428, 'gold_entailment': 0.5568550229072571, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 138
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.58 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.43317972350230416, 'r1_recall': 0.5081081081081081, 'r1_f1': 0.4676616915422886, 'r2_precision': 0.16666666666666666, 'r2_recall': 0.1956521739130435, 'r2_f1': 0.18, 'rL_precision': 0.2626728110599078, 'rL_recall': 0.3081081081081081, 'rL_f1': 0.28358208955223874, 'bs_precision': 0.2894589900970459, 'bs_recall': 0.2892467677593231, 'bs_f1': 0.29178130626678467, 'bs_mnli_precision': 0.6348618268966675, 'bs_mnli_recall': 0.6378424167633057, 'bs_mnli_f1': 0.6363486051559448, 'unique_bigram_ratio': 0.9428571428571428, 'nid': -0.22684810378314713, 'grammatical_errors': 5, 'pegasus_entailment': 0.470438486430794, 'gold_entailment': 0.3984559988602996, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 139
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 66.98 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.23703703703703705, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.3316062176165803, 'r2_precision': 0.09701492537313433, 'r2_recall': 0.22807017543859648, 'r2_f1': 0.13612565445026178, 'rL_precision': 0.17037037037037037, 'rL_recall': 0.39655172413793105, 'rL_f1': 0.2383419689119171, 'bs_precision': 0.23095373809337616, 'bs_recall': 0.42704716324806213, 'bs_f1': 0.32302039861679077, 'bs_mnli_precision': 0.5854753851890564, 'bs_mnli_recall': 0.6846808195114136, 'bs_mnli_f1': 0.6312038898468018, 'unique_bigram_ratio': 0.937007874015748, 'nid': -0.2571652124797028, 'grammatical_errors': 3, 'pegasus_entailment': 0.46393267686168355, 'gold_entailment': 0.05555352196097374, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 140
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.73 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4172661870503597, 'r1_recall': 0.6590909090909091, 'r1_f1': 0.5110132158590308, 'r2_precision': 0.21014492753623187, 'r2_recall': 0.3333333333333333, 'r2_f1': 0.2577777777777778, 'rL_precision': 0.2733812949640288, 'rL_recall': 0.4318181818181818, 'rL_f1': 0.33480176211453744, 'bs_precision': 0.37851086258888245, 'bs_recall': 0.5236678719520569, 'bs_f1': 0.4488624930381775, 'bs_mnli_precision': 0.6461493372917175, 'bs_mnli_recall': 0.7215654850006104, 'bs_mnli_f1': 0.6817781329154968, 'unique_bigram_ratio': 0.9779411764705882, 'nid': -0.2969481834063028, 'grammatical_errors': 4, 'pegasus_entailment': 0.18898812246819338, 'gold_entailment': 0.19046531183024248, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 32, 'pegasus_smog': 26}
*** Analysing case 141
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.41 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.30434782608695654, 'r1_recall': 0.6021505376344086, 'r1_f1': 0.40433212996389895, 'r2_precision': 0.1366120218579235, 'r2_recall': 0.2717391304347826, 'r2_f1': 0.1818181818181818, 'rL_precision': 0.22826086956521738, 'rL_recall': 0.45161290322580644, 'rL_f1': 0.3032490974729242, 'bs_precision': 0.27689802646636963, 'bs_recall': 0.38251999020576477, 'bs_f1': 0.3295988142490387, 'bs_mnli_precision': 0.6131373643875122, 'bs_mnli_recall': 0.6872965097427368, 'bs_mnli_f1': 0.6481024026870728, 'unique_bigram_ratio': 0.9333333333333333, 'nid': -0.18608952119944489, 'grammatical_errors': 1, 'pegasus_entailment': 0.4405451603233814, 'gold_entailment': 0.25944631298383075, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 142
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.45 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.358974358974359, 'r1_recall': 0.6194690265486725, 'r1_f1': 0.45454545454545453, 'r2_precision': 0.17010309278350516, 'r2_recall': 0.29464285714285715, 'r2_f1': 0.21568627450980393, 'rL_precision': 0.2512820512820513, 'rL_recall': 0.4336283185840708, 'rL_f1': 0.3181818181818182, 'bs_precision': 0.3036041557788849, 'bs_recall': 0.4346080720424652, 'bs_f1': 0.3676914572715759, 'bs_mnli_precision': 0.6418991088867188, 'bs_mnli_recall': 0.7150760889053345, 'bs_mnli_f1': 0.6765145063400269, 'unique_bigram_ratio': 0.9470899470899471, 'nid': -0.23433354968320974, 'grammatical_errors': 2, 'pegasus_entailment': 0.44110381106535596, 'gold_entailment': 0.30847955246766406, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 143
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.96 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3716216216216216, 'r1_recall': 0.6875, 'r1_f1': 0.48245614035087725, 'r2_precision': 0.23129251700680273, 'r2_recall': 0.43037974683544306, 'r2_f1': 0.3008849557522124, 'rL_precision': 0.25675675675675674, 'rL_recall': 0.475, 'rL_f1': 0.33333333333333337, 'bs_precision': 0.3409675657749176, 'bs_recall': 0.5236848592758179, 'bs_f1': 0.42767083644866943, 'bs_mnli_precision': 0.6423720121383667, 'bs_mnli_recall': 0.7788573503494263, 'bs_mnli_f1': 0.7040610909461975, 'unique_bigram_ratio': 0.9440559440559441, 'nid': -0.26552263034918333, 'grammatical_errors': 3, 'pegasus_entailment': 0.6318226635456086, 'gold_entailment': 0.43176404796540735, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 144
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.98 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3197969543147208, 'r1_recall': 0.6237623762376238, 'r1_f1': 0.42281879194630867, 'r2_precision': 0.11734693877551021, 'r2_recall': 0.23, 'r2_f1': 0.1554054054054054, 'rL_precision': 0.20812182741116753, 'rL_recall': 0.40594059405940597, 'rL_f1': 0.2751677852348994, 'bs_precision': 0.29961609840393066, 'bs_recall': 0.45571544766426086, 'bs_f1': 0.3747599422931671, 'bs_mnli_precision': 0.6020404100418091, 'bs_mnli_recall': 0.7023240327835083, 'bs_mnli_f1': 0.6483271718025208, 'unique_bigram_ratio': 0.9583333333333334, 'nid': -0.2511567033507349, 'grammatical_errors': 4, 'pegasus_entailment': 0.2766998250569616, 'gold_entailment': 0.1184319904340165, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 145
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.78 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5548387096774193, 'r1_recall': 0.41148325358851673, 'r1_f1': 0.47252747252747246, 'r2_precision': 0.24675324675324675, 'r2_recall': 0.18269230769230768, 'r2_f1': 0.2099447513812155, 'rL_precision': 0.3419354838709677, 'rL_recall': 0.2535885167464115, 'rL_f1': 0.29120879120879123, 'bs_precision': 0.3747626543045044, 'bs_recall': 0.2602333426475525, 'bs_f1': 0.31698763370513916, 'bs_mnli_precision': 0.6771499514579773, 'bs_mnli_recall': 0.6013917326927185, 'bs_mnli_f1': 0.6370263695716858, 'unique_bigram_ratio': 0.9530201342281879, 'nid': -0.21165804387107467, 'grammatical_errors': 0, 'pegasus_entailment': 0.7068623006343842, 'gold_entailment': 0.40202381610870364, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 146
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.24 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5638297872340425, 'r1_recall': 0.585635359116022, 'r1_f1': 0.5745257452574525, 'r2_precision': 0.25668449197860965, 'r2_recall': 0.26666666666666666, 'r2_f1': 0.2615803814713896, 'rL_precision': 0.3191489361702128, 'rL_recall': 0.3314917127071823, 'rL_f1': 0.3252032520325204, 'bs_precision': 0.38147297501564026, 'bs_recall': 0.3859592080116272, 'bs_f1': 0.38581767678260803, 'bs_mnli_precision': 0.684146523475647, 'bs_mnli_recall': 0.681346595287323, 'bs_mnli_f1': 0.6827437281608582, 'unique_bigram_ratio': 0.9510869565217391, 'nid': -0.21102041042569875, 'grammatical_errors': 0, 'pegasus_entailment': 0.5508851536682674, 'gold_entailment': 0.3704015128314495, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 147
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.67 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.16, 'r1_recall': 0.5423728813559322, 'r1_f1': 0.2471042471042471, 'r2_precision': 0.04522613065326633, 'r2_recall': 0.15517241379310345, 'r2_f1': 0.07003891050583658, 'rL_precision': 0.1, 'rL_recall': 0.3389830508474576, 'rL_f1': 0.15444015444015446, 'bs_precision': 0.16748937964439392, 'bs_recall': 0.4275820553302765, 'bs_f1': 0.2849791944026947, 'bs_mnli_precision': 0.5474914312362671, 'bs_mnli_recall': 0.670427680015564, 'bs_mnli_f1': 0.6027550101280212, 'unique_bigram_ratio': 0.9489795918367347, 'nid': -0.23352089472901705, 'grammatical_errors': 1, 'pegasus_entailment': 0.5875195960203806, 'gold_entailment': 0.3027220889925957, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 148
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.99 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5314285714285715, 'r1_recall': 0.5740740740740741, 'r1_f1': 0.5519287833827894, 'r2_precision': 0.28160919540229884, 'r2_recall': 0.30434782608695654, 'r2_f1': 0.29253731343283584, 'rL_precision': 0.37714285714285717, 'rL_recall': 0.4074074074074074, 'rL_f1': 0.3916913946587537, 'bs_precision': 0.45678555965423584, 'bs_recall': 0.46232908964157104, 'bs_f1': 0.46139809489250183, 'bs_mnli_precision': 0.7206074595451355, 'bs_mnli_recall': 0.7199081182479858, 'bs_mnli_f1': 0.7202576398849487, 'unique_bigram_ratio': 0.9526627218934911, 'nid': -0.20178894138794123, 'grammatical_errors': 0, 'pegasus_entailment': 0.6662277430295944, 'gold_entailment': 0.35478063821792605, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 149
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 69.83 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4146341463414634, 'r1_recall': 0.6219512195121951, 'r1_f1': 0.49756097560975604, 'r2_precision': 0.2540983606557377, 'r2_recall': 0.38271604938271603, 'r2_f1': 0.3054187192118227, 'rL_precision': 0.2926829268292683, 'rL_recall': 0.43902439024390244, 'rL_f1': 0.35121951219512193, 'bs_precision': 0.4572600722312927, 'bs_recall': 0.5317563414573669, 'bs_f1': 0.49518924951553345, 'bs_mnli_precision': 0.6921803951263428, 'bs_mnli_recall': 0.746383786201477, 'bs_mnli_f1': 0.7182608842849731, 'unique_bigram_ratio': 0.957983193277311, 'nid': -0.26831561137798454, 'grammatical_errors': 2, 'pegasus_entailment': 0.41862909495830536, 'gold_entailment': 0.2855427513519923, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 150
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.40 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.37341772151898733, 'r1_recall': 0.6145833333333334, 'r1_f1': 0.4645669291338583, 'r2_precision': 0.19745222929936307, 'r2_recall': 0.3263157894736842, 'r2_f1': 0.246031746031746, 'rL_precision': 0.27848101265822783, 'rL_recall': 0.4583333333333333, 'rL_f1': 0.3464566929133858, 'bs_precision': 0.33146822452545166, 'bs_recall': 0.44071564078330994, 'bs_f1': 0.3857406973838806, 'bs_mnli_precision': 0.6403194665908813, 'bs_mnli_recall': 0.7039616703987122, 'bs_mnli_f1': 0.6706340312957764, 'unique_bigram_ratio': 0.9473684210526315, 'nid': -0.24582037083448016, 'grammatical_errors': 5, 'pegasus_entailment': 0.281758311825494, 'gold_entailment': 0.1343405332416296, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 151
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.01 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.33163265306122447, 'r1_recall': 0.7065217391304348, 'r1_f1': 0.4513888888888889, 'r2_precision': 0.2, 'r2_recall': 0.42857142857142855, 'r2_f1': 0.27272727272727276, 'rL_precision': 0.20918367346938777, 'rL_recall': 0.44565217391304346, 'rL_f1': 0.28472222222222227, 'bs_precision': 0.2669799029827118, 'bs_recall': 0.4630998373031616, 'bs_f1': 0.35918402671813965, 'bs_mnli_precision': 0.6106767058372498, 'bs_mnli_recall': 0.7230680584907532, 'bs_mnli_f1': 0.6621369123458862, 'unique_bigram_ratio': 0.9738219895287958, 'nid': -0.24889847448520053, 'grammatical_errors': 3, 'pegasus_entailment': 0.569052942097187, 'gold_entailment': 0.04695487022399902, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 152
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.16 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.640625, 'r1_recall': 0.422680412371134, 'r1_f1': 0.5093167701863354, 'r2_precision': 0.2992125984251969, 'r2_recall': 0.19689119170984457, 'r2_f1': 0.2375, 'rL_precision': 0.359375, 'rL_recall': 0.23711340206185566, 'rL_f1': 0.2857142857142857, 'bs_precision': 0.4126180410385132, 'bs_recall': 0.3163726031780243, 'bs_f1': 0.3647390902042389, 'bs_mnli_precision': 0.7157865762710571, 'bs_mnli_recall': 0.649980902671814, 'bs_mnli_f1': 0.6812983751296997, 'unique_bigram_ratio': 0.9354838709677419, 'nid': -0.19494678661935017, 'grammatical_errors': 3, 'pegasus_entailment': 0.40420805625617506, 'gold_entailment': 0.16933492511244758, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 153
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.81 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.609375, 'r1_recall': 0.46987951807228917, 'r1_f1': 0.5306122448979592, 'r2_precision': 0.2992125984251969, 'r2_recall': 0.23030303030303031, 'r2_f1': 0.2602739726027397, 'rL_precision': 0.3671875, 'rL_recall': 0.28313253012048195, 'rL_f1': 0.3197278911564626, 'bs_precision': 0.47501686215400696, 'bs_recall': 0.3579118847846985, 'bs_f1': 0.4157220721244812, 'bs_mnli_precision': 0.7018992900848389, 'bs_mnli_recall': 0.6560119390487671, 'bs_mnli_f1': 0.6781802773475647, 'unique_bigram_ratio': 0.967479674796748, 'nid': -0.2750687847540938, 'grammatical_errors': 2, 'pegasus_entailment': 0.45496037006378176, 'gold_entailment': 0.31278096139431, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 154
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.64 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.1875, 'r1_recall': 0.711864406779661, 'r1_f1': 0.2968197879858657, 'r2_precision': 0.10762331838565023, 'r2_recall': 0.41379310344827586, 'r2_f1': 0.17081850533807827, 'rL_precision': 0.12946428571428573, 'rL_recall': 0.4915254237288136, 'rL_f1': 0.2049469964664311, 'bs_precision': 0.14069870114326477, 'bs_recall': 0.5211214423179626, 'bs_f1': 0.3021259903907776, 'bs_mnli_precision': 0.5432659387588501, 'bs_mnli_recall': 0.7287253141403198, 'bs_mnli_f1': 0.6224753856658936, 'unique_bigram_ratio': 0.9409090909090909, 'nid': -0.22816804021142234, 'grammatical_errors': 3, 'pegasus_entailment': 0.5237503558397293, 'gold_entailment': 0.20022279024124146, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 155
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.38 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5502958579881657, 'r1_recall': 0.5375722543352601, 'r1_f1': 0.5438596491228069, 'r2_precision': 0.2857142857142857, 'r2_recall': 0.27906976744186046, 'r2_f1': 0.2823529411764706, 'rL_precision': 0.33136094674556216, 'rL_recall': 0.3236994219653179, 'rL_f1': 0.3274853801169591, 'bs_precision': 0.43375277519226074, 'bs_recall': 0.3956439793109894, 'bs_f1': 0.4164092540740967, 'bs_mnli_precision': 0.702149510383606, 'bs_mnli_recall': 0.6869603395462036, 'bs_mnli_f1': 0.6944718956947327, 'unique_bigram_ratio': 0.9573170731707317, 'nid': -0.23927539930233155, 'grammatical_errors': 0, 'pegasus_entailment': 0.5530767577389876, 'gold_entailment': 0.30944216357810156, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 156
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.01 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2777777777777778, 'r1_recall': 0.49382716049382713, 'r1_f1': 0.35555555555555557, 'r2_precision': 0.1258741258741259, 'r2_recall': 0.225, 'r2_f1': 0.16143497757847533, 'rL_precision': 0.20833333333333334, 'rL_recall': 0.37037037037037035, 'rL_f1': 0.26666666666666666, 'bs_precision': 0.31367751955986023, 'bs_recall': 0.4636343717575073, 'bs_f1': 0.3861425220966339, 'bs_mnli_precision': 0.6240308284759521, 'bs_mnli_recall': 0.7075934410095215, 'bs_mnli_f1': 0.6631902456283569, 'unique_bigram_ratio': 0.9785714285714285, 'nid': -0.24651898201849254, 'grammatical_errors': 5, 'pegasus_entailment': 0.438966978341341, 'gold_entailment': 0.41874147951602936, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 157
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 37.58 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3102310231023102, 'r1_recall': 0.6308724832214765, 'r1_f1': 0.41592920353982293, 'r2_precision': 0.12251655629139073, 'r2_recall': 0.25, 'r2_f1': 0.16444444444444445, 'rL_precision': 0.16831683168316833, 'rL_recall': 0.3422818791946309, 'rL_f1': 0.22566371681415934, 'bs_precision': 0.21944978833198547, 'bs_recall': 0.37953299283981323, 'bs_f1': 0.29622629284858704, 'bs_mnli_precision': 0.587653636932373, 'bs_mnli_recall': 0.6742343306541443, 'bs_mnli_f1': 0.6279736757278442, 'unique_bigram_ratio': 0.9530201342281879, 'nid': -0.22420559064206103, 'grammatical_errors': 1, 'pegasus_entailment': 0.74726988474528, 'gold_entailment': 0.44160938635468483, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 158
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.52 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3048128342245989, 'r1_recall': 0.6129032258064516, 'r1_f1': 0.40714285714285714, 'r2_precision': 0.14516129032258066, 'r2_recall': 0.29347826086956524, 'r2_f1': 0.19424460431654678, 'rL_precision': 0.21390374331550802, 'rL_recall': 0.43010752688172044, 'rL_f1': 0.2857142857142857, 'bs_precision': 0.30437079071998596, 'bs_recall': 0.49036410450935364, 'bs_f1': 0.3923983573913574, 'bs_mnli_precision': 0.6101694107055664, 'bs_mnli_recall': 0.725579023361206, 'bs_mnli_f1': 0.6628884673118591, 'unique_bigram_ratio': 0.9482758620689655, 'nid': -0.28183005197008604, 'grammatical_errors': 0, 'pegasus_entailment': 0.28540375605225565, 'gold_entailment': 0.2001424226909876, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 159
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.04 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5081967213114754, 'r1_recall': 0.38509316770186336, 'r1_f1': 0.4381625441696113, 'r2_precision': 0.2231404958677686, 'r2_recall': 0.16875, 'r2_f1': 0.1921708185053381, 'rL_precision': 0.3360655737704918, 'rL_recall': 0.2546583850931677, 'rL_f1': 0.2897526501766784, 'bs_precision': 0.349458783864975, 'bs_recall': 0.23602384328842163, 'bs_f1': 0.29230815172195435, 'bs_mnli_precision': 0.6498637199401855, 'bs_mnli_recall': 0.5964518785476685, 'bs_mnli_f1': 0.62201327085495, 'unique_bigram_ratio': 0.9833333333333333, 'nid': -0.22845323356650682, 'grammatical_errors': 2, 'pegasus_entailment': 0.5677004804213842, 'gold_entailment': 0.2438025139272213, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 160
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.40 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.10480349344978165, 'r1_recall': 0.631578947368421, 'r1_f1': 0.1797752808988764, 'r2_precision': 0.03070175438596491, 'r2_recall': 0.1891891891891892, 'r2_f1': 0.05283018867924528, 'rL_precision': 0.06550218340611354, 'rL_recall': 0.39473684210526316, 'rL_f1': 0.11235955056179775, 'bs_precision': 0.07800719141960144, 'bs_recall': 0.37779897451400757, 'bs_f1': 0.20936410129070282, 'bs_mnli_precision': 0.4840303659439087, 'bs_mnli_recall': 0.671358585357666, 'bs_mnli_f1': 0.5625082850456238, 'unique_bigram_ratio': 0.9678899082568807, 'nid': -0.2662988936607671, 'grammatical_errors': 3, 'pegasus_entailment': 0.6256166435778141, 'gold_entailment': 0.12172186374664307, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 21, 'pegasus_ari': 33, 'pegasus_smog': 26}
*** Analysing case 161
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 41.13 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2857142857142857, 'r1_recall': 0.7407407407407407, 'r1_f1': 0.41237113402061853, 'r2_precision': 0.15412186379928317, 'r2_recall': 0.40186915887850466, 'r2_f1': 0.2227979274611399, 'rL_precision': 0.17857142857142858, 'rL_recall': 0.46296296296296297, 'rL_f1': 0.2577319587628866, 'bs_precision': 0.25042226910591125, 'bs_recall': 0.49049609899520874, 'bs_f1': 0.3606407940387726, 'bs_mnli_precision': 0.5966624617576599, 'bs_mnli_recall': 0.717978835105896, 'bs_mnli_f1': 0.6517230868339539, 'unique_bigram_ratio': 0.9438202247191011, 'nid': -0.23480124605648123, 'grammatical_errors': 1, 'pegasus_entailment': 0.7548151295632124, 'gold_entailment': 0.5465081830819448, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 162
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.22 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.327683615819209, 'r1_recall': 0.5631067961165048, 'r1_f1': 0.41428571428571426, 'r2_precision': 0.1875, 'r2_recall': 0.3235294117647059, 'r2_f1': 0.2374100719424461, 'rL_precision': 0.23728813559322035, 'rL_recall': 0.4077669902912621, 'rL_f1': 0.30000000000000004, 'bs_precision': 0.3441050052642822, 'bs_recall': 0.44001340866088867, 'bs_f1': 0.3922578990459442, 'bs_mnli_precision': 0.6512995362281799, 'bs_mnli_recall': 0.6954336166381836, 'bs_mnli_f1': 0.6726434826850891, 'unique_bigram_ratio': 0.936046511627907, 'nid': -0.23924005308137763, 'grammatical_errors': 0, 'pegasus_entailment': 0.4526748899370432, 'gold_entailment': 0.2111239922232926, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 163
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.90 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.4539877300613497, 'r1_f1': 0.4252873563218391, 'r2_precision': 0.15760869565217392, 'r2_recall': 0.17901234567901234, 'r2_f1': 0.1676300578034682, 'rL_precision': 0.24324324324324326, 'rL_recall': 0.27607361963190186, 'rL_f1': 0.25862068965517243, 'bs_precision': 0.21433556079864502, 'bs_recall': 0.2457667738199234, 'bs_f1': 0.232448548078537, 'bs_mnli_precision': 0.5830471515655518, 'bs_mnli_recall': 0.5940346717834473, 'bs_mnli_f1': 0.5884896516799927, 'unique_bigram_ratio': 0.9392265193370166, 'nid': -0.2224026245620403, 'grammatical_errors': 11, 'pegasus_entailment': 0.6440746635198593, 'gold_entailment': 0.32320318805674714, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 164
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 69.98 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.47115384615384615, 'r1_recall': 0.44954128440366975, 'r1_f1': 0.460093896713615, 'r2_precision': 0.3106796116504854, 'r2_recall': 0.2962962962962963, 'r2_f1': 0.30331753554502366, 'rL_precision': 0.38461538461538464, 'rL_recall': 0.3669724770642202, 'rL_f1': 0.37558685446009393, 'bs_precision': 0.4431934356689453, 'bs_recall': 0.44867098331451416, 'bs_f1': 0.44781947135925293, 'bs_mnli_precision': 0.7038863897323608, 'bs_mnli_recall': 0.7116842269897461, 'bs_mnli_f1': 0.7077638506889343, 'unique_bigram_ratio': 1.0, 'nid': -0.31112173215200634, 'grammatical_errors': 1, 'pegasus_entailment': 0.3617628489931424, 'gold_entailment': 0.3791093627611796, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 165
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.03 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.48314606741573035, 'r1_recall': 0.48863636363636365, 'r1_f1': 0.4858757062146893, 'r2_precision': 0.20903954802259886, 'r2_recall': 0.21142857142857144, 'r2_f1': 0.2102272727272727, 'rL_precision': 0.24719101123595505, 'rL_recall': 0.25, 'rL_f1': 0.2485875706214689, 'bs_precision': 0.372893750667572, 'bs_recall': 0.34956324100494385, 'bs_f1': 0.3632984161376953, 'bs_mnli_precision': 0.6367828249931335, 'bs_mnli_recall': 0.6267120242118835, 'bs_mnli_f1': 0.6317072510719299, 'unique_bigram_ratio': 0.9540229885057471, 'nid': -0.24559677112513278, 'grammatical_errors': 1, 'pegasus_entailment': 0.6153382390737534, 'gold_entailment': 0.2743997275829315, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 166
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.31 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.49324324324324326, 'r1_recall': 0.4866666666666667, 'r1_f1': 0.4899328859060403, 'r2_precision': 0.19727891156462585, 'r2_recall': 0.19463087248322147, 'r2_f1': 0.19594594594594594, 'rL_precision': 0.30405405405405406, 'rL_recall': 0.3, 'rL_f1': 0.30201342281879195, 'bs_precision': 0.36025577783584595, 'bs_recall': 0.3505825996398926, 'bs_f1': 0.3576025664806366, 'bs_mnli_precision': 0.6595157384872437, 'bs_mnli_recall': 0.6418554782867432, 'bs_mnli_f1': 0.6505658030509949, 'unique_bigram_ratio': 0.9507042253521126, 'nid': -0.21483875136074992, 'grammatical_errors': 1, 'pegasus_entailment': 0.5008674571290612, 'gold_entailment': 0.309232097864151, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 167
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.25 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.43125, 'r1_recall': 0.4928571428571429, 'r1_f1': 0.4600000000000001, 'r2_precision': 0.1320754716981132, 'r2_recall': 0.1510791366906475, 'r2_f1': 0.14093959731543623, 'rL_precision': 0.2375, 'rL_recall': 0.2714285714285714, 'rL_f1': 0.25333333333333335, 'bs_precision': 0.35199299454689026, 'bs_recall': 0.395111620426178, 'bs_f1': 0.3753064274787903, 'bs_mnli_precision': 0.6536303162574768, 'bs_mnli_recall': 0.6663087010383606, 'bs_mnli_f1': 0.659908652305603, 'unique_bigram_ratio': 0.9554140127388535, 'nid': -0.26017490815805755, 'grammatical_errors': 5, 'pegasus_entailment': 0.7271160909107753, 'gold_entailment': 0.3125865161418915, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 168
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.41 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.5369127516778524, 'r1_f1': 0.4584527220630373, 'r2_precision': 0.1407035175879397, 'r2_recall': 0.1891891891891892, 'r2_f1': 0.16138328530259366, 'rL_precision': 0.18, 'rL_recall': 0.24161073825503357, 'rL_f1': 0.20630372492836674, 'bs_precision': 0.26758989691734314, 'bs_recall': 0.39573103189468384, 'bs_f1': 0.3304177522659302, 'bs_mnli_precision': 0.5978586673736572, 'bs_mnli_recall': 0.6672663688659668, 'bs_mnli_f1': 0.6306586265563965, 'unique_bigram_ratio': 0.9585492227979274, 'nid': -0.27452433951361677, 'grammatical_errors': 2, 'pegasus_entailment': 0.6253538072109223, 'gold_entailment': 0.30767417047172785, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 169
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 44.95 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.23868312757201646, 'r1_recall': 0.6373626373626373, 'r1_f1': 0.34730538922155685, 'r2_precision': 0.10743801652892562, 'r2_recall': 0.28888888888888886, 'r2_f1': 0.1566265060240964, 'rL_precision': 0.1440329218106996, 'rL_recall': 0.38461538461538464, 'rL_f1': 0.20958083832335328, 'bs_precision': 0.16524599492549896, 'bs_recall': 0.35101941227912903, 'bs_f1': 0.2527585029602051, 'bs_mnli_precision': 0.5601176023483276, 'bs_mnli_recall': 0.644082248210907, 'bs_mnli_f1': 0.5991726517677307, 'unique_bigram_ratio': 0.9276595744680851, 'nid': -0.21655365632050372, 'grammatical_errors': 3, 'pegasus_entailment': 0.5915467206920896, 'gold_entailment': 0.5406734272837639, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 170
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 42.24 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.20141342756183744, 'r1_recall': 0.7402597402597403, 'r1_f1': 0.31666666666666665, 'r2_precision': 0.11702127659574468, 'r2_recall': 0.4342105263157895, 'r2_f1': 0.18435754189944134, 'rL_precision': 0.17314487632508835, 'rL_recall': 0.6363636363636364, 'rL_f1': 0.27222222222222225, 'bs_precision': 0.2635396718978882, 'bs_recall': 0.5375872254371643, 'bs_f1': 0.387397825717926, 'bs_mnli_precision': 0.6056159734725952, 'bs_mnli_recall': 0.7688376903533936, 'bs_mnli_f1': 0.6775352358818054, 'unique_bigram_ratio': 0.9333333333333333, 'nid': -0.19844306745466977, 'grammatical_errors': 1, 'pegasus_entailment': 0.6265883054584265, 'gold_entailment': 0.3637595350543658, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 171
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.72 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.32592592592592595, 'r1_recall': 0.6027397260273972, 'r1_f1': 0.42307692307692313, 'r2_precision': 0.16417910447761194, 'r2_recall': 0.3055555555555556, 'r2_f1': 0.21359223300970875, 'rL_precision': 0.2518518518518518, 'rL_recall': 0.4657534246575342, 'rL_f1': 0.32692307692307687, 'bs_precision': 0.3524273633956909, 'bs_recall': 0.5008001923561096, 'bs_f1': 0.42420342564582825, 'bs_mnli_precision': 0.6294138431549072, 'bs_mnli_recall': 0.7127963900566101, 'bs_mnli_f1': 0.6685150861740112, 'unique_bigram_ratio': 0.9923076923076923, 'nid': -0.3064802084031364, 'grammatical_errors': 1, 'pegasus_entailment': 0.5221367962658405, 'gold_entailment': 0.24189993490775427, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 172
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 33.39 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.7483443708609272, 'r1_recall': 0.3070652173913043, 'r1_f1': 0.43545279383429675, 'r2_precision': 0.37333333333333335, 'r2_recall': 0.15258855585831063, 'r2_f1': 0.21663442940038685, 'rL_precision': 0.4966887417218543, 'rL_recall': 0.20380434782608695, 'rL_f1': 0.2890173410404624, 'bs_precision': 0.45659226179122925, 'bs_recall': 0.2019568830728531, 'bs_f1': 0.31764450669288635, 'bs_mnli_precision': 0.6993822455406189, 'bs_mnli_recall': 0.567229151725769, 'bs_mnli_f1': 0.6264115571975708, 'unique_bigram_ratio': 0.9251700680272109, 'nid': -0.18940190649583655, 'grammatical_errors': 1, 'pegasus_entailment': 0.4757135510444641, 'gold_entailment': 0.2063936430674333, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 173
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.17 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3238095238095238, 'r1_recall': 0.6181818181818182, 'r1_f1': 0.42500000000000004, 'r2_precision': 0.11004784688995216, 'r2_recall': 0.21100917431192662, 'r2_f1': 0.14465408805031446, 'rL_precision': 0.17142857142857143, 'rL_recall': 0.32727272727272727, 'rL_f1': 0.225, 'bs_precision': 0.30832788348197937, 'bs_recall': 0.4066702723503113, 'bs_f1': 0.35766181349754333, 'bs_mnli_precision': 0.6120752692222595, 'bs_mnli_recall': 0.6592193841934204, 'bs_mnli_f1': 0.6347732543945312, 'unique_bigram_ratio': 0.9512195121951219, 'nid': -0.2651403002342221, 'grammatical_errors': 1, 'pegasus_entailment': 0.5976842003209251, 'gold_entailment': 0.3224881514906883, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 174
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.96 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.375, 'r1_recall': 0.4112903225806452, 'r1_f1': 0.39230769230769225, 'r2_precision': 0.14814814814814814, 'r2_recall': 0.16260162601626016, 'r2_f1': 0.15503875968992248, 'rL_precision': 0.25, 'rL_recall': 0.27419354838709675, 'rL_f1': 0.26153846153846155, 'bs_precision': 0.3806171119213104, 'bs_recall': 0.4070053994655609, 'bs_f1': 0.39574000239372253, 'bs_mnli_precision': 0.6494271159172058, 'bs_mnli_recall': 0.6676222681999207, 'bs_mnli_f1': 0.6583989858627319, 'unique_bigram_ratio': 0.9846153846153847, 'nid': -0.27127168823315584, 'grammatical_errors': 0, 'pegasus_entailment': 0.5304944694042206, 'gold_entailment': 0.49640387296676636, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 175
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 39.85 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2779552715654952, 'r1_recall': 0.725, 'r1_f1': 0.40184757505773666, 'r2_precision': 0.16025641025641027, 'r2_recall': 0.42016806722689076, 'r2_f1': 0.2320185614849188, 'rL_precision': 0.19169329073482427, 'rL_recall': 0.5, 'rL_f1': 0.27713625866050806, 'bs_precision': 0.27813926339149475, 'bs_recall': 0.4941166043281555, 'bs_f1': 0.37866222858428955, 'bs_mnli_precision': 0.6051758527755737, 'bs_mnli_recall': 0.7310217618942261, 'bs_mnli_f1': 0.6621726155281067, 'unique_bigram_ratio': 0.9379084967320261, 'nid': -0.2210413684830339, 'grammatical_errors': 5, 'pegasus_entailment': 0.7129881296839032, 'gold_entailment': 0.28084319282788783, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 176
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 44.91 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6161137440758294, 'r1_recall': 0.5531914893617021, 'r1_f1': 0.5829596412556054, 'r2_precision': 0.36666666666666664, 'r2_recall': 0.32905982905982906, 'r2_f1': 0.34684684684684686, 'rL_precision': 0.36018957345971564, 'rL_recall': 0.32340425531914896, 'rL_f1': 0.3408071748878924, 'bs_precision': 0.4651782810688019, 'bs_recall': 0.40085068345069885, 'bs_f1': 0.4341382384300232, 'bs_mnli_precision': 0.7304837703704834, 'bs_mnli_recall': 0.683745801448822, 'bs_mnli_f1': 0.7063424587249756, 'unique_bigram_ratio': 0.9408866995073891, 'nid': -0.24550086569669527, 'grammatical_errors': 4, 'pegasus_entailment': 0.507585597889764, 'gold_entailment': 0.27496714517474174, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 177
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.17 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4293193717277487, 'r1_recall': 0.5394736842105263, 'r1_f1': 0.478134110787172, 'r2_precision': 0.21578947368421053, 'r2_recall': 0.271523178807947, 'r2_f1': 0.24046920821114368, 'rL_precision': 0.2931937172774869, 'rL_recall': 0.3684210526315789, 'rL_f1': 0.32653061224489793, 'bs_precision': 0.34083864092826843, 'bs_recall': 0.3696388602256775, 'bs_f1': 0.35726654529571533, 'bs_mnli_precision': 0.6528164744377136, 'bs_mnli_recall': 0.6702080965042114, 'bs_mnli_f1': 0.6613979935646057, 'unique_bigram_ratio': 0.9411764705882353, 'nid': -0.1847392328140458, 'grammatical_errors': 3, 'pegasus_entailment': 0.4533179569989443, 'gold_entailment': 0.26843771934509275, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 178
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.57 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24031007751937986, 'r1_recall': 0.7209302325581395, 'r1_f1': 0.3604651162790698, 'r2_precision': 0.12840466926070038, 'r2_recall': 0.38823529411764707, 'r2_f1': 0.1929824561403509, 'rL_precision': 0.17054263565891473, 'rL_recall': 0.5116279069767442, 'rL_f1': 0.2558139534883721, 'bs_precision': 0.17751091718673706, 'bs_recall': 0.44848400354385376, 'bs_f1': 0.29933062195777893, 'bs_mnli_precision': 0.5497517585754395, 'bs_mnli_recall': 0.7169919013977051, 'bs_mnli_f1': 0.6223320364952087, 'unique_bigram_ratio': 0.9322709163346613, 'nid': -0.2054919501040573, 'grammatical_errors': 5, 'pegasus_entailment': 0.5907998085021973, 'gold_entailment': 0.39487820491194725, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 179
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.76 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.26519337016574585, 'r1_recall': 0.64, 'r1_f1': 0.375, 'r2_precision': 0.07777777777777778, 'r2_recall': 0.1891891891891892, 'r2_f1': 0.11023622047244096, 'rL_precision': 0.16574585635359115, 'rL_recall': 0.4, 'rL_f1': 0.23437499999999997, 'bs_precision': 0.1884041130542755, 'bs_recall': 0.38104957342147827, 'bs_f1': 0.2788691222667694, 'bs_mnli_precision': 0.5722055435180664, 'bs_mnli_recall': 0.6374684572219849, 'bs_mnli_f1': 0.6030765175819397, 'unique_bigram_ratio': 0.9050279329608939, 'nid': -0.2085102780905872, 'grammatical_errors': 0, 'pegasus_entailment': 0.5147151226798693, 'gold_entailment': 0.3385295420885086, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 180
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.62 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.29931972789115646, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.3713080168776371, 'r2_precision': 0.1095890410958904, 'r2_recall': 0.1797752808988764, 'r2_f1': 0.13617021276595745, 'rL_precision': 0.21768707482993196, 'rL_recall': 0.35555555555555557, 'rL_f1': 0.27004219409282704, 'bs_precision': 0.23982030153274536, 'bs_recall': 0.3409048020839691, 'bs_f1': 0.2905111014842987, 'bs_mnli_precision': 0.589148998260498, 'bs_mnli_recall': 0.6527745723724365, 'bs_mnli_f1': 0.619331955909729, 'unique_bigram_ratio': 0.9586206896551724, 'nid': -0.2092884265563486, 'grammatical_errors': 2, 'pegasus_entailment': 0.45125704045806614, 'gold_entailment': 0.3262929171323776, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 181
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.50 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.49710982658959535, 'r1_recall': 0.524390243902439, 'r1_f1': 0.5103857566765578, 'r2_precision': 0.22674418604651161, 'r2_recall': 0.2392638036809816, 'r2_f1': 0.23283582089552238, 'rL_precision': 0.3179190751445087, 'rL_recall': 0.3353658536585366, 'rL_f1': 0.3264094955489614, 'bs_precision': 0.342843234539032, 'bs_recall': 0.40762099623680115, 'bs_f1': 0.37649717926979065, 'bs_mnli_precision': 0.6582865118980408, 'bs_mnli_recall': 0.688795804977417, 'bs_mnli_f1': 0.6731956601142883, 'unique_bigram_ratio': 0.9156626506024096, 'nid': -0.18847977801136473, 'grammatical_errors': 1, 'pegasus_entailment': 0.7112691849470139, 'gold_entailment': 0.6729863584041595, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 182
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 34.12 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4838709677419355, 'r1_recall': 0.47038327526132406, 'r1_f1': 0.47703180212014135, 'r2_precision': 0.14388489208633093, 'r2_recall': 0.13986013986013987, 'r2_f1': 0.14184397163120566, 'rL_precision': 0.26523297491039427, 'rL_recall': 0.2578397212543554, 'rL_f1': 0.26148409893992935, 'bs_precision': 0.23611138761043549, 'bs_recall': 0.27128908038139343, 'bs_f1': 0.25596436858177185, 'bs_mnli_precision': 0.602803111076355, 'bs_mnli_recall': 0.6246880292892456, 'bs_mnli_f1': 0.6135504841804504, 'unique_bigram_ratio': 0.9264705882352942, 'nid': -0.20033719516395965, 'grammatical_errors': 2, 'pegasus_entailment': 0.7380984971920649, 'gold_entailment': 0.4846398246785005, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 183
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.37 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5826771653543307, 'r1_recall': 0.4134078212290503, 'r1_f1': 0.4836601307189542, 'r2_precision': 0.25396825396825395, 'r2_recall': 0.1797752808988764, 'r2_f1': 0.21052631578947367, 'rL_precision': 0.29133858267716534, 'rL_recall': 0.20670391061452514, 'rL_f1': 0.2418300653594771, 'bs_precision': 0.45069757103919983, 'bs_recall': 0.2916102409362793, 'bs_f1': 0.36806032061576843, 'bs_mnli_precision': 0.7126392126083374, 'bs_mnli_recall': 0.6215636730194092, 'bs_mnli_f1': 0.6639929413795471, 'unique_bigram_ratio': 0.9516129032258065, 'nid': -0.2300783371713524, 'grammatical_errors': 0, 'pegasus_entailment': 0.5320057287812233, 'gold_entailment': 0.2309613823890686, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 184
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.97 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3853211009174312, 'r1_recall': 0.7368421052631579, 'r1_f1': 0.5060240963855421, 'r2_precision': 0.1889400921658986, 'r2_recall': 0.36283185840707965, 'r2_f1': 0.24848484848484848, 'rL_precision': 0.25688073394495414, 'rL_recall': 0.49122807017543857, 'rL_f1': 0.3373493975903614, 'bs_precision': 0.265341579914093, 'bs_recall': 0.5613511800765991, 'bs_f1': 0.39778438210487366, 'bs_mnli_precision': 0.5820454359054565, 'bs_mnli_recall': 0.7480361461639404, 'bs_mnli_f1': 0.6546832323074341, 'unique_bigram_ratio': 0.9619047619047619, 'nid': -0.26289132393950765, 'grammatical_errors': 6, 'pegasus_entailment': 0.385692654975823, 'gold_entailment': 0.3575664430856705, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 185
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.17 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4883720930232558, 'r1_recall': 0.6461538461538462, 'r1_f1': 0.5562913907284769, 'r2_precision': 0.27485380116959063, 'r2_recall': 0.3643410852713178, 'r2_f1': 0.3133333333333333, 'rL_precision': 0.27906976744186046, 'rL_recall': 0.36923076923076925, 'rL_f1': 0.3178807947019867, 'bs_precision': 0.38102269172668457, 'bs_recall': 0.40234634280204773, 'bs_f1': 0.3936697542667389, 'bs_mnli_precision': 0.665372371673584, 'bs_mnli_recall': 0.6788724660873413, 'bs_mnli_f1': 0.672054648399353, 'unique_bigram_ratio': 0.9583333333333334, 'nid': -0.2364172937585034, 'grammatical_errors': 3, 'pegasus_entailment': 0.5871975968281428, 'gold_entailment': 0.6630053520202637, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 186
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.71 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3127962085308057, 'r1_recall': 0.6346153846153846, 'r1_f1': 0.41904761904761906, 'r2_precision': 0.12380952380952381, 'r2_recall': 0.2524271844660194, 'r2_f1': 0.16613418530351437, 'rL_precision': 0.2037914691943128, 'rL_recall': 0.41346153846153844, 'rL_f1': 0.273015873015873, 'bs_precision': 0.273458331823349, 'bs_recall': 0.3773685097694397, 'bs_f1': 0.3253863453865051, 'bs_mnli_precision': 0.6006097793579102, 'bs_mnli_recall': 0.6633756756782532, 'bs_mnli_f1': 0.6304343938827515, 'unique_bigram_ratio': 0.9512195121951219, 'nid': -0.20677437705655466, 'grammatical_errors': 5, 'pegasus_entailment': 0.48135279544762205, 'gold_entailment': 0.4371963973556246, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 187
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.77 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.36054421768707484, 'r1_recall': 0.6309523809523809, 'r1_f1': 0.45887445887445893, 'r2_precision': 0.17123287671232876, 'r2_recall': 0.30120481927710846, 'r2_f1': 0.2183406113537118, 'rL_precision': 0.2108843537414966, 'rL_recall': 0.36904761904761907, 'rL_f1': 0.2683982683982684, 'bs_precision': 0.35463985800743103, 'bs_recall': 0.4894336462020874, 'bs_f1': 0.42039167881011963, 'bs_mnli_precision': 0.6599156856536865, 'bs_mnli_recall': 0.7404856085777283, 'bs_mnli_f1': 0.697882890701294, 'unique_bigram_ratio': 0.993006993006993, 'nid': -0.2856629005540705, 'grammatical_errors': 2, 'pegasus_entailment': 0.682783305644989, 'gold_entailment': 0.3834309857338667, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 188
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.27 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5121951219512195, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.5153374233128833, 'r2_precision': 0.294478527607362, 'r2_recall': 0.2981366459627329, 'r2_f1': 0.29629629629629634, 'rL_precision': 0.2865853658536585, 'rL_recall': 0.29012345679012347, 'rL_f1': 0.2883435582822086, 'bs_precision': 0.3330610394477844, 'bs_recall': 0.3133316934108734, 'bs_f1': 0.325425922870636, 'bs_mnli_precision': 0.641527533531189, 'bs_mnli_recall': 0.642933189868927, 'bs_mnli_f1': 0.6422295570373535, 'unique_bigram_ratio': 0.949685534591195, 'nid': -0.2407151747314289, 'grammatical_errors': 2, 'pegasus_entailment': 0.47193066456488203, 'gold_entailment': 0.4016061246395111, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 189
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 68.35 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.391304347826087, 'r1_recall': 0.7012987012987013, 'r1_f1': 0.5023255813953489, 'r2_precision': 0.23357664233576642, 'r2_recall': 0.42105263157894735, 'r2_f1': 0.3004694835680751, 'rL_precision': 0.2826086956521739, 'rL_recall': 0.5064935064935064, 'rL_f1': 0.36279069767441857, 'bs_precision': 0.37731924653053284, 'bs_recall': 0.5953338742256165, 'bs_f1': 0.47907912731170654, 'bs_mnli_precision': 0.6649477481842041, 'bs_mnli_recall': 0.7924772500991821, 'bs_mnli_f1': 0.723132848739624, 'unique_bigram_ratio': 0.9398496240601504, 'nid': -0.24907113879904808, 'grammatical_errors': 0, 'pegasus_entailment': 0.4214101262390614, 'gold_entailment': 0.061859619338065386, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 190
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.39 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5257142857142857, 'r1_recall': 0.6388888888888888, 'r1_f1': 0.5768025078369905, 'r2_precision': 0.28160919540229884, 'r2_recall': 0.34265734265734266, 'r2_f1': 0.30914826498422715, 'rL_precision': 0.3485714285714286, 'rL_recall': 0.4236111111111111, 'rL_f1': 0.3824451410658307, 'bs_precision': 0.41963815689086914, 'bs_recall': 0.4694150984287262, 'bs_f1': 0.44593873620033264, 'bs_mnli_precision': 0.6952424049377441, 'bs_mnli_recall': 0.7203353643417358, 'bs_mnli_f1': 0.707566499710083, 'unique_bigram_ratio': 0.9476744186046512, 'nid': -0.2167704564137929, 'grammatical_errors': 2, 'pegasus_entailment': 0.500610813498497, 'gold_entailment': 0.26277305036783216, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 191
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.12 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.34810126582278483, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.47210300429184554, 'r2_precision': 0.17197452229299362, 'r2_recall': 0.36486486486486486, 'r2_f1': 0.23376623376623376, 'rL_precision': 0.26582278481012656, 'rL_recall': 0.56, 'rL_f1': 0.3605150214592275, 'bs_precision': 0.307697594165802, 'bs_recall': 0.529486358165741, 'bs_f1': 0.41075626015663147, 'bs_mnli_precision': 0.6434404850006104, 'bs_mnli_recall': 0.7674256563186646, 'bs_mnli_f1': 0.6999852657318115, 'unique_bigram_ratio': 0.9671052631578947, 'nid': -0.2278237627881492, 'grammatical_errors': 0, 'pegasus_entailment': 0.24855328910052776, 'gold_entailment': 0.33294159173965454, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 192
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.95 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.43434343434343436, 'r1_recall': 0.7107438016528925, 'r1_f1': 0.5391849529780565, 'r2_precision': 0.25888324873096447, 'r2_recall': 0.425, 'r2_f1': 0.3217665615141956, 'rL_precision': 0.3282828282828283, 'rL_recall': 0.5371900826446281, 'rL_f1': 0.40752351097178685, 'bs_precision': 0.40841877460479736, 'bs_recall': 0.5066528916358948, 'bs_f1': 0.45751893520355225, 'bs_mnli_precision': 0.6734378337860107, 'bs_mnli_recall': 0.7449352741241455, 'bs_mnli_f1': 0.7073845863342285, 'unique_bigram_ratio': 0.9473684210526315, 'nid': -0.21415674707593157, 'grammatical_errors': 2, 'pegasus_entailment': 0.6749456251660982, 'gold_entailment': 0.4929489865899086, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 193
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.76 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.36923076923076925, 'r1_recall': 0.6486486486486487, 'r1_f1': 0.47058823529411764, 'r2_precision': 0.18041237113402062, 'r2_recall': 0.3181818181818182, 'r2_f1': 0.23026315789473684, 'rL_precision': 0.23076923076923078, 'rL_recall': 0.40540540540540543, 'rL_f1': 0.29411764705882354, 'bs_precision': 0.30292001366615295, 'bs_recall': 0.4299090802669525, 'bs_f1': 0.36521679162979126, 'bs_mnli_precision': 0.6261447668075562, 'bs_mnli_recall': 0.6982831954956055, 'bs_mnli_f1': 0.6602493524551392, 'unique_bigram_ratio': 0.9629629629629629, 'nid': -0.2792610931621162, 'grammatical_errors': 1, 'pegasus_entailment': 0.8019681473573049, 'gold_entailment': 0.5156226853529612, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 194
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.16 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.39565217391304347, 'r1_recall': 0.558282208588957, 'r1_f1': 0.4631043256997455, 'r2_precision': 0.1222707423580786, 'r2_recall': 0.1728395061728395, 'r2_f1': 0.14322250639386186, 'rL_precision': 0.1826086956521739, 'rL_recall': 0.25766871165644173, 'rL_f1': 0.21374045801526717, 'bs_precision': 0.16184589266777039, 'bs_recall': 0.19426672160625458, 'bs_f1': 0.18060357868671417, 'bs_mnli_precision': 0.5527070760726929, 'bs_mnli_recall': 0.571530282497406, 'bs_mnli_f1': 0.5619611144065857, 'unique_bigram_ratio': 0.9429824561403509, 'nid': -0.22225643040001675, 'grammatical_errors': 6, 'pegasus_entailment': 0.45682562461921145, 'gold_entailment': 0.2782011019686858, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 195
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.59 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4859154929577465, 'r1_recall': 0.39204545454545453, 'r1_f1': 0.43396226415094336, 'r2_precision': 0.1276595744680851, 'r2_recall': 0.10285714285714286, 'r2_f1': 0.1139240506329114, 'rL_precision': 0.23943661971830985, 'rL_recall': 0.19318181818181818, 'rL_f1': 0.2138364779874214, 'bs_precision': 0.3081066608428955, 'bs_recall': 0.2362133413553238, 'bs_f1': 0.2734821140766144, 'bs_mnli_precision': 0.633313775062561, 'bs_mnli_recall': 0.5922078490257263, 'bs_mnli_f1': 0.6120714545249939, 'unique_bigram_ratio': 0.9705882352941176, 'nid': -0.2557804284661678, 'grammatical_errors': 3, 'pegasus_entailment': 0.26203512996435163, 'gold_entailment': 0.23377676432331404, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 196
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.67 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2557077625570776, 'r1_recall': 0.7, 'r1_f1': 0.3745819397993311, 'r2_precision': 0.16972477064220184, 'r2_recall': 0.46835443037974683, 'r2_f1': 0.2491582491582492, 'rL_precision': 0.1917808219178082, 'rL_recall': 0.525, 'rL_f1': 0.2809364548494983, 'bs_precision': 0.1813049167394638, 'bs_recall': 0.4987403154373169, 'bs_f1': 0.32081079483032227, 'bs_mnli_precision': 0.5824757814407349, 'bs_mnli_recall': 0.7378837466239929, 'bs_mnli_f1': 0.6510339379310608, 'unique_bigram_ratio': 0.9138755980861244, 'nid': -0.19800138115367627, 'grammatical_errors': 2, 'pegasus_entailment': 0.352354707462447, 'gold_entailment': 0.14650428046782812, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 197
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.08 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.18385650224215247, 'r1_recall': 0.6833333333333333, 'r1_f1': 0.28975265017667845, 'r2_precision': 0.05855855855855856, 'r2_recall': 0.22033898305084745, 'r2_f1': 0.09252669039145908, 'rL_precision': 0.1210762331838565, 'rL_recall': 0.45, 'rL_f1': 0.19081272084805656, 'bs_precision': 0.1876244992017746, 'bs_recall': 0.45198071002960205, 'bs_f1': 0.30697497725486755, 'bs_mnli_precision': 0.5488578081130981, 'bs_mnli_recall': 0.6920060515403748, 'bs_mnli_f1': 0.6121750473976135, 'unique_bigram_ratio': 0.9447004608294931, 'nid': -0.2439700311647348, 'grammatical_errors': 3, 'pegasus_entailment': 0.3531480520963669, 'gold_entailment': 0.19017131999135017, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 32, 'pegasus_smog': 25}
*** Analysing case 198
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.65 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.23976608187134502, 'r1_recall': 0.6833333333333333, 'r1_f1': 0.35497835497835495, 'r2_precision': 0.11764705882352941, 'r2_recall': 0.3389830508474576, 'r2_f1': 0.17467248908296942, 'rL_precision': 0.15204678362573099, 'rL_recall': 0.43333333333333335, 'rL_f1': 0.2251082251082251, 'bs_precision': 0.2778712511062622, 'bs_recall': 0.4786038398742676, 'bs_f1': 0.3720467686653137, 'bs_mnli_precision': 0.5988022089004517, 'bs_mnli_recall': 0.700161874294281, 'bs_mnli_f1': 0.6455274820327759, 'unique_bigram_ratio': 0.9404761904761905, 'nid': -0.22260550688023573, 'grammatical_errors': 1, 'pegasus_entailment': 0.6937332332134247, 'gold_entailment': 0.3803890347480774, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 199
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.02 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.33121019108280253, 'r1_recall': 0.5306122448979592, 'r1_f1': 0.4078431372549019, 'r2_precision': 0.11538461538461539, 'r2_recall': 0.18556701030927836, 'r2_f1': 0.14229249011857706, 'rL_precision': 0.17834394904458598, 'rL_recall': 0.2857142857142857, 'rL_f1': 0.2196078431372549, 'bs_precision': 0.23831070959568024, 'bs_recall': 0.3074781894683838, 'bs_f1': 0.2742954194545746, 'bs_mnli_precision': 0.576203465461731, 'bs_mnli_recall': 0.6469921469688416, 'bs_mnli_f1': 0.6095495223999023, 'unique_bigram_ratio': 0.9741935483870968, 'nid': -0.24281888371813976, 'grammatical_errors': 0, 'pegasus_entailment': 0.5375306059916815, 'gold_entailment': 0.3185114972293377, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 200
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.27 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3875, 'r1_recall': 0.7153846153846154, 'r1_f1': 0.5027027027027027, 'r2_precision': 0.200836820083682, 'r2_recall': 0.37209302325581395, 'r2_f1': 0.2608695652173913, 'rL_precision': 0.2708333333333333, 'rL_recall': 0.5, 'rL_f1': 0.35135135135135137, 'bs_precision': 0.3126983940601349, 'bs_recall': 0.46351808309555054, 'bs_f1': 0.38554152846336365, 'bs_mnli_precision': 0.6445812582969666, 'bs_mnli_recall': 0.7330653667449951, 'bs_mnli_f1': 0.6859816908836365, 'unique_bigram_ratio': 0.9529914529914529, 'nid': -0.24806589156488856, 'grammatical_errors': 3, 'pegasus_entailment': 0.586598025900977, 'gold_entailment': 0.42710655967571903, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 201
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.73 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.17560975609756097, 'r1_recall': 0.782608695652174, 'r1_f1': 0.28685258964143423, 'r2_precision': 0.09803921568627451, 'r2_recall': 0.4444444444444444, 'r2_f1': 0.1606425702811245, 'rL_precision': 0.13658536585365855, 'rL_recall': 0.6086956521739131, 'rL_f1': 0.22310756972111556, 'bs_precision': 0.2142581045627594, 'bs_recall': 0.6090670824050903, 'bs_f1': 0.38238534331321716, 'bs_mnli_precision': 0.5471951961517334, 'bs_mnli_recall': 0.7894873023033142, 'bs_mnli_f1': 0.6463817954063416, 'unique_bigram_ratio': 0.94, 'nid': -0.23611853258068205, 'grammatical_errors': 0, 'pegasus_entailment': 0.36480926296540667, 'gold_entailment': 0.4935446009039879, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 202
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.58 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3711340206185567, 'r1_recall': 0.631578947368421, 'r1_f1': 0.4675324675324675, 'r2_precision': 0.19170984455958548, 'r2_recall': 0.3274336283185841, 'r2_f1': 0.24183006535947713, 'rL_precision': 0.23711340206185566, 'rL_recall': 0.40350877192982454, 'rL_f1': 0.2987012987012987, 'bs_precision': 0.3373403549194336, 'bs_recall': 0.46936437487602234, 'bs_f1': 0.4018656015396118, 'bs_mnli_precision': 0.6567174792289734, 'bs_mnli_recall': 0.7126204967498779, 'bs_mnli_f1': 0.6835278272628784, 'unique_bigram_ratio': 0.9456521739130435, 'nid': -0.2609335300963045, 'grammatical_errors': 2, 'pegasus_entailment': 0.3037778687264238, 'gold_entailment': 0.4602645840495825, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 203
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.56 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3767123287671233, 'r1_recall': 0.4954954954954955, 'r1_f1': 0.4280155642023346, 'r2_precision': 0.19310344827586207, 'r2_recall': 0.2545454545454545, 'r2_f1': 0.21960784313725487, 'rL_precision': 0.2602739726027397, 'rL_recall': 0.34234234234234234, 'rL_f1': 0.29571984435797666, 'bs_precision': 0.3685060143470764, 'bs_recall': 0.29912322759628296, 'bs_f1': 0.33506354689598083, 'bs_mnli_precision': 0.6495379209518433, 'bs_mnli_recall': 0.6356567740440369, 'bs_mnli_f1': 0.6425224542617798, 'unique_bigram_ratio': 0.9645390070921985, 'nid': -0.24245730420204104, 'grammatical_errors': 1, 'pegasus_entailment': 0.42821724712848663, 'gold_entailment': 0.33602030628493856, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 204
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.62 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.365296803652968, 'r1_f1': 0.4407713498622589, 'r2_precision': 0.1888111888111888, 'r2_recall': 0.12385321100917432, 'r2_f1': 0.14958448753462605, 'rL_precision': 0.3055555555555556, 'rL_recall': 0.2009132420091324, 'rL_f1': 0.24242424242424243, 'bs_precision': 0.3481449782848358, 'bs_recall': 0.23725156486034393, 'bs_f1': 0.2923916280269623, 'bs_mnli_precision': 0.6429028511047363, 'bs_mnli_recall': 0.583349883556366, 'bs_mnli_f1': 0.611680269241333, 'unique_bigram_ratio': 0.9712230215827338, 'nid': -0.25242934650462123, 'grammatical_errors': 1, 'pegasus_entailment': 0.19356261938810349, 'gold_entailment': 0.265766279771924, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 205
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.16 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3618421052631579, 'r1_recall': 0.6707317073170732, 'r1_f1': 0.47008547008547014, 'r2_precision': 0.1986754966887417, 'r2_recall': 0.37037037037037035, 'r2_f1': 0.25862068965517243, 'rL_precision': 0.29605263157894735, 'rL_recall': 0.5487804878048781, 'rL_f1': 0.3846153846153846, 'bs_precision': 0.38156285881996155, 'bs_recall': 0.5372466444969177, 'bs_f1': 0.4565637707710266, 'bs_mnli_precision': 0.6671925187110901, 'bs_mnli_recall': 0.7697360515594482, 'bs_mnli_f1': 0.7148054242134094, 'unique_bigram_ratio': 0.952054794520548, 'nid': -0.26079706330860564, 'grammatical_errors': 2, 'pegasus_entailment': 0.4383205386499564, 'gold_entailment': 0.11239153542555869, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 206
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.21 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.23893805309734514, 'r1_recall': 0.6136363636363636, 'r1_f1': 0.34394904458598724, 'r2_precision': 0.07111111111111111, 'r2_recall': 0.1839080459770115, 'r2_f1': 0.10256410256410256, 'rL_precision': 0.13274336283185842, 'rL_recall': 0.3409090909090909, 'rL_f1': 0.19108280254777069, 'bs_precision': 0.1880740374326706, 'bs_recall': 0.3487294614315033, 'bs_f1': 0.26504090428352356, 'bs_mnli_precision': 0.5436525344848633, 'bs_mnli_recall': 0.6587903499603271, 'bs_mnli_f1': 0.5957090258598328, 'unique_bigram_ratio': 0.9140271493212669, 'nid': -0.2342497553656735, 'grammatical_errors': 5, 'pegasus_entailment': 0.5332217539350191, 'gold_entailment': 0.35337280854582787, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 207
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.64 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.37333333333333335, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.4462151394422311, 'r2_precision': 0.12080536912751678, 'r2_recall': 0.18, 'r2_f1': 0.14457831325301204, 'rL_precision': 0.22, 'rL_recall': 0.32673267326732675, 'rL_f1': 0.26294820717131473, 'bs_precision': 0.23811250925064087, 'bs_recall': 0.3573682904243469, 'bs_f1': 0.2969934940338135, 'bs_mnli_precision': 0.5946834087371826, 'bs_mnli_recall': 0.6790751218795776, 'bs_mnli_f1': 0.63408362865448, 'unique_bigram_ratio': 0.9659863945578231, 'nid': -0.2812025342252773, 'grammatical_errors': 1, 'pegasus_entailment': 0.43685925006866455, 'gold_entailment': 0.12240819819271564, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 208
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.68 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3581081081081081, 'r1_recall': 0.49074074074074076, 'r1_f1': 0.41406250000000006, 'r2_precision': 0.11564625850340136, 'r2_recall': 0.1588785046728972, 'r2_f1': 0.13385826771653545, 'rL_precision': 0.2635135135135135, 'rL_recall': 0.3611111111111111, 'rL_f1': 0.3046875, 'bs_precision': 0.3140510022640228, 'bs_recall': 0.3810923397541046, 'bs_f1': 0.3488475978374481, 'bs_mnli_precision': 0.6318644881248474, 'bs_mnli_recall': 0.6882437467575073, 'bs_mnli_f1': 0.6588501930236816, 'unique_bigram_ratio': 0.9366197183098591, 'nid': -0.23190194009958964, 'grammatical_errors': 2, 'pegasus_entailment': 0.3703639085094134, 'gold_entailment': 0.28246343849847716, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 209
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.08 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.14583333333333334, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.23333333333333336, 'r2_precision': 0.041884816753926704, 'r2_recall': 0.1702127659574468, 'r2_f1': 0.06722689075630252, 'rL_precision': 0.10416666666666667, 'rL_recall': 0.4166666666666667, 'rL_f1': 0.16666666666666669, 'bs_precision': 0.03715434670448303, 'bs_recall': 0.2644290030002594, 'bs_f1': 0.14056244492530823, 'bs_mnli_precision': 0.48298758268356323, 'bs_mnli_recall': 0.596878170967102, 'bs_mnli_f1': 0.5339270234107971, 'unique_bigram_ratio': 0.9042553191489362, 'nid': -0.18933084714081994, 'grammatical_errors': 1, 'pegasus_entailment': 0.6441224416097006, 'gold_entailment': 0.5491272881627083, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 210
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.49 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3372093023255814, 'r1_recall': 0.5858585858585859, 'r1_f1': 0.42804428044280446, 'r2_precision': 0.15789473684210525, 'r2_recall': 0.2755102040816326, 'r2_f1': 0.2007434944237918, 'rL_precision': 0.26744186046511625, 'rL_recall': 0.46464646464646464, 'rL_f1': 0.33948339483394835, 'bs_precision': 0.2838224768638611, 'bs_recall': 0.45591628551483154, 'bs_f1': 0.365867018699646, 'bs_mnli_precision': 0.6211732029914856, 'bs_mnli_recall': 0.7159708738327026, 'bs_mnli_f1': 0.6652116775512695, 'unique_bigram_ratio': 0.9636363636363636, 'nid': -0.2541587384126329, 'grammatical_errors': 1, 'pegasus_entailment': 0.4935417132718222, 'gold_entailment': 0.3202972158789635, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 211
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.79 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3953488372093023, 'r1_recall': 0.5379746835443038, 'r1_f1': 0.4557640750670241, 'r2_precision': 0.14485981308411214, 'r2_recall': 0.19745222929936307, 'r2_f1': 0.16711590296495954, 'rL_precision': 0.20930232558139536, 'rL_recall': 0.2848101265822785, 'rL_f1': 0.2412868632707775, 'bs_precision': 0.3382519483566284, 'bs_recall': 0.3585066497325897, 'bs_f1': 0.35051843523979187, 'bs_mnli_precision': 0.664371907711029, 'bs_mnli_recall': 0.6505420207977295, 'bs_mnli_f1': 0.6573842167854309, 'unique_bigram_ratio': 0.9154929577464789, 'nid': -0.1897218785356285, 'grammatical_errors': 3, 'pegasus_entailment': 0.5546539649367332, 'gold_entailment': 0.260837584733963, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 212
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.87 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4008810572687225, 'r1_recall': 0.5759493670886076, 'r1_f1': 0.4727272727272727, 'r2_precision': 0.1592920353982301, 'r2_recall': 0.22929936305732485, 'r2_f1': 0.18798955613577026, 'rL_precision': 0.1894273127753304, 'rL_recall': 0.2721518987341772, 'rL_f1': 0.22337662337662337, 'bs_precision': 0.2469024956226349, 'bs_recall': 0.2770636975765228, 'bs_f1': 0.26429611444473267, 'bs_mnli_precision': 0.6160801649093628, 'bs_mnli_recall': 0.6163468956947327, 'bs_mnli_f1': 0.6162135004997253, 'unique_bigram_ratio': 0.9144144144144144, 'nid': -0.21056043206574993, 'grammatical_errors': 8, 'pegasus_entailment': 0.22841115705668927, 'gold_entailment': 0.10342179648578168, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 213
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.80 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5766423357664233, 'r1_recall': 0.40932642487046633, 'r1_f1': 0.47878787878787876, 'r2_precision': 0.17647058823529413, 'r2_recall': 0.125, 'r2_f1': 0.14634146341463414, 'rL_precision': 0.32116788321167883, 'rL_recall': 0.22797927461139897, 'rL_f1': 0.26666666666666666, 'bs_precision': 0.3183239996433258, 'bs_recall': 0.24935488402843475, 'bs_f1': 0.2852259576320648, 'bs_mnli_precision': 0.6678992509841919, 'bs_mnli_recall': 0.6112884283065796, 'bs_mnli_f1': 0.6383411884307861, 'unique_bigram_ratio': 0.9185185185185185, 'nid': -0.22679901620694798, 'grammatical_errors': 0, 'pegasus_entailment': 0.5794180759361812, 'gold_entailment': 0.5066506548060311, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 214
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.34 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4715447154471545, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5087719298245614, 'r2_precision': 0.2540983606557377, 'r2_recall': 0.2980769230769231, 'r2_f1': 0.2743362831858407, 'rL_precision': 0.3902439024390244, 'rL_recall': 0.45714285714285713, 'rL_f1': 0.42105263157894735, 'bs_precision': 0.42539194226264954, 'bs_recall': 0.4328855276107788, 'bs_f1': 0.4310780465602875, 'bs_mnli_precision': 0.6944662928581238, 'bs_mnli_recall': 0.7003653049468994, 'bs_mnli_f1': 0.6974033117294312, 'unique_bigram_ratio': 0.9743589743589743, 'nid': -0.2632169056951066, 'grammatical_errors': 2, 'pegasus_entailment': 0.7193892076611519, 'gold_entailment': 0.6515191694100698, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 24}
*** Analysing case 215
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.30 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3588516746411483, 'r1_recall': 0.6, 'r1_f1': 0.4491017964071856, 'r2_precision': 0.10576923076923077, 'r2_recall': 0.1774193548387097, 'r2_f1': 0.1325301204819277, 'rL_precision': 0.19617224880382775, 'rL_recall': 0.328, 'rL_f1': 0.2455089820359282, 'bs_precision': 0.3095659613609314, 'bs_recall': 0.3871457874774933, 'bs_f1': 0.34930703043937683, 'bs_mnli_precision': 0.6256445646286011, 'bs_mnli_recall': 0.6829953193664551, 'bs_mnli_f1': 0.6530632376670837, 'unique_bigram_ratio': 0.9595959595959596, 'nid': -0.25466828322416335, 'grammatical_errors': 3, 'pegasus_entailment': 0.3024241756647825, 'gold_entailment': 0.17858117930591105, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 216
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.24 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.15584415584415584, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.254416961130742, 'r2_precision': 0.030434782608695653, 'r2_recall': 0.13725490196078433, 'r2_f1': 0.04982206405693951, 'rL_precision': 0.09523809523809523, 'rL_recall': 0.4230769230769231, 'rL_f1': 0.15547703180212014, 'bs_precision': 0.06023404002189636, 'bs_recall': 0.3385644555091858, 'bs_f1': 0.1833748072385788, 'bs_mnli_precision': 0.5211880207061768, 'bs_mnli_recall': 0.6681819558143616, 'bs_mnli_f1': 0.5856015086174011, 'unique_bigram_ratio': 0.9298245614035088, 'nid': -0.2047031474781209, 'grammatical_errors': 2, 'pegasus_entailment': 0.46235957162247765, 'gold_entailment': 0.32955028613408405, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 217
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 67.91 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2706766917293233, 'r1_recall': 0.5901639344262295, 'r1_f1': 0.3711340206185567, 'r2_precision': 0.07575757575757576, 'r2_recall': 0.16666666666666666, 'r2_f1': 0.10416666666666666, 'rL_precision': 0.16541353383458646, 'rL_recall': 0.36065573770491804, 'rL_f1': 0.22680412371134018, 'bs_precision': 0.2435375154018402, 'bs_recall': 0.3689790666103363, 'bs_f1': 0.30517369508743286, 'bs_mnli_precision': 0.5860260725021362, 'bs_mnli_recall': 0.6700426340103149, 'bs_mnli_f1': 0.6252245306968689, 'unique_bigram_ratio': 0.9689922480620154, 'nid': -0.25886714687711176, 'grammatical_errors': 2, 'pegasus_entailment': 0.54944708943367, 'gold_entailment': 0.3470381249984105, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 218
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 72.24 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2923076923076923, 'r1_recall': 0.6129032258064516, 'r1_f1': 0.39583333333333337, 'r2_precision': 0.11627906976744186, 'r2_recall': 0.2459016393442623, 'r2_f1': 0.15789473684210525, 'rL_precision': 0.18461538461538463, 'rL_recall': 0.3870967741935484, 'rL_f1': 0.25, 'bs_precision': 0.3228365182876587, 'bs_recall': 0.4539755582809448, 'bs_f1': 0.3869747221469879, 'bs_mnli_precision': 0.6178991794586182, 'bs_mnli_recall': 0.6833027601242065, 'bs_mnli_f1': 0.6489572525024414, 'unique_bigram_ratio': 0.9609375, 'nid': -0.25105077809965226, 'grammatical_errors': 0, 'pegasus_entailment': 0.5733364969491959, 'gold_entailment': 0.37772065959870815, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 219
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.05 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.21428571428571427, 'r1_recall': 0.559322033898305, 'r1_f1': 0.30985915492957744, 'r2_precision': 0.058823529411764705, 'r2_recall': 0.15517241379310345, 'r2_f1': 0.08530805687203792, 'rL_precision': 0.11688311688311688, 'rL_recall': 0.3050847457627119, 'rL_f1': 0.16901408450704225, 'bs_precision': 0.2424747198820114, 'bs_recall': 0.4208953082561493, 'bs_f1': 0.327134907245636, 'bs_mnli_precision': 0.5660861730575562, 'bs_mnli_recall': 0.6506761312484741, 'bs_mnli_f1': 0.6054407954216003, 'unique_bigram_ratio': 0.9276315789473685, 'nid': -0.22572343141669404, 'grammatical_errors': 0, 'pegasus_entailment': 0.5146837743620077, 'gold_entailment': 0.39488983899354935, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 220
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.85 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3630573248407643, 'r1_recall': 0.5, 'r1_f1': 0.42066420664206644, 'r2_precision': 0.1346153846153846, 'r2_recall': 0.18584070796460178, 'r2_f1': 0.15613382899628253, 'rL_precision': 0.1910828025477707, 'rL_recall': 0.2631578947368421, 'rL_f1': 0.22140221402214022, 'bs_precision': 0.22711610794067383, 'bs_recall': 0.29132452607154846, 'bs_f1': 0.26080596446990967, 'bs_mnli_precision': 0.5981645584106445, 'bs_mnli_recall': 0.6110745668411255, 'bs_mnli_f1': 0.6045506596565247, 'unique_bigram_ratio': 0.9548387096774194, 'nid': -0.2493705549901175, 'grammatical_errors': 3, 'pegasus_entailment': 0.5848046143849691, 'gold_entailment': 0.32857729991277057, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 221
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.66 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.23195876288659795, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.30716723549488056, 'r2_precision': 0.09844559585492228, 'r2_recall': 0.19387755102040816, 'r2_f1': 0.13058419243986252, 'rL_precision': 0.15463917525773196, 'rL_recall': 0.30303030303030304, 'rL_f1': 0.20477815699658702, 'bs_precision': 0.22540678083896637, 'bs_recall': 0.36223527789115906, 'bs_f1': 0.2920782268047333, 'bs_mnli_precision': 0.5752443075180054, 'bs_mnli_recall': 0.6383377313613892, 'bs_mnli_f1': 0.6051508784294128, 'unique_bigram_ratio': 0.9267015706806283, 'nid': -0.21186703035256826, 'grammatical_errors': 1, 'pegasus_entailment': 0.37899189349263906, 'gold_entailment': 0.24489756176869074, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 222
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 67.61 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.16339869281045752, 'r1_recall': 0.625, 'r1_f1': 0.25906735751295334, 'r2_precision': 0.07236842105263158, 'r2_recall': 0.28205128205128205, 'r2_f1': 0.11518324607329844, 'rL_precision': 0.08496732026143791, 'rL_recall': 0.325, 'rL_f1': 0.13471502590673576, 'bs_precision': 0.1269979327917099, 'bs_recall': 0.40227532386779785, 'bs_f1': 0.24989226460456848, 'bs_mnli_precision': 0.5295525193214417, 'bs_mnli_recall': 0.6918262243270874, 'bs_mnli_f1': 0.5999094247817993, 'unique_bigram_ratio': 0.9337748344370861, 'nid': -0.22777931815735641, 'grammatical_errors': 1, 'pegasus_entailment': 0.6768022745847702, 'gold_entailment': 0.7223065793514252, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 223
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.81 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.592, 'r1_recall': 0.4277456647398844, 'r1_f1': 0.4966442953020134, 'r2_precision': 0.25, 'r2_recall': 0.18023255813953487, 'r2_f1': 0.20945945945945946, 'rL_precision': 0.408, 'rL_recall': 0.2947976878612717, 'rL_f1': 0.34228187919463093, 'bs_precision': 0.5007354021072388, 'bs_recall': 0.3459209203720093, 'bs_f1': 0.42054083943367004, 'bs_mnli_precision': 0.7325162291526794, 'bs_mnli_recall': 0.6474164724349976, 'bs_mnli_f1': 0.6873423457145691, 'unique_bigram_ratio': 0.9586776859504132, 'nid': -0.2593036856558577, 'grammatical_errors': 0, 'pegasus_entailment': 0.41256852944691974, 'gold_entailment': 0.21222790330648422, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 224
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 70.24 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4365079365079365, 'r1_recall': 0.6875, 'r1_f1': 0.5339805825242718, 'r2_precision': 0.264, 'r2_recall': 0.4177215189873418, 'r2_f1': 0.3235294117647059, 'rL_precision': 0.35714285714285715, 'rL_recall': 0.5625, 'rL_f1': 0.4368932038834951, 'bs_precision': 0.416638046503067, 'bs_recall': 0.5852112770080566, 'bs_f1': 0.4973054528236389, 'bs_mnli_precision': 0.6870964765548706, 'bs_mnli_recall': 0.7888186573982239, 'bs_mnli_f1': 0.7344521284103394, 'unique_bigram_ratio': 0.9516129032258065, 'nid': -0.22731974592396265, 'grammatical_errors': 2, 'pegasus_entailment': 0.36645888686180117, 'gold_entailment': 0.14630531426519156, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 225
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.33 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.55625, 'r1_recall': 0.5, 'r1_f1': 0.5266272189349113, 'r2_precision': 0.23270440251572327, 'r2_recall': 0.20903954802259886, 'r2_f1': 0.22023809523809523, 'rL_precision': 0.30625, 'rL_recall': 0.2752808988764045, 'rL_f1': 0.2899408284023669, 'bs_precision': 0.4096779227256775, 'bs_recall': 0.38003435730934143, 'bs_f1': 0.3967464864253998, 'bs_mnli_precision': 0.6698576211929321, 'bs_mnli_recall': 0.664685845375061, 'bs_mnli_f1': 0.6672617197036743, 'unique_bigram_ratio': 0.9607843137254902, 'nid': -0.2321222896609867, 'grammatical_errors': 0, 'pegasus_entailment': 0.4042622574738094, 'gold_entailment': 0.4055493488907814, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 226
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.64 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5359116022099447, 'r1_recall': 0.6024844720496895, 'r1_f1': 0.5672514619883041, 'r2_precision': 0.22777777777777777, 'r2_recall': 0.25625, 'r2_f1': 0.2411764705882353, 'rL_precision': 0.30939226519337015, 'rL_recall': 0.34782608695652173, 'rL_f1': 0.32748538011695905, 'bs_precision': 0.3019134998321533, 'bs_recall': 0.36210939288139343, 'bs_f1': 0.3335148096084595, 'bs_mnli_precision': 0.6297612190246582, 'bs_mnli_recall': 0.6733213067054749, 'bs_mnli_f1': 0.6508132219314575, 'unique_bigram_ratio': 0.9602272727272727, 'nid': -0.21866013982740085, 'grammatical_errors': 0, 'pegasus_entailment': 0.35616421699523926, 'gold_entailment': 0.26805658106292996, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 227
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.50 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.40559440559440557, 'r1_recall': 0.43283582089552236, 'r1_f1': 0.41877256317689526, 'r2_precision': 0.1619718309859155, 'r2_recall': 0.17293233082706766, 'r2_f1': 0.16727272727272727, 'rL_precision': 0.3006993006993007, 'rL_recall': 0.3208955223880597, 'rL_f1': 0.31046931407942235, 'bs_precision': 0.33191370964050293, 'bs_recall': 0.33128851652145386, 'bs_f1': 0.33388519287109375, 'bs_mnli_precision': 0.6599248647689819, 'bs_mnli_recall': 0.6414982080459595, 'bs_mnli_f1': 0.6505810618400574, 'unique_bigram_ratio': 0.948905109489051, 'nid': -0.22306507481692273, 'grammatical_errors': 2, 'pegasus_entailment': 0.6110925922791163, 'gold_entailment': 0.6283396542072296, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 228
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.13 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.564935064935065, 'r1_recall': 0.35802469135802467, 'r1_f1': 0.43828715365239296, 'r2_precision': 0.24836601307189543, 'r2_recall': 0.15702479338842976, 'r2_f1': 0.1924050632911392, 'rL_precision': 0.35714285714285715, 'rL_recall': 0.22633744855967078, 'rL_f1': 0.2770780856423174, 'bs_precision': 0.3368959426879883, 'bs_recall': 0.25019946694374084, 'bs_f1': 0.29429903626441956, 'bs_mnli_precision': 0.6529091596603394, 'bs_mnli_recall': 0.5832501649856567, 'bs_mnli_f1': 0.6161169409751892, 'unique_bigram_ratio': 0.9657534246575342, 'nid': -0.23336452757893, 'grammatical_errors': 3, 'pegasus_entailment': 0.515162970471595, 'gold_entailment': 0.16753706485033035, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 229
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 80.34 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4888888888888889, 'r1_recall': 0.5365853658536586, 'r1_f1': 0.5116279069767442, 'r2_precision': 0.2247191011235955, 'r2_recall': 0.24691358024691357, 'r2_f1': 0.23529411764705882, 'rL_precision': 0.32222222222222224, 'rL_recall': 0.35365853658536583, 'rL_f1': 0.3372093023255814, 'bs_precision': 0.40802881121635437, 'bs_recall': 0.421718955039978, 'bs_f1': 0.416835218667984, 'bs_mnli_precision': 0.6938998103141785, 'bs_mnli_recall': 0.6943222880363464, 'bs_mnli_f1': 0.6941109895706177, 'unique_bigram_ratio': 0.9651162790697675, 'nid': -0.34395329022554244, 'grammatical_errors': 3, 'pegasus_entailment': 0.3043046295642853, 'gold_entailment': 0.5218499600887299, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 230
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.65 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4662576687116564, 'r1_recall': 0.5, 'r1_f1': 0.48253968253968255, 'r2_precision': 0.1728395061728395, 'r2_recall': 0.18543046357615894, 'r2_f1': 0.17891373801916932, 'rL_precision': 0.26993865030674846, 'rL_recall': 0.2894736842105263, 'rL_f1': 0.27936507936507937, 'bs_precision': 0.27517932653427124, 'bs_recall': 0.2582424283027649, 'bs_f1': 0.2691521644592285, 'bs_mnli_precision': 0.6245789527893066, 'bs_mnli_recall': 0.6082113981246948, 'bs_mnli_f1': 0.6162865161895752, 'unique_bigram_ratio': 0.9620253164556962, 'nid': -0.2242808143258228, 'grammatical_errors': 2, 'pegasus_entailment': 0.4795345216989517, 'gold_entailment': 0.1884281449019909, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 231
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.96 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.20348837209302326, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.2868852459016394, 'r2_precision': 0.04093567251461988, 'r2_recall': 0.09859154929577464, 'r2_f1': 0.05785123966942149, 'rL_precision': 0.14534883720930233, 'rL_recall': 0.3472222222222222, 'rL_f1': 0.20491803278688525, 'bs_precision': 0.13527904450893402, 'bs_recall': 0.272786021232605, 'bs_f1': 0.2021905928850174, 'bs_mnli_precision': 0.5446051955223083, 'bs_mnli_recall': 0.6394068002700806, 'bs_mnli_f1': 0.5882107019424438, 'unique_bigram_ratio': 0.9518072289156626, 'nid': -0.2524042794061776, 'grammatical_errors': 1, 'pegasus_entailment': 0.4274503712852796, 'gold_entailment': 0.22858014181256295, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 232
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.63 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5369127516778524, 'r1_recall': 0.35874439461883406, 'r1_f1': 0.4301075268817204, 'r2_precision': 0.20270270270270271, 'r2_recall': 0.13513513513513514, 'r2_f1': 0.16216216216216217, 'rL_precision': 0.3221476510067114, 'rL_recall': 0.21524663677130046, 'rL_f1': 0.2580645161290323, 'bs_precision': 0.3416268527507782, 'bs_recall': 0.23759301006793976, 'bs_f1': 0.28963398933410645, 'bs_mnli_precision': 0.6637977361679077, 'bs_mnli_recall': 0.6159005165100098, 'bs_mnli_f1': 0.6389527320861816, 'unique_bigram_ratio': 0.9517241379310345, 'nid': -0.2782890082800098, 'grammatical_errors': 1, 'pegasus_entailment': 0.4040938034653664, 'gold_entailment': 0.18157018484039741, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 233
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.20 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.17372881355932204, 'r1_recall': 0.36283185840707965, 'r1_f1': 0.23495702005730662, 'r2_precision': 0.03829787234042553, 'r2_recall': 0.08035714285714286, 'r2_f1': 0.05187319884726225, 'rL_precision': 0.0847457627118644, 'rL_recall': 0.17699115044247787, 'rL_f1': 0.11461318051575932, 'bs_precision': 0.11111823469400406, 'bs_recall': 0.10232003778219223, 'bs_f1': 0.10975168645381927, 'bs_mnli_precision': 0.5193026065826416, 'bs_mnli_recall': 0.5301294326782227, 'bs_mnli_f1': 0.5246601700782776, 'unique_bigram_ratio': 0.9696969696969697, 'nid': -0.26981711228180383, 'grammatical_errors': 1, 'pegasus_entailment': 0.5945230941288173, 'gold_entailment': 0.20482175331562757, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 234
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.29 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.22641509433962265, 'r1_recall': 0.782608695652174, 'r1_f1': 0.35121951219512193, 'r2_precision': 0.15822784810126583, 'r2_recall': 0.5555555555555556, 'r2_f1': 0.24630541871921185, 'rL_precision': 0.15723270440251572, 'rL_recall': 0.5434782608695652, 'rL_f1': 0.24390243902439024, 'bs_precision': 0.18477199971675873, 'bs_recall': 0.5672847628593445, 'bs_f1': 0.347923219203949, 'bs_mnli_precision': 0.559333324432373, 'bs_mnli_recall': 0.7997580766677856, 'bs_mnli_f1': 0.6582800149917603, 'unique_bigram_ratio': 0.9487179487179487, 'nid': -0.2560470541003075, 'grammatical_errors': 5, 'pegasus_entailment': 0.6088138073682785, 'gold_entailment': 0.1907833106815815, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 235
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 44.20 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5129310344827587, 'r1_recall': 0.6574585635359116, 'r1_f1': 0.576271186440678, 'r2_precision': 0.19913419913419914, 'r2_recall': 0.25555555555555554, 'r2_f1': 0.2238442822384428, 'rL_precision': 0.25, 'rL_recall': 0.32044198895027626, 'rL_f1': 0.28087167070217917, 'bs_precision': 0.3197876513004303, 'bs_recall': 0.35499730706214905, 'bs_f1': 0.3393907845020294, 'bs_mnli_precision': 0.6592295169830322, 'bs_mnli_recall': 0.6749904155731201, 'bs_mnli_f1': 0.6670169234275818, 'unique_bigram_ratio': 0.9254385964912281, 'nid': -0.18847275803942187, 'grammatical_errors': 5, 'pegasus_entailment': 0.4879535867108239, 'gold_entailment': 0.39374553319066763, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 236
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.62 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.42660550458715596, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.4708860759493671, 'r2_precision': 0.15207373271889402, 'r2_recall': 0.1875, 'r2_f1': 0.16793893129770993, 'rL_precision': 0.22477064220183487, 'rL_recall': 0.2768361581920904, 'rL_f1': 0.24810126582278483, 'bs_precision': 0.3003251552581787, 'bs_recall': 0.3203652501106262, 'bs_f1': 0.312613308429718, 'bs_mnli_precision': 0.6187622547149658, 'bs_mnli_recall': 0.6336656212806702, 'bs_mnli_f1': 0.6261253356933594, 'unique_bigram_ratio': 0.92018779342723, 'nid': -0.20133670878188226, 'grammatical_errors': 2, 'pegasus_entailment': 0.3118076757527888, 'gold_entailment': 0.08394635021686554, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 237
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.18 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.423841059602649, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5182186234817814, 'r2_precision': 0.26, 'r2_recall': 0.4105263157894737, 'r2_f1': 0.31836734693877555, 'rL_precision': 0.304635761589404, 'rL_recall': 0.4791666666666667, 'rL_f1': 0.3724696356275303, 'bs_precision': 0.3530372381210327, 'bs_recall': 0.4767957627773285, 'bs_f1': 0.4138464331626892, 'bs_mnli_precision': 0.6654704809188843, 'bs_mnli_recall': 0.7454063892364502, 'bs_mnli_f1': 0.7031739950180054, 'unique_bigram_ratio': 0.9727891156462585, 'nid': -0.25321241536327666, 'grammatical_errors': 0, 'pegasus_entailment': 0.3157348304986954, 'gold_entailment': 0.28760173730552197, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 238
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.12 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5103448275862069, 'r1_recall': 0.5103448275862069, 'r1_f1': 0.5103448275862069, 'r2_precision': 0.1875, 'r2_recall': 0.1875, 'r2_f1': 0.1875, 'rL_precision': 0.30344827586206896, 'rL_recall': 0.30344827586206896, 'rL_f1': 0.30344827586206896, 'bs_precision': 0.3205413222312927, 'bs_recall': 0.3781434893608093, 'bs_f1': 0.35086262226104736, 'bs_mnli_precision': 0.6575956344604492, 'bs_mnli_recall': 0.6901758909225464, 'bs_mnli_f1': 0.6734919548034668, 'unique_bigram_ratio': 0.971830985915493, 'nid': -0.27182110206332233, 'grammatical_errors': 1, 'pegasus_entailment': 0.4902330736319224, 'gold_entailment': 0.4458471898521696, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 239
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 74.99 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.12403100775193798, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.20382165605095542, 'r2_precision': 0.046875, 'r2_recall': 0.2222222222222222, 'r2_f1': 0.07741935483870968, 'rL_precision': 0.11627906976744186, 'rL_recall': 0.5357142857142857, 'rL_f1': 0.1910828025477707, 'bs_precision': 0.13490718603134155, 'bs_recall': 0.447439044713974, 'bs_f1': 0.2718793451786041, 'bs_mnli_precision': 0.545058012008667, 'bs_mnli_recall': 0.7257818579673767, 'bs_mnli_f1': 0.622569739818573, 'unique_bigram_ratio': 0.975609756097561, 'nid': -0.23493577885500216, 'grammatical_errors': 1, 'pegasus_entailment': 0.7414476573467255, 'gold_entailment': 0.3934065252542496, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 240
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 73.13 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.21311475409836064, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.28888888888888886, 'r2_precision': 0.08264462809917356, 'r2_recall': 0.17543859649122806, 'r2_f1': 0.11235955056179775, 'rL_precision': 0.14754098360655737, 'rL_recall': 0.3103448275862069, 'rL_f1': 0.2, 'bs_precision': 0.16913533210754395, 'bs_recall': 0.3379431962966919, 'bs_f1': 0.24953100085258484, 'bs_mnli_precision': 0.5498366951942444, 'bs_mnli_recall': 0.636436939239502, 'bs_mnli_f1': 0.589975893497467, 'unique_bigram_ratio': 0.9830508474576272, 'nid': -0.2748010576902924, 'grammatical_errors': 0, 'pegasus_entailment': 0.372206615904967, 'gold_entailment': 0.22212692396715283, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 241
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 69.61 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5703125, 'r1_recall': 0.6134453781512605, 'r1_f1': 0.5910931174089069, 'r2_precision': 0.2677165354330709, 'r2_recall': 0.288135593220339, 'r2_f1': 0.27755102040816326, 'rL_precision': 0.4296875, 'rL_recall': 0.46218487394957986, 'rL_f1': 0.4453441295546559, 'bs_precision': 0.5176137089729309, 'bs_recall': 0.5213462710380554, 'bs_f1': 0.5211194157600403, 'bs_mnli_precision': 0.7211431264877319, 'bs_mnli_recall': 0.733269989490509, 'bs_mnli_f1': 0.7271559834480286, 'unique_bigram_ratio': 0.9669421487603306, 'nid': -0.26679460902049956, 'grammatical_errors': 2, 'pegasus_entailment': 0.5526097388938069, 'gold_entailment': 0.45732443034648895, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 242
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.38 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.23529411764705882, 'r1_recall': 0.7323943661971831, 'r1_f1': 0.3561643835616438, 'r2_precision': 0.08636363636363636, 'r2_recall': 0.2714285714285714, 'r2_f1': 0.1310344827586207, 'rL_precision': 0.15384615384615385, 'rL_recall': 0.4788732394366197, 'rL_f1': 0.23287671232876714, 'bs_precision': 0.2283896505832672, 'bs_recall': 0.5438866019248962, 'bs_f1': 0.36783429980278015, 'bs_mnli_precision': 0.5849835872650146, 'bs_mnli_recall': 0.735849142074585, 'bs_mnli_f1': 0.6518004536628723, 'unique_bigram_ratio': 0.9124423963133641, 'nid': -0.18596924897845168, 'grammatical_errors': 1, 'pegasus_entailment': 0.5520293727517128, 'gold_entailment': 0.5413166085879008, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 243
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.81 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.15668202764976957, 'r1_recall': 0.6181818181818182, 'r1_f1': 0.25, 'r2_precision': 0.07407407407407407, 'r2_recall': 0.2962962962962963, 'r2_f1': 0.11851851851851852, 'rL_precision': 0.10599078341013825, 'rL_recall': 0.41818181818181815, 'rL_f1': 0.1691176470588235, 'bs_precision': 0.18371683359146118, 'bs_recall': 0.457944393157959, 'bs_f1': 0.3068618178367615, 'bs_mnli_precision': 0.5568434000015259, 'bs_mnli_recall': 0.705064058303833, 'bs_mnli_f1': 0.6222489476203918, 'unique_bigram_ratio': 0.9241706161137441, 'nid': -0.18182326205420818, 'grammatical_errors': 1, 'pegasus_entailment': 0.5431624606251717, 'gold_entailment': 0.31454577421148616, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 244
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.06 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.17180616740088106, 'r1_recall': 0.48148148148148145, 'r1_f1': 0.2532467532467533, 'r2_precision': 0.030973451327433628, 'r2_recall': 0.0875, 'r2_f1': 0.04575163398692811, 'rL_precision': 0.11013215859030837, 'rL_recall': 0.30864197530864196, 'rL_f1': 0.1623376623376623, 'bs_precision': 0.15954065322875977, 'bs_recall': 0.3017524480819702, 'bs_f1': 0.22851885855197906, 'bs_mnli_precision': 0.5468853116035461, 'bs_mnli_recall': 0.6193274855613708, 'bs_mnli_f1': 0.580856442451477, 'unique_bigram_ratio': 0.9363636363636364, 'nid': -0.2153776407703698, 'grammatical_errors': 3, 'pegasus_entailment': 0.41469503231346605, 'gold_entailment': 0.3057096600532532, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 245
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 59.19 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3821656050955414, 'r1_recall': 0.7407407407407407, 'r1_f1': 0.5042016806722689, 'r2_precision': 0.21153846153846154, 'r2_recall': 0.4125, 'r2_f1': 0.2796610169491525, 'rL_precision': 0.25477707006369427, 'rL_recall': 0.49382716049382713, 'rL_f1': 0.3361344537815126, 'bs_precision': 0.35876569151878357, 'bs_recall': 0.5648189783096313, 'bs_f1': 0.4554364085197449, 'bs_mnli_precision': 0.6481962203979492, 'bs_mnli_recall': 0.7720532417297363, 'bs_mnli_f1': 0.7047240138053894, 'unique_bigram_ratio': 0.9605263157894737, 'nid': -0.2661054657277966, 'grammatical_errors': 0, 'pegasus_entailment': 0.5128943721453348, 'gold_entailment': 0.28350428491830826, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 246
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 71.43 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.42063492063492064, 'r1_recall': 0.6385542168674698, 'r1_f1': 0.507177033492823, 'r2_precision': 0.192, 'r2_recall': 0.2926829268292683, 'r2_f1': 0.23188405797101447, 'rL_precision': 0.2698412698412698, 'rL_recall': 0.40963855421686746, 'rL_f1': 0.3253588516746412, 'bs_precision': 0.3893199563026428, 'bs_recall': 0.5493282675743103, 'bs_f1': 0.4662231504917145, 'bs_mnli_precision': 0.6721625924110413, 'bs_mnli_recall': 0.7419232130050659, 'bs_mnli_f1': 0.7053221464157104, 'unique_bigram_ratio': 0.95, 'nid': -0.2509663273339373, 'grammatical_errors': 1, 'pegasus_entailment': 0.6897620856761932, 'gold_entailment': 0.5906610774497191, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 247
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.46 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5223880597014925, 'r1_recall': 0.6306306306306306, 'r1_f1': 0.5714285714285714, 'r2_precision': 0.2857142857142857, 'r2_recall': 0.34545454545454546, 'r2_f1': 0.3127572016460905, 'rL_precision': 0.3805970149253731, 'rL_recall': 0.4594594594594595, 'rL_f1': 0.4163265306122449, 'bs_precision': 0.4310387969017029, 'bs_recall': 0.4924503564834595, 'bs_f1': 0.46285441517829895, 'bs_mnli_precision': 0.7047133445739746, 'bs_mnli_recall': 0.7434163093566895, 'bs_mnli_f1': 0.723547637462616, 'unique_bigram_ratio': 0.9538461538461539, 'nid': -0.258654431873943, 'grammatical_errors': 1, 'pegasus_entailment': 0.47556111092368764, 'gold_entailment': 0.49694829881191255, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 248
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 34.88 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6588235294117647, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.4426877470355731, 'r2_precision': 0.2485207100591716, 'r2_recall': 0.1253731343283582, 'r2_f1': 0.16666666666666663, 'rL_precision': 0.3352941176470588, 'rL_recall': 0.16964285714285715, 'rL_f1': 0.22529644268774704, 'bs_precision': 0.37548795342445374, 'bs_recall': 0.21500329673290253, 'bs_f1': 0.29195916652679443, 'bs_mnli_precision': 0.6664076447486877, 'bs_mnli_recall': 0.5778030753135681, 'bs_mnli_f1': 0.6189504265785217, 'unique_bigram_ratio': 0.9397590361445783, 'nid': -0.2279672675700959, 'grammatical_errors': 1, 'pegasus_entailment': 0.3538423548452556, 'gold_entailment': 0.39640727368268097, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 249
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.20 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5141242937853108, 'r1_recall': 0.4099099099099099, 'r1_f1': 0.45614035087719296, 'r2_precision': 0.19886363636363635, 'r2_recall': 0.1583710407239819, 'r2_f1': 0.17632241813602015, 'rL_precision': 0.3107344632768362, 'rL_recall': 0.24774774774774774, 'rL_f1': 0.2756892230576441, 'bs_precision': 0.29556718468666077, 'bs_recall': 0.22383040189743042, 'bs_f1': 0.2610553503036499, 'bs_mnli_precision': 0.6596841812133789, 'bs_mnli_recall': 0.6106206178665161, 'bs_mnli_f1': 0.6342049241065979, 'unique_bigram_ratio': 0.9132947976878613, 'nid': -0.18763846792945205, 'grammatical_errors': 2, 'pegasus_entailment': 0.3105010041035712, 'gold_entailment': 0.16110482085496186, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 250
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.23 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.23148148148148148, 'r1_recall': 0.6410256410256411, 'r1_f1': 0.34013605442176875, 'r2_precision': 0.09302325581395349, 'r2_recall': 0.2597402597402597, 'r2_f1': 0.136986301369863, 'rL_precision': 0.14351851851851852, 'rL_recall': 0.3974358974358974, 'rL_f1': 0.21088435374149658, 'bs_precision': 0.21053338050842285, 'bs_recall': 0.4408201575279236, 'bs_f1': 0.3165401816368103, 'bs_mnli_precision': 0.5865827202796936, 'bs_mnli_recall': 0.7350696921348572, 'bs_mnli_f1': 0.6524849534034729, 'unique_bigram_ratio': 0.9567307692307693, 'nid': -0.21997531969904527, 'grammatical_errors': 4, 'pegasus_entailment': 0.7418912516699897, 'gold_entailment': 0.5256185904145241, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 251
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 66.25 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.43537414965986393, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5099601593625498, 'r2_precision': 0.23972602739726026, 'r2_recall': 0.33980582524271846, 'r2_f1': 0.2811244979919678, 'rL_precision': 0.25170068027210885, 'rL_recall': 0.3557692307692308, 'rL_f1': 0.2948207171314741, 'bs_precision': 0.30720454454421997, 'bs_recall': 0.4166036546230316, 'bs_f1': 0.3615787923336029, 'bs_mnli_precision': 0.617728590965271, 'bs_mnli_recall': 0.6800340414047241, 'bs_mnli_f1': 0.6473856568336487, 'unique_bigram_ratio': 0.9790209790209791, 'nid': -0.2790548723723132, 'grammatical_errors': 1, 'pegasus_entailment': 0.6726579566796621, 'gold_entailment': 0.6921737343072891, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 252
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.09 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24444444444444444, 'r1_recall': 0.4520547945205479, 'r1_f1': 0.3173076923076923, 'r2_precision': 0.07462686567164178, 'r2_recall': 0.1388888888888889, 'r2_f1': 0.0970873786407767, 'rL_precision': 0.15555555555555556, 'rL_recall': 0.2876712328767123, 'rL_f1': 0.20192307692307693, 'bs_precision': 0.12382929772138596, 'bs_recall': 0.2663363516330719, 'bs_f1': 0.1928911954164505, 'bs_mnli_precision': 0.5182012319564819, 'bs_mnli_recall': 0.618848979473114, 'bs_mnli_f1': 0.5640706419944763, 'unique_bigram_ratio': 0.9689922480620154, 'nid': -0.2687970183616599, 'grammatical_errors': 1, 'pegasus_entailment': 0.6144745051860809, 'gold_entailment': 0.30659813806414604, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 253
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 75.36 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3302752293577982, 'r1_recall': 0.5538461538461539, 'r1_f1': 0.41379310344827586, 'r2_precision': 0.14814814814814814, 'r2_recall': 0.25, 'r2_f1': 0.18604651162790697, 'rL_precision': 0.24770642201834864, 'rL_recall': 0.4153846153846154, 'rL_f1': 0.3103448275862069, 'bs_precision': 0.29955795407295227, 'bs_recall': 0.44414371252059937, 'bs_f1': 0.36965852975845337, 'bs_mnli_precision': 0.6155678033828735, 'bs_mnli_recall': 0.6842444539070129, 'bs_mnli_f1': 0.6480917930603027, 'unique_bigram_ratio': 0.9809523809523809, 'nid': -0.3035273860398666, 'grammatical_errors': 0, 'pegasus_entailment': 0.4685448110103607, 'gold_entailment': 0.37969016035397846, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 254
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.24 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.21161825726141079, 'r1_recall': 0.7083333333333334, 'r1_f1': 0.32587859424920124, 'r2_precision': 0.10833333333333334, 'r2_recall': 0.36619718309859156, 'r2_f1': 0.1672025723472669, 'rL_precision': 0.15352697095435686, 'rL_recall': 0.5138888888888888, 'rL_f1': 0.23642172523961663, 'bs_precision': 0.19387014210224152, 'bs_recall': 0.5032823085784912, 'bs_f1': 0.3305543065071106, 'bs_mnli_precision': 0.5791816711425781, 'bs_mnli_recall': 0.7435505390167236, 'bs_mnli_f1': 0.6511534452438354, 'unique_bigram_ratio': 0.9145299145299145, 'nid': -0.20357536920195418, 'grammatical_errors': 3, 'pegasus_entailment': 0.49858632251958956, 'gold_entailment': 0.5235315908988317, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 255
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 72.00 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.421875, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5167464114832536, 'r2_precision': 0.2047244094488189, 'r2_recall': 0.325, 'r2_f1': 0.251207729468599, 'rL_precision': 0.3046875, 'rL_recall': 0.48148148148148145, 'rL_f1': 0.37320574162679426, 'bs_precision': 0.28336453437805176, 'bs_recall': 0.43369999527931213, 'bs_f1': 0.3559812009334564, 'bs_mnli_precision': 0.6327951550483704, 'bs_mnli_recall': 0.712205171585083, 'bs_mnli_f1': 0.6701560020446777, 'unique_bigram_ratio': 0.9523809523809523, 'nid': -0.22376709500836567, 'grammatical_errors': 2, 'pegasus_entailment': 0.45408144912549425, 'gold_entailment': 0.41317164804786444, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 256
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.17 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.1862348178137652, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.2848297213622291, 'r2_precision': 0.06910569105691057, 'r2_recall': 0.22666666666666666, 'r2_f1': 0.1059190031152648, 'rL_precision': 0.12955465587044535, 'rL_recall': 0.42105263157894735, 'rL_f1': 0.1981424148606811, 'bs_precision': 0.14937785267829895, 'bs_recall': 0.410653293132782, 'bs_f1': 0.2671443223953247, 'bs_mnli_precision': 0.5270394682884216, 'bs_mnli_recall': 0.6926449537277222, 'bs_mnli_f1': 0.5985995531082153, 'unique_bigram_ratio': 0.9426229508196722, 'nid': -0.22481706547875824, 'grammatical_errors': 5, 'pegasus_entailment': 0.539532461669296, 'gold_entailment': 0.36376368161290884, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 257
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 69.51 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.34558823529411764, 'r1_recall': 0.5595238095238095, 'r1_f1': 0.4272727272727273, 'r2_precision': 0.13333333333333333, 'r2_recall': 0.21686746987951808, 'r2_f1': 0.1651376146788991, 'rL_precision': 0.22794117647058823, 'rL_recall': 0.36904761904761907, 'rL_f1': 0.28181818181818186, 'bs_precision': 0.2414783537387848, 'bs_recall': 0.3974490165710449, 'bs_f1': 0.31651049852371216, 'bs_mnli_precision': 0.6050320863723755, 'bs_mnli_recall': 0.7035480737686157, 'bs_mnli_f1': 0.6505817174911499, 'unique_bigram_ratio': 0.9545454545454546, 'nid': -0.22385289008199805, 'grammatical_errors': 0, 'pegasus_entailment': 0.5057200163602829, 'gold_entailment': 0.554744553565979, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 258
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.52 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.42528735632183906, 'r1_recall': 0.4713375796178344, 'r1_f1': 0.44712990936555896, 'r2_precision': 0.16184971098265896, 'r2_recall': 0.1794871794871795, 'r2_f1': 0.1702127659574468, 'rL_precision': 0.21839080459770116, 'rL_recall': 0.24203821656050956, 'rL_f1': 0.229607250755287, 'bs_precision': 0.25106334686279297, 'bs_recall': 0.2557050883769989, 'bs_f1': 0.25593045353889465, 'bs_mnli_precision': 0.5899808406829834, 'bs_mnli_recall': 0.5933590531349182, 'bs_mnli_f1': 0.5916651487350464, 'unique_bigram_ratio': 0.9529411764705882, 'nid': -0.24536521419930035, 'grammatical_errors': 1, 'pegasus_entailment': 0.49106832407414913, 'gold_entailment': 0.20792156245027268, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 259
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.66 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4098360655737705, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.45871559633027525, 'r2_precision': 0.19230769230769232, 'r2_recall': 0.24475524475524477, 'r2_f1': 0.2153846153846154, 'rL_precision': 0.29508196721311475, 'rL_recall': 0.375, 'rL_f1': 0.3302752293577982, 'bs_precision': 0.3176146149635315, 'bs_recall': 0.39920711517333984, 'bs_f1': 0.35920459032058716, 'bs_mnli_precision': 0.6192713975906372, 'bs_mnli_recall': 0.6758517622947693, 'bs_mnli_f1': 0.6463257074356079, 'unique_bigram_ratio': 0.9485714285714286, 'nid': -0.22237357672194058, 'grammatical_errors': 2, 'pegasus_entailment': 0.4166311983551298, 'gold_entailment': 0.37266136426478624, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 260
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.23 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3072289156626506, 'r1_recall': 0.5425531914893617, 'r1_f1': 0.39230769230769236, 'r2_precision': 0.13333333333333333, 'r2_recall': 0.23655913978494625, 'r2_f1': 0.17054263565891475, 'rL_precision': 0.1566265060240964, 'rL_recall': 0.2765957446808511, 'rL_f1': 0.2, 'bs_precision': 0.25516167283058167, 'bs_recall': 0.32740119099617004, 'bs_f1': 0.29254066944122314, 'bs_mnli_precision': 0.6014999747276306, 'bs_mnli_recall': 0.6502638459205627, 'bs_mnli_f1': 0.6249321103096008, 'unique_bigram_ratio': 0.9503105590062112, 'nid': -0.24375179942469116, 'grammatical_errors': 0, 'pegasus_entailment': 0.6129945789774259, 'gold_entailment': 0.07096001754204433, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 261
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.65 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4439461883408072, 'r1_recall': 0.518324607329843, 'r1_f1': 0.47826086956521735, 'r2_precision': 0.17117117117117117, 'r2_recall': 0.2, 'r2_f1': 0.18446601941747576, 'rL_precision': 0.2556053811659193, 'rL_recall': 0.29842931937172773, 'rL_f1': 0.2753623188405797, 'bs_precision': 0.21766769886016846, 'bs_recall': 0.28429874777793884, 'bs_f1': 0.252516508102417, 'bs_mnli_precision': 0.6092562675476074, 'bs_mnli_recall': 0.6315411329269409, 'bs_mnli_f1': 0.6201986074447632, 'unique_bigram_ratio': 0.91324200913242, 'nid': -0.2013330588088642, 'grammatical_errors': 2, 'pegasus_entailment': 0.2376314545981586, 'gold_entailment': 0.09226907901465893, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 262
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.82 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.1891891891891892, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.2991452991452992, 'r2_precision': 0.10326086956521739, 'r2_recall': 0.3958333333333333, 'r2_f1': 0.16379310344827586, 'rL_precision': 0.16756756756756758, 'rL_recall': 0.6326530612244898, 'rL_f1': 0.26495726495726496, 'bs_precision': 0.19114089012145996, 'bs_recall': 0.5106467604637146, 'bs_f1': 0.3315642476081848, 'bs_mnli_precision': 0.5670692920684814, 'bs_mnli_recall': 0.7117390632629395, 'bs_mnli_f1': 0.6312210559844971, 'unique_bigram_ratio': 0.9222222222222223, 'nid': -0.20045899252831134, 'grammatical_errors': 5, 'pegasus_entailment': 0.47377834655344486, 'gold_entailment': 0.12817314267158508, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 263
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.35 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.26903553299492383, 'r1_recall': 0.6385542168674698, 'r1_f1': 0.3785714285714285, 'r2_precision': 0.11734693877551021, 'r2_recall': 0.2804878048780488, 'r2_f1': 0.16546762589928057, 'rL_precision': 0.15228426395939088, 'rL_recall': 0.3614457831325301, 'rL_f1': 0.21428571428571427, 'bs_precision': 0.22776798903942108, 'bs_recall': 0.36972177028656006, 'bs_f1': 0.2966878116130829, 'bs_mnli_precision': 0.5863636136054993, 'bs_mnli_recall': 0.6599062085151672, 'bs_mnli_f1': 0.6209650039672852, 'unique_bigram_ratio': 0.9523809523809523, 'nid': -0.2195172314185203, 'grammatical_errors': 2, 'pegasus_entailment': 0.6464106057371412, 'gold_entailment': 0.6424704392751058, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 264
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 72.29 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.35772357723577236, 'r1_recall': 0.5641025641025641, 'r1_f1': 0.4378109452736319, 'r2_precision': 0.1885245901639344, 'r2_recall': 0.2987012987012987, 'r2_f1': 0.23115577889447236, 'rL_precision': 0.2682926829268293, 'rL_recall': 0.4230769230769231, 'rL_f1': 0.3283582089552239, 'bs_precision': 0.30777549743652344, 'bs_recall': 0.4524780511856079, 'bs_f1': 0.3779289424419403, 'bs_mnli_precision': 0.6225770115852356, 'bs_mnli_recall': 0.7195761799812317, 'bs_mnli_f1': 0.667571485042572, 'unique_bigram_ratio': 0.95, 'nid': -0.2819407506934346, 'grammatical_errors': 0, 'pegasus_entailment': 0.2777184905484319, 'gold_entailment': 0.13062531240284442, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 265
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 75.27 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.37815126050420167, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.45, 'r2_precision': 0.22033898305084745, 'r2_recall': 0.325, 'r2_f1': 0.2626262626262626, 'rL_precision': 0.3025210084033613, 'rL_recall': 0.4444444444444444, 'rL_f1': 0.36, 'bs_precision': 0.46296563744544983, 'bs_recall': 0.5309147834777832, 'bs_f1': 0.49779012799263, 'bs_mnli_precision': 0.6848673224449158, 'bs_mnli_recall': 0.722894549369812, 'bs_mnli_f1': 0.7033673524856567, 'unique_bigram_ratio': 0.9912280701754386, 'nid': -0.3001641387980456, 'grammatical_errors': 0, 'pegasus_entailment': 0.41069204253809793, 'gold_entailment': 0.3491732142865658, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 266
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 44.55 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.36507936507936506, 'r1_recall': 0.6715328467153284, 'r1_f1': 0.47300771208226217, 'r2_precision': 0.1593625498007968, 'r2_recall': 0.29411764705882354, 'r2_f1': 0.20671834625322996, 'rL_precision': 0.21428571428571427, 'rL_recall': 0.39416058394160586, 'rL_f1': 0.27763496143958866, 'bs_precision': 0.3022702932357788, 'bs_recall': 0.5092113018035889, 'bs_f1': 0.39913058280944824, 'bs_mnli_precision': 0.6506301164627075, 'bs_mnli_recall': 0.727947473526001, 'bs_mnli_f1': 0.6871206164360046, 'unique_bigram_ratio': 0.9227642276422764, 'nid': -0.21728708170806232, 'grammatical_errors': 2, 'pegasus_entailment': 0.5513545240868222, 'gold_entailment': 0.3150320887565613, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 267
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 70.25 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.16030534351145037, 'r1_recall': 0.4772727272727273, 'r1_f1': 0.24000000000000005, 'r2_precision': 0.023076923076923078, 'r2_recall': 0.06976744186046512, 'r2_f1': 0.034682080924855495, 'rL_precision': 0.0916030534351145, 'rL_recall': 0.2727272727272727, 'rL_f1': 0.13714285714285715, 'bs_precision': 0.09494826197624207, 'bs_recall': 0.3254234790802002, 'bs_f1': 0.20015253126621246, 'bs_mnli_precision': 0.5187661647796631, 'bs_mnli_recall': 0.5969158411026001, 'bs_mnli_f1': 0.5551039576530457, 'unique_bigram_ratio': 0.9606299212598425, 'nid': -0.27839671100978647, 'grammatical_errors': 0, 'pegasus_entailment': 0.6418826033671697, 'gold_entailment': 0.7484732866287231, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 268
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.64 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.1837837837837838, 'r1_recall': 0.576271186440678, 'r1_f1': 0.2786885245901639, 'r2_precision': 0.07608695652173914, 'r2_recall': 0.2413793103448276, 'r2_f1': 0.11570247933884296, 'rL_precision': 0.12972972972972974, 'rL_recall': 0.4067796610169492, 'rL_f1': 0.19672131147540986, 'bs_precision': 0.19060693681240082, 'bs_recall': 0.38973933458328247, 'bs_f1': 0.2837715744972229, 'bs_mnli_precision': 0.5751305222511292, 'bs_mnli_recall': 0.6917117834091187, 'bs_mnli_f1': 0.6280569434165955, 'unique_bigram_ratio': 0.9447513812154696, 'nid': -0.21451818289606694, 'grammatical_errors': 1, 'pegasus_entailment': 0.48891104970659527, 'gold_entailment': 0.2562423273921013, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 269
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.11 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.5746268656716418, 'r1_f1': 0.5150501672240803, 'r2_precision': 0.20121951219512196, 'r2_recall': 0.24812030075187969, 'r2_f1': 0.22222222222222224, 'rL_precision': 0.2787878787878788, 'rL_recall': 0.34328358208955223, 'rL_f1': 0.30769230769230765, 'bs_precision': 0.3584434688091278, 'bs_recall': 0.4042852222919464, 'bs_f1': 0.3830442726612091, 'bs_mnli_precision': 0.6773478388786316, 'bs_mnli_recall': 0.6879680156707764, 'bs_mnli_f1': 0.6826165914535522, 'unique_bigram_ratio': 0.9382716049382716, 'nid': -0.20089114731185354, 'grammatical_errors': 0, 'pegasus_entailment': 0.5652128888501061, 'gold_entailment': 0.5622213433186213, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 270
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.49 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4406779661016949, 'r1_recall': 0.5, 'r1_f1': 0.4684684684684685, 'r2_precision': 0.16477272727272727, 'r2_recall': 0.1870967741935484, 'r2_f1': 0.17522658610271902, 'rL_precision': 0.2655367231638418, 'rL_recall': 0.30128205128205127, 'rL_f1': 0.2822822822822823, 'bs_precision': 0.35532939434051514, 'bs_recall': 0.3320808708667755, 'bs_f1': 0.345833957195282, 'bs_mnli_precision': 0.6552506685256958, 'bs_mnli_recall': 0.6644608378410339, 'bs_mnli_f1': 0.6598236560821533, 'unique_bigram_ratio': 0.9707602339181286, 'nid': -0.2425060414618665, 'grammatical_errors': 1, 'pegasus_entailment': 0.5135486690061433, 'gold_entailment': 0.21310917101800442, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 271
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.84 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24299065420560748, 'r1_recall': 0.8, 'r1_f1': 0.37275985663082434, 'r2_precision': 0.1596244131455399, 'r2_recall': 0.53125, 'r2_f1': 0.24548736462093865, 'rL_precision': 0.1822429906542056, 'rL_recall': 0.6, 'rL_f1': 0.2795698924731183, 'bs_precision': 0.19593562185764313, 'bs_recall': 0.5096769332885742, 'bs_f1': 0.33427393436431885, 'bs_mnli_precision': 0.5663881301879883, 'bs_mnli_recall': 0.7680371999740601, 'bs_mnli_f1': 0.6519767642021179, 'unique_bigram_ratio': 0.9710144927536232, 'nid': -0.2271518081809636, 'grammatical_errors': 3, 'pegasus_entailment': 0.6211336553096771, 'gold_entailment': 0.6227165758609772, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 272
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.66 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.30864197530864196, 'r1_recall': 0.5681818181818182, 'r1_f1': 0.4, 'r2_precision': 0.14906832298136646, 'r2_recall': 0.27586206896551724, 'r2_f1': 0.1935483870967742, 'rL_precision': 0.17901234567901234, 'rL_recall': 0.32954545454545453, 'rL_f1': 0.232, 'bs_precision': 0.21039439737796783, 'bs_recall': 0.32384416460990906, 'bs_f1': 0.26669609546661377, 'bs_mnli_precision': 0.578404426574707, 'bs_mnli_recall': 0.6346704959869385, 'bs_mnli_f1': 0.6052325367927551, 'unique_bigram_ratio': 0.9746835443037974, 'nid': -0.26109497706637486, 'grammatical_errors': 0, 'pegasus_entailment': 0.7748894989490509, 'gold_entailment': 0.5035586754480997, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 273
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.08 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2631578947368421, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.35294117647058815, 'r2_precision': 0.09411764705882353, 'r2_recall': 0.1927710843373494, 'r2_f1': 0.1264822134387352, 'rL_precision': 0.16374269005847952, 'rL_recall': 0.3333333333333333, 'rL_f1': 0.2196078431372549, 'bs_precision': 0.26879656314849854, 'bs_recall': 0.3551304042339325, 'bs_f1': 0.3126850724220276, 'bs_mnli_precision': 0.5965140461921692, 'bs_mnli_recall': 0.675142765045166, 'bs_mnli_f1': 0.6333975195884705, 'unique_bigram_ratio': 0.9642857142857143, 'nid': -0.28000867568964405, 'grammatical_errors': 3, 'pegasus_entailment': 0.5155165418982506, 'gold_entailment': 0.4136940836906433, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 274
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 79.81 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4157303370786517, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.44578313253012053, 'r2_precision': 0.19318181818181818, 'r2_recall': 0.2236842105263158, 'r2_f1': 0.20731707317073172, 'rL_precision': 0.23595505617977527, 'rL_recall': 0.2727272727272727, 'rL_f1': 0.25301204819277107, 'bs_precision': 0.41938814520835876, 'bs_recall': 0.4322497248649597, 'bs_f1': 0.4277476966381073, 'bs_mnli_precision': 0.6776597499847412, 'bs_mnli_recall': 0.6840598583221436, 'bs_mnli_f1': 0.680844783782959, 'unique_bigram_ratio': 0.9651162790697675, 'nid': -0.2666393369332809, 'grammatical_errors': 0, 'pegasus_entailment': 0.4314257511869073, 'gold_entailment': 0.27001741031805676, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 275
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.46 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.208, 'r1_recall': 0.65, 'r1_f1': 0.3151515151515151, 'r2_precision': 0.08835341365461848, 'r2_recall': 0.27848101265822783, 'r2_f1': 0.13414634146341464, 'rL_precision': 0.148, 'rL_recall': 0.4625, 'rL_f1': 0.22424242424242422, 'bs_precision': 0.16729991137981415, 'bs_recall': 0.3586564362049103, 'bs_f1': 0.25714239478111267, 'bs_mnli_precision': 0.5543954968452454, 'bs_mnli_recall': 0.6610339283943176, 'bs_mnli_f1': 0.603036642074585, 'unique_bigram_ratio': 0.9102040816326531, 'nid': -0.1756475832954809, 'grammatical_errors': 6, 'pegasus_entailment': 0.5578016117215157, 'gold_entailment': 0.19151685138543448, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 276
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.82 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.40625, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4789473684210527, 'r2_precision': 0.13452914798206278, 'r2_recall': 0.1935483870967742, 'r2_f1': 0.15873015873015872, 'rL_precision': 0.20535714285714285, 'rL_recall': 0.2948717948717949, 'rL_f1': 0.24210526315789474, 'bs_precision': 0.21898771822452545, 'bs_recall': 0.3673571050167084, 'bs_f1': 0.29069894552230835, 'bs_mnli_precision': 0.6015333533287048, 'bs_mnli_recall': 0.6575317978858948, 'bs_mnli_f1': 0.6282872557640076, 'unique_bigram_ratio': 0.9369369369369369, 'nid': -0.22026173530695559, 'grammatical_errors': 4, 'pegasus_entailment': 0.2931772442534566, 'gold_entailment': 0.23074810802936555, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 277
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.70 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24770642201834864, 'r1_recall': 0.7105263157894737, 'r1_f1': 0.3673469387755102, 'r2_precision': 0.12903225806451613, 'r2_recall': 0.37333333333333335, 'r2_f1': 0.19178082191780818, 'rL_precision': 0.1743119266055046, 'rL_recall': 0.5, 'rL_f1': 0.2585034013605442, 'bs_precision': 0.23164696991443634, 'bs_recall': 0.5321629047393799, 'bs_f1': 0.3654417097568512, 'bs_mnli_precision': 0.5824699997901917, 'bs_mnli_recall': 0.7234408855438232, 'bs_mnli_f1': 0.6453467011451721, 'unique_bigram_ratio': 0.9671361502347418, 'nid': -0.24466080553753256, 'grammatical_errors': 2, 'pegasus_entailment': 0.6715526708534786, 'gold_entailment': 0.7355806032816569, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 278
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.39 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.30303030303030304, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.39999999999999997, 'r2_precision': 0.11585365853658537, 'r2_recall': 0.2261904761904762, 'r2_f1': 0.1532258064516129, 'rL_precision': 0.19393939393939394, 'rL_recall': 0.3764705882352941, 'rL_f1': 0.256, 'bs_precision': 0.25210386514663696, 'bs_recall': 0.4081101715564728, 'bs_f1': 0.3271634876728058, 'bs_mnli_precision': 0.609886646270752, 'bs_mnli_recall': 0.6767475008964539, 'bs_mnli_f1': 0.641579806804657, 'unique_bigram_ratio': 0.94375, 'nid': -0.23574624141151412, 'grammatical_errors': 1, 'pegasus_entailment': 0.5750750824809074, 'gold_entailment': 0.44874518513679507, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 279
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.77 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.549618320610687, 'r1_f1': 0.5413533834586467, 'r2_precision': 0.2462686567164179, 'r2_recall': 0.25384615384615383, 'r2_f1': 0.25, 'rL_precision': 0.31851851851851853, 'rL_recall': 0.3282442748091603, 'rL_f1': 0.32330827067669177, 'bs_precision': 0.3957290053367615, 'bs_recall': 0.39074012637138367, 'bs_f1': 0.3953031897544861, 'bs_mnli_precision': 0.6901254653930664, 'bs_mnli_recall': 0.6854991912841797, 'bs_mnli_f1': 0.6878045797348022, 'unique_bigram_ratio': 0.9772727272727273, 'nid': -0.29064806327300885, 'grammatical_errors': 1, 'pegasus_entailment': 0.15521243773400784, 'gold_entailment': 0.14966250707705817, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 280
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.41 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.34574468085106386, 'r1_recall': 0.6132075471698113, 'r1_f1': 0.44217687074829937, 'r2_precision': 0.11229946524064172, 'r2_recall': 0.2, 'r2_f1': 0.14383561643835616, 'rL_precision': 0.19680851063829788, 'rL_recall': 0.3490566037735849, 'rL_f1': 0.25170068027210885, 'bs_precision': 0.2991734445095062, 'bs_recall': 0.44012805819511414, 'bs_f1': 0.36767351627349854, 'bs_mnli_precision': 0.616753101348877, 'bs_mnli_recall': 0.7005239129066467, 'bs_mnli_f1': 0.6559748649597168, 'unique_bigram_ratio': 0.9567567567567568, 'nid': -0.2362673875944421, 'grammatical_errors': 1, 'pegasus_entailment': 0.5237607657909393, 'gold_entailment': 0.29814552469179034, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 281
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.40 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5823529411764706, 'r1_recall': 0.5409836065573771, 'r1_f1': 0.5609065155807367, 'r2_precision': 0.23668639053254437, 'r2_recall': 0.21978021978021978, 'r2_f1': 0.2279202279202279, 'rL_precision': 0.27058823529411763, 'rL_recall': 0.25136612021857924, 'rL_f1': 0.26062322946175637, 'bs_precision': 0.3272159695625305, 'bs_recall': 0.34549787640571594, 'bs_f1': 0.3385525941848755, 'bs_mnli_precision': 0.6511855125427246, 'bs_mnli_recall': 0.6459975838661194, 'bs_mnli_f1': 0.6485812067985535, 'unique_bigram_ratio': 0.9757575757575757, 'nid': -0.2880852014246291, 'grammatical_errors': 2, 'pegasus_entailment': 0.5964378820998328, 'gold_entailment': 0.4487687924078533, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 282
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 68.85 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.32857142857142857, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.4259259259259259, 'r2_precision': 0.1510791366906475, 'r2_recall': 0.28, 'r2_f1': 0.19626168224299068, 'rL_precision': 0.24285714285714285, 'rL_recall': 0.4473684210526316, 'rL_f1': 0.3148148148148148, 'bs_precision': 0.24538351595401764, 'bs_recall': 0.4118388891220093, 'bs_f1': 0.32494115829467773, 'bs_mnli_precision': 0.602322518825531, 'bs_mnli_recall': 0.7082384824752808, 'bs_mnli_f1': 0.6510006189346313, 'unique_bigram_ratio': 0.9343065693430657, 'nid': -0.24407839497522366, 'grammatical_errors': 0, 'pegasus_entailment': 0.49681675620377064, 'gold_entailment': 0.597611591219902, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 283
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.64 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.27717391304347827, 'r1_recall': 0.5543478260869565, 'r1_f1': 0.3695652173913043, 'r2_precision': 0.12021857923497267, 'r2_recall': 0.24175824175824176, 'r2_f1': 0.16058394160583941, 'rL_precision': 0.1793478260869565, 'rL_recall': 0.358695652173913, 'rL_f1': 0.2391304347826087, 'bs_precision': 0.2387988567352295, 'bs_recall': 0.4340512752532959, 'bs_f1': 0.33054256439208984, 'bs_mnli_precision': 0.5876324772834778, 'bs_mnli_recall': 0.6816064119338989, 'bs_mnli_f1': 0.6311405301094055, 'unique_bigram_ratio': 0.9831460674157303, 'nid': -0.2674365211497933, 'grammatical_errors': 1, 'pegasus_entailment': 0.7487734109163284, 'gold_entailment': 0.22852072616418204, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 19, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 284
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.38 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5325443786982249, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.4675324675324675, 'r2_precision': 0.27380952380952384, 'r2_recall': 0.21395348837209302, 'r2_f1': 0.2402088772845953, 'rL_precision': 0.3076923076923077, 'rL_recall': 0.24074074074074073, 'rL_f1': 0.2701298701298701, 'bs_precision': 0.30126258730888367, 'bs_recall': 0.2136068195104599, 'bs_f1': 0.2582160532474518, 'bs_mnli_precision': 0.6347527503967285, 'bs_mnli_recall': 0.5950338840484619, 'bs_mnli_f1': 0.6142519116401672, 'unique_bigram_ratio': 0.9512195121951219, 'nid': -0.22635699461449565, 'grammatical_errors': 0, 'pegasus_entailment': 0.5993944220244884, 'gold_entailment': 0.5020520289738973, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 285
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.41 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4411764705882353, 'r1_recall': 0.594059405940594, 'r1_f1': 0.5063291139240507, 'r2_precision': 0.21481481481481482, 'r2_recall': 0.29, 'r2_f1': 0.24680851063829787, 'rL_precision': 0.23529411764705882, 'rL_recall': 0.31683168316831684, 'rL_f1': 0.27004219409282704, 'bs_precision': 0.30611252784729004, 'bs_recall': 0.4012656807899475, 'bs_f1': 0.35398826003074646, 'bs_mnli_precision': 0.6233506798744202, 'bs_mnli_recall': 0.677260160446167, 'bs_mnli_f1': 0.6491881608963013, 'unique_bigram_ratio': 0.9323308270676691, 'nid': -0.2518427314544205, 'grammatical_errors': 5, 'pegasus_entailment': 0.5538847098747889, 'gold_entailment': 0.3639770969748497, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 286
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.05 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4125874125874126, 'r1_recall': 0.6020408163265306, 'r1_f1': 0.48962655601659755, 'r2_precision': 0.21830985915492956, 'r2_recall': 0.31958762886597936, 'r2_f1': 0.2594142259414226, 'rL_precision': 0.32167832167832167, 'rL_recall': 0.46938775510204084, 'rL_f1': 0.3817427385892116, 'bs_precision': 0.3825853168964386, 'bs_recall': 0.4574739933013916, 'bs_f1': 0.42089101672172546, 'bs_mnli_precision': 0.6592434048652649, 'bs_mnli_recall': 0.7272425293922424, 'bs_mnli_f1': 0.6915754675865173, 'unique_bigram_ratio': 0.9574468085106383, 'nid': -0.2396422047695539, 'grammatical_errors': 2, 'pegasus_entailment': 0.4533792108297348, 'gold_entailment': 0.27803238946944475, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 287
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 66.12 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.39705882352941174, 'r1_recall': 0.7714285714285715, 'r1_f1': 0.5242718446601942, 'r2_precision': 0.2222222222222222, 'r2_recall': 0.43478260869565216, 'r2_f1': 0.29411764705882354, 'rL_precision': 0.3088235294117647, 'rL_recall': 0.6, 'rL_f1': 0.4077669902912622, 'bs_precision': 0.34465476870536804, 'bs_recall': 0.579958438873291, 'bs_f1': 0.4534626007080078, 'bs_mnli_precision': 0.6672323942184448, 'bs_mnli_recall': 0.7825648188591003, 'bs_mnli_f1': 0.7203112244606018, 'unique_bigram_ratio': 0.9772727272727273, 'nid': -0.3077836189634884, 'grammatical_errors': 0, 'pegasus_entailment': 0.7005233407020569, 'gold_entailment': 0.5284433762232462, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 288
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 44.98 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.32894736842105265, 'r1_recall': 0.5639097744360902, 'r1_f1': 0.41551246537396125, 'r2_precision': 0.11013215859030837, 'r2_recall': 0.1893939393939394, 'r2_f1': 0.13927576601671307, 'rL_precision': 0.16228070175438597, 'rL_recall': 0.2781954887218045, 'rL_f1': 0.20498614958448755, 'bs_precision': 0.2099795639514923, 'bs_recall': 0.39682021737098694, 'bs_f1': 0.29809945821762085, 'bs_mnli_precision': 0.5862482190132141, 'bs_mnli_recall': 0.6708126664161682, 'bs_mnli_f1': 0.6256860494613647, 'unique_bigram_ratio': 0.9773755656108597, 'nid': -0.22868446756624095, 'grammatical_errors': 8, 'pegasus_entailment': 0.4422852471470833, 'gold_entailment': 0.430023230612278, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 289
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.73 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2722772277227723, 'r1_recall': 0.6111111111111112, 'r1_f1': 0.3767123287671233, 'r2_precision': 0.13432835820895522, 'r2_recall': 0.30337078651685395, 'r2_f1': 0.18620689655172412, 'rL_precision': 0.17326732673267325, 'rL_recall': 0.3888888888888889, 'rL_f1': 0.23972602739726026, 'bs_precision': 0.23689252138137817, 'bs_recall': 0.4506523013114929, 'bs_f1': 0.3363085389137268, 'bs_mnli_precision': 0.5954141616821289, 'bs_mnli_recall': 0.718647837638855, 'bs_mnli_f1': 0.6512525081634521, 'unique_bigram_ratio': 0.923469387755102, 'nid': -0.2322057551466541, 'grammatical_errors': 2, 'pegasus_entailment': 0.33042647782713175, 'gold_entailment': 0.06393496692180634, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 290
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.97 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3652694610778443, 'r1_recall': 0.5304347826086957, 'r1_f1': 0.4326241134751773, 'r2_precision': 0.16265060240963855, 'r2_recall': 0.23684210526315788, 'r2_f1': 0.19285714285714284, 'rL_precision': 0.2155688622754491, 'rL_recall': 0.3130434782608696, 'rL_f1': 0.25531914893617025, 'bs_precision': 0.2683223783969879, 'bs_recall': 0.3210998475551605, 'bs_f1': 0.29650190472602844, 'bs_mnli_precision': 0.6162463426589966, 'bs_mnli_recall': 0.6470512747764587, 'bs_mnli_f1': 0.6312732696533203, 'unique_bigram_ratio': 0.9433962264150944, 'nid': -0.25770639601294687, 'grammatical_errors': 3, 'pegasus_entailment': 0.7462249249219894, 'gold_entailment': 0.4143307626247406, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 291
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.69 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3010752688172043, 'r1_recall': 0.5045045045045045, 'r1_f1': 0.37710437710437716, 'r2_precision': 0.07027027027027027, 'r2_recall': 0.11818181818181818, 'r2_f1': 0.088135593220339, 'rL_precision': 0.13440860215053763, 'rL_recall': 0.22522522522522523, 'rL_f1': 0.16835016835016833, 'bs_precision': 0.17451049387454987, 'bs_recall': 0.24862757325172424, 'bs_f1': 0.21294578909873962, 'bs_mnli_precision': 0.5609712600708008, 'bs_mnli_recall': 0.5877805948257446, 'bs_mnli_f1': 0.5740630626678467, 'unique_bigram_ratio': 0.9234972677595629, 'nid': -0.21904713787117647, 'grammatical_errors': 1, 'pegasus_entailment': 0.4327212359224047, 'gold_entailment': 0.13877983515461287, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 292
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 37.49 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.25696594427244585, 'r1_recall': 0.6014492753623188, 'r1_f1': 0.3600867678958785, 'r2_precision': 0.12422360248447205, 'r2_recall': 0.291970802919708, 'r2_f1': 0.17429193899782133, 'rL_precision': 0.15479876160990713, 'rL_recall': 0.36231884057971014, 'rL_f1': 0.21691973969631234, 'bs_precision': 0.254446417093277, 'bs_recall': 0.30966731905937195, 'bs_f1': 0.2838246524333954, 'bs_mnli_precision': 0.6021054983139038, 'bs_mnli_recall': 0.6414830684661865, 'bs_mnli_f1': 0.6211708188056946, 'unique_bigram_ratio': 0.8753993610223643, 'nid': -0.15211365374995633, 'grammatical_errors': 3, 'pegasus_entailment': 0.40349981121041556, 'gold_entailment': 0.4736177995800972, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 293
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.82 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.19205298013245034, 'r1_recall': 0.58, 'r1_f1': 0.2885572139303483, 'r2_precision': 0.1, 'r2_recall': 0.30612244897959184, 'r2_f1': 0.15075376884422112, 'rL_precision': 0.17218543046357615, 'rL_recall': 0.52, 'rL_f1': 0.25870646766169153, 'bs_precision': 0.1841670274734497, 'bs_recall': 0.5293735265731812, 'bs_f1': 0.3339402973651886, 'bs_mnli_precision': 0.5336132645606995, 'bs_mnli_recall': 0.7199597358703613, 'bs_mnli_f1': 0.6129361391067505, 'unique_bigram_ratio': 0.993103448275862, 'nid': -0.27037103542820895, 'grammatical_errors': 3, 'pegasus_entailment': 0.3679375469684601, 'gold_entailment': 0.15477624582126737, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 294
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.65 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.1752136752136752, 'r1_recall': 0.7321428571428571, 'r1_f1': 0.2827586206896552, 'r2_precision': 0.09871244635193133, 'r2_recall': 0.41818181818181815, 'r2_f1': 0.15972222222222218, 'rL_precision': 0.15384615384615385, 'rL_recall': 0.6428571428571429, 'rL_f1': 0.2482758620689655, 'bs_precision': 0.13362109661102295, 'bs_recall': 0.5435846447944641, 'bs_f1': 0.30501845479011536, 'bs_mnli_precision': 0.5018068552017212, 'bs_mnli_recall': 0.7328193187713623, 'bs_mnli_f1': 0.5957005620002747, 'unique_bigram_ratio': 0.911504424778761, 'nid': -0.2102566392136329, 'grammatical_errors': 2, 'pegasus_entailment': 0.546733045578003, 'gold_entailment': 0.426454355319341, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 295
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.26 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.13372093023255813, 'r1_recall': 0.48936170212765956, 'r1_f1': 0.21004566210045664, 'r2_precision': 0.04678362573099415, 'r2_recall': 0.17391304347826086, 'r2_f1': 0.07373271889400922, 'rL_precision': 0.09302325581395349, 'rL_recall': 0.3404255319148936, 'rL_f1': 0.1461187214611872, 'bs_precision': 0.14491692185401917, 'bs_recall': 0.21940501034259796, 'bs_f1': 0.18358635902404785, 'bs_mnli_precision': 0.5354290008544922, 'bs_mnli_recall': 0.5994429588317871, 'bs_mnli_f1': 0.5656306147575378, 'unique_bigram_ratio': 0.9693251533742331, 'nid': -0.26087892526544, 'grammatical_errors': 4, 'pegasus_entailment': 0.5037503788868586, 'gold_entailment': 0.3564464896917343, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 296
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.67 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.22929936305732485, 'r1_recall': 0.5070422535211268, 'r1_f1': 0.31578947368421056, 'r2_precision': 0.10897435897435898, 'r2_recall': 0.24285714285714285, 'r2_f1': 0.1504424778761062, 'rL_precision': 0.17834394904458598, 'rL_recall': 0.39436619718309857, 'rL_f1': 0.24561403508771928, 'bs_precision': 0.28302812576293945, 'bs_recall': 0.42327502369880676, 'bs_f1': 0.3512149751186371, 'bs_mnli_precision': 0.5962397456169128, 'bs_mnli_recall': 0.6834543943405151, 'bs_mnli_f1': 0.6368751525878906, 'unique_bigram_ratio': 0.9545454545454546, 'nid': -0.2747101467327686, 'grammatical_errors': 1, 'pegasus_entailment': 0.20135526320276162, 'gold_entailment': 0.1613908164203167, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 297
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.52 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5266272189349113, 'r1_recall': 0.48633879781420764, 'r1_f1': 0.5056818181818181, 'r2_precision': 0.18452380952380953, 'r2_recall': 0.17032967032967034, 'r2_f1': 0.17714285714285716, 'rL_precision': 0.3254437869822485, 'rL_recall': 0.3005464480874317, 'rL_f1': 0.3125, 'bs_precision': 0.368699848651886, 'bs_recall': 0.34429851174354553, 'bs_f1': 0.35857415199279785, 'bs_mnli_precision': 0.6614980697631836, 'bs_mnli_recall': 0.6647818088531494, 'bs_mnli_f1': 0.6631358861923218, 'unique_bigram_ratio': 0.9695121951219512, 'nid': -0.2493448616302032, 'grammatical_errors': 6, 'pegasus_entailment': 0.5710288935473987, 'gold_entailment': 0.44814291410148144, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 298
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.94 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4658385093167702, 'r1_recall': 0.5474452554744526, 'r1_f1': 0.5033557046979865, 'r2_precision': 0.275, 'r2_recall': 0.3235294117647059, 'r2_f1': 0.2972972972972973, 'rL_precision': 0.30434782608695654, 'rL_recall': 0.35766423357664234, 'rL_f1': 0.3288590604026846, 'bs_precision': 0.3707839846611023, 'bs_recall': 0.3999176323413849, 'bs_f1': 0.3872760832309723, 'bs_mnli_precision': 0.6606742739677429, 'bs_mnli_recall': 0.6861188411712646, 'bs_mnli_f1': 0.673156201839447, 'unique_bigram_ratio': 0.9612903225806452, 'nid': -0.2532105196900356, 'grammatical_errors': 1, 'pegasus_entailment': 0.7057901974767447, 'gold_entailment': 0.5828942159811655, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 299
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.22 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.43609022556390975, 'r1_recall': 0.6373626373626373, 'r1_f1': 0.5178571428571428, 'r2_precision': 0.23484848484848486, 'r2_recall': 0.34444444444444444, 'r2_f1': 0.27927927927927926, 'rL_precision': 0.3007518796992481, 'rL_recall': 0.43956043956043955, 'rL_f1': 0.35714285714285715, 'bs_precision': 0.3459116220474243, 'bs_recall': 0.4832691252231598, 'bs_f1': 0.4128093123435974, 'bs_mnli_precision': 0.6390570402145386, 'bs_mnli_recall': 0.7345784902572632, 'bs_mnli_f1': 0.6834965348243713, 'unique_bigram_ratio': 0.9765625, 'nid': -0.28392142051673774, 'grammatical_errors': 3, 'pegasus_entailment': 0.3488377884030342, 'gold_entailment': 0.39362016320228577, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 300
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.77 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.41721854304635764, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.4436619718309859, 'r2_precision': 0.16666666666666666, 'r2_recall': 0.1893939393939394, 'r2_f1': 0.17730496453900704, 'rL_precision': 0.2582781456953642, 'rL_recall': 0.2932330827067669, 'rL_f1': 0.2746478873239437, 'bs_precision': 0.26093193888664246, 'bs_recall': 0.30214735865592957, 'bs_f1': 0.2836122214794159, 'bs_mnli_precision': 0.6029224991798401, 'bs_mnli_recall': 0.6209079027175903, 'bs_mnli_f1': 0.6117830276489258, 'unique_bigram_ratio': 0.9591836734693877, 'nid': -0.25045162747753613, 'grammatical_errors': 1, 'pegasus_entailment': 0.2587167024612427, 'gold_entailment': 0.13513974752277136, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 301
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 38.14 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.35777126099706746, 'r1_recall': 0.7439024390243902, 'r1_f1': 0.48316831683168326, 'r2_precision': 0.17058823529411765, 'r2_recall': 0.3558282208588957, 'r2_f1': 0.23061630218687873, 'rL_precision': 0.17595307917888564, 'rL_recall': 0.36585365853658536, 'rL_f1': 0.23762376237623767, 'bs_precision': 0.2852482795715332, 'bs_recall': 0.4404856860637665, 'bs_f1': 0.36000537872314453, 'bs_mnli_precision': 0.6323552131652832, 'bs_mnli_recall': 0.7182551622390747, 'bs_mnli_f1': 0.6725735664367676, 'unique_bigram_ratio': 0.8821752265861027, 'nid': -0.15016471598899717, 'grammatical_errors': 1, 'pegasus_entailment': 0.548669173485703, 'gold_entailment': 0.43501041643321514, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 302
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.35 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6178010471204188, 'r1_recall': 0.5870646766169154, 'r1_f1': 0.6020408163265306, 'r2_precision': 0.3684210526315789, 'r2_recall': 0.35, 'r2_f1': 0.358974358974359, 'rL_precision': 0.39267015706806285, 'rL_recall': 0.373134328358209, 'rL_f1': 0.3826530612244899, 'bs_precision': 0.4762873649597168, 'bs_recall': 0.41892316937446594, 'bs_f1': 0.44885334372520447, 'bs_mnli_precision': 0.7215652465820312, 'bs_mnli_recall': 0.7023146152496338, 'bs_mnli_f1': 0.7118098139762878, 'unique_bigram_ratio': 0.9629629629629629, 'nid': -0.23202011661738786, 'grammatical_errors': 2, 'pegasus_entailment': 0.6205674678087234, 'gold_entailment': 0.34605237399227917, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 303
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.02 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.28272251308900526, 'r1_recall': 0.54, 'r1_f1': 0.37113402061855677, 'r2_precision': 0.08421052631578947, 'r2_recall': 0.16161616161616163, 'r2_f1': 0.11072664359861592, 'rL_precision': 0.17801047120418848, 'rL_recall': 0.34, 'rL_f1': 0.23367697594501718, 'bs_precision': 0.1964682638645172, 'bs_recall': 0.3013724684715271, 'bs_f1': 0.24894112348556519, 'bs_mnli_precision': 0.5728674530982971, 'bs_mnli_recall': 0.6351391673088074, 'bs_mnli_f1': 0.6023982763290405, 'unique_bigram_ratio': 0.9518716577540107, 'nid': -0.2321439828600631, 'grammatical_errors': 5, 'pegasus_entailment': 0.40472280730803806, 'gold_entailment': 0.3554480771223704, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 304
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.66 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.408, 'r1_recall': 0.6375, 'r1_f1': 0.49756097560975604, 'r2_precision': 0.20161290322580644, 'r2_recall': 0.31645569620253167, 'r2_f1': 0.24630541871921183, 'rL_precision': 0.312, 'rL_recall': 0.4875, 'rL_f1': 0.38048780487804873, 'bs_precision': 0.43631863594055176, 'bs_recall': 0.5146033763885498, 'bs_f1': 0.4760812222957611, 'bs_mnli_precision': 0.6821519136428833, 'bs_mnli_recall': 0.7310732007026672, 'bs_mnli_f1': 0.7057657837867737, 'unique_bigram_ratio': 0.9583333333333334, 'nid': -0.24985681735972554, 'grammatical_errors': 0, 'pegasus_entailment': 0.2002795549109578, 'gold_entailment': 0.21609134723742804, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 305
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.72 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2953020134228188, 'r1_recall': 0.5365853658536586, 'r1_f1': 0.38095238095238093, 'r2_precision': 0.14189189189189189, 'r2_recall': 0.25925925925925924, 'r2_f1': 0.1834061135371179, 'rL_precision': 0.20134228187919462, 'rL_recall': 0.36585365853658536, 'rL_f1': 0.2597402597402597, 'bs_precision': 0.2761886417865753, 'bs_recall': 0.4462363123893738, 'bs_f1': 0.3573414385318756, 'bs_mnli_precision': 0.5966211557388306, 'bs_mnli_recall': 0.690927267074585, 'bs_mnli_f1': 0.6403204798698425, 'unique_bigram_ratio': 0.9724137931034482, 'nid': -0.3024710229708014, 'grammatical_errors': 0, 'pegasus_entailment': 0.4502349626272917, 'gold_entailment': 0.1756998689379543, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 306
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 37.64 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.08683473389355742, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.1530864197530864, 'r2_precision': 0.033707865168539325, 'r2_recall': 0.2553191489361702, 'r2_f1': 0.059553349875930514, 'rL_precision': 0.06162464985994398, 'rL_recall': 0.4583333333333333, 'rL_f1': 0.10864197530864199, 'bs_precision': 0.030273526906967163, 'bs_recall': 0.339182049036026, 'bs_f1': 0.1640724092721939, 'bs_mnli_precision': 0.494970440864563, 'bs_mnli_recall': 0.6680520176887512, 'bs_mnli_f1': 0.568632185459137, 'unique_bigram_ratio': 0.8505747126436781, 'nid': -0.14291611891890832, 'grammatical_errors': 5, 'pegasus_entailment': 0.4682857405083875, 'gold_entailment': 0.34639371434847516, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 307
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.69 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24817518248175183, 'r1_recall': 0.5396825396825397, 'r1_f1': 0.33999999999999997, 'r2_precision': 0.10294117647058823, 'r2_recall': 0.22580645161290322, 'r2_f1': 0.1414141414141414, 'rL_precision': 0.1678832116788321, 'rL_recall': 0.36507936507936506, 'rL_f1': 0.22999999999999998, 'bs_precision': 0.22023922204971313, 'bs_recall': 0.4192056953907013, 'bs_f1': 0.3134613037109375, 'bs_mnli_precision': 0.5948693752288818, 'bs_mnli_recall': 0.6652168035507202, 'bs_mnli_f1': 0.6280794739723206, 'unique_bigram_ratio': 0.9770992366412213, 'nid': -0.30192723095603013, 'grammatical_errors': 2, 'pegasus_entailment': 0.7115943680206934, 'gold_entailment': 0.20981659243504205, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 308
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 78.81 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.17592592592592593, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.2676056338028169, 'r2_precision': 0.102803738317757, 'r2_recall': 0.3333333333333333, 'r2_f1': 0.15714285714285714, 'rL_precision': 0.16666666666666666, 'rL_recall': 0.5294117647058824, 'rL_f1': 0.2535211267605634, 'bs_precision': 0.1747058480978012, 'bs_recall': 0.4887740910053253, 'bs_f1': 0.312859445810318, 'bs_mnli_precision': 0.5856558084487915, 'bs_mnli_recall': 0.7351627349853516, 'bs_mnli_f1': 0.6519477367401123, 'unique_bigram_ratio': 0.9902912621359223, 'nid': -0.31531685012029564, 'grammatical_errors': 0, 'pegasus_entailment': 0.5261463448405266, 'gold_entailment': 0.2944624647498131, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 309
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.02 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24358974358974358, 'r1_recall': 0.5, 'r1_f1': 0.3275862068965517, 'r2_precision': 0.07096774193548387, 'r2_recall': 0.14666666666666667, 'r2_f1': 0.09565217391304347, 'rL_precision': 0.15384615384615385, 'rL_recall': 0.3157894736842105, 'rL_f1': 0.20689655172413793, 'bs_precision': 0.1490001082420349, 'bs_recall': 0.2888718247413635, 'bs_f1': 0.2169521152973175, 'bs_mnli_precision': 0.5323679447174072, 'bs_mnli_recall': 0.6069064140319824, 'bs_mnli_f1': 0.5671988129615784, 'unique_bigram_ratio': 0.9006622516556292, 'nid': -0.2010904487778311, 'grammatical_errors': 2, 'pegasus_entailment': 0.38499131202697756, 'gold_entailment': 0.1278301477432251, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 310
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.45 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6518987341772152, 'r1_recall': 0.5597826086956522, 'r1_f1': 0.6023391812865497, 'r2_precision': 0.3630573248407643, 'r2_recall': 0.3114754098360656, 'r2_f1': 0.3352941176470588, 'rL_precision': 0.45569620253164556, 'rL_recall': 0.391304347826087, 'rL_f1': 0.4210526315789474, 'bs_precision': 0.4677291810512543, 'bs_recall': 0.42796507477760315, 'bs_f1': 0.44942712783813477, 'bs_mnli_precision': 0.7396641969680786, 'bs_mnli_recall': 0.702567458152771, 'bs_mnli_f1': 0.7206387519836426, 'unique_bigram_ratio': 0.9337748344370861, 'nid': -0.2406588606518283, 'grammatical_errors': 1, 'pegasus_entailment': 0.485971637070179, 'gold_entailment': 0.3659604012966156, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 311
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 71.58 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.38235294117647056, 'r1_recall': 0.582089552238806, 'r1_f1': 0.4615384615384615, 'r2_precision': 0.10891089108910891, 'r2_recall': 0.16666666666666666, 'r2_f1': 0.13173652694610777, 'rL_precision': 0.24509803921568626, 'rL_recall': 0.373134328358209, 'rL_f1': 0.2958579881656805, 'bs_precision': 0.38623541593551636, 'bs_recall': 0.5644112229347229, 'bs_f1': 0.4710514545440674, 'bs_mnli_precision': 0.6536277532577515, 'bs_mnli_recall': 0.726811408996582, 'bs_mnli_f1': 0.6882796883583069, 'unique_bigram_ratio': 0.9896907216494846, 'nid': -0.3013507605575614, 'grammatical_errors': 1, 'pegasus_entailment': 0.5428649559617043, 'gold_entailment': 0.4458993971347809, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 312
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.44 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.44642857142857145, 'r1_f1': 0.5208333333333334, 'r2_precision': 0.24369747899159663, 'r2_recall': 0.17365269461077845, 'r2_f1': 0.20279720279720279, 'rL_precision': 0.35833333333333334, 'rL_recall': 0.25595238095238093, 'rL_f1': 0.29861111111111105, 'bs_precision': 0.43190646171569824, 'bs_recall': 0.3453938961029053, 'bs_f1': 0.3892126977443695, 'bs_mnli_precision': 0.6850243806838989, 'bs_mnli_recall': 0.636437714099884, 'bs_mnli_f1': 0.6598377823829651, 'unique_bigram_ratio': 1.0, 'nid': -0.2545926146301918, 'grammatical_errors': 2, 'pegasus_entailment': 0.35281459242105484, 'gold_entailment': 0.4122570678591728, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 313
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.96 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4329268292682927, 'r1_recall': 0.5378787878787878, 'r1_f1': 0.47972972972972977, 'r2_precision': 0.18404907975460122, 'r2_recall': 0.22900763358778625, 'r2_f1': 0.2040816326530612, 'rL_precision': 0.2621951219512195, 'rL_recall': 0.32575757575757575, 'rL_f1': 0.29054054054054057, 'bs_precision': 0.34512796998023987, 'bs_recall': 0.35399627685546875, 'bs_f1': 0.351767897605896, 'bs_mnli_precision': 0.6597073078155518, 'bs_mnli_recall': 0.6719951033592224, 'bs_mnli_f1': 0.6657944917678833, 'unique_bigram_ratio': 0.930379746835443, 'nid': -0.2152229858065009, 'grammatical_errors': 5, 'pegasus_entailment': 0.40106827517350513, 'gold_entailment': 0.38262936659157276, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 314
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.35 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5777777777777777, 'r1_recall': 0.4936708860759494, 'r1_f1': 0.5324232081911263, 'r2_precision': 0.2537313432835821, 'r2_recall': 0.21656050955414013, 'r2_f1': 0.23367697594501718, 'rL_precision': 0.3037037037037037, 'rL_recall': 0.25949367088607594, 'rL_f1': 0.27986348122866894, 'bs_precision': 0.3640243411064148, 'bs_recall': 0.35651978850364685, 'bs_f1': 0.362446665763855, 'bs_mnli_precision': 0.6500599980354309, 'bs_mnli_recall': 0.6510859727859497, 'bs_mnli_f1': 0.6505725383758545, 'unique_bigram_ratio': 0.9398496240601504, 'nid': -0.24762079718241603, 'grammatical_errors': 1, 'pegasus_entailment': 0.48872601687908174, 'gold_entailment': 0.5300308257341385, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 315
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 39.79 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6933333333333334, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.4663677130044843, 'r2_precision': 0.3825503355704698, 'r2_recall': 0.19322033898305085, 'r2_f1': 0.25675675675675674, 'rL_precision': 0.4, 'rL_recall': 0.20270270270270271, 'rL_f1': 0.26905829596412556, 'bs_precision': 0.3840745985507965, 'bs_recall': 0.2531178891658783, 'bs_f1': 0.317210853099823, 'bs_mnli_precision': 0.6947612762451172, 'bs_mnli_recall': 0.6037665605545044, 'bs_mnli_f1': 0.6460756659507751, 'unique_bigram_ratio': 0.9370629370629371, 'nid': -0.21831195803201475, 'grammatical_errors': 0, 'pegasus_entailment': 0.5033369532653263, 'gold_entailment': 0.32197340291280013, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 316
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 68.01 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3007518796992481, 'r1_recall': 0.7272727272727273, 'r1_f1': 0.425531914893617, 'r2_precision': 0.13636363636363635, 'r2_recall': 0.3333333333333333, 'r2_f1': 0.1935483870967742, 'rL_precision': 0.21052631578947367, 'rL_recall': 0.509090909090909, 'rL_f1': 0.2978723404255319, 'bs_precision': 0.2502351701259613, 'bs_recall': 0.5733431577682495, 'bs_f1': 0.39284375309944153, 'bs_mnli_precision': 0.5902077555656433, 'bs_mnli_recall': 0.7690224647521973, 'bs_mnli_f1': 0.6678529977798462, 'unique_bigram_ratio': 0.967479674796748, 'nid': -0.26587063518601894, 'grammatical_errors': 6, 'pegasus_entailment': 0.4083272278308868, 'gold_entailment': 0.48821277419726056, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 13, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 317
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.32 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5137614678899083, 'r1_recall': 0.5685279187817259, 'r1_f1': 0.5397590361445784, 'r2_precision': 0.24423963133640553, 'r2_recall': 0.27040816326530615, 'r2_f1': 0.2566585956416465, 'rL_precision': 0.25229357798165136, 'rL_recall': 0.27918781725888325, 'rL_f1': 0.2650602409638554, 'bs_precision': 0.3162775933742523, 'bs_recall': 0.31399300694465637, 'bs_f1': 0.3174745738506317, 'bs_mnli_precision': 0.6428245306015015, 'bs_mnli_recall': 0.6341489553451538, 'bs_mnli_f1': 0.6384572982788086, 'unique_bigram_ratio': 0.9285714285714286, 'nid': -0.21208042845336972, 'grammatical_errors': 0, 'pegasus_entailment': 0.49352571591734884, 'gold_entailment': 0.4695510317881902, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 318
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.61 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.23783783783783785, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.35918367346938773, 'r2_precision': 0.08695652173913043, 'r2_recall': 0.2711864406779661, 'r2_f1': 0.13168724279835392, 'rL_precision': 0.13513513513513514, 'rL_recall': 0.4166666666666667, 'rL_f1': 0.20408163265306126, 'bs_precision': 0.21911370754241943, 'bs_recall': 0.4456615149974823, 'bs_f1': 0.32366040349006653, 'bs_mnli_precision': 0.5733775496482849, 'bs_mnli_recall': 0.7064937353134155, 'bs_mnli_f1': 0.633013129234314, 'unique_bigram_ratio': 0.9162011173184358, 'nid': -0.188196947199609, 'grammatical_errors': 2, 'pegasus_entailment': 0.5807813008626302, 'gold_entailment': 0.538555383682251, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 319
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 68.80 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.45161290322580644, 'r1_recall': 0.45528455284552843, 'r1_f1': 0.4534412955465587, 'r2_precision': 0.13008130081300814, 'r2_recall': 0.13114754098360656, 'r2_f1': 0.1306122448979592, 'rL_precision': 0.2661290322580645, 'rL_recall': 0.2682926829268293, 'rL_f1': 0.2672064777327935, 'bs_precision': 0.3861783742904663, 'bs_recall': 0.3451043665409088, 'bs_f1': 0.367459237575531, 'bs_mnli_precision': 0.6750824451446533, 'bs_mnli_recall': 0.6470297574996948, 'bs_mnli_f1': 0.6607584953308105, 'unique_bigram_ratio': 0.9426229508196722, 'nid': -0.2501817922907381, 'grammatical_errors': 0, 'pegasus_entailment': 0.41123381576367785, 'gold_entailment': 0.3929012045264244, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 320
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.09 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.47651006711409394, 'r1_recall': 0.6761904761904762, 'r1_f1': 0.5590551181102362, 'r2_precision': 0.2702702702702703, 'r2_recall': 0.38461538461538464, 'r2_f1': 0.31746031746031744, 'rL_precision': 0.28859060402684567, 'rL_recall': 0.4095238095238095, 'rL_f1': 0.33858267716535434, 'bs_precision': 0.42522546648979187, 'bs_recall': 0.5369076132774353, 'bs_f1': 0.48046597838401794, 'bs_mnli_precision': 0.6778166890144348, 'bs_mnli_recall': 0.749640703201294, 'bs_mnli_f1': 0.7119218111038208, 'unique_bigram_ratio': 0.9657534246575342, 'nid': -0.2647103545933256, 'grammatical_errors': 5, 'pegasus_entailment': 0.6423275843262672, 'gold_entailment': 0.4459916154543559, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 321
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.97 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6212121212121212, 'r1_recall': 0.6259541984732825, 'r1_f1': 0.623574144486692, 'r2_precision': 0.31297709923664124, 'r2_recall': 0.3153846153846154, 'r2_f1': 0.314176245210728, 'rL_precision': 0.3560606060606061, 'rL_recall': 0.35877862595419846, 'rL_f1': 0.3574144486692016, 'bs_precision': 0.43193763494491577, 'bs_recall': 0.44454866647720337, 'bs_f1': 0.4401310086250305, 'bs_mnli_precision': 0.7003346681594849, 'bs_mnli_recall': 0.6960029602050781, 'bs_mnli_f1': 0.6981621384620667, 'unique_bigram_ratio': 0.9612403100775194, 'nid': -0.22188241343630932, 'grammatical_errors': 2, 'pegasus_entailment': 0.47282823324203493, 'gold_entailment': 0.5844258069992065, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 322
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.06 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.20398009950248755, 'r1_recall': 0.6119402985074627, 'r1_f1': 0.30597014925373134, 'r2_precision': 0.075, 'r2_recall': 0.22727272727272727, 'r2_f1': 0.11278195488721805, 'rL_precision': 0.11442786069651742, 'rL_recall': 0.34328358208955223, 'rL_f1': 0.17164179104477612, 'bs_precision': 0.2057708352804184, 'bs_recall': 0.4142935574054718, 'bs_f1': 0.30287981033325195, 'bs_mnli_precision': 0.5489403009414673, 'bs_mnli_recall': 0.6647059917449951, 'bs_mnli_f1': 0.601301908493042, 'unique_bigram_ratio': 0.9427083333333334, 'nid': -0.21659533143161624, 'grammatical_errors': 2, 'pegasus_entailment': 0.5039362396512713, 'gold_entailment': 0.19999108215173086, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 323
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.69 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.22448979591836735, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.32352941176470584, 'r2_precision': 0.04794520547945205, 'r2_recall': 0.125, 'r2_f1': 0.0693069306930693, 'rL_precision': 0.11564625850340136, 'rL_recall': 0.2982456140350877, 'rL_f1': 0.16666666666666666, 'bs_precision': 0.1190667524933815, 'bs_recall': 0.2636219263076782, 'bs_f1': 0.18900391459465027, 'bs_mnli_precision': 0.5459989905357361, 'bs_mnli_recall': 0.6244362592697144, 'bs_mnli_f1': 0.5825894474983215, 'unique_bigram_ratio': 0.971830985915493, 'nid': -0.25325314039238633, 'grammatical_errors': 2, 'pegasus_entailment': 0.24183583669364453, 'gold_entailment': 0.3412640392780304, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 324
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.45 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.22346368715083798, 'r1_recall': 0.7017543859649122, 'r1_f1': 0.3389830508474576, 'r2_precision': 0.07865168539325842, 'r2_recall': 0.25, 'r2_f1': 0.11965811965811966, 'rL_precision': 0.12849162011173185, 'rL_recall': 0.40350877192982454, 'rL_f1': 0.19491525423728814, 'bs_precision': 0.20572413504123688, 'bs_recall': 0.4832557141780853, 'bs_f1': 0.33038175106048584, 'bs_mnli_precision': 0.5682616829872131, 'bs_mnli_recall': 0.6935454607009888, 'bs_mnli_f1': 0.6246838569641113, 'unique_bigram_ratio': 0.9425287356321839, 'nid': -0.22593772206835894, 'grammatical_errors': 0, 'pegasus_entailment': 0.4685038762787978, 'gold_entailment': 0.4279245287179947, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 325
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 44.79 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3426294820717131, 'r1_recall': 0.671875, 'r1_f1': 0.45382585751978893, 'r2_precision': 0.14, 'r2_recall': 0.2755905511811024, 'r2_f1': 0.18567639257294433, 'rL_precision': 0.18725099601593626, 'rL_recall': 0.3671875, 'rL_f1': 0.2480211081794195, 'bs_precision': 0.2516756057739258, 'bs_recall': 0.33285224437713623, 'bs_f1': 0.29321610927581787, 'bs_mnli_precision': 0.6097120046615601, 'bs_mnli_recall': 0.6569798588752747, 'bs_mnli_f1': 0.6324639916419983, 'unique_bigram_ratio': 0.9102040816326531, 'nid': -0.17977579445074388, 'grammatical_errors': 3, 'pegasus_entailment': 0.3430341720581055, 'gold_entailment': 0.26117296516895294, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 326
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.87 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4681818181818182, 'r1_recall': 0.5786516853932584, 'r1_f1': 0.5175879396984925, 'r2_precision': 0.1689497716894977, 'r2_recall': 0.20903954802259886, 'r2_f1': 0.18686868686868682, 'rL_precision': 0.2590909090909091, 'rL_recall': 0.3202247191011236, 'rL_f1': 0.2864321608040202, 'bs_precision': 0.2703365981578827, 'bs_recall': 0.3111369013786316, 'bs_f1': 0.29278865456581116, 'bs_mnli_precision': 0.6265580058097839, 'bs_mnli_recall': 0.6361000537872314, 'bs_mnli_f1': 0.6312929391860962, 'unique_bigram_ratio': 0.9481132075471698, 'nid': -0.23727773916186856, 'grammatical_errors': 8, 'pegasus_entailment': 0.4869925156235695, 'gold_entailment': 0.40572436451911925, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 327
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.59 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6484375, 'r1_recall': 0.50920245398773, 'r1_f1': 0.570446735395189, 'r2_precision': 0.28346456692913385, 'r2_recall': 0.2222222222222222, 'r2_f1': 0.2491349480968858, 'rL_precision': 0.390625, 'rL_recall': 0.3067484662576687, 'rL_f1': 0.3436426116838488, 'bs_precision': 0.40702274441719055, 'bs_recall': 0.33855748176574707, 'bs_f1': 0.3739653527736664, 'bs_mnli_precision': 0.708734393119812, 'bs_mnli_recall': 0.6585456132888794, 'bs_mnli_f1': 0.6827188730239868, 'unique_bigram_ratio': 0.9758064516129032, 'nid': -0.21134995208918728, 'grammatical_errors': 1, 'pegasus_entailment': 0.24616081586905889, 'gold_entailment': 0.22490210756659507, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 328
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 38.60 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4146341463414634, 'r1_recall': 0.616580310880829, 'r1_f1': 0.49583333333333335, 'r2_precision': 0.1958041958041958, 'r2_recall': 0.2916666666666667, 'r2_f1': 0.23430962343096234, 'rL_precision': 0.23344947735191637, 'rL_recall': 0.3471502590673575, 'rL_f1': 0.2791666666666667, 'bs_precision': 0.3733525574207306, 'bs_recall': 0.4603378474712372, 'bs_f1': 0.41732290387153625, 'bs_mnli_precision': 0.6474262475967407, 'bs_mnli_recall': 0.6930813193321228, 'bs_mnli_f1': 0.669476330280304, 'unique_bigram_ratio': 0.9113475177304965, 'nid': -0.1716965730246276, 'grammatical_errors': 0, 'pegasus_entailment': 0.6491242974168725, 'gold_entailment': 0.5153234650691351, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 329
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.50 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.38562091503267976, 'r1_recall': 0.5841584158415841, 'r1_f1': 0.4645669291338583, 'r2_precision': 0.18421052631578946, 'r2_recall': 0.28, 'r2_f1': 0.2222222222222222, 'rL_precision': 0.24183006535947713, 'rL_recall': 0.36633663366336633, 'rL_f1': 0.29133858267716534, 'bs_precision': 0.3529800772666931, 'bs_recall': 0.4554455578327179, 'bs_f1': 0.4041255712509155, 'bs_mnli_precision': 0.6575107574462891, 'bs_mnli_recall': 0.7033295631408691, 'bs_mnli_f1': 0.6796488165855408, 'unique_bigram_ratio': 0.9315068493150684, 'nid': -0.19274409395436098, 'grammatical_errors': 2, 'pegasus_entailment': 0.5172333955764771, 'gold_entailment': 0.15844962745904922, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 330
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.16 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.29239766081871343, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.39215686274509803, 'r2_precision': 0.11176470588235295, 'r2_recall': 0.2289156626506024, 'r2_f1': 0.15019762845849802, 'rL_precision': 0.1695906432748538, 'rL_recall': 0.34523809523809523, 'rL_f1': 0.22745098039215683, 'bs_precision': 0.22901742160320282, 'bs_recall': 0.3550994098186493, 'bs_f1': 0.29094281792640686, 'bs_mnli_precision': 0.6025874614715576, 'bs_mnli_recall': 0.669003427028656, 'bs_mnli_f1': 0.6340609192848206, 'unique_bigram_ratio': 0.9289940828402367, 'nid': -0.233965446762741, 'grammatical_errors': 1, 'pegasus_entailment': 0.517059016196678, 'gold_entailment': 0.36856448696926236, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 331
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.53 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2648401826484018, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.37540453074433655, 'r2_precision': 0.11926605504587157, 'r2_recall': 0.29213483146067415, 'r2_f1': 0.1693811074918567, 'rL_precision': 0.1689497716894977, 'rL_recall': 0.4111111111111111, 'rL_f1': 0.23948220064724918, 'bs_precision': 0.18422101438045502, 'bs_recall': 0.4293300211429596, 'bs_f1': 0.2959684431552887, 'bs_mnli_precision': 0.5635779500007629, 'bs_mnli_recall': 0.6777452826499939, 'bs_mnli_f1': 0.6154115200042725, 'unique_bigram_ratio': 0.9342723004694836, 'nid': -0.21096209421540535, 'grammatical_errors': 1, 'pegasus_entailment': 0.5841473937034607, 'gold_entailment': 0.7721721728642782, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 332
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.62 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.20437956204379562, 'r1_recall': 0.5490196078431373, 'r1_f1': 0.2978723404255319, 'r2_precision': 0.058823529411764705, 'r2_recall': 0.16, 'r2_f1': 0.08602150537634409, 'rL_precision': 0.12408759124087591, 'rL_recall': 0.3333333333333333, 'rL_f1': 0.18085106382978722, 'bs_precision': 0.2561741769313812, 'bs_recall': 0.40254300832748413, 'bs_f1': 0.32704097032546997, 'bs_mnli_precision': 0.6004263162612915, 'bs_mnli_recall': 0.6646406054496765, 'bs_mnli_f1': 0.6309037208557129, 'unique_bigram_ratio': 0.9555555555555556, 'nid': -0.2512426083846824, 'grammatical_errors': 2, 'pegasus_entailment': 0.6013660311698914, 'gold_entailment': 0.439644530415535, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 333
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.88 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.423841059602649, 'r1_recall': 0.43243243243243246, 'r1_f1': 0.4280936454849499, 'r2_precision': 0.24666666666666667, 'r2_recall': 0.25170068027210885, 'r2_f1': 0.24915824915824916, 'rL_precision': 0.2980132450331126, 'rL_recall': 0.30405405405405406, 'rL_f1': 0.3010033444816053, 'bs_precision': 0.2801383137702942, 'bs_recall': 0.31500494480133057, 'bs_f1': 0.29970189929008484, 'bs_mnli_precision': 0.6095480918884277, 'bs_mnli_recall': 0.6469182968139648, 'bs_mnli_f1': 0.6276774406433105, 'unique_bigram_ratio': 0.9657534246575342, 'nid': -0.2623448248005924, 'grammatical_errors': 2, 'pegasus_entailment': 0.6373810410499573, 'gold_entailment': 0.1910469446863447, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 334
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.10 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3891625615763547, 'r1_recall': 0.6030534351145038, 'r1_f1': 0.47305389221556887, 'r2_precision': 0.18811881188118812, 'r2_recall': 0.2923076923076923, 'r2_f1': 0.2289156626506024, 'rL_precision': 0.2512315270935961, 'rL_recall': 0.3893129770992366, 'rL_f1': 0.30538922155688625, 'bs_precision': 0.24993488192558289, 'bs_recall': 0.3690803050994873, 'bs_f1': 0.30875876545906067, 'bs_mnli_precision': 0.609505832195282, 'bs_mnli_recall': 0.6538606882095337, 'bs_mnli_f1': 0.6309046745300293, 'unique_bigram_ratio': 0.9238578680203046, 'nid': -0.21017036023920377, 'grammatical_errors': 2, 'pegasus_entailment': 0.3995095586234873, 'gold_entailment': 0.3321390748023987, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 335
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 59.86 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6559139784946236, 'r1_recall': 0.5169491525423728, 'r1_f1': 0.5781990521327014, 'r2_precision': 0.3804347826086957, 'r2_recall': 0.29914529914529914, 'r2_f1': 0.3349282296650718, 'rL_precision': 0.3978494623655914, 'rL_recall': 0.3135593220338983, 'rL_f1': 0.35071090047393366, 'bs_precision': 0.6086773872375488, 'bs_recall': 0.5145811438560486, 'bs_f1': 0.5615452527999878, 'bs_mnli_precision': 0.7706796526908875, 'bs_mnli_recall': 0.7138268947601318, 'bs_mnli_f1': 0.7411645650863647, 'unique_bigram_ratio': 0.9560439560439561, 'nid': -0.27217840321043174, 'grammatical_errors': 0, 'pegasus_entailment': 0.4182204470038414, 'gold_entailment': 0.3016773983836174, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 336
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.91 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5413533834586466, 'r1_recall': 0.5538461538461539, 'r1_f1': 0.5475285171102662, 'r2_precision': 0.25, 'r2_recall': 0.2558139534883721, 'r2_f1': 0.25287356321839083, 'rL_precision': 0.2932330827067669, 'rL_recall': 0.3, 'rL_f1': 0.2965779467680608, 'bs_precision': 0.46383556723594666, 'bs_recall': 0.5000293254852295, 'bs_f1': 0.48345279693603516, 'bs_mnli_precision': 0.68526291847229, 'bs_mnli_recall': 0.7119252681732178, 'bs_mnli_f1': 0.6983397006988525, 'unique_bigram_ratio': 0.9609375, 'nid': -0.23345279200051516, 'grammatical_errors': 2, 'pegasus_entailment': 0.2382226437330246, 'gold_entailment': 0.21903600096702575, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 337
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.58 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4166666666666667, 'r1_recall': 0.42016806722689076, 'r1_f1': 0.4184100418410042, 'r2_precision': 0.11764705882352941, 'r2_recall': 0.11864406779661017, 'r2_f1': 0.11814345991561181, 'rL_precision': 0.21666666666666667, 'rL_recall': 0.2184873949579832, 'rL_f1': 0.21757322175732216, 'bs_precision': 0.22026397287845612, 'bs_recall': 0.2393372654914856, 'bs_f1': 0.23234625160694122, 'bs_mnli_precision': 0.5897387862205505, 'bs_mnli_recall': 0.5737802982330322, 'bs_mnli_f1': 0.5816500782966614, 'unique_bigram_ratio': 0.9576271186440678, 'nid': -0.2676534941587314, 'grammatical_errors': 0, 'pegasus_entailment': 0.44240084290504456, 'gold_entailment': 0.449555279687047, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 338
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.09 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6302521008403361, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.5703422053231938, 'r2_precision': 0.4152542372881356, 'r2_recall': 0.34265734265734266, 'r2_f1': 0.37547892720306514, 'rL_precision': 0.44537815126050423, 'rL_recall': 0.3680555555555556, 'rL_f1': 0.4030418250950571, 'bs_precision': 0.514607846736908, 'bs_recall': 0.4531581401824951, 'bs_f1': 0.4849328398704529, 'bs_mnli_precision': 0.73833167552948, 'bs_mnli_recall': 0.6956779956817627, 'bs_mnli_f1': 0.7163705229759216, 'unique_bigram_ratio': 0.9658119658119658, 'nid': -0.24363705955220838, 'grammatical_errors': 0, 'pegasus_entailment': 0.5747866183519363, 'gold_entailment': 0.6909903407096862, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 339
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.97 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.31693989071038253, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.42490842490842495, 'r2_precision': 0.14835164835164835, 'r2_recall': 0.30337078651685395, 'r2_f1': 0.19926199261992622, 'rL_precision': 0.21311475409836064, 'rL_recall': 0.43333333333333335, 'rL_f1': 0.2857142857142857, 'bs_precision': 0.30789220333099365, 'bs_recall': 0.447448194026947, 'bs_f1': 0.3757740259170532, 'bs_mnli_precision': 0.6313864588737488, 'bs_mnli_recall': 0.7040294408798218, 'bs_mnli_f1': 0.665732204914093, 'unique_bigram_ratio': 0.9415204678362573, 'nid': -0.2399761470998485, 'grammatical_errors': 3, 'pegasus_entailment': 0.5040743883166995, 'gold_entailment': 0.14618210680782795, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 340
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 59.88 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.31645569620253167, 'r1_recall': 0.37593984962406013, 'r1_f1': 0.3436426116838488, 'r2_precision': 0.08280254777070063, 'r2_recall': 0.09848484848484848, 'r2_f1': 0.08996539792387542, 'rL_precision': 0.16455696202531644, 'rL_recall': 0.19548872180451127, 'rL_f1': 0.17869415807560138, 'bs_precision': 0.18815922737121582, 'bs_recall': 0.21589238941669464, 'bs_f1': 0.20456556975841522, 'bs_mnli_precision': 0.5615856647491455, 'bs_mnli_recall': 0.5736905336380005, 'bs_mnli_f1': 0.5675735473632812, 'unique_bigram_ratio': 0.9411764705882353, 'nid': -0.22880031868096262, 'grammatical_errors': 2, 'pegasus_entailment': 0.39536995589733126, 'gold_entailment': 0.25148168578743935, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 341
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 43.30 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4576271186440678, 'r1_recall': 0.5094339622641509, 'r1_f1': 0.48214285714285715, 'r2_precision': 0.14893617021276595, 'r2_recall': 0.16587677725118483, 'r2_f1': 0.1569506726457399, 'rL_precision': 0.2584745762711864, 'rL_recall': 0.28773584905660377, 'rL_f1': 0.27232142857142855, 'bs_precision': 0.3304362893104553, 'bs_recall': 0.36503270268440247, 'bs_f1': 0.3497089445590973, 'bs_mnli_precision': 0.6381803750991821, 'bs_mnli_recall': 0.6619081497192383, 'bs_mnli_f1': 0.6498277187347412, 'unique_bigram_ratio': 0.9439655172413793, 'nid': -0.2361812364042979, 'grammatical_errors': 4, 'pegasus_entailment': 0.36795162260532377, 'gold_entailment': 0.22175065167248248, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 342
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.04 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.22077922077922077, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.3222748815165877, 'r2_precision': 0.0784313725490196, 'r2_recall': 0.21428571428571427, 'r2_f1': 0.11483253588516748, 'rL_precision': 0.14935064935064934, 'rL_recall': 0.40350877192982454, 'rL_f1': 0.21800947867298578, 'bs_precision': 0.23833656311035156, 'bs_recall': 0.487054705619812, 'bs_f1': 0.3519430160522461, 'bs_mnli_precision': 0.5797322988510132, 'bs_mnli_recall': 0.7155347466468811, 'bs_mnli_f1': 0.6405143737792969, 'unique_bigram_ratio': 0.959731543624161, 'nid': -0.2203709372765894, 'grammatical_errors': 2, 'pegasus_entailment': 0.537688460201025, 'gold_entailment': 0.5792497098445892, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 343
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.70 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.46405228758169936, 'r1_recall': 0.5546875, 'r1_f1': 0.5053380782918149, 'r2_precision': 0.20394736842105263, 'r2_recall': 0.2440944881889764, 'r2_f1': 0.2222222222222222, 'rL_precision': 0.27450980392156865, 'rL_recall': 0.328125, 'rL_f1': 0.29893238434163705, 'bs_precision': 0.45386171340942383, 'bs_recall': 0.4491536021232605, 'bs_f1': 0.4533778131008148, 'bs_mnli_precision': 0.6979514360427856, 'bs_mnli_recall': 0.6954845190048218, 'bs_mnli_f1': 0.696715772151947, 'unique_bigram_ratio': 0.9798657718120806, 'nid': -0.26192690020621634, 'grammatical_errors': 6, 'pegasus_entailment': 0.5528441270192465, 'gold_entailment': 0.449563692510128, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 344
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.17 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.22346368715083798, 'r1_recall': 0.7017543859649122, 'r1_f1': 0.3389830508474576, 'r2_precision': 0.10112359550561797, 'r2_recall': 0.32142857142857145, 'r2_f1': 0.15384615384615385, 'rL_precision': 0.1564245810055866, 'rL_recall': 0.49122807017543857, 'rL_f1': 0.23728813559322032, 'bs_precision': 0.18617196381092072, 'bs_recall': 0.43613675236701965, 'bs_f1': 0.2998577952384949, 'bs_mnli_precision': 0.5600135922431946, 'bs_mnli_recall': 0.6842727661132812, 'bs_mnli_f1': 0.6159387230873108, 'unique_bigram_ratio': 0.9261363636363636, 'nid': -0.19878433855732114, 'grammatical_errors': 0, 'pegasus_entailment': 0.7050582936831883, 'gold_entailment': 0.48595885932445526, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 345
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.83 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5523809523809524, 'r1_recall': 0.6073298429319371, 'r1_f1': 0.5785536159600997, 'r2_precision': 0.20574162679425836, 'r2_recall': 0.22631578947368422, 'r2_f1': 0.2155388471177945, 'rL_precision': 0.2714285714285714, 'rL_recall': 0.29842931937172773, 'rL_f1': 0.28428927680798005, 'bs_precision': 0.3157564103603363, 'bs_recall': 0.3324704170227051, 'bs_f1': 0.32636207342147827, 'bs_mnli_precision': 0.6553456783294678, 'bs_mnli_recall': 0.6560192108154297, 'bs_mnli_f1': 0.6556822657585144, 'unique_bigram_ratio': 0.9704433497536946, 'nid': -0.22989583200406183, 'grammatical_errors': 0, 'pegasus_entailment': 0.5175316277891397, 'gold_entailment': 0.3887277692556381, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 346
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.50 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.62, 'r1_recall': 0.4217687074829932, 'r1_f1': 0.5020242914979757, 'r2_precision': 0.1919191919191919, 'r2_recall': 0.13013698630136986, 'r2_f1': 0.15510204081632653, 'rL_precision': 0.37, 'rL_recall': 0.25170068027210885, 'rL_f1': 0.2995951417004049, 'bs_precision': 0.4086727201938629, 'bs_recall': 0.33133020997047424, 'bs_f1': 0.37091559171676636, 'bs_mnli_precision': 0.7072035074234009, 'bs_mnli_recall': 0.6350811719894409, 'bs_mnli_f1': 0.6692047715187073, 'unique_bigram_ratio': 0.9583333333333334, 'nid': -0.2354147063983032, 'grammatical_errors': 1, 'pegasus_entailment': 0.5348706692457199, 'gold_entailment': 0.38513219108184177, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 347
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.30 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.48484848484848486, 'r1_recall': 0.5194805194805194, 'r1_f1': 0.5015673981191222, 'r2_precision': 0.18292682926829268, 'r2_recall': 0.19607843137254902, 'r2_f1': 0.1892744479495268, 'rL_precision': 0.24848484848484848, 'rL_recall': 0.2662337662337662, 'rL_f1': 0.25705329153605017, 'bs_precision': 0.39230141043663025, 'bs_recall': 0.3735962510108948, 'bs_f1': 0.3849862217903137, 'bs_mnli_precision': 0.6727672815322876, 'bs_mnli_recall': 0.6615486145019531, 'bs_mnli_f1': 0.667110800743103, 'unique_bigram_ratio': 0.9622641509433962, 'nid': -0.2539683694116295, 'grammatical_errors': 3, 'pegasus_entailment': 0.5365944548199574, 'gold_entailment': 0.182183900475502, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 348
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.77 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2810810810810811, 'r1_recall': 0.6933333333333334, 'r1_f1': 0.4, 'r2_precision': 0.09782608695652174, 'r2_recall': 0.24324324324324326, 'r2_f1': 0.13953488372093026, 'rL_precision': 0.17297297297297298, 'rL_recall': 0.4266666666666667, 'rL_f1': 0.24615384615384614, 'bs_precision': 0.21089062094688416, 'bs_recall': 0.46160048246383667, 'bs_f1': 0.32507750391960144, 'bs_mnli_precision': 0.5674690008163452, 'bs_mnli_recall': 0.7196561098098755, 'bs_mnli_f1': 0.6345654129981995, 'unique_bigram_ratio': 0.9364161849710982, 'nid': -0.23895345707587334, 'grammatical_errors': 3, 'pegasus_entailment': 0.5636773233612379, 'gold_entailment': 0.406603766605258, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 349
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.88 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.43137254901960786, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.49253731343283585, 'r2_precision': 0.19736842105263158, 'r2_recall': 0.2631578947368421, 'r2_f1': 0.22556390977443608, 'rL_precision': 0.23529411764705882, 'rL_recall': 0.3130434782608696, 'rL_f1': 0.26865671641791045, 'bs_precision': 0.27574262022972107, 'bs_recall': 0.3037138879299164, 'bs_f1': 0.2919800579547882, 'bs_mnli_precision': 0.6219217777252197, 'bs_mnli_recall': 0.6358946561813354, 'bs_mnli_f1': 0.62883061170578, 'unique_bigram_ratio': 0.9795918367346939, 'nid': -0.23784325005459173, 'grammatical_errors': 0, 'pegasus_entailment': 0.4616621737368405, 'gold_entailment': 0.2521680347621441, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 350
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.97 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5740740740740741, 'r1_recall': 0.40522875816993464, 'r1_f1': 0.47509578544061304, 'r2_precision': 0.17757009345794392, 'r2_recall': 0.125, 'r2_f1': 0.1467181467181467, 'rL_precision': 0.25925925925925924, 'rL_recall': 0.1830065359477124, 'rL_f1': 0.21455938697318008, 'bs_precision': 0.33995527029037476, 'bs_recall': 0.2863198518753052, 'bs_f1': 0.31486010551452637, 'bs_mnli_precision': 0.6631126403808594, 'bs_mnli_recall': 0.6130959391593933, 'bs_mnli_f1': 0.6371241211891174, 'unique_bigram_ratio': 0.9619047619047619, 'nid': -0.2599432485117539, 'grammatical_errors': 3, 'pegasus_entailment': 0.463765475153923, 'gold_entailment': 0.2466181144118309, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 351
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.91 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3835616438356164, 'r1_recall': 0.5490196078431373, 'r1_f1': 0.45161290322580644, 'r2_precision': 0.13793103448275862, 'r2_recall': 0.19801980198019803, 'r2_f1': 0.16260162601626016, 'rL_precision': 0.2671232876712329, 'rL_recall': 0.38235294117647056, 'rL_f1': 0.31451612903225806, 'bs_precision': 0.3674948215484619, 'bs_recall': 0.40806838870048523, 'bs_f1': 0.38953524827957153, 'bs_mnli_precision': 0.6764324903488159, 'bs_mnli_recall': 0.6775898337364197, 'bs_mnli_f1': 0.677010715007782, 'unique_bigram_ratio': 0.9652777777777778, 'nid': -0.22984656561416195, 'grammatical_errors': 1, 'pegasus_entailment': 0.5666819177567959, 'gold_entailment': 0.3959098719060421, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 352
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 68.33 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2642857142857143, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.3756345177664975, 'r2_precision': 0.11510791366906475, 'r2_recall': 0.2857142857142857, 'r2_f1': 0.1641025641025641, 'rL_precision': 0.21428571428571427, 'rL_recall': 0.5263157894736842, 'rL_f1': 0.3045685279187817, 'bs_precision': 0.21941226720809937, 'bs_recall': 0.4408894181251526, 'bs_f1': 0.3218979239463806, 'bs_mnli_precision': 0.6044338941574097, 'bs_mnli_recall': 0.7153114676475525, 'bs_mnli_f1': 0.6552150845527649, 'unique_bigram_ratio': 0.9202898550724637, 'nid': -0.18390117511586102, 'grammatical_errors': 1, 'pegasus_entailment': 0.4397714614868164, 'gold_entailment': 0.40786682566006977, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 353
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.76 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2631578947368421, 'r1_recall': 0.625, 'r1_f1': 0.37037037037037035, 'r2_precision': 0.12582781456953643, 'r2_recall': 0.30158730158730157, 'r2_f1': 0.17757009345794392, 'rL_precision': 0.19736842105263158, 'rL_recall': 0.46875, 'rL_f1': 0.2777777777777778, 'bs_precision': 0.20816083252429962, 'bs_recall': 0.3876439034938812, 'bs_f1': 0.2931789457798004, 'bs_mnli_precision': 0.6103484630584717, 'bs_mnli_recall': 0.6940340399742126, 'bs_mnli_f1': 0.649506688117981, 'unique_bigram_ratio': 0.9387755102040817, 'nid': -0.2657751360849072, 'grammatical_errors': 1, 'pegasus_entailment': 0.2933166798736368, 'gold_entailment': 0.38656931184232235, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 354
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.39 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.20087336244541484, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.3026315789473684, 'r2_precision': 0.04824561403508772, 'r2_recall': 0.14864864864864866, 'r2_f1': 0.0728476821192053, 'rL_precision': 0.10480349344978165, 'rL_recall': 0.32, 'rL_f1': 0.15789473684210528, 'bs_precision': 0.12203619629144669, 'bs_recall': 0.33949044346809387, 'bs_f1': 0.22227704524993896, 'bs_mnli_precision': 0.5186960101127625, 'bs_mnli_recall': 0.6529375314712524, 'bs_mnli_f1': 0.5781263709068298, 'unique_bigram_ratio': 0.9417040358744395, 'nid': -0.22538163368195874, 'grammatical_errors': 5, 'pegasus_entailment': 0.26809166744351387, 'gold_entailment': 0.2963452525436878, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 355
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 59.52 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2945205479452055, 'r1_recall': 0.8113207547169812, 'r1_f1': 0.43216080402010054, 'r2_precision': 0.16551724137931034, 'r2_recall': 0.46153846153846156, 'r2_f1': 0.2436548223350254, 'rL_precision': 0.1917808219178082, 'rL_recall': 0.5283018867924528, 'rL_f1': 0.2814070351758794, 'bs_precision': 0.25664979219436646, 'bs_recall': 0.6334350109100342, 'bs_f1': 0.419187992811203, 'bs_mnli_precision': 0.5860134959220886, 'bs_mnli_recall': 0.7932101488113403, 'bs_mnli_f1': 0.6740486025810242, 'unique_bigram_ratio': 0.95, 'nid': -0.25797385384533333, 'grammatical_errors': 4, 'pegasus_entailment': 0.6159405750887734, 'gold_entailment': 0.7162427306175232, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 356
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.52 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3837837837837838, 'r1_recall': 0.7634408602150538, 'r1_f1': 0.5107913669064748, 'r2_precision': 0.25, 'r2_recall': 0.5, 'r2_f1': 0.3333333333333333, 'rL_precision': 0.32432432432432434, 'rL_recall': 0.6451612903225806, 'rL_f1': 0.43165467625899284, 'bs_precision': 0.34431248903274536, 'bs_recall': 0.5209320783615112, 'bs_f1': 0.4283999800682068, 'bs_mnli_precision': 0.6379671096801758, 'bs_mnli_recall': 0.7751226425170898, 'bs_mnli_f1': 0.6998886466026306, 'unique_bigram_ratio': 0.95, 'nid': -0.24357432828221914, 'grammatical_errors': 6, 'pegasus_entailment': 0.42156413942575455, 'gold_entailment': 0.28302749805152416, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 357
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 76.40 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.43636363636363634, 'r1_recall': 0.8275862068965517, 'r1_f1': 0.5714285714285714, 'r2_precision': 0.28440366972477066, 'r2_recall': 0.543859649122807, 'r2_f1': 0.3734939759036145, 'rL_precision': 0.38181818181818183, 'rL_recall': 0.7241379310344828, 'rL_f1': 0.5000000000000001, 'bs_precision': 0.45677879452705383, 'bs_recall': 0.6866580247879028, 'bs_f1': 0.5637831091880798, 'bs_mnli_precision': 0.70587557554245, 'bs_mnli_recall': 0.8486118316650391, 'bs_mnli_f1': 0.7706905007362366, 'unique_bigram_ratio': 0.9626168224299065, 'nid': -0.2879209079496938, 'grammatical_errors': 2, 'pegasus_entailment': 0.4781037026550621, 'gold_entailment': 0.5568345785140991, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 358
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 81.10 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6296296296296297, 'r1_recall': 0.5, 'r1_f1': 0.5573770491803278, 'r2_precision': 0.3875, 'r2_recall': 0.3069306930693069, 'r2_f1': 0.34254143646408836, 'rL_precision': 0.48148148148148145, 'rL_recall': 0.38235294117647056, 'rL_f1': 0.4262295081967213, 'bs_precision': 0.40552154183387756, 'bs_recall': 0.35426247119903564, 'bs_f1': 0.3814721703529358, 'bs_mnli_precision': 0.703274667263031, 'bs_mnli_recall': 0.6547236442565918, 'bs_mnli_f1': 0.6781312227249146, 'unique_bigram_ratio': 0.9743589743589743, 'nid': -0.3202549189343795, 'grammatical_errors': 1, 'pegasus_entailment': 0.4643641486763954, 'gold_entailment': 0.4145592600107193, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 359
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.96 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3782608695652174, 'r1_recall': 0.5506329113924051, 'r1_f1': 0.44845360824742264, 'r2_precision': 0.17467248908296942, 'r2_recall': 0.25477707006369427, 'r2_f1': 0.20725388601036265, 'rL_precision': 0.23478260869565218, 'rL_recall': 0.34177215189873417, 'rL_f1': 0.2783505154639175, 'bs_precision': 0.29236963391304016, 'bs_recall': 0.39471954107284546, 'bs_f1': 0.3435598611831665, 'bs_mnli_precision': 0.6308896541595459, 'bs_mnli_recall': 0.6743380427360535, 'bs_mnli_f1': 0.6518906354904175, 'unique_bigram_ratio': 0.88, 'nid': -0.1625393013262746, 'grammatical_errors': 1, 'pegasus_entailment': 0.5470078617334366, 'gold_entailment': 0.4494457349181175, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 360
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.91 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.18421052631578946, 'r1_recall': 0.7368421052631579, 'r1_f1': 0.29473684210526313, 'r2_precision': 0.11013215859030837, 'r2_recall': 0.44642857142857145, 'r2_f1': 0.17667844522968196, 'rL_precision': 0.14473684210526316, 'rL_recall': 0.5789473684210527, 'rL_f1': 0.23157894736842105, 'bs_precision': 0.15586444735527039, 'bs_recall': 0.5022277235984802, 'bs_f1': 0.30554017424583435, 'bs_mnli_precision': 0.5398772954940796, 'bs_mnli_recall': 0.7328705787658691, 'bs_mnli_f1': 0.6217416524887085, 'unique_bigram_ratio': 0.9422222222222222, 'nid': -0.22301037763465548, 'grammatical_errors': 2, 'pegasus_entailment': 0.7163947895169258, 'gold_entailment': 0.4347098668416341, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 361
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.24 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.5033557046979866, 'r1_f1': 0.47770700636942676, 'r2_precision': 0.1951219512195122, 'r2_recall': 0.21621621621621623, 'r2_f1': 0.20512820512820515, 'rL_precision': 0.3212121212121212, 'rL_recall': 0.35570469798657717, 'rL_f1': 0.33757961783439494, 'bs_precision': 0.3074745237827301, 'bs_recall': 0.3316837549209595, 'bs_f1': 0.32177627086639404, 'bs_mnli_precision': 0.6262166500091553, 'bs_mnli_recall': 0.6387547850608826, 'bs_mnli_f1': 0.6324235200881958, 'unique_bigram_ratio': 0.9627329192546584, 'nid': -0.22709513986906793, 'grammatical_errors': 2, 'pegasus_entailment': 0.37062392632166546, 'gold_entailment': 0.25070133358240126, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 362
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.38 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.42196531791907516, 'r1_recall': 0.5328467153284672, 'r1_f1': 0.4709677419354839, 'r2_precision': 0.18023255813953487, 'r2_recall': 0.22794117647058823, 'r2_f1': 0.20129870129870128, 'rL_precision': 0.2254335260115607, 'rL_recall': 0.2846715328467153, 'rL_f1': 0.25161290322580643, 'bs_precision': 0.32582035660743713, 'bs_recall': 0.3604857921600342, 'bs_f1': 0.34514111280441284, 'bs_mnli_precision': 0.6768536567687988, 'bs_mnli_recall': 0.6647941470146179, 'bs_mnli_f1': 0.6707696318626404, 'unique_bigram_ratio': 0.9532163742690059, 'nid': -0.22839029775236508, 'grammatical_errors': 3, 'pegasus_entailment': 0.49136424958705904, 'gold_entailment': 0.24957742355763912, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 363
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.41 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.34074074074074073, 'r1_recall': 0.696969696969697, 'r1_f1': 0.4577114427860696, 'r2_precision': 0.16417910447761194, 'r2_recall': 0.3384615384615385, 'r2_f1': 0.22110552763819094, 'rL_precision': 0.22962962962962963, 'rL_recall': 0.4696969696969697, 'rL_f1': 0.3084577114427861, 'bs_precision': 0.23198916018009186, 'bs_recall': 0.48346832394599915, 'bs_f1': 0.3466491997241974, 'bs_mnli_precision': 0.6064026355743408, 'bs_mnli_recall': 0.7354233264923096, 'bs_mnli_f1': 0.6647101044654846, 'unique_bigram_ratio': 0.9696969696969697, 'nid': -0.2991901178376537, 'grammatical_errors': 3, 'pegasus_entailment': 0.4195912331342697, 'gold_entailment': 0.3509052147467931, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 364
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.93 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.47183098591549294, 'r1_recall': 0.6036036036036037, 'r1_f1': 0.5296442687747035, 'r2_precision': 0.24822695035460993, 'r2_recall': 0.3181818181818182, 'r2_f1': 0.2788844621513944, 'rL_precision': 0.3380281690140845, 'rL_recall': 0.43243243243243246, 'rL_f1': 0.3794466403162055, 'bs_precision': 0.360803484916687, 'bs_recall': 0.4594942629337311, 'bs_f1': 0.41020429134368896, 'bs_mnli_precision': 0.6743770241737366, 'bs_mnli_recall': 0.7141257524490356, 'bs_mnli_f1': 0.6936824321746826, 'unique_bigram_ratio': 0.920863309352518, 'nid': -0.2362714794530778, 'grammatical_errors': 3, 'pegasus_entailment': 0.4508588820695877, 'gold_entailment': 0.3264853447675705, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 365
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.00 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24669603524229075, 'r1_recall': 0.7, 'r1_f1': 0.36482084690553745, 'r2_precision': 0.11504424778761062, 'r2_recall': 0.3291139240506329, 'r2_f1': 0.17049180327868851, 'rL_precision': 0.18061674008810572, 'rL_recall': 0.5125, 'rL_f1': 0.2671009771986971, 'bs_precision': 0.21539856493473053, 'bs_recall': 0.48121100664138794, 'bs_f1': 0.3355830907821655, 'bs_mnli_precision': 0.5682164430618286, 'bs_mnli_recall': 0.7124764323234558, 'bs_mnli_f1': 0.6322215795516968, 'unique_bigram_ratio': 0.9642857142857143, 'nid': -0.2655864820685603, 'grammatical_errors': 5, 'pegasus_entailment': 0.5329575432198388, 'gold_entailment': 0.24312419816851616, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 366
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.27 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3364485981308411, 'r1_recall': 0.5669291338582677, 'r1_f1': 0.4222873900293255, 'r2_precision': 0.11737089201877934, 'r2_recall': 0.1984126984126984, 'r2_f1': 0.14749262536873156, 'rL_precision': 0.21495327102803738, 'rL_recall': 0.36220472440944884, 'rL_f1': 0.2697947214076246, 'bs_precision': 0.2784497141838074, 'bs_recall': 0.3674786388874054, 'bs_f1': 0.32356148958206177, 'bs_mnli_precision': 0.5972648859024048, 'bs_mnli_recall': 0.6674550771713257, 'bs_mnli_f1': 0.6304122805595398, 'unique_bigram_ratio': 0.95260663507109, 'nid': -0.22895411461361537, 'grammatical_errors': 0, 'pegasus_entailment': 0.6078434718979729, 'gold_entailment': 0.44149199766772135, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 367
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.33 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.7050359712230215, 'r1_recall': 0.49746192893401014, 'r1_f1': 0.5833333333333333, 'r2_precision': 0.3695652173913043, 'r2_recall': 0.2602040816326531, 'r2_f1': 0.3053892215568862, 'rL_precision': 0.41007194244604317, 'rL_recall': 0.2893401015228426, 'rL_f1': 0.3392857142857143, 'bs_precision': 0.5016526579856873, 'bs_recall': 0.3951150178909302, 'bs_f1': 0.4480608105659485, 'bs_mnli_precision': 0.7130714058876038, 'bs_mnli_recall': 0.6837209463119507, 'bs_mnli_f1': 0.698087751865387, 'unique_bigram_ratio': 0.9705882352941176, 'nid': -0.26605995750819833, 'grammatical_errors': 2, 'pegasus_entailment': 0.5053106723353267, 'gold_entailment': 0.43034090800210834, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 19, 'pegasus_ari': 31, 'pegasus_smog': 27}
*** Analysing case 368
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 44.94 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.4888888888888889, 'r2_precision': 0.22981366459627328, 'r2_recall': 0.15289256198347106, 'r2_f1': 0.18362282878411912, 'rL_precision': 0.30246913580246915, 'rL_recall': 0.20164609053497942, 'rL_f1': 0.2419753086419753, 'bs_precision': 0.32853662967681885, 'bs_recall': 0.22146128118038177, 'bs_f1': 0.27489662170410156, 'bs_mnli_precision': 0.6402412056922913, 'bs_mnli_recall': 0.5717476606369019, 'bs_mnli_f1': 0.6040589809417725, 'unique_bigram_ratio': 0.91875, 'nid': -0.23177222698211764, 'grammatical_errors': 1, 'pegasus_entailment': 0.6813215129077435, 'gold_entailment': 0.5106238722801208, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 369
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.91 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5724137931034483, 'r1_recall': 0.5971223021582733, 'r1_f1': 0.5845070422535211, 'r2_precision': 0.2986111111111111, 'r2_recall': 0.3115942028985507, 'r2_f1': 0.3049645390070922, 'rL_precision': 0.36551724137931035, 'rL_recall': 0.381294964028777, 'rL_f1': 0.3732394366197183, 'bs_precision': 0.4723464250564575, 'bs_recall': 0.46955397725105286, 'bs_f1': 0.47275662422180176, 'bs_mnli_precision': 0.7090685367584229, 'bs_mnli_recall': 0.7181988954544067, 'bs_mnli_f1': 0.7136045098304749, 'unique_bigram_ratio': 0.935251798561151, 'nid': -0.24485603662204158, 'grammatical_errors': 4, 'pegasus_entailment': 0.5332649633288383, 'gold_entailment': 0.6691098610560099, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 370
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 81.93 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.1839080459770115, 'r1_recall': 0.2191780821917808, 'r1_f1': 0.2, 'r2_precision': 0.03488372093023256, 'r2_recall': 0.041666666666666664, 'r2_f1': 0.0379746835443038, 'rL_precision': 0.12643678160919541, 'rL_recall': 0.1506849315068493, 'rL_f1': 0.1375, 'bs_precision': 0.17090879380702972, 'bs_recall': 0.18201600015163422, 'bs_f1': 0.17924551665782928, 'bs_mnli_precision': 0.5432043671607971, 'bs_mnli_recall': 0.5512690544128418, 'bs_mnli_f1': 0.5472070574760437, 'unique_bigram_ratio': 0.9375, 'nid': -0.22843859823814539, 'grammatical_errors': 1, 'pegasus_entailment': 0.016542993907933123, 'gold_entailment': 0.009347605790632466, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 371
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 59.30 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.16265060240963855, 'r1_recall': 0.4426229508196721, 'r1_f1': 0.2378854625550661, 'r2_precision': 0.04242424242424243, 'r2_recall': 0.11666666666666667, 'r2_f1': 0.062222222222222234, 'rL_precision': 0.1144578313253012, 'rL_recall': 0.3114754098360656, 'rL_f1': 0.16740088105726872, 'bs_precision': 0.1257539540529251, 'bs_recall': 0.2911824882030487, 'bs_f1': 0.2046002447605133, 'bs_mnli_precision': 0.5333645343780518, 'bs_mnli_recall': 0.5958350896835327, 'bs_mnli_f1': 0.5628717541694641, 'unique_bigram_ratio': 0.950920245398773, 'nid': -0.250302639187584, 'grammatical_errors': 1, 'pegasus_entailment': 0.4341633554015841, 'gold_entailment': 0.2202574387192726, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 372
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.26 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3005181347150259, 'r1_recall': 0.6744186046511628, 'r1_f1': 0.4157706093189964, 'r2_precision': 0.171875, 'r2_recall': 0.38823529411764707, 'r2_f1': 0.23826714801444046, 'rL_precision': 0.20207253886010362, 'rL_recall': 0.45348837209302323, 'rL_f1': 0.27956989247311825, 'bs_precision': 0.2183699756860733, 'bs_recall': 0.5081328749656677, 'bs_f1': 0.34788721799850464, 'bs_mnli_precision': 0.5589913725852966, 'bs_mnli_recall': 0.726184606552124, 'bs_mnli_f1': 0.6317125558853149, 'unique_bigram_ratio': 0.9470899470899471, 'nid': -0.21764904797649187, 'grammatical_errors': 3, 'pegasus_entailment': 0.5656910352408886, 'gold_entailment': 0.34428404768308, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 373
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 73.53 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.34545454545454546, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.4130434782608695, 'r2_precision': 0.2018348623853211, 'r2_recall': 0.3013698630136986, 'r2_f1': 0.24175824175824176, 'rL_precision': 0.2818181818181818, 'rL_recall': 0.4189189189189189, 'rL_f1': 0.33695652173913043, 'bs_precision': 0.3710746765136719, 'bs_recall': 0.4805017113685608, 'bs_f1': 0.4253709018230438, 'bs_mnli_precision': 0.6662230491638184, 'bs_mnli_recall': 0.718367874622345, 'bs_mnli_f1': 0.6913135647773743, 'unique_bigram_ratio': 0.9626168224299065, 'nid': -0.26391520987441064, 'grammatical_errors': 0, 'pegasus_entailment': 0.36108474582433703, 'gold_entailment': 0.2984454110264778, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 374
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.84 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4925373134328358, 'r1_recall': 0.5689655172413793, 'r1_f1': 0.528, 'r2_precision': 0.24, 'r2_recall': 0.2774566473988439, 'r2_f1': 0.257372654155496, 'rL_precision': 0.31840796019900497, 'rL_recall': 0.367816091954023, 'rL_f1': 0.3413333333333333, 'bs_precision': 0.3756329119205475, 'bs_recall': 0.4144451916217804, 'bs_f1': 0.3967984616756439, 'bs_mnli_precision': 0.6839193105697632, 'bs_mnli_recall': 0.691261351108551, 'bs_mnli_f1': 0.6875706911087036, 'unique_bigram_ratio': 0.9226804123711341, 'nid': -0.22562367280525475, 'grammatical_errors': 1, 'pegasus_entailment': 0.6294408266743025, 'gold_entailment': 0.45814467817544935, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 375
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.21 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.3472222222222222, 'r1_f1': 0.42735042735042733, 'r2_precision': 0.15730337078651685, 'r2_recall': 0.0979020979020979, 'r2_f1': 0.12068965517241378, 'rL_precision': 0.36666666666666664, 'rL_recall': 0.22916666666666666, 'rL_f1': 0.28205128205128205, 'bs_precision': 0.4012041687965393, 'bs_recall': 0.2895433008670807, 'bs_f1': 0.3449726998806, 'bs_mnli_precision': 0.6995788216590881, 'bs_mnli_recall': 0.6259365081787109, 'bs_mnli_f1': 0.6607120037078857, 'unique_bigram_ratio': 0.9886363636363636, 'nid': -0.31084890160708767, 'grammatical_errors': 0, 'pegasus_entailment': 0.4305338114500046, 'gold_entailment': 0.4784515559673309, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 376
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.51 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6964285714285714, 'r1_recall': 0.4, 'r1_f1': 0.50814332247557, 'r2_precision': 0.2972972972972973, 'r2_recall': 0.17010309278350516, 'r2_f1': 0.21639344262295082, 'rL_precision': 0.4642857142857143, 'rL_recall': 0.26666666666666666, 'rL_f1': 0.33876221498371334, 'bs_precision': 0.4476219713687897, 'bs_recall': 0.35232433676719666, 'bs_f1': 0.40018782019615173, 'bs_mnli_precision': 0.7058824896812439, 'bs_mnli_recall': 0.6478614807128906, 'bs_mnli_f1': 0.6756286025047302, 'unique_bigram_ratio': 0.9636363636363636, 'nid': -0.2641459097734069, 'grammatical_errors': 0, 'pegasus_entailment': 0.6710420716553926, 'gold_entailment': 0.49374585300683976, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 377
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.51 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.28421052631578947, 'r1_recall': 0.7397260273972602, 'r1_f1': 0.4106463878326997, 'r2_precision': 0.1693121693121693, 'r2_recall': 0.4444444444444444, 'r2_f1': 0.24521072796934862, 'rL_precision': 0.22105263157894736, 'rL_recall': 0.5753424657534246, 'rL_f1': 0.31939163498098855, 'bs_precision': 0.2569626271724701, 'bs_recall': 0.5270647406578064, 'bs_f1': 0.37920862436294556, 'bs_mnli_precision': 0.6087403893470764, 'bs_mnli_recall': 0.77652508020401, 'bs_mnli_f1': 0.6824716329574585, 'unique_bigram_ratio': 0.9243243243243243, 'nid': -0.1927115688029155, 'grammatical_errors': 2, 'pegasus_entailment': 0.3854283466935158, 'gold_entailment': 0.2316696010529995, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 378
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.82 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.32978723404255317, 'r1_recall': 0.8266666666666667, 'r1_f1': 0.4714828897338403, 'r2_precision': 0.1925133689839572, 'r2_recall': 0.4864864864864865, 'r2_f1': 0.27586206896551724, 'rL_precision': 0.2393617021276596, 'rL_recall': 0.6, 'rL_f1': 0.3422053231939164, 'bs_precision': 0.3598936200141907, 'bs_recall': 0.6407583951950073, 'bs_f1': 0.48725202679634094, 'bs_mnli_precision': 0.6460044384002686, 'bs_mnli_recall': 0.8139677047729492, 'bs_mnli_f1': 0.7203243374824524, 'unique_bigram_ratio': 0.9402173913043478, 'nid': -0.24182513823433882, 'grammatical_errors': 2, 'pegasus_entailment': 0.49389877263456583, 'gold_entailment': 0.49592578411102295, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 379
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.39 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3836477987421384, 'r1_recall': 0.5350877192982456, 'r1_f1': 0.4468864468864469, 'r2_precision': 0.16455696202531644, 'r2_recall': 0.23008849557522124, 'r2_f1': 0.19188191881918817, 'rL_precision': 0.27044025157232704, 'rL_recall': 0.37719298245614036, 'rL_f1': 0.315018315018315, 'bs_precision': 0.3324179947376251, 'bs_recall': 0.396901935338974, 'bs_f1': 0.36596137285232544, 'bs_mnli_precision': 0.6344769597053528, 'bs_mnli_recall': 0.6588456034660339, 'bs_mnli_f1': 0.6464317440986633, 'unique_bigram_ratio': 0.9617834394904459, 'nid': -0.2852702662857325, 'grammatical_errors': 1, 'pegasus_entailment': 0.4622781164944172, 'gold_entailment': 0.3967882487922907, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 380
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 32.44 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.7468354430379747, 'r1_recall': 0.31382978723404253, 'r1_f1': 0.44194756554307113, 'r2_precision': 0.3184713375796178, 'r2_recall': 0.13333333333333333, 'r2_f1': 0.18796992481203006, 'rL_precision': 0.4620253164556962, 'rL_recall': 0.19414893617021275, 'rL_f1': 0.27340823970037453, 'bs_precision': 0.44466257095336914, 'bs_recall': 0.21377460658550262, 'bs_f1': 0.3200646936893463, 'bs_mnli_precision': 0.711367666721344, 'bs_mnli_recall': 0.5884902477264404, 'bs_mnli_f1': 0.6441211104393005, 'unique_bigram_ratio': 0.967741935483871, 'nid': -0.23294657699840204, 'grammatical_errors': 1, 'pegasus_entailment': 0.6139193219797952, 'gold_entailment': 0.43261295231059194, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 381
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.60 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.21022727272727273, 'r1_recall': 0.6271186440677966, 'r1_f1': 0.3148936170212766, 'r2_precision': 0.06857142857142857, 'r2_recall': 0.20689655172413793, 'r2_f1': 0.10300429184549356, 'rL_precision': 0.125, 'rL_recall': 0.3728813559322034, 'rL_f1': 0.18723404255319148, 'bs_precision': 0.21126356720924377, 'bs_recall': 0.4428543746471405, 'bs_f1': 0.31780171394348145, 'bs_mnli_precision': 0.5669993162155151, 'bs_mnli_recall': 0.6798405051231384, 'bs_mnli_f1': 0.6183137893676758, 'unique_bigram_ratio': 0.9364161849710982, 'nid': -0.20081198922621213, 'grammatical_errors': 4, 'pegasus_entailment': 0.3839729134259479, 'gold_entailment': 0.3143106511173149, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 382
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.35 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.478494623655914, 'r1_recall': 0.5297619047619048, 'r1_f1': 0.5028248587570622, 'r2_precision': 0.21081081081081082, 'r2_recall': 0.23353293413173654, 'r2_f1': 0.22159090909090912, 'rL_precision': 0.26344086021505375, 'rL_recall': 0.2916666666666667, 'rL_f1': 0.27683615819209034, 'bs_precision': 0.36460772156715393, 'bs_recall': 0.4236282706260681, 'bs_f1': 0.3954772353172302, 'bs_mnli_precision': 0.6565306782722473, 'bs_mnli_recall': 0.6865800619125366, 'bs_mnli_f1': 0.6712191700935364, 'unique_bigram_ratio': 0.9666666666666667, 'nid': -0.29863632396171913, 'grammatical_errors': 10, 'pegasus_entailment': 0.4442225194403103, 'gold_entailment': 0.23043152038007975, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 383
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.94 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3520408163265306, 'r1_recall': 0.5348837209302325, 'r1_f1': 0.4246153846153846, 'r2_precision': 0.13846153846153847, 'r2_recall': 0.2109375, 'r2_f1': 0.16718266253869968, 'rL_precision': 0.20408163265306123, 'rL_recall': 0.31007751937984496, 'rL_f1': 0.24615384615384617, 'bs_precision': 0.24766530096530914, 'bs_recall': 0.34686705470085144, 'bs_f1': 0.2974884808063507, 'bs_mnli_precision': 0.6064679026603699, 'bs_mnli_recall': 0.6599794626235962, 'bs_mnli_f1': 0.6320931911468506, 'unique_bigram_ratio': 0.9682539682539683, 'nid': -0.25273261534265723, 'grammatical_errors': 6, 'pegasus_entailment': 0.4839525790885091, 'gold_entailment': 0.3625423423945904, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 384
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.53 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4567901234567901, 'r1_recall': 0.4966442953020134, 'r1_f1': 0.4758842443729904, 'r2_precision': 0.18633540372670807, 'r2_recall': 0.20270270270270271, 'r2_f1': 0.1941747572815534, 'rL_precision': 0.21604938271604937, 'rL_recall': 0.2348993288590604, 'rL_f1': 0.22508038585209006, 'bs_precision': 0.3256174623966217, 'bs_recall': 0.34118419885635376, 'bs_f1': 0.33562612533569336, 'bs_mnli_precision': 0.6459739208221436, 'bs_mnli_recall': 0.6446698307991028, 'bs_mnli_f1': 0.645321249961853, 'unique_bigram_ratio': 0.954248366013072, 'nid': -0.24659102851262382, 'grammatical_errors': 4, 'pegasus_entailment': 0.5266047666470209, 'gold_entailment': 0.3615335871775945, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 385
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.64 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3963963963963964, 'r1_recall': 0.5207100591715976, 'r1_f1': 0.4501278772378517, 'r2_precision': 0.16289592760180996, 'r2_recall': 0.21428571428571427, 'r2_f1': 0.18508997429305912, 'rL_precision': 0.22972972972972974, 'rL_recall': 0.30177514792899407, 'rL_f1': 0.26086956521739135, 'bs_precision': 0.34663429856300354, 'bs_recall': 0.411763072013855, 'bs_f1': 0.38044360280036926, 'bs_mnli_precision': 0.639460563659668, 'bs_mnli_recall': 0.6757231950759888, 'bs_mnli_f1': 0.6570919752120972, 'unique_bigram_ratio': 0.9357798165137615, 'nid': -0.23718237913536555, 'grammatical_errors': 2, 'pegasus_entailment': 0.5289576692240578, 'gold_entailment': 0.4909678910459791, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 386
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 68.98 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5076923076923077, 'r1_recall': 0.5038167938931297, 'r1_f1': 0.5057471264367815, 'r2_precision': 0.21705426356589147, 'r2_recall': 0.2153846153846154, 'r2_f1': 0.21621621621621623, 'rL_precision': 0.36923076923076925, 'rL_recall': 0.366412213740458, 'rL_f1': 0.36781609195402304, 'bs_precision': 0.3752729594707489, 'bs_recall': 0.3934493064880371, 'bs_f1': 0.3863963484764099, 'bs_mnli_precision': 0.678609311580658, 'bs_mnli_recall': 0.6809878349304199, 'bs_mnli_f1': 0.6797964572906494, 'unique_bigram_ratio': 0.96875, 'nid': -0.2308852375154966, 'grammatical_errors': 0, 'pegasus_entailment': 0.4594454728066921, 'gold_entailment': 0.35949778705835345, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 387
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 66.25 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4330708661417323, 'r1_recall': 0.4435483870967742, 'r1_f1': 0.4382470119521913, 'r2_precision': 0.11904761904761904, 'r2_recall': 0.12195121951219512, 'r2_f1': 0.12048192771084337, 'rL_precision': 0.23622047244094488, 'rL_recall': 0.24193548387096775, 'rL_f1': 0.2390438247011952, 'bs_precision': 0.2641824781894684, 'bs_recall': 0.27479493618011475, 'bs_f1': 0.2719590365886688, 'bs_mnli_precision': 0.6153546571731567, 'bs_mnli_recall': 0.6262683272361755, 'bs_mnli_f1': 0.6207635402679443, 'unique_bigram_ratio': 0.96, 'nid': -0.25901719074056384, 'grammatical_errors': 1, 'pegasus_entailment': 0.2534204459904383, 'gold_entailment': 0.11509111601238449, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 388
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.02 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.36538461538461536, 'r1_recall': 0.6867469879518072, 'r1_f1': 0.4769874476987448, 'r2_precision': 0.16129032258064516, 'r2_recall': 0.3048780487804878, 'r2_f1': 0.21097046413502107, 'rL_precision': 0.23717948717948717, 'rL_recall': 0.4457831325301205, 'rL_f1': 0.30962343096234307, 'bs_precision': 0.28760841488838196, 'bs_recall': 0.4263001084327698, 'bs_f1': 0.35510900616645813, 'bs_mnli_precision': 0.6099172830581665, 'bs_mnli_recall': 0.7004870176315308, 'bs_mnli_f1': 0.6520722508430481, 'unique_bigram_ratio': 0.9602649006622517, 'nid': -0.2604072984042176, 'grammatical_errors': 5, 'pegasus_entailment': 0.5437119513750076, 'gold_entailment': 0.2314024455845356, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 389
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.77 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.1858974358974359, 'r1_recall': 0.7435897435897436, 'r1_f1': 0.2974358974358975, 'r2_precision': 0.09032258064516129, 'r2_recall': 0.3684210526315789, 'r2_f1': 0.14507772020725387, 'rL_precision': 0.15384615384615385, 'rL_recall': 0.6153846153846154, 'rL_f1': 0.24615384615384617, 'bs_precision': 0.20393605530261993, 'bs_recall': 0.5470318794250488, 'bs_f1': 0.35327890515327454, 'bs_mnli_precision': 0.5603868961334229, 'bs_mnli_recall': 0.7509256601333618, 'bs_mnli_f1': 0.6418132781982422, 'unique_bigram_ratio': 0.9802631578947368, 'nid': -0.28970662441252815, 'grammatical_errors': 7, 'pegasus_entailment': 0.6248537413775921, 'gold_entailment': 0.5021608471870422, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 390
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.69 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4266666666666667, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.481203007518797, 'r2_precision': 0.20134228187919462, 'r2_recall': 0.2608695652173913, 'r2_f1': 0.22727272727272727, 'rL_precision': 0.28, 'rL_recall': 0.3620689655172414, 'rL_f1': 0.31578947368421056, 'bs_precision': 0.3492031991481781, 'bs_recall': 0.4127558171749115, 'bs_f1': 0.3822614252567291, 'bs_mnli_precision': 0.6532515287399292, 'bs_mnli_recall': 0.684415876865387, 'bs_mnli_f1': 0.6684706807136536, 'unique_bigram_ratio': 0.9659863945578231, 'nid': -0.2397481639192014, 'grammatical_errors': 2, 'pegasus_entailment': 0.29867627993226054, 'gold_entailment': 0.21915844827890396, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 391
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.51 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5882352941176471, 'r1_recall': 0.43243243243243246, 'r1_f1': 0.4984423676012461, 'r2_precision': 0.1925925925925926, 'r2_recall': 0.14130434782608695, 'r2_f1': 0.1630094043887147, 'rL_precision': 0.3014705882352941, 'rL_recall': 0.22162162162162163, 'rL_f1': 0.25545171339563866, 'bs_precision': 0.42479774355888367, 'bs_recall': 0.31490829586982727, 'bs_f1': 0.36950361728668213, 'bs_mnli_precision': 0.704269289970398, 'bs_mnli_recall': 0.6246022582054138, 'bs_mnli_f1': 0.6620477437973022, 'unique_bigram_ratio': 0.9618320610687023, 'nid': -0.27926124538337627, 'grammatical_errors': 1, 'pegasus_entailment': 0.5271331916252772, 'gold_entailment': 0.32716941740363836, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 392
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 67.25 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.432, 'r1_recall': 0.5625, 'r1_f1': 0.4886877828054299, 'r2_precision': 0.20967741935483872, 'r2_recall': 0.2736842105263158, 'r2_f1': 0.23744292237442924, 'rL_precision': 0.248, 'rL_recall': 0.3229166666666667, 'rL_f1': 0.28054298642533937, 'bs_precision': 0.3236430585384369, 'bs_recall': 0.3916589021682739, 'bs_f1': 0.35887300968170166, 'bs_mnli_precision': 0.6138735413551331, 'bs_mnli_recall': 0.6477223634719849, 'bs_mnli_f1': 0.6303438544273376, 'unique_bigram_ratio': 1.0, 'nid': -0.2982989437973098, 'grammatical_errors': 2, 'pegasus_entailment': 0.43924396485090256, 'gold_entailment': 0.3306465024749438, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 393
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 29.73 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.49279538904899134, 'r1_recall': 0.44415584415584414, 'r1_f1': 0.4672131147540983, 'r2_precision': 0.14739884393063585, 'r2_recall': 0.1328125, 'r2_f1': 0.13972602739726028, 'rL_precision': 0.2132564841498559, 'rL_recall': 0.19220779220779222, 'rL_f1': 0.20218579234972675, 'bs_precision': 0.24322368204593658, 'bs_recall': 0.2292979508638382, 'bs_f1': 0.23882603645324707, 'bs_mnli_precision': 0.628160834312439, 'bs_mnli_recall': 0.5905545949935913, 'bs_mnli_f1': 0.6087775230407715, 'unique_bigram_ratio': 0.9058823529411765, 'nid': -0.17347942592480048, 'grammatical_errors': 3, 'pegasus_entailment': 0.7011503657469382, 'gold_entailment': 0.4736650165389566, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 394
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.84 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6491228070175439, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.5736434108527132, 'r2_precision': 0.3185840707964602, 'r2_recall': 0.2517482517482518, 'r2_f1': 0.28125, 'rL_precision': 0.35964912280701755, 'rL_recall': 0.2847222222222222, 'rL_f1': 0.3178294573643411, 'bs_precision': 0.44925734400749207, 'bs_recall': 0.3827977478504181, 'bs_f1': 0.4171425402164459, 'bs_mnli_precision': 0.7106641530990601, 'bs_mnli_recall': 0.6756107211112976, 'bs_mnli_f1': 0.6926942467689514, 'unique_bigram_ratio': 0.9732142857142857, 'nid': -0.24134906627078867, 'grammatical_errors': 0, 'pegasus_entailment': 0.5236796364188194, 'gold_entailment': 0.3404087449113528, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 395
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 39.07 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.15384615384615385, 'r1_recall': 0.7076923076923077, 'r1_f1': 0.25274725274725274, 'r2_precision': 0.04697986577181208, 'r2_recall': 0.21875, 'r2_f1': 0.07734806629834255, 'rL_precision': 0.0903010033444816, 'rL_recall': 0.4153846153846154, 'rL_f1': 0.14835164835164832, 'bs_precision': 0.13825318217277527, 'bs_recall': 0.456880658864975, 'bs_f1': 0.2775242328643799, 'bs_mnli_precision': 0.5402241349220276, 'bs_mnli_recall': 0.6930270195007324, 'bs_mnli_f1': 0.6071592569351196, 'unique_bigram_ratio': 0.9450171821305842, 'nid': -0.2290123158859012, 'grammatical_errors': 6, 'pegasus_entailment': 0.47787328126529854, 'gold_entailment': 0.2986266016960144, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 396
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 75.58 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.34210526315789475, 'r1_recall': 0.65, 'r1_f1': 0.4482758620689655, 'r2_precision': 0.1592920353982301, 'r2_recall': 0.3050847457627119, 'r2_f1': 0.20930232558139536, 'rL_precision': 0.21052631578947367, 'rL_recall': 0.4, 'rL_f1': 0.27586206896551724, 'bs_precision': 0.3399551808834076, 'bs_recall': 0.5207583904266357, 'bs_f1': 0.42583543062210083, 'bs_mnli_precision': 0.6609377264976501, 'bs_mnli_recall': 0.7432795166969299, 'bs_mnli_f1': 0.6996943950653076, 'unique_bigram_ratio': 0.9821428571428571, 'nid': -0.2612546582012121, 'grammatical_errors': 0, 'pegasus_entailment': 0.29550496364633244, 'gold_entailment': 0.18554921199878058, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 397
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 82.88 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3614457831325301, 'r1_recall': 0.37037037037037035, 'r1_f1': 0.3658536585365854, 'r2_precision': 0.06097560975609756, 'r2_recall': 0.0625, 'r2_f1': 0.06172839506172839, 'rL_precision': 0.24096385542168675, 'rL_recall': 0.24691358024691357, 'rL_f1': 0.24390243902439024, 'bs_precision': 0.277311772108078, 'bs_recall': 0.2770487666130066, 'bs_f1': 0.2796502411365509, 'bs_mnli_precision': 0.6088477373123169, 'bs_mnli_recall': 0.5995067358016968, 'bs_mnli_f1': 0.604141116142273, 'unique_bigram_ratio': 0.9873417721518988, 'nid': -0.31567240751245773, 'grammatical_errors': 0, 'pegasus_entailment': 0.3445041961967945, 'gold_entailment': 0.19134983979165554, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 398
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.11 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.36942675159235666, 'r1_recall': 0.5576923076923077, 'r1_f1': 0.4444444444444445, 'r2_precision': 0.07051282051282051, 'r2_recall': 0.10679611650485436, 'r2_f1': 0.08494208494208495, 'rL_precision': 0.21019108280254778, 'rL_recall': 0.3173076923076923, 'rL_f1': 0.25287356321839083, 'bs_precision': 0.3042333424091339, 'bs_recall': 0.44589126110076904, 'bs_f1': 0.37304389476776123, 'bs_mnli_precision': 0.6518745422363281, 'bs_mnli_recall': 0.69178307056427, 'bs_mnli_f1': 0.6712361574172974, 'unique_bigram_ratio': 0.9090909090909091, 'nid': -0.2206446583680033, 'grammatical_errors': 0, 'pegasus_entailment': 0.33181044459342957, 'gold_entailment': 0.3098476052284241, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 399
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.08 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.21658986175115208, 'r1_recall': 0.5465116279069767, 'r1_f1': 0.31023102310231027, 'r2_precision': 0.037037037037037035, 'r2_recall': 0.09411764705882353, 'r2_f1': 0.053156146179401995, 'rL_precision': 0.11059907834101383, 'rL_recall': 0.27906976744186046, 'rL_f1': 0.15841584158415842, 'bs_precision': 0.16976189613342285, 'bs_recall': 0.3195931911468506, 'bs_f1': 0.24204789102077484, 'bs_mnli_precision': 0.5448815822601318, 'bs_mnli_recall': 0.6380618810653687, 'bs_mnli_f1': 0.5878018140792847, 'unique_bigram_ratio': 0.9198113207547169, 'nid': -0.20854060260650664, 'grammatical_errors': 1, 'pegasus_entailment': 0.16345162565509477, 'gold_entailment': 0.11020919270813465, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 400
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.16 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.40588235294117647, 'r1_recall': 0.4423076923076923, 'r1_f1': 0.4233128834355828, 'r2_precision': 0.0650887573964497, 'r2_recall': 0.07096774193548387, 'r2_f1': 0.06790123456790122, 'rL_precision': 0.20588235294117646, 'rL_recall': 0.22435897435897437, 'rL_f1': 0.2147239263803681, 'bs_precision': 0.22095458209514618, 'bs_recall': 0.21999138593673706, 'bs_f1': 0.22313664853572845, 'bs_mnli_precision': 0.5772074460983276, 'bs_mnli_recall': 0.5917818546295166, 'bs_mnli_f1': 0.5844038128852844, 'unique_bigram_ratio': 0.9520958083832335, 'nid': -0.259289610192472, 'grammatical_errors': 0, 'pegasus_entailment': 0.5196495928934642, 'gold_entailment': 0.3918491474219731, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 401
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.73 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.46261682242990654, 'r1_recall': 0.6, 'r1_f1': 0.5224274406332453, 'r2_precision': 0.1643192488262911, 'r2_recall': 0.21341463414634146, 'r2_f1': 0.1856763925729443, 'rL_precision': 0.2383177570093458, 'rL_recall': 0.3090909090909091, 'rL_f1': 0.2691292875989446, 'bs_precision': 0.33128878474235535, 'bs_recall': 0.35000964999198914, 'bs_f1': 0.3428270220756531, 'bs_mnli_precision': 0.6502121090888977, 'bs_mnli_recall': 0.6545194387435913, 'bs_mnli_f1': 0.6523586511611938, 'unique_bigram_ratio': 0.9230769230769231, 'nid': -0.19294856610945788, 'grammatical_errors': 2, 'pegasus_entailment': 0.6079309185345968, 'gold_entailment': 0.3784470804966986, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 402
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 38.56 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.16356877323420074, 'r1_recall': 0.7213114754098361, 'r1_f1': 0.26666666666666666, 'r2_precision': 0.06343283582089553, 'r2_recall': 0.2833333333333333, 'r2_f1': 0.10365853658536585, 'rL_precision': 0.11524163568773234, 'rL_recall': 0.5081967213114754, 'rL_f1': 0.18787878787878787, 'bs_precision': 0.13966284692287445, 'bs_recall': 0.5528908371925354, 'bs_f1': 0.3123309910297394, 'bs_mnli_precision': 0.5293960571289062, 'bs_mnli_recall': 0.7382237911224365, 'bs_mnli_f1': 0.616608738899231, 'unique_bigram_ratio': 0.9536679536679536, 'nid': -0.24133101718458505, 'grammatical_errors': 4, 'pegasus_entailment': 0.4030911359522078, 'gold_entailment': 0.2865070002153516, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 403
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 66.29 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6216216216216216, 'r1_recall': 0.46, 'r1_f1': 0.5287356321839081, 'r2_precision': 0.36363636363636365, 'r2_recall': 0.2684563758389262, 'r2_f1': 0.30888030888030893, 'rL_precision': 0.36936936936936937, 'rL_recall': 0.2733333333333333, 'rL_f1': 0.31417624521072796, 'bs_precision': 0.4745130240917206, 'bs_recall': 0.3898467719554901, 'bs_f1': 0.4327085614204407, 'bs_mnli_precision': 0.7143591642379761, 'bs_mnli_recall': 0.6755039095878601, 'bs_mnli_f1': 0.6943884491920471, 'unique_bigram_ratio': 0.944954128440367, 'nid': -0.27558711444516804, 'grammatical_errors': 1, 'pegasus_entailment': 0.6926054805517197, 'gold_entailment': 0.525087316830953, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 404
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 67.57 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.31496062992125984, 'r1_recall': 0.43956043956043955, 'r1_f1': 0.3669724770642202, 'r2_precision': 0.05555555555555555, 'r2_recall': 0.07777777777777778, 'r2_f1': 0.06481481481481481, 'rL_precision': 0.14960629921259844, 'rL_recall': 0.2087912087912088, 'rL_f1': 0.1743119266055046, 'bs_precision': 0.21274513006210327, 'bs_recall': 0.29493194818496704, 'bs_f1': 0.254831999540329, 'bs_mnli_precision': 0.5762403607368469, 'bs_mnli_recall': 0.607463002204895, 'bs_mnli_f1': 0.5914398431777954, 'unique_bigram_ratio': 0.967479674796748, 'nid': -0.2995684884163068, 'grammatical_errors': 2, 'pegasus_entailment': 0.19999538082629442, 'gold_entailment': 0.08747735545039177, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 405
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.18 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.35514018691588783, 'r1_recall': 0.5801526717557252, 'r1_f1': 0.4405797101449276, 'r2_precision': 0.14553990610328638, 'r2_recall': 0.23846153846153847, 'r2_f1': 0.18075801749271134, 'rL_precision': 0.21962616822429906, 'rL_recall': 0.35877862595419846, 'rL_f1': 0.27246376811594203, 'bs_precision': 0.2577876150608063, 'bs_recall': 0.3492642343044281, 'bs_f1': 0.30406296253204346, 'bs_mnli_precision': 0.6009266376495361, 'bs_mnli_recall': 0.6541098356246948, 'bs_mnli_f1': 0.6263914108276367, 'unique_bigram_ratio': 0.9166666666666666, 'nid': -0.20328051079099474, 'grammatical_errors': 1, 'pegasus_entailment': 0.3645843682544572, 'gold_entailment': 0.2421675082296133, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 406
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 67.04 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.390625, 'r1_recall': 0.5494505494505495, 'r1_f1': 0.4566210045662101, 'r2_precision': 0.18110236220472442, 'r2_recall': 0.25555555555555554, 'r2_f1': 0.2119815668202765, 'rL_precision': 0.2265625, 'rL_recall': 0.31868131868131866, 'rL_f1': 0.2648401826484018, 'bs_precision': 0.2607732117176056, 'bs_recall': 0.35830602049827576, 'bs_f1': 0.3098154664039612, 'bs_mnli_precision': 0.6023691892623901, 'bs_mnli_recall': 0.658279299736023, 'bs_mnli_f1': 0.6290844082832336, 'unique_bigram_ratio': 0.9596774193548387, 'nid': -0.24178285901582663, 'grammatical_errors': 1, 'pegasus_entailment': 0.21562649309635162, 'gold_entailment': 0.13919377233833075, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 407
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 72.43 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5081967213114754, 'r1_recall': 0.5904761904761905, 'r1_f1': 0.5462555066079295, 'r2_precision': 0.21487603305785125, 'r2_recall': 0.25, 'r2_f1': 0.23111111111111113, 'rL_precision': 0.27049180327868855, 'rL_recall': 0.3142857142857143, 'rL_f1': 0.29074889867841414, 'bs_precision': 0.41554057598114014, 'bs_recall': 0.4466158449649811, 'bs_f1': 0.4328303039073944, 'bs_mnli_precision': 0.6700748205184937, 'bs_mnli_recall': 0.6764039993286133, 'bs_mnli_f1': 0.6732245087623596, 'unique_bigram_ratio': 0.9487179487179487, 'nid': -0.25310306484664946, 'grammatical_errors': 1, 'pegasus_entailment': 0.42408837378025055, 'gold_entailment': 0.2821546122431755, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 408
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.81 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.28205128205128205, 'r1_recall': 0.6027397260273972, 'r1_f1': 0.3842794759825327, 'r2_precision': 0.10967741935483871, 'r2_recall': 0.2361111111111111, 'r2_f1': 0.14977973568281938, 'rL_precision': 0.20512820512820512, 'rL_recall': 0.4383561643835616, 'rL_f1': 0.27947598253275113, 'bs_precision': 0.28441938757896423, 'bs_recall': 0.44442713260650635, 'bs_f1': 0.36124905943870544, 'bs_mnli_precision': 0.6144078373908997, 'bs_mnli_recall': 0.7098327875137329, 'bs_mnli_f1': 0.658682107925415, 'unique_bigram_ratio': 0.9868421052631579, 'nid': -0.2580502789051904, 'grammatical_errors': 3, 'pegasus_entailment': 0.5682264745235444, 'gold_entailment': 0.3987802391250928, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 409
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.81 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3493150684931507, 'r1_recall': 0.408, 'r1_f1': 0.37638376383763833, 'r2_precision': 0.14482758620689656, 'r2_recall': 0.1693548387096774, 'r2_f1': 0.15613382899628253, 'rL_precision': 0.1917808219178082, 'rL_recall': 0.224, 'rL_f1': 0.2066420664206642, 'bs_precision': 0.2537647783756256, 'bs_recall': 0.29231420159339905, 'bs_f1': 0.27518633008003235, 'bs_mnli_precision': 0.5924856662750244, 'bs_mnli_recall': 0.5991936922073364, 'bs_mnli_f1': 0.5958207845687866, 'unique_bigram_ratio': 0.9436619718309859, 'nid': -0.23042892188374609, 'grammatical_errors': 1, 'pegasus_entailment': 0.5203928351402283, 'gold_entailment': 0.20334817934781313, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 410
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.97 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.29310344827586204, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.3930635838150289, 'r2_precision': 0.11688311688311688, 'r2_recall': 0.23893805309734514, 'r2_f1': 0.1569767441860465, 'rL_precision': 0.1939655172413793, 'rL_recall': 0.39473684210526316, 'rL_f1': 0.26011560693641617, 'bs_precision': 0.27036768198013306, 'bs_recall': 0.36169615387916565, 'bs_f1': 0.31655237078666687, 'bs_mnli_precision': 0.6073540449142456, 'bs_mnli_recall': 0.6601637601852417, 'bs_mnli_f1': 0.6326587796211243, 'unique_bigram_ratio': 0.92, 'nid': -0.21772140625291092, 'grammatical_errors': 1, 'pegasus_entailment': 0.37203873456879094, 'gold_entailment': 0.09027768820524215, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 411
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.87 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.27918781725888325, 'r1_recall': 0.6179775280898876, 'r1_f1': 0.3846153846153846, 'r2_precision': 0.1326530612244898, 'r2_recall': 0.29545454545454547, 'r2_f1': 0.18309859154929578, 'rL_precision': 0.19289340101522842, 'rL_recall': 0.42696629213483145, 'rL_f1': 0.26573426573426573, 'bs_precision': 0.28276851773262024, 'bs_recall': 0.44288209080696106, 'bs_f1': 0.35964226722717285, 'bs_mnli_precision': 0.5867197513580322, 'bs_mnli_recall': 0.7022161483764648, 'bs_mnli_f1': 0.639293372631073, 'unique_bigram_ratio': 0.9315789473684211, 'nid': -0.19735549307260292, 'grammatical_errors': 0, 'pegasus_entailment': 0.6041692554950714, 'gold_entailment': 0.504205796867609, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 412
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 73.61 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.20155038759689922, 'r1_recall': 0.6046511627906976, 'r1_f1': 0.3023255813953488, 'r2_precision': 0.078125, 'r2_recall': 0.23809523809523808, 'r2_f1': 0.11764705882352941, 'rL_precision': 0.13953488372093023, 'rL_recall': 0.4186046511627907, 'rL_f1': 0.20930232558139536, 'bs_precision': 0.16688571870326996, 'bs_recall': 0.4636480212211609, 'bs_f1': 0.29843831062316895, 'bs_mnli_precision': 0.5662972927093506, 'bs_mnli_recall': 0.6958869695663452, 'bs_mnli_f1': 0.6244395971298218, 'unique_bigram_ratio': 0.9590163934426229, 'nid': -0.2401039422448712, 'grammatical_errors': 0, 'pegasus_entailment': 0.4424621671438217, 'gold_entailment': 0.3549400568008423, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 413
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.23 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6258064516129033, 'r1_recall': 0.43891402714932126, 'r1_f1': 0.5159574468085107, 'r2_precision': 0.24675324675324675, 'r2_recall': 0.17272727272727273, 'r2_f1': 0.20320855614973263, 'rL_precision': 0.3096774193548387, 'rL_recall': 0.2171945701357466, 'rL_f1': 0.2553191489361702, 'bs_precision': 0.353598028421402, 'bs_recall': 0.25010576844215393, 'bs_f1': 0.3018847703933716, 'bs_mnli_precision': 0.6859975457191467, 'bs_mnli_recall': 0.6157391667366028, 'bs_mnli_f1': 0.6489723324775696, 'unique_bigram_ratio': 0.9210526315789473, 'nid': -0.23617225347447235, 'grammatical_errors': 5, 'pegasus_entailment': 0.37242342717945576, 'gold_entailment': 0.2772023370489478, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 414
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.38 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.38636363636363635, 'r1_recall': 0.45132743362831856, 'r1_f1': 0.41632653061224495, 'r2_precision': 0.07633587786259542, 'r2_recall': 0.08928571428571429, 'r2_f1': 0.0823045267489712, 'rL_precision': 0.18181818181818182, 'rL_recall': 0.21238938053097345, 'rL_f1': 0.19591836734693877, 'bs_precision': 0.29412347078323364, 'bs_recall': 0.2960166335105896, 'bs_f1': 0.297478049993515, 'bs_mnli_precision': 0.6186316013336182, 'bs_mnli_recall': 0.6005272269248962, 'bs_mnli_f1': 0.6094449758529663, 'unique_bigram_ratio': 0.9465648854961832, 'nid': -0.2615043589165815, 'grammatical_errors': 0, 'pegasus_entailment': 0.3536295589680473, 'gold_entailment': 0.7300523718198141, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 415
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.71 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.104, 'r1_recall': 0.7027027027027027, 'r1_f1': 0.18118466898954702, 'r2_precision': 0.05220883534136546, 'r2_recall': 0.3611111111111111, 'r2_f1': 0.0912280701754386, 'rL_precision': 0.08, 'rL_recall': 0.5405405405405406, 'rL_f1': 0.1393728222996516, 'bs_precision': 0.05278490111231804, 'bs_recall': 0.5449670553207397, 'bs_f1': 0.24779440462589264, 'bs_mnli_precision': 0.48779916763305664, 'bs_mnli_recall': 0.698607325553894, 'bs_mnli_f1': 0.5744743943214417, 'unique_bigram_ratio': 0.9330543933054394, 'nid': -0.18377196095646742, 'grammatical_errors': 1, 'pegasus_entailment': 0.4674724054833253, 'gold_entailment': 0.3365607261657715, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 416
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 73.03 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.36507936507936506, 'r1_recall': 0.5609756097560976, 'r1_f1': 0.4423076923076923, 'r2_precision': 0.16, 'r2_recall': 0.24691358024691357, 'r2_f1': 0.1941747572815534, 'rL_precision': 0.24603174603174602, 'rL_recall': 0.3780487804878049, 'rL_f1': 0.2980769230769231, 'bs_precision': 0.41910386085510254, 'bs_recall': 0.4830041527748108, 'bs_f1': 0.4521334767341614, 'bs_mnli_precision': 0.6717100143432617, 'bs_mnli_recall': 0.7033874988555908, 'bs_mnli_f1': 0.6871839165687561, 'unique_bigram_ratio': 0.9354838709677419, 'nid': -0.2231243781605512, 'grammatical_errors': 0, 'pegasus_entailment': 0.37295472621917725, 'gold_entailment': 0.40528710434834164, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 417
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.06 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3298429319371728, 'r1_recall': 0.5887850467289719, 'r1_f1': 0.4228187919463088, 'r2_precision': 0.11578947368421053, 'r2_recall': 0.20754716981132076, 'r2_f1': 0.14864864864864866, 'rL_precision': 0.2198952879581152, 'rL_recall': 0.3925233644859813, 'rL_f1': 0.2818791946308725, 'bs_precision': 0.24548332393169403, 'bs_recall': 0.35119470953941345, 'bs_f1': 0.2982650101184845, 'bs_mnli_precision': 0.5916836261749268, 'bs_mnli_recall': 0.655765175819397, 'bs_mnli_f1': 0.6220784783363342, 'unique_bigram_ratio': 0.9565217391304348, 'nid': -0.21838468635958108, 'grammatical_errors': 1, 'pegasus_entailment': 0.4882632600409644, 'gold_entailment': 0.22131715416908265, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 418
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 39.73 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.16875, 'r1_recall': 0.75, 'r1_f1': 0.27551020408163274, 'r2_precision': 0.09717868338557993, 'r2_recall': 0.43661971830985913, 'r2_f1': 0.158974358974359, 'rL_precision': 0.103125, 'rL_recall': 0.4583333333333333, 'rL_f1': 0.16836734693877553, 'bs_precision': 0.1698586642742157, 'bs_recall': 0.4173015356063843, 'bs_f1': 0.2824084162712097, 'bs_mnli_precision': 0.5655212998390198, 'bs_mnli_recall': 0.713445782661438, 'bs_mnli_f1': 0.6309291124343872, 'unique_bigram_ratio': 0.8603174603174604, 'nid': -0.13354072630025327, 'grammatical_errors': 8, 'pegasus_entailment': 0.4734680573729908, 'gold_entailment': 0.4154505083958308, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 419
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.03 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2693877551020408, 'r1_recall': 0.75, 'r1_f1': 0.39639639639639634, 'r2_precision': 0.12704918032786885, 'r2_recall': 0.3563218390804598, 'r2_f1': 0.18731117824773416, 'rL_precision': 0.17551020408163265, 'rL_recall': 0.48863636363636365, 'rL_f1': 0.25825825825825827, 'bs_precision': 0.22879870235919952, 'bs_recall': 0.4668983817100525, 'bs_f1': 0.338077187538147, 'bs_mnli_precision': 0.5981586575508118, 'bs_mnli_recall': 0.741094708442688, 'bs_mnli_f1': 0.6619990468025208, 'unique_bigram_ratio': 0.9110169491525424, 'nid': -0.1885243195411188, 'grammatical_errors': 2, 'pegasus_entailment': 0.4959832392632961, 'gold_entailment': 0.33761775866150856, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 420
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.22 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3836477987421384, 'r1_recall': 0.6853932584269663, 'r1_f1': 0.4919354838709678, 'r2_precision': 0.15822784810126583, 'r2_recall': 0.2840909090909091, 'r2_f1': 0.2032520325203252, 'rL_precision': 0.23270440251572327, 'rL_recall': 0.4157303370786517, 'rL_f1': 0.2983870967741935, 'bs_precision': 0.31884604692459106, 'bs_recall': 0.43471649289131165, 'bs_f1': 0.37613484263420105, 'bs_mnli_precision': 0.6261965036392212, 'bs_mnli_recall': 0.6983428001403809, 'bs_mnli_f1': 0.6603047847747803, 'unique_bigram_ratio': 0.9735099337748344, 'nid': -0.26887403493739437, 'grammatical_errors': 0, 'pegasus_entailment': 0.5913989444573721, 'gold_entailment': 0.31315270562966663, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 421
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.45 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.19, 'r1_recall': 0.6440677966101694, 'r1_f1': 0.2934362934362934, 'r2_precision': 0.04522613065326633, 'r2_recall': 0.15517241379310345, 'r2_f1': 0.07003891050583658, 'rL_precision': 0.125, 'rL_recall': 0.423728813559322, 'rL_f1': 0.19305019305019305, 'bs_precision': 0.17213641107082367, 'bs_recall': 0.3908535838127136, 'bs_f1': 0.27321913838386536, 'bs_mnli_precision': 0.549697995185852, 'bs_mnli_recall': 0.6365419626235962, 'bs_mnli_f1': 0.5899410843849182, 'unique_bigram_ratio': 0.9484536082474226, 'nid': -0.22348669987844172, 'grammatical_errors': 4, 'pegasus_entailment': 0.5531509593129158, 'gold_entailment': 0.3660885691642761, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 422
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.27 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4557823129251701, 'r1_recall': 0.6767676767676768, 'r1_f1': 0.5447154471544716, 'r2_precision': 0.2191780821917808, 'r2_recall': 0.32653061224489793, 'r2_f1': 0.26229508196721313, 'rL_precision': 0.2653061224489796, 'rL_recall': 0.3939393939393939, 'rL_f1': 0.3170731707317074, 'bs_precision': 0.3896944224834442, 'bs_recall': 0.45339781045913696, 'bs_f1': 0.4227127134799957, 'bs_mnli_precision': 0.6521790623664856, 'bs_mnli_recall': 0.6911672353744507, 'bs_mnli_f1': 0.6711073517799377, 'unique_bigram_ratio': 0.972027972027972, 'nid': -0.2617638876301349, 'grammatical_errors': 1, 'pegasus_entailment': 0.6297942896684011, 'gold_entailment': 0.33421773463487625, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 423
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.01 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3219178082191781, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.38842975206611574, 'r2_precision': 0.12413793103448276, 'r2_recall': 0.18947368421052632, 'r2_f1': 0.15, 'rL_precision': 0.2191780821917808, 'rL_recall': 0.3333333333333333, 'rL_f1': 0.2644628099173554, 'bs_precision': 0.2914183437824249, 'bs_recall': 0.35995417833328247, 'bs_f1': 0.3269751965999603, 'bs_mnli_precision': 0.5929752588272095, 'bs_mnli_recall': 0.6330854892730713, 'bs_mnli_f1': 0.6123742461204529, 'unique_bigram_ratio': 0.9640287769784173, 'nid': -0.2370928433676569, 'grammatical_errors': 1, 'pegasus_entailment': 0.3241294909800802, 'gold_entailment': 0.3641952611505985, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 424
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.71 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4127906976744186, 'r1_recall': 0.7553191489361702, 'r1_f1': 0.5338345864661654, 'r2_precision': 0.17543859649122806, 'r2_recall': 0.3225806451612903, 'r2_f1': 0.22727272727272727, 'rL_precision': 0.22674418604651161, 'rL_recall': 0.4148936170212766, 'rL_f1': 0.2932330827067669, 'bs_precision': 0.3281848430633545, 'bs_recall': 0.4287671148777008, 'bs_f1': 0.378510445356369, 'bs_mnli_precision': 0.6328230500221252, 'bs_mnli_recall': 0.6906896829605103, 'bs_mnli_f1': 0.6604912877082825, 'unique_bigram_ratio': 0.9698795180722891, 'nid': -0.2590843692233318, 'grammatical_errors': 1, 'pegasus_entailment': 0.4669344297477177, 'gold_entailment': 0.5049354508519173, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 425
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.05 seconds, 21.21 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.8205128205128205, 'r1_recall': 0.1839080459770115, 'r1_f1': 0.3004694835680751, 'r2_precision': 0.3448275862068966, 'r2_recall': 0.07677543186180422, 'r2_f1': 0.12558869701726844, 'rL_precision': 0.5299145299145299, 'rL_recall': 0.11877394636015326, 'rL_f1': 0.19405320813771518, 'bs_precision': 0.4217425584793091, 'bs_recall': 0.19313380122184753, 'bs_f1': 0.2983689606189728, 'bs_mnli_precision': 0.6738553643226624, 'bs_mnli_recall': 0.5345008373260498, 'bs_mnli_f1': 0.596142590045929, 'unique_bigram_ratio': 0.9557522123893806, 'nid': -0.29634265405447735, 'grammatical_errors': 0, 'pegasus_entailment': 0.6389581014712652, 'gold_entailment': 0.42597146052867174, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 426
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.43 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5402298850574713, 'r1_recall': 0.47, 'r1_f1': 0.502673796791444, 'r2_precision': 0.23121387283236994, 'r2_recall': 0.20100502512562815, 'r2_f1': 0.21505376344086022, 'rL_precision': 0.3505747126436782, 'rL_recall': 0.305, 'rL_f1': 0.32620320855614976, 'bs_precision': 0.31657594442367554, 'bs_recall': 0.30184996128082275, 'bs_f1': 0.31152671575546265, 'bs_mnli_precision': 0.6572097539901733, 'bs_mnli_recall': 0.6458996534347534, 'bs_mnli_f1': 0.6515056490898132, 'unique_bigram_ratio': 0.9352941176470588, 'nid': -0.21504557801988367, 'grammatical_errors': 1, 'pegasus_entailment': 0.4268743097782135, 'gold_entailment': 0.3419160325494077, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 427
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.38 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2662337662337662, 'r1_recall': 0.5256410256410257, 'r1_f1': 0.3534482758620689, 'r2_precision': 0.09803921568627451, 'r2_recall': 0.19480519480519481, 'r2_f1': 0.13043478260869565, 'rL_precision': 0.15584415584415584, 'rL_recall': 0.3076923076923077, 'rL_f1': 0.20689655172413793, 'bs_precision': 0.1947300285100937, 'bs_recall': 0.29892927408218384, 'bs_f1': 0.24688686430454254, 'bs_mnli_precision': 0.5957200527191162, 'bs_mnli_recall': 0.6318827271461487, 'bs_mnli_f1': 0.6132687926292419, 'unique_bigram_ratio': 0.9266666666666666, 'nid': -0.22013093385127758, 'grammatical_errors': 3, 'pegasus_entailment': 0.20353302633157, 'gold_entailment': 0.11385504435747862, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 428
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.17 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.43537414965986393, 'r1_recall': 0.6095238095238096, 'r1_f1': 0.5079365079365079, 'r2_precision': 0.2602739726027397, 'r2_recall': 0.36538461538461536, 'r2_f1': 0.304, 'rL_precision': 0.22448979591836735, 'rL_recall': 0.3142857142857143, 'rL_f1': 0.26190476190476186, 'bs_precision': 0.32931339740753174, 'bs_recall': 0.41842353343963623, 'bs_f1': 0.37436139583587646, 'bs_mnli_precision': 0.6586964130401611, 'bs_mnli_recall': 0.7021282911300659, 'bs_mnli_f1': 0.6797192692756653, 'unique_bigram_ratio': 0.9788732394366197, 'nid': -0.22037944831456824, 'grammatical_errors': 0, 'pegasus_entailment': 0.681730384627978, 'gold_entailment': 0.5987249836325645, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 429
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.41 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3945945945945946, 'r1_recall': 0.5367647058823529, 'r1_f1': 0.45482866043613707, 'r2_precision': 0.20652173913043478, 'r2_recall': 0.2814814814814815, 'r2_f1': 0.2382445141065831, 'rL_precision': 0.25405405405405407, 'rL_recall': 0.34558823529411764, 'rL_f1': 0.2928348909657321, 'bs_precision': 0.27818530797958374, 'bs_recall': 0.38508909940719604, 'bs_f1': 0.3314657509326935, 'bs_mnli_precision': 0.6180320382118225, 'bs_mnli_recall': 0.6735880374908447, 'bs_mnli_f1': 0.6446152329444885, 'unique_bigram_ratio': 0.9337016574585635, 'nid': -0.2211798035226109, 'grammatical_errors': 1, 'pegasus_entailment': 0.778464694817861, 'gold_entailment': 0.5320647358894348, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 430
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.80 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2780487804878049, 'r1_recall': 0.504424778761062, 'r1_f1': 0.3584905660377359, 'r2_precision': 0.08333333333333333, 'r2_recall': 0.15178571428571427, 'r2_f1': 0.10759493670886075, 'rL_precision': 0.15609756097560976, 'rL_recall': 0.2831858407079646, 'rL_f1': 0.20125786163522014, 'bs_precision': 0.22778740525245667, 'bs_recall': 0.367022305727005, 'bs_f1': 0.29551607370376587, 'bs_mnli_precision': 0.587859034538269, 'bs_mnli_recall': 0.6467650532722473, 'bs_mnli_f1': 0.6159067749977112, 'unique_bigram_ratio': 0.9303482587064676, 'nid': -0.2098210114900183, 'grammatical_errors': 0, 'pegasus_entailment': 0.33056969195604324, 'gold_entailment': 0.3958990275859833, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 431
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.13 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.26373626373626374, 'r1_recall': 0.5647058823529412, 'r1_f1': 0.35955056179775285, 'r2_precision': 0.0718232044198895, 'r2_recall': 0.15476190476190477, 'r2_f1': 0.0981132075471698, 'rL_precision': 0.14285714285714285, 'rL_recall': 0.3058823529411765, 'rL_f1': 0.1947565543071161, 'bs_precision': 0.19636507332324982, 'bs_recall': 0.34278008341789246, 'bs_f1': 0.26720529794692993, 'bs_mnli_precision': 0.5727007389068604, 'bs_mnli_recall': 0.6704210638999939, 'bs_mnli_f1': 0.6177200675010681, 'unique_bigram_ratio': 0.96, 'nid': -0.2456805448845174, 'grammatical_errors': 4, 'pegasus_entailment': 0.6233587265014648, 'gold_entailment': 0.41168450315793353, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 432
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.02 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24731182795698925, 'r1_recall': 0.696969696969697, 'r1_f1': 0.36507936507936506, 'r2_precision': 0.14054054054054055, 'r2_recall': 0.4, 'r2_f1': 0.20800000000000002, 'rL_precision': 0.1774193548387097, 'rL_recall': 0.5, 'rL_f1': 0.2619047619047619, 'bs_precision': 0.2708452343940735, 'bs_recall': 0.4796690046787262, 'bs_f1': 0.36837059259414673, 'bs_mnli_precision': 0.5974488258361816, 'bs_mnli_recall': 0.6956303715705872, 'bs_mnli_f1': 0.6428122520446777, 'unique_bigram_ratio': 0.9550561797752809, 'nid': -0.22317882597477956, 'grammatical_errors': 0, 'pegasus_entailment': 0.6876246498690711, 'gold_entailment': 0.45224709808826447, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 433
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.45 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2909090909090909, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.41025641025641024, 'r2_precision': 0.136986301369863, 'r2_recall': 0.32967032967032966, 'r2_f1': 0.1935483870967742, 'rL_precision': 0.17272727272727273, 'rL_recall': 0.41304347826086957, 'rL_f1': 0.2435897435897436, 'bs_precision': 0.20810574293136597, 'bs_recall': 0.40005868673324585, 'bs_f1': 0.2983585298061371, 'bs_mnli_precision': 0.5900789499282837, 'bs_mnli_recall': 0.6922174692153931, 'bs_mnli_f1': 0.6370804309844971, 'unique_bigram_ratio': 0.9534883720930233, 'nid': -0.23508162932352183, 'grammatical_errors': 1, 'pegasus_entailment': 0.570956002920866, 'gold_entailment': 0.4653097490469615, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 434
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 66.30 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.33613445378151263, 'r1_recall': 0.4819277108433735, 'r1_f1': 0.39603960396039606, 'r2_precision': 0.0847457627118644, 'r2_recall': 0.12195121951219512, 'r2_f1': 0.09999999999999999, 'rL_precision': 0.18487394957983194, 'rL_recall': 0.26506024096385544, 'rL_f1': 0.21782178217821785, 'bs_precision': 0.19383053481578827, 'bs_recall': 0.33387288451194763, 'bs_f1': 0.2618945240974426, 'bs_mnli_precision': 0.5838293433189392, 'bs_mnli_recall': 0.6158735752105713, 'bs_mnli_f1': 0.5994235277175903, 'unique_bigram_ratio': 0.956140350877193, 'nid': -0.2743717986019458, 'grammatical_errors': 2, 'pegasus_entailment': 0.39585012942552567, 'gold_entailment': 0.10687718043724696, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 435
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.56 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5209580838323353, 'r1_recall': 0.6904761904761905, 'r1_f1': 0.5938566552901023, 'r2_precision': 0.2469879518072289, 'r2_recall': 0.328, 'r2_f1': 0.28178694158075596, 'rL_precision': 0.2874251497005988, 'rL_recall': 0.38095238095238093, 'rL_f1': 0.32764505119453924, 'bs_precision': 0.32288190722465515, 'bs_recall': 0.3822494447231293, 'bs_f1': 0.3540331721305847, 'bs_mnli_precision': 0.6463889479637146, 'bs_mnli_recall': 0.6786521077156067, 'bs_mnli_f1': 0.6621277332305908, 'unique_bigram_ratio': 0.9386503067484663, 'nid': -0.22675997492477484, 'grammatical_errors': 1, 'pegasus_entailment': 0.30763339357716696, 'gold_entailment': 0.49125447558859986, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 436
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 72.91 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5327868852459017, 'r1_recall': 0.6372549019607843, 'r1_f1': 0.5803571428571429, 'r2_precision': 0.18181818181818182, 'r2_recall': 0.21782178217821782, 'r2_f1': 0.19819819819819817, 'rL_precision': 0.319672131147541, 'rL_recall': 0.38235294117647056, 'rL_f1': 0.3482142857142857, 'bs_precision': 0.44819673895835876, 'bs_recall': 0.48530879616737366, 'bs_f1': 0.46830904483795166, 'bs_mnli_precision': 0.6840977668762207, 'bs_mnli_recall': 0.7137132883071899, 'bs_mnli_f1': 0.6985917687416077, 'unique_bigram_ratio': 0.9830508474576272, 'nid': -0.2995935253102413, 'grammatical_errors': 0, 'pegasus_entailment': 0.3677916768938303, 'gold_entailment': 0.29040102163950604, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 437
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.95 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.45054945054945056, 'r1_recall': 0.5093167701863354, 'r1_f1': 0.47813411078717194, 'r2_precision': 0.23204419889502761, 'r2_recall': 0.2625, 'r2_f1': 0.24633431085043986, 'rL_precision': 0.2802197802197802, 'rL_recall': 0.3167701863354037, 'rL_f1': 0.2973760932944607, 'bs_precision': 0.2984166443347931, 'bs_recall': 0.33367621898651123, 'bs_f1': 0.3181118667125702, 'bs_mnli_precision': 0.6332926154136658, 'bs_mnli_recall': 0.6517313122749329, 'bs_mnli_f1': 0.6423797011375427, 'unique_bigram_ratio': 0.9497206703910615, 'nid': -0.22335022651960146, 'grammatical_errors': 2, 'pegasus_entailment': 0.4369492083787918, 'gold_entailment': 0.6180086374282837, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 438
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 86.23 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2619047619047619, 'r1_recall': 0.38596491228070173, 'r1_f1': 0.31205673758865243, 'r2_precision': 0.08433734939759036, 'r2_recall': 0.125, 'r2_f1': 0.10071942446043165, 'rL_precision': 0.17857142857142858, 'rL_recall': 0.2631578947368421, 'rL_f1': 0.2127659574468085, 'bs_precision': 0.3047892451286316, 'bs_recall': 0.42036065459251404, 'bs_f1': 0.3619585335254669, 'bs_mnli_precision': 0.6200857162475586, 'bs_mnli_recall': 0.657990574836731, 'bs_mnli_f1': 0.6384760141372681, 'unique_bigram_ratio': 0.9876543209876543, 'nid': -0.2915146269219786, 'grammatical_errors': 1, 'pegasus_entailment': 0.31268618553876876, 'gold_entailment': 0.05044260248541832, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 439
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 43.06 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.640625, 'r1_recall': 0.36283185840707965, 'r1_f1': 0.46327683615819215, 'r2_precision': 0.2204724409448819, 'r2_recall': 0.12444444444444444, 'r2_f1': 0.1590909090909091, 'rL_precision': 0.3125, 'rL_recall': 0.17699115044247787, 'rL_f1': 0.22598870056497175, 'bs_precision': 0.301146537065506, 'bs_recall': 0.17940425872802734, 'bs_f1': 0.23942767083644867, 'bs_mnli_precision': 0.6330066323280334, 'bs_mnli_recall': 0.5525931715965271, 'bs_mnli_f1': 0.5900728702545166, 'unique_bigram_ratio': 0.9919354838709677, 'nid': -0.22001431192092902, 'grammatical_errors': 0, 'pegasus_entailment': 0.6309045510632652, 'gold_entailment': 0.59876235468047, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 440
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.26 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.1778846153846154, 'r1_recall': 0.6166666666666667, 'r1_f1': 0.27611940298507465, 'r2_precision': 0.057971014492753624, 'r2_recall': 0.2033898305084746, 'r2_f1': 0.09022556390977444, 'rL_precision': 0.1201923076923077, 'rL_recall': 0.4166666666666667, 'rL_f1': 0.1865671641791045, 'bs_precision': 0.18324004113674164, 'bs_recall': 0.41908809542655945, 'bs_f1': 0.29129210114479065, 'bs_mnli_precision': 0.5710017681121826, 'bs_mnli_recall': 0.6775404214859009, 'bs_mnli_f1': 0.6197256445884705, 'unique_bigram_ratio': 0.9310344827586207, 'nid': -0.21023331956449853, 'grammatical_errors': 7, 'pegasus_entailment': 0.5463354852464464, 'gold_entailment': 0.642833024263382, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 441
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.98 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3507853403141361, 'r1_recall': 0.6633663366336634, 'r1_f1': 0.45890410958904104, 'r2_precision': 0.1631578947368421, 'r2_recall': 0.31, 'r2_f1': 0.21379310344827587, 'rL_precision': 0.17801047120418848, 'rL_recall': 0.33663366336633666, 'rL_f1': 0.2328767123287671, 'bs_precision': 0.20841968059539795, 'bs_recall': 0.34001919627189636, 'bs_f1': 0.2727866768836975, 'bs_mnli_precision': 0.6048307418823242, 'bs_mnli_recall': 0.6736466884613037, 'bs_mnli_f1': 0.6373866200447083, 'unique_bigram_ratio': 0.9679144385026738, 'nid': -0.23272950177324514, 'grammatical_errors': 7, 'pegasus_entailment': 0.48530084805356133, 'gold_entailment': 0.5190190275510153, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 442
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.08 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.21518987341772153, 'r1_recall': 0.6938775510204082, 'r1_f1': 0.3285024154589372, 'r2_precision': 0.10828025477707007, 'r2_recall': 0.3541666666666667, 'r2_f1': 0.16585365853658537, 'rL_precision': 0.15822784810126583, 'rL_recall': 0.5102040816326531, 'rL_f1': 0.24154589371980673, 'bs_precision': 0.21037159860134125, 'bs_recall': 0.4977852404117584, 'bs_f1': 0.33889493346214294, 'bs_mnli_precision': 0.5541095733642578, 'bs_mnli_recall': 0.710607647895813, 'bs_mnli_f1': 0.6226759552955627, 'unique_bigram_ratio': 0.974025974025974, 'nid': -0.24228299132211895, 'grammatical_errors': 1, 'pegasus_entailment': 0.5860827362630516, 'gold_entailment': 0.28166988492012024, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 443
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.98 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.1301775147928994, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.20465116279069767, 'r2_precision': 0.023809523809523808, 'r2_recall': 0.08888888888888889, 'r2_f1': 0.03755868544600939, 'rL_precision': 0.08284023668639054, 'rL_recall': 0.30434782608695654, 'rL_f1': 0.1302325581395349, 'bs_precision': 0.1358899027109146, 'bs_recall': 0.3238789439201355, 'bs_f1': 0.22420117259025574, 'bs_mnli_precision': 0.5383487939834595, 'bs_mnli_recall': 0.6528802514076233, 'bs_mnli_f1': 0.5901086330413818, 'unique_bigram_ratio': 0.9575757575757575, 'nid': -0.2217401124020253, 'grammatical_errors': 2, 'pegasus_entailment': 0.6916432430346807, 'gold_entailment': 0.6174269914627075, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 444
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.50 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4472361809045226, 'r1_recall': 0.6095890410958904, 'r1_f1': 0.5159420289855072, 'r2_precision': 0.1919191919191919, 'r2_recall': 0.2620689655172414, 'r2_f1': 0.22157434402332363, 'rL_precision': 0.23618090452261306, 'rL_recall': 0.3219178082191781, 'rL_f1': 0.27246376811594203, 'bs_precision': 0.27489712834358215, 'bs_recall': 0.42829298973083496, 'bs_f1': 0.3488438129425049, 'bs_mnli_precision': 0.6323277950286865, 'bs_mnli_recall': 0.7132203578948975, 'bs_mnli_f1': 0.6703425049781799, 'unique_bigram_ratio': 0.9375, 'nid': -0.24212111790324187, 'grammatical_errors': 4, 'pegasus_entailment': 0.458009901146094, 'gold_entailment': 0.38235898440082866, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 445
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 36.80 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4020618556701031, 'r1_recall': 0.609375, 'r1_f1': 0.4844720496894411, 'r2_precision': 0.16206896551724137, 'r2_recall': 0.24607329842931938, 'r2_f1': 0.19542619542619544, 'rL_precision': 0.21649484536082475, 'rL_recall': 0.328125, 'rL_f1': 0.2608695652173913, 'bs_precision': 0.27498677372932434, 'bs_recall': 0.40796059370040894, 'bs_f1': 0.3399584889411926, 'bs_mnli_precision': 0.6131410598754883, 'bs_mnli_recall': 0.6791609525680542, 'bs_mnli_f1': 0.6444646120071411, 'unique_bigram_ratio': 0.9257950530035336, 'nid': -0.22455612290873872, 'grammatical_errors': 5, 'pegasus_entailment': 0.4583131562579762, 'gold_entailment': 0.3645241955916087, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 446
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 71.92 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3504273504273504, 'r1_recall': 0.5540540540540541, 'r1_f1': 0.42931937172774864, 'r2_precision': 0.1206896551724138, 'r2_recall': 0.1917808219178082, 'r2_f1': 0.14814814814814814, 'rL_precision': 0.20512820512820512, 'rL_recall': 0.32432432432432434, 'rL_f1': 0.25130890052356025, 'bs_precision': 0.30398812890052795, 'bs_recall': 0.4402685761451721, 'bs_f1': 0.37041985988616943, 'bs_mnli_precision': 0.614784836769104, 'bs_mnli_recall': 0.6687004566192627, 'bs_mnli_f1': 0.6406102180480957, 'unique_bigram_ratio': 0.9385964912280702, 'nid': -0.253800969918355, 'grammatical_errors': 1, 'pegasus_entailment': 0.44235186092555523, 'gold_entailment': 0.39876213918129605, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 447
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.24 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.37058823529411766, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.46840148698884765, 'r2_precision': 0.14792899408284024, 'r2_recall': 0.25510204081632654, 'r2_f1': 0.18726591760299624, 'rL_precision': 0.24705882352941178, 'rL_recall': 0.42424242424242425, 'rL_f1': 0.31226765799256506, 'bs_precision': 0.3004682660102844, 'bs_recall': 0.45250052213668823, 'bs_f1': 0.3738366365432739, 'bs_mnli_precision': 0.6269373893737793, 'bs_mnli_recall': 0.7065374255180359, 'bs_mnli_f1': 0.6643615365028381, 'unique_bigram_ratio': 0.9464285714285714, 'nid': -0.2329391533025078, 'grammatical_errors': 1, 'pegasus_entailment': 0.5828320321937402, 'gold_entailment': 0.4327055538694064, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 448
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.48 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.25316455696202533, 'r1_recall': 0.7228915662650602, 'r1_f1': 0.37500000000000006, 'r2_precision': 0.1483050847457627, 'r2_recall': 0.4268292682926829, 'r2_f1': 0.220125786163522, 'rL_precision': 0.20253164556962025, 'rL_recall': 0.5783132530120482, 'rL_f1': 0.3, 'bs_precision': 0.26233068108558655, 'bs_recall': 0.6018017530441284, 'bs_f1': 0.41124752163887024, 'bs_mnli_precision': 0.6029167175292969, 'bs_mnli_recall': 0.7588359117507935, 'bs_mnli_f1': 0.6719500422477722, 'unique_bigram_ratio': 0.9559471365638766, 'nid': -0.22440277031935718, 'grammatical_errors': 5, 'pegasus_entailment': 0.5097112398255955, 'gold_entailment': 0.2683797553181648, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 449
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.09 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2084942084942085, 'r1_recall': 0.7605633802816901, 'r1_f1': 0.32727272727272727, 'r2_precision': 0.10852713178294573, 'r2_recall': 0.4, 'r2_f1': 0.17073170731707318, 'rL_precision': 0.1274131274131274, 'rL_recall': 0.4647887323943662, 'rL_f1': 0.19999999999999998, 'bs_precision': 0.18676252663135529, 'bs_recall': 0.4994947910308838, 'bs_f1': 0.3245925307273865, 'bs_mnli_precision': 0.5642695426940918, 'bs_mnli_recall': 0.7166675329208374, 'bs_mnli_f1': 0.631402850151062, 'unique_bigram_ratio': 0.9411764705882353, 'nid': -0.20508148020870376, 'grammatical_errors': 1, 'pegasus_entailment': 0.5600296296179295, 'gold_entailment': 0.4776098132133484, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 450
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.61 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3812154696132597, 'r1_recall': 0.6, 'r1_f1': 0.46621621621621623, 'r2_precision': 0.17777777777777778, 'r2_recall': 0.2807017543859649, 'r2_f1': 0.21768707482993196, 'rL_precision': 0.281767955801105, 'rL_recall': 0.4434782608695652, 'rL_f1': 0.3445945945945946, 'bs_precision': 0.366746723651886, 'bs_recall': 0.4891138970851898, 'bs_f1': 0.42691540718078613, 'bs_mnli_precision': 0.6536909341812134, 'bs_mnli_recall': 0.7105686664581299, 'bs_mnli_f1': 0.6809441447257996, 'unique_bigram_ratio': 0.9602272727272727, 'nid': -0.2594902332401867, 'grammatical_errors': 3, 'pegasus_entailment': 0.4811196882898609, 'gold_entailment': 0.22453389316797256, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 451
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.52 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4918032786885246, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.5128205128205129, 'r2_precision': 0.2087912087912088, 'r2_recall': 0.2275449101796407, 'r2_f1': 0.2177650429799427, 'rL_precision': 0.2786885245901639, 'rL_recall': 0.30357142857142855, 'rL_f1': 0.29059829059829057, 'bs_precision': 0.4129302203655243, 'bs_recall': 0.42384469509124756, 'bs_f1': 0.4203508198261261, 'bs_mnli_precision': 0.6914370059967041, 'bs_mnli_recall': 0.682988703250885, 'bs_mnli_f1': 0.6871868968009949, 'unique_bigram_ratio': 0.9482758620689655, 'nid': -0.2371948514116906, 'grammatical_errors': 2, 'pegasus_entailment': 0.6141242567035887, 'gold_entailment': 0.3407990166119167, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 452
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.04 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.11196911196911197, 'r1_recall': 0.5471698113207547, 'r1_f1': 0.1858974358974359, 'r2_precision': 0.03875968992248062, 'r2_recall': 0.19230769230769232, 'r2_f1': 0.06451612903225806, 'rL_precision': 0.06563706563706563, 'rL_recall': 0.32075471698113206, 'rL_f1': 0.10897435897435898, 'bs_precision': 0.11593127995729446, 'bs_recall': 0.41455307602882385, 'bs_f1': 0.2474568486213684, 'bs_mnli_precision': 0.5044964551925659, 'bs_mnli_recall': 0.664781391620636, 'bs_mnli_f1': 0.573652982711792, 'unique_bigram_ratio': 0.9407114624505929, 'nid': -0.21923608622341595, 'grammatical_errors': 1, 'pegasus_entailment': 0.6640685245394706, 'gold_entailment': 0.1593722514808178, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 453
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.04 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.39593908629441626, 'r1_recall': 0.7222222222222222, 'r1_f1': 0.5114754098360655, 'r2_precision': 0.2193877551020408, 'r2_recall': 0.40186915887850466, 'r2_f1': 0.28382838283828377, 'rL_precision': 0.26903553299492383, 'rL_recall': 0.49074074074074076, 'rL_f1': 0.34754098360655733, 'bs_precision': 0.3859017491340637, 'bs_recall': 0.558019757270813, 'bs_f1': 0.4680907428264618, 'bs_mnli_precision': 0.672437310218811, 'bs_mnli_recall': 0.7650456428527832, 'bs_mnli_f1': 0.7157583832740784, 'unique_bigram_ratio': 0.9375, 'nid': -0.22510135814771748, 'grammatical_errors': 1, 'pegasus_entailment': 0.7193793475627899, 'gold_entailment': 0.6904072090983391, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 454
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.73 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3897058823529412, 'r1_recall': 0.4690265486725664, 'r1_f1': 0.42570281124497994, 'r2_precision': 0.14074074074074075, 'r2_recall': 0.16964285714285715, 'r2_f1': 0.15384615384615385, 'rL_precision': 0.25735294117647056, 'rL_recall': 0.30973451327433627, 'rL_f1': 0.2811244979919678, 'bs_precision': 0.3129802644252777, 'bs_recall': 0.3753550052642822, 'bs_f1': 0.3455807566642761, 'bs_mnli_precision': 0.6285642385482788, 'bs_mnli_recall': 0.6547303199768066, 'bs_mnli_f1': 0.6413804888725281, 'unique_bigram_ratio': 0.9224806201550387, 'nid': -0.24352292938343711, 'grammatical_errors': 2, 'pegasus_entailment': 0.5587762415409088, 'gold_entailment': 0.1727272868156433, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 455
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 72.24 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.25663716814159293, 'r1_recall': 0.4084507042253521, 'r1_f1': 0.31521739130434784, 'r2_precision': 0.125, 'r2_recall': 0.2, 'r2_f1': 0.15384615384615385, 'rL_precision': 0.17699115044247787, 'rL_recall': 0.28169014084507044, 'rL_f1': 0.2173913043478261, 'bs_precision': 0.26886582374572754, 'bs_recall': 0.3463767170906067, 'bs_f1': 0.3086684048175812, 'bs_mnli_precision': 0.5797157883644104, 'bs_mnli_recall': 0.6460824608802795, 'bs_mnli_f1': 0.6111025214195251, 'unique_bigram_ratio': 0.9814814814814815, 'nid': -0.237207635748103, 'grammatical_errors': 0, 'pegasus_entailment': 0.7899160385131836, 'gold_entailment': 0.5569389760494232, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 456
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 42.84 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.50920245398773, 'r1_recall': 0.3789954337899543, 'r1_f1': 0.43455497382198943, 'r2_precision': 0.15432098765432098, 'r2_recall': 0.11467889908256881, 'r2_f1': 0.13157894736842107, 'rL_precision': 0.3128834355828221, 'rL_recall': 0.2328767123287671, 'rL_f1': 0.2670157068062827, 'bs_precision': 0.3408161699771881, 'bs_recall': 0.22429372370243073, 'bs_f1': 0.2819717228412628, 'bs_mnli_precision': 0.6450007557868958, 'bs_mnli_recall': 0.5994170904159546, 'bs_mnli_f1': 0.6213740110397339, 'unique_bigram_ratio': 0.9556962025316456, 'nid': -0.2559772795801689, 'grammatical_errors': 2, 'pegasus_entailment': 0.7508281717697779, 'gold_entailment': 0.4976559612486098, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 457
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.79 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.13953488372093023, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.2195121951219512, 'r2_precision': 0.03125, 'r2_recall': 0.11764705882352941, 'r2_f1': 0.04938271604938271, 'rL_precision': 0.07751937984496124, 'rL_recall': 0.2857142857142857, 'rL_f1': 0.1219512195121951, 'bs_precision': 0.13115550577640533, 'bs_recall': 0.3454989492893219, 'bs_f1': 0.23020708560943604, 'bs_mnli_precision': 0.5169035196304321, 'bs_mnli_recall': 0.678852915763855, 'bs_mnli_f1': 0.5869112610816956, 'unique_bigram_ratio': 1.0, 'nid': -0.28677361328146933, 'grammatical_errors': 2, 'pegasus_entailment': 0.6926275317867597, 'gold_entailment': 0.8428828517595927, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 458
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 66.58 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.7951807228915663, 'r1_f1': 0.5569620253164557, 'r2_precision': 0.28104575163398693, 'r2_recall': 0.524390243902439, 'r2_f1': 0.3659574468085106, 'rL_precision': 0.2922077922077922, 'rL_recall': 0.5421686746987951, 'rL_f1': 0.37974683544303794, 'bs_precision': 0.3990043103694916, 'bs_recall': 0.6041275858879089, 'bs_f1': 0.49539047479629517, 'bs_mnli_precision': 0.6846978664398193, 'bs_mnli_recall': 0.7893264293670654, 'bs_mnli_f1': 0.7332987785339355, 'unique_bigram_ratio': 0.9662162162162162, 'nid': -0.27655193900195507, 'grammatical_errors': 5, 'pegasus_entailment': 0.4255759686231613, 'gold_entailment': 0.5517454544703165, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 459
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.48 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.15023474178403756, 'r1_recall': 0.6530612244897959, 'r1_f1': 0.24427480916030533, 'r2_precision': 0.0330188679245283, 'r2_recall': 0.14583333333333334, 'r2_f1': 0.053846153846153856, 'rL_precision': 0.0892018779342723, 'rL_recall': 0.3877551020408163, 'rL_f1': 0.1450381679389313, 'bs_precision': 0.09584110975265503, 'bs_recall': 0.3933449983596802, 'bs_f1': 0.2266428917646408, 'bs_mnli_precision': 0.5133805274963379, 'bs_mnli_recall': 0.6671809554100037, 'bs_mnli_f1': 0.5802623629570007, 'unique_bigram_ratio': 0.9420289855072463, 'nid': -0.1952413138808089, 'grammatical_errors': 1, 'pegasus_entailment': 0.28032386442646384, 'gold_entailment': 0.16322572552599013, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 460
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.43 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6134453781512605, 'r1_recall': 0.4294117647058823, 'r1_f1': 0.5051903114186851, 'r2_precision': 0.3220338983050847, 'r2_recall': 0.22485207100591717, 'r2_f1': 0.264808362369338, 'rL_precision': 0.33613445378151263, 'rL_recall': 0.23529411764705882, 'rL_f1': 0.2768166089965398, 'bs_precision': 0.4465274512767792, 'bs_recall': 0.4081098437309265, 'bs_f1': 0.42898455262184143, 'bs_mnli_precision': 0.6767110824584961, 'bs_mnli_recall': 0.6702612638473511, 'bs_mnli_f1': 0.6734707355499268, 'unique_bigram_ratio': 0.9482758620689655, 'nid': -0.26824271835965363, 'grammatical_errors': 2, 'pegasus_entailment': 0.47454046458005905, 'gold_entailment': 0.27312973514199257, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 461
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.10 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.627906976744186, 'r1_f1': 0.5567010309278351, 'r2_precision': 0.2484472049689441, 'r2_recall': 0.3125, 'r2_f1': 0.27681660899653976, 'rL_precision': 0.35802469135802467, 'rL_recall': 0.4496124031007752, 'rL_f1': 0.39862542955326463, 'bs_precision': 0.43290412425994873, 'bs_recall': 0.46937626600265503, 'bs_f1': 0.45275574922561646, 'bs_mnli_precision': 0.7006731033325195, 'bs_mnli_recall': 0.7269753813743591, 'bs_mnli_f1': 0.713581919670105, 'unique_bigram_ratio': 0.9615384615384616, 'nid': -0.22806956719251947, 'grammatical_errors': 0, 'pegasus_entailment': 0.6290342254298074, 'gold_entailment': 0.5098268896341324, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 462
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.00 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2643171806167401, 'r1_recall': 0.6896551724137931, 'r1_f1': 0.38216560509554137, 'r2_precision': 0.11061946902654868, 'r2_recall': 0.29069767441860467, 'r2_f1': 0.16025641025641027, 'rL_precision': 0.19823788546255505, 'rL_recall': 0.5172413793103449, 'rL_f1': 0.28662420382165604, 'bs_precision': 0.28294458985328674, 'bs_recall': 0.47862502932548523, 'bs_f1': 0.3750149607658386, 'bs_mnli_precision': 0.6129368543624878, 'bs_mnli_recall': 0.7089341878890991, 'bs_mnli_f1': 0.6574497818946838, 'unique_bigram_ratio': 0.9464285714285714, 'nid': -0.2329035286862371, 'grammatical_errors': 0, 'pegasus_entailment': 0.5862707085907459, 'gold_entailment': 0.43759339054425556, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 463
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.81 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.46853146853146854, 'r1_recall': 0.5037593984962406, 'r1_f1': 0.4855072463768116, 'r2_precision': 0.2535211267605634, 'r2_recall': 0.2727272727272727, 'r2_f1': 0.2627737226277372, 'rL_precision': 0.3776223776223776, 'rL_recall': 0.40601503759398494, 'rL_f1': 0.391304347826087, 'bs_precision': 0.4117445945739746, 'bs_recall': 0.4285828471183777, 'bs_f1': 0.4220879375934601, 'bs_mnli_precision': 0.681186318397522, 'bs_mnli_recall': 0.7049428820610046, 'bs_mnli_f1': 0.6928610801696777, 'unique_bigram_ratio': 0.95, 'nid': -0.26324610487721634, 'grammatical_errors': 0, 'pegasus_entailment': 0.4965300649404526, 'gold_entailment': 0.14413364324718714, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 464
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.89 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3160377358490566, 'r1_recall': 0.6036036036036037, 'r1_f1': 0.4148606811145511, 'r2_precision': 0.14218009478672985, 'r2_recall': 0.2727272727272727, 'r2_f1': 0.18691588785046728, 'rL_precision': 0.17452830188679244, 'rL_recall': 0.3333333333333333, 'rL_f1': 0.22910216718266255, 'bs_precision': 0.2663249671459198, 'bs_recall': 0.3741331994533539, 'bs_f1': 0.3200303316116333, 'bs_mnli_precision': 0.6079465746879578, 'bs_mnli_recall': 0.6708660125732422, 'bs_mnli_f1': 0.6378583908081055, 'unique_bigram_ratio': 0.9333333333333333, 'nid': -0.20540299812290774, 'grammatical_errors': 3, 'pegasus_entailment': 0.24184776097536087, 'gold_entailment': 0.09690462611615658, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 465
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.28 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3877551020408163, 'r1_recall': 0.59375, 'r1_f1': 0.46913580246913583, 'r2_precision': 0.19863013698630136, 'r2_recall': 0.30526315789473685, 'r2_f1': 0.24066390041493776, 'rL_precision': 0.30612244897959184, 'rL_recall': 0.46875, 'rL_f1': 0.3703703703703704, 'bs_precision': 0.3165625333786011, 'bs_recall': 0.4095556139945984, 'bs_f1': 0.3634262681007385, 'bs_mnli_precision': 0.6454313397407532, 'bs_mnli_recall': 0.6987941265106201, 'bs_mnli_f1': 0.6710535883903503, 'unique_bigram_ratio': 0.9790209790209791, 'nid': -0.27609878176215363, 'grammatical_errors': 2, 'pegasus_entailment': 0.36479074880480766, 'gold_entailment': 0.16735884547233582, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 466
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.88 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5285714285714286, 'r1_f1': 0.513888888888889, 'r2_precision': 0.2108843537414966, 'r2_recall': 0.22302158273381295, 'r2_f1': 0.2167832167832168, 'rL_precision': 0.32432432432432434, 'rL_recall': 0.34285714285714286, 'rL_f1': 0.33333333333333337, 'bs_precision': 0.35310104489326477, 'bs_recall': 0.43694227933883667, 'bs_f1': 0.39565619826316833, 'bs_mnli_precision': 0.6709724068641663, 'bs_mnli_recall': 0.6897134184837341, 'bs_mnli_f1': 0.6802138090133667, 'unique_bigram_ratio': 0.9726027397260274, 'nid': -0.26188312988921925, 'grammatical_errors': 3, 'pegasus_entailment': 0.46343602364261943, 'gold_entailment': 0.47395063042640684, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 467
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.95 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.31223628691983124, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.3884514435695538, 'r2_precision': 0.1228813559322034, 'r2_recall': 0.20279720279720279, 'r2_f1': 0.1530343007915567, 'rL_precision': 0.1940928270042194, 'rL_recall': 0.3194444444444444, 'rL_f1': 0.24146981627296588, 'bs_precision': 0.2526802718639374, 'bs_recall': 0.306436151266098, 'bs_f1': 0.28136900067329407, 'bs_mnli_precision': 0.599425196647644, 'bs_mnli_recall': 0.6408923864364624, 'bs_mnli_f1': 0.6194655895233154, 'unique_bigram_ratio': 0.9260869565217391, 'nid': -0.21921774131197713, 'grammatical_errors': 6, 'pegasus_entailment': 0.742307152066912, 'gold_entailment': 0.6037763605515162, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 468
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.62 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4088050314465409, 'r1_recall': 0.7065217391304348, 'r1_f1': 0.5179282868525897, 'r2_precision': 0.22784810126582278, 'r2_recall': 0.3956043956043956, 'r2_f1': 0.28915662650602403, 'rL_precision': 0.25157232704402516, 'rL_recall': 0.43478260869565216, 'rL_f1': 0.3187250996015936, 'bs_precision': 0.38022956252098083, 'bs_recall': 0.5896105766296387, 'bs_f1': 0.47836726903915405, 'bs_mnli_precision': 0.6490016579627991, 'bs_mnli_recall': 0.7683840990066528, 'bs_mnli_f1': 0.7036652565002441, 'unique_bigram_ratio': 0.9802631578947368, 'nid': -0.2745888875588751, 'grammatical_errors': 3, 'pegasus_entailment': 0.37626969814300537, 'gold_entailment': 0.1790099861100316, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 469
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.79 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.29004329004329005, 'r1_recall': 0.6504854368932039, 'r1_f1': 0.4011976047904192, 'r2_precision': 0.10434782608695652, 'r2_recall': 0.23529411764705882, 'r2_f1': 0.14457831325301204, 'rL_precision': 0.1774891774891775, 'rL_recall': 0.39805825242718446, 'rL_f1': 0.24550898203592814, 'bs_precision': 0.2549454867839813, 'bs_recall': 0.3901119828224182, 'bs_f1': 0.3208891749382019, 'bs_mnli_precision': 0.5999468564987183, 'bs_mnli_recall': 0.6867128610610962, 'bs_mnli_f1': 0.6404042840003967, 'unique_bigram_ratio': 0.9292035398230089, 'nid': -0.21324171218410082, 'grammatical_errors': 4, 'pegasus_entailment': 0.6448588669300079, 'gold_entailment': 0.5708258092403412, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 470
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 72.32 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.35398230088495575, 'r1_recall': 0.5970149253731343, 'r1_f1': 0.4444444444444444, 'r2_precision': 0.14285714285714285, 'r2_recall': 0.24242424242424243, 'r2_f1': 0.1797752808988764, 'rL_precision': 0.21238938053097345, 'rL_recall': 0.3582089552238806, 'rL_f1': 0.2666666666666666, 'bs_precision': 0.34560465812683105, 'bs_recall': 0.45349499583244324, 'bs_f1': 0.399239182472229, 'bs_mnli_precision': 0.6301147937774658, 'bs_mnli_recall': 0.6910097002983093, 'bs_mnli_f1': 0.6591588258743286, 'unique_bigram_ratio': 0.990909090909091, 'nid': -0.31504692301989823, 'grammatical_errors': 1, 'pegasus_entailment': 0.3605500370264053, 'gold_entailment': 0.13834990188479424, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 471
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.90 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2972972972972973, 'r1_recall': 0.4835164835164835, 'r1_f1': 0.3682008368200837, 'r2_precision': 0.16326530612244897, 'r2_recall': 0.26666666666666666, 'r2_f1': 0.20253164556962022, 'rL_precision': 0.21621621621621623, 'rL_recall': 0.3516483516483517, 'rL_f1': 0.26778242677824265, 'bs_precision': 0.19414480030536652, 'bs_recall': 0.31974124908447266, 'bs_f1': 0.25586122274398804, 'bs_mnli_precision': 0.5827850103378296, 'bs_mnli_recall': 0.6648829579353333, 'bs_mnli_f1': 0.6211329102516174, 'unique_bigram_ratio': 0.9652777777777778, 'nid': -0.24999331678057768, 'grammatical_errors': 0, 'pegasus_entailment': 0.3371919648987906, 'gold_entailment': 0.08973820507526398, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 472
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.86 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.34134615384615385, 'r1_recall': 0.4965034965034965, 'r1_f1': 0.4045584045584045, 'r2_precision': 0.1642512077294686, 'r2_recall': 0.23943661971830985, 'r2_f1': 0.19484240687679086, 'rL_precision': 0.23076923076923078, 'rL_recall': 0.3356643356643357, 'rL_f1': 0.27350427350427353, 'bs_precision': 0.28570130467414856, 'bs_recall': 0.3355020582675934, 'bs_f1': 0.3124137222766876, 'bs_mnli_precision': 0.6108599901199341, 'bs_mnli_recall': 0.6527936458587646, 'bs_mnli_f1': 0.6311310529708862, 'unique_bigram_ratio': 0.9353233830845771, 'nid': -0.226079039694856, 'grammatical_errors': 1, 'pegasus_entailment': 0.36208198804940495, 'gold_entailment': 0.11421643146313727, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 473
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.57 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.546875, 'r1_recall': 0.5737704918032787, 'r1_f1': 0.5599999999999999, 'r2_precision': 0.25196850393700787, 'r2_recall': 0.2644628099173554, 'r2_f1': 0.25806451612903225, 'rL_precision': 0.3515625, 'rL_recall': 0.36885245901639346, 'rL_f1': 0.36, 'bs_precision': 0.4143519997596741, 'bs_recall': 0.44948917627334595, 'bs_f1': 0.4336167573928833, 'bs_mnli_precision': 0.6892772912979126, 'bs_mnli_recall': 0.7113228440284729, 'bs_mnli_f1': 0.7001265287399292, 'unique_bigram_ratio': 0.9669421487603306, 'nid': -0.2931469243376672, 'grammatical_errors': 1, 'pegasus_entailment': 0.4081118028610945, 'gold_entailment': 0.32846583649516103, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 474
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.12 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5088757396449705, 'r1_recall': 0.5180722891566265, 'r1_f1': 0.5134328358208955, 'r2_precision': 0.23809523809523808, 'r2_recall': 0.24242424242424243, 'r2_f1': 0.24024024024024024, 'rL_precision': 0.3254437869822485, 'rL_recall': 0.3313253012048193, 'rL_f1': 0.3283582089552239, 'bs_precision': 0.3298164904117584, 'bs_recall': 0.2831745445728302, 'bs_f1': 0.3083905279636383, 'bs_mnli_precision': 0.6363115310668945, 'bs_mnli_recall': 0.6356037259101868, 'bs_mnli_f1': 0.6359574794769287, 'unique_bigram_ratio': 0.9451219512195121, 'nid': -0.20483352458614368, 'grammatical_errors': 1, 'pegasus_entailment': 0.48619034389654797, 'gold_entailment': 0.4222841590642929, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 475
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 77.15 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3089430894308943, 'r1_recall': 0.6909090909090909, 'r1_f1': 0.4269662921348315, 'r2_precision': 0.20491803278688525, 'r2_recall': 0.46296296296296297, 'r2_f1': 0.2840909090909091, 'rL_precision': 0.2682926829268293, 'rL_recall': 0.6, 'rL_f1': 0.3707865168539326, 'bs_precision': 0.36269834637641907, 'bs_recall': 0.6505211591720581, 'bs_f1': 0.4928460121154785, 'bs_mnli_precision': 0.6341015696525574, 'bs_mnli_recall': 0.7673787474632263, 'bs_mnli_f1': 0.6944029927253723, 'unique_bigram_ratio': 0.9421487603305785, 'nid': -0.2792159766484714, 'grammatical_errors': 1, 'pegasus_entailment': 0.18915075063705444, 'gold_entailment': 0.15200016275048256, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 476
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 66.58 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.6081081081081081, 'r1_f1': 0.43062200956937796, 'r2_precision': 0.13432835820895522, 'r2_recall': 0.2465753424657534, 'r2_f1': 0.17391304347826086, 'rL_precision': 0.25925925925925924, 'rL_recall': 0.47297297297297297, 'rL_f1': 0.3349282296650718, 'bs_precision': 0.32464271783828735, 'bs_recall': 0.5361219048500061, 'bs_f1': 0.42348143458366394, 'bs_mnli_precision': 0.6261029839515686, 'bs_mnli_recall': 0.7186322212219238, 'bs_mnli_f1': 0.6691842675209045, 'unique_bigram_ratio': 0.9689922480620154, 'nid': -0.27783759236831473, 'grammatical_errors': 1, 'pegasus_entailment': 0.4923576325178146, 'gold_entailment': 0.3336254097521305, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 477
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 43.32 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.512396694214876, 'r1_recall': 0.6078431372549019, 'r1_f1': 0.5560538116591928, 'r2_precision': 0.26556016597510373, 'r2_recall': 0.31527093596059114, 'r2_f1': 0.2882882882882883, 'rL_precision': 0.2975206611570248, 'rL_recall': 0.35294117647058826, 'rL_f1': 0.3228699551569507, 'bs_precision': 0.3992899954319, 'bs_recall': 0.41073718667030334, 'bs_f1': 0.4070199728012085, 'bs_mnli_precision': 0.6782264709472656, 'bs_mnli_recall': 0.7065042853355408, 'bs_mnli_f1': 0.6920766234397888, 'unique_bigram_ratio': 0.9324894514767933, 'nid': -0.21854783479821993, 'grammatical_errors': 7, 'pegasus_entailment': 0.32159640919417143, 'gold_entailment': 0.19473529565665457, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 478
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.77 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5511811023622047, 'r1_recall': 0.32407407407407407, 'r1_f1': 0.40816326530612246, 'r2_precision': 0.23809523809523808, 'r2_recall': 0.13953488372093023, 'r2_f1': 0.17595307917888564, 'rL_precision': 0.3228346456692913, 'rL_recall': 0.18981481481481483, 'rL_f1': 0.23906705539358603, 'bs_precision': 0.3898716866970062, 'bs_recall': 0.2778574526309967, 'bs_f1': 0.3334600031375885, 'bs_mnli_precision': 0.6684962511062622, 'bs_mnli_recall': 0.6100314855575562, 'bs_mnli_f1': 0.6379271149635315, 'unique_bigram_ratio': 0.9836065573770492, 'nid': -0.2954178685264992, 'grammatical_errors': 0, 'pegasus_entailment': 0.3072292432188988, 'gold_entailment': 0.1330234280321747, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 479
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.15 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.43448275862068964, 'r1_recall': 0.5206611570247934, 'r1_f1': 0.47368421052631576, 'r2_precision': 0.18055555555555555, 'r2_recall': 0.21666666666666667, 'r2_f1': 0.19696969696969693, 'rL_precision': 0.3103448275862069, 'rL_recall': 0.371900826446281, 'rL_f1': 0.3383458646616541, 'bs_precision': 0.34114351868629456, 'bs_recall': 0.4266148507595062, 'bs_f1': 0.3844820261001587, 'bs_mnli_precision': 0.6420062184333801, 'bs_mnli_recall': 0.6890543699264526, 'bs_mnli_f1': 0.6646987795829773, 'unique_bigram_ratio': 0.948905109489051, 'nid': -0.2366582907425363, 'grammatical_errors': 3, 'pegasus_entailment': 0.5445900758107504, 'gold_entailment': 0.28021978338559467, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 480
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.96 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.34497816593886466, 'r1_recall': 0.5524475524475524, 'r1_f1': 0.42473118279569894, 'r2_precision': 0.14035087719298245, 'r2_recall': 0.22535211267605634, 'r2_f1': 0.17297297297297295, 'rL_precision': 0.20087336244541484, 'rL_recall': 0.32167832167832167, 'rL_f1': 0.2473118279569892, 'bs_precision': 0.197914257645607, 'bs_recall': 0.32808440923690796, 'bs_f1': 0.261650025844574, 'bs_mnli_precision': 0.572430431842804, 'bs_mnli_recall': 0.6567420363426208, 'bs_mnli_f1': 0.6116946935653687, 'unique_bigram_ratio': 0.9357798165137615, 'nid': -0.22360252825570015, 'grammatical_errors': 1, 'pegasus_entailment': 0.33969865553081036, 'gold_entailment': 0.2762581280299595, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 481
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.20 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3163841807909605, 'r1_recall': 0.6436781609195402, 'r1_f1': 0.42424242424242425, 'r2_precision': 0.1875, 'r2_recall': 0.38372093023255816, 'r2_f1': 0.2519083969465649, 'rL_precision': 0.23728813559322035, 'rL_recall': 0.4827586206896552, 'rL_f1': 0.31818181818181823, 'bs_precision': 0.28663963079452515, 'bs_recall': 0.46371182799339294, 'bs_f1': 0.37082284688949585, 'bs_mnli_precision': 0.6059286594390869, 'bs_mnli_recall': 0.6923412084579468, 'bs_mnli_f1': 0.6462591290473938, 'unique_bigram_ratio': 0.9476744186046512, 'nid': -0.27062914694727214, 'grammatical_errors': 9, 'pegasus_entailment': 0.4608310401439667, 'gold_entailment': 0.15548457764089108, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 482
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 41.20 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.27169811320754716, 'r1_recall': 0.7912087912087912, 'r1_f1': 0.4044943820224719, 'r2_precision': 0.14393939393939395, 'r2_recall': 0.4222222222222222, 'r2_f1': 0.21468926553672316, 'rL_precision': 0.1811320754716981, 'rL_recall': 0.5274725274725275, 'rL_f1': 0.2696629213483146, 'bs_precision': 0.2602514624595642, 'bs_recall': 0.5320197939872742, 'bs_f1': 0.38318300247192383, 'bs_mnli_precision': 0.5883742570877075, 'bs_mnli_recall': 0.7739379405975342, 'bs_mnli_f1': 0.66851806640625, 'unique_bigram_ratio': 0.9565217391304348, 'nid': -0.2345557109810208, 'grammatical_errors': 5, 'pegasus_entailment': 0.8339741587638855, 'gold_entailment': 0.29588853133221465, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 19, 'pegasus_ari': 35, 'pegasus_smog': 24}
*** Analysing case 483
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.27 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3439153439153439, 'r1_recall': 0.6372549019607843, 'r1_f1': 0.4467353951890034, 'r2_precision': 0.1595744680851064, 'r2_recall': 0.297029702970297, 'r2_f1': 0.20761245674740486, 'rL_precision': 0.25396825396825395, 'rL_recall': 0.47058823529411764, 'rL_f1': 0.32989690721649484, 'bs_precision': 0.2622571885585785, 'bs_recall': 0.3739579916000366, 'bs_f1': 0.31772580742836, 'bs_mnli_precision': 0.5927771329879761, 'bs_mnli_recall': 0.6792013645172119, 'bs_mnli_f1': 0.6330532431602478, 'unique_bigram_ratio': 0.9565217391304348, 'nid': -0.24028465441740576, 'grammatical_errors': 5, 'pegasus_entailment': 0.47755966770152253, 'gold_entailment': 0.2418678691610694, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 484
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.06 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.40441176470588236, 'r1_recall': 0.4824561403508772, 'r1_f1': 0.44, 'r2_precision': 0.15555555555555556, 'r2_recall': 0.18584070796460178, 'r2_f1': 0.16935483870967744, 'rL_precision': 0.2426470588235294, 'rL_recall': 0.2894736842105263, 'rL_f1': 0.264, 'bs_precision': 0.36043140292167664, 'bs_recall': 0.3483654260635376, 'bs_f1': 0.35657447576522827, 'bs_mnli_precision': 0.6505923867225647, 'bs_mnli_recall': 0.6470315456390381, 'bs_mnli_f1': 0.6488071084022522, 'unique_bigram_ratio': 0.9626865671641791, 'nid': -0.25427089139938897, 'grammatical_errors': 4, 'pegasus_entailment': 0.4095883880342756, 'gold_entailment': 0.25008774548768997, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 485
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.75 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3176470588235294, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.40148698884758366, 'r2_precision': 0.1301775147928994, 'r2_recall': 0.22448979591836735, 'r2_f1': 0.1647940074906367, 'rL_precision': 0.21764705882352942, 'rL_recall': 0.37373737373737376, 'rL_f1': 0.275092936802974, 'bs_precision': 0.30180037021636963, 'bs_recall': 0.41906607151031494, 'bs_f1': 0.3597364127635956, 'bs_mnli_precision': 0.6049714684486389, 'bs_mnli_recall': 0.6938418745994568, 'bs_mnli_f1': 0.6463662385940552, 'unique_bigram_ratio': 0.9629629629629629, 'nid': -0.23034349243614072, 'grammatical_errors': 4, 'pegasus_entailment': 0.4776463359594345, 'gold_entailment': 0.15016283392906188, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 486
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.64 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.19, 'r1_recall': 0.42696629213483145, 'r1_f1': 0.2629757785467128, 'r2_precision': 0.03015075376884422, 'r2_recall': 0.06818181818181818, 'r2_f1': 0.04181184668989547, 'rL_precision': 0.12, 'rL_recall': 0.2696629213483146, 'rL_f1': 0.16608996539792387, 'bs_precision': 0.158445343375206, 'bs_recall': 0.28347739577293396, 'bs_f1': 0.21991196274757385, 'bs_mnli_precision': 0.5465805530548096, 'bs_mnli_recall': 0.6171355843544006, 'bs_mnli_f1': 0.5797192454338074, 'unique_bigram_ratio': 0.9744897959183674, 'nid': -0.2384031179754713, 'grammatical_errors': 0, 'pegasus_entailment': 0.7407811284065247, 'gold_entailment': 0.6753274872899055, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 487
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.82 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6991150442477876, 'r1_recall': 0.48466257668711654, 'r1_f1': 0.572463768115942, 'r2_precision': 0.4107142857142857, 'r2_recall': 0.2839506172839506, 'r2_f1': 0.33576642335766416, 'rL_precision': 0.5221238938053098, 'rL_recall': 0.3619631901840491, 'rL_f1': 0.427536231884058, 'bs_precision': 0.4838031530380249, 'bs_recall': 0.4353429079055786, 'bs_f1': 0.4609677791595459, 'bs_mnli_precision': 0.7067587375640869, 'bs_mnli_recall': 0.685466468334198, 'bs_mnli_f1': 0.6959497928619385, 'unique_bigram_ratio': 0.9727272727272728, 'nid': -0.2612826109015418, 'grammatical_errors': 0, 'pegasus_entailment': 0.37688208371400833, 'gold_entailment': 0.22971470219393572, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 488
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.14 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5304347826086957, 'r1_recall': 0.33516483516483514, 'r1_f1': 0.41077441077441085, 'r2_precision': 0.22807017543859648, 'r2_recall': 0.143646408839779, 'r2_f1': 0.17627118644067793, 'rL_precision': 0.3739130434782609, 'rL_recall': 0.23626373626373626, 'rL_f1': 0.2895622895622895, 'bs_precision': 0.3699724078178406, 'bs_recall': 0.24825437366962433, 'bs_f1': 0.30823975801467896, 'bs_mnli_precision': 0.658275842666626, 'bs_mnli_recall': 0.5931700468063354, 'bs_mnli_f1': 0.6240293979644775, 'unique_bigram_ratio': 0.9819819819819819, 'nid': -0.25896987256328186, 'grammatical_errors': 1, 'pegasus_entailment': 0.5729623287916183, 'gold_entailment': 0.35956671213110286, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 489
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 39.77 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5774647887323944, 'r1_recall': 0.29818181818181816, 'r1_f1': 0.39328537170263783, 'r2_precision': 0.20567375886524822, 'r2_recall': 0.10583941605839416, 'r2_f1': 0.1397590361445783, 'rL_precision': 0.31690140845070425, 'rL_recall': 0.16363636363636364, 'rL_f1': 0.21582733812949642, 'bs_precision': 0.29153624176979065, 'bs_recall': 0.177218496799469, 'bs_f1': 0.23394043743610382, 'bs_mnli_precision': 0.6425890922546387, 'bs_mnli_recall': 0.5674513578414917, 'bs_mnli_f1': 0.602687418460846, 'unique_bigram_ratio': 0.9694656488549618, 'nid': -0.29889574634218796, 'grammatical_errors': 1, 'pegasus_entailment': 0.5712514668703079, 'gold_entailment': 0.48602470631400746, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 490
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.84 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3728813559322034, 'r1_recall': 0.6055045871559633, 'r1_f1': 0.4615384615384615, 'r2_precision': 0.125, 'r2_recall': 0.2037037037037037, 'r2_f1': 0.15492957746478872, 'rL_precision': 0.23163841807909605, 'rL_recall': 0.3761467889908257, 'rL_f1': 0.2867132867132867, 'bs_precision': 0.3486882150173187, 'bs_recall': 0.49250903725624084, 'bs_f1': 0.4184529781341553, 'bs_mnli_precision': 0.6427946090698242, 'bs_mnli_recall': 0.7006247639656067, 'bs_mnli_f1': 0.6704649925231934, 'unique_bigram_ratio': 0.976878612716763, 'nid': -0.24448530185542694, 'grammatical_errors': 1, 'pegasus_entailment': 0.4569381425778071, 'gold_entailment': 0.5052527710795403, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 491
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 69.75 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.11904761904761904, 'r1_recall': 0.25862068965517243, 'r1_f1': 0.16304347826086957, 'r2_precision': 0.016, 'r2_recall': 0.03508771929824561, 'r2_f1': 0.021978021978021976, 'rL_precision': 0.07936507936507936, 'rL_recall': 0.1724137931034483, 'rL_f1': 0.10869565217391304, 'bs_precision': 0.10845312476158142, 'bs_recall': 0.14183905720710754, 'bs_f1': 0.12784311175346375, 'bs_mnli_precision': 0.5057867765426636, 'bs_mnli_recall': 0.5524054765701294, 'bs_mnli_f1': 0.528069257736206, 'unique_bigram_ratio': 0.9590163934426229, 'nid': -0.22299679631839497, 'grammatical_errors': 0, 'pegasus_entailment': 0.32110945880413055, 'gold_entailment': 0.23228991031646729, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 492
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.81 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4720496894409938, 'r1_recall': 0.4198895027624309, 'r1_f1': 0.4444444444444444, 'r2_precision': 0.1625, 'r2_recall': 0.14444444444444443, 'r2_f1': 0.15294117647058822, 'rL_precision': 0.2857142857142857, 'rL_recall': 0.2541436464088398, 'rL_f1': 0.26900584795321636, 'bs_precision': 0.317474901676178, 'bs_recall': 0.22451996803283691, 'bs_f1': 0.2715378999710083, 'bs_mnli_precision': 0.642216682434082, 'bs_mnli_recall': 0.6017404794692993, 'bs_mnli_f1': 0.6213200688362122, 'unique_bigram_ratio': 0.9556962025316456, 'nid': -0.2832526762558416, 'grammatical_errors': 0, 'pegasus_entailment': 0.26154924975708127, 'gold_entailment': 0.0833507351577282, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 493
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.19 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.26063829787234044, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.369811320754717, 'r2_precision': 0.12299465240641712, 'r2_recall': 0.3026315789473684, 'r2_f1': 0.17490494296577946, 'rL_precision': 0.19680851063829788, 'rL_recall': 0.4805194805194805, 'rL_f1': 0.2792452830188679, 'bs_precision': 0.3072187304496765, 'bs_recall': 0.49678999185562134, 'bs_f1': 0.3967740833759308, 'bs_mnli_precision': 0.6264427304267883, 'bs_mnli_recall': 0.7195140719413757, 'bs_mnli_f1': 0.6697604656219482, 'unique_bigram_ratio': 0.918918918918919, 'nid': -0.22135957817985896, 'grammatical_errors': 1, 'pegasus_entailment': 0.48782217502593994, 'gold_entailment': 0.2926903925836086, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 494
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 59.10 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3433734939759036, 'r1_recall': 0.7125, 'r1_f1': 0.4634146341463415, 'r2_precision': 0.21818181818181817, 'r2_recall': 0.45569620253164556, 'r2_f1': 0.29508196721311475, 'rL_precision': 0.22289156626506024, 'rL_recall': 0.4625, 'rL_f1': 0.30081300813008127, 'bs_precision': 0.265133798122406, 'bs_recall': 0.5833055973052979, 'bs_f1': 0.40606850385665894, 'bs_mnli_precision': 0.5918343663215637, 'bs_mnli_recall': 0.7731258869171143, 'bs_mnli_f1': 0.6704407334327698, 'unique_bigram_ratio': 0.9634146341463414, 'nid': -0.266395130920726, 'grammatical_errors': 0, 'pegasus_entailment': 0.45037346995539135, 'gold_entailment': 0.4268649771809578, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 495
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 69.18 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4153846153846154, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.4843049327354261, 'r2_precision': 0.16279069767441862, 'r2_recall': 0.22826086956521738, 'r2_f1': 0.1900452488687783, 'rL_precision': 0.24615384615384617, 'rL_recall': 0.34408602150537637, 'rL_f1': 0.2869955156950673, 'bs_precision': 0.4192807972431183, 'bs_recall': 0.5097523331642151, 'bs_f1': 0.46476811170578003, 'bs_mnli_precision': 0.6764917373657227, 'bs_mnli_recall': 0.7287311553955078, 'bs_mnli_f1': 0.7016404271125793, 'unique_bigram_ratio': 0.9448818897637795, 'nid': -0.23992528436761473, 'grammatical_errors': 1, 'pegasus_entailment': 0.42501706182956694, 'gold_entailment': 0.30357828363776207, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 496
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.48 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.233201581027668, 'r1_recall': 0.7283950617283951, 'r1_f1': 0.3532934131736527, 'r2_precision': 0.11904761904761904, 'r2_recall': 0.375, 'r2_f1': 0.18072289156626503, 'rL_precision': 0.15810276679841898, 'rL_recall': 0.49382716049382713, 'rL_f1': 0.23952095808383234, 'bs_precision': 0.2163439840078354, 'bs_recall': 0.46605542302131653, 'bs_f1': 0.3301776945590973, 'bs_mnli_precision': 0.5953766703605652, 'bs_mnli_recall': 0.733428418636322, 'bs_mnli_f1': 0.657231330871582, 'unique_bigram_ratio': 0.9109311740890689, 'nid': -0.19035053590971818, 'grammatical_errors': 3, 'pegasus_entailment': 0.31933196187019347, 'gold_entailment': 0.15238043712452054, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 497
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 78.34 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5233644859813084, 'r1_recall': 0.6222222222222222, 'r1_f1': 0.5685279187817258, 'r2_precision': 0.25471698113207547, 'r2_recall': 0.30337078651685395, 'r2_f1': 0.2769230769230769, 'rL_precision': 0.37383177570093457, 'rL_recall': 0.4444444444444444, 'rL_f1': 0.4060913705583756, 'bs_precision': 0.5064087510108948, 'bs_recall': 0.5044075846672058, 'bs_f1': 0.5070976614952087, 'bs_mnli_precision': 0.7222947478294373, 'bs_mnli_recall': 0.7421005368232727, 'bs_mnli_f1': 0.7320637106895447, 'unique_bigram_ratio': 0.9904761904761905, 'nid': -0.2825603349336483, 'grammatical_errors': 1, 'pegasus_entailment': 0.25287669128738344, 'gold_entailment': 0.3504833048209548, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 498
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.40 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.18681318681318682, 'r1_recall': 0.4927536231884058, 'r1_f1': 0.2709163346613546, 'r2_precision': 0.049723756906077346, 'r2_recall': 0.1323529411764706, 'r2_f1': 0.07228915662650601, 'rL_precision': 0.11538461538461539, 'rL_recall': 0.30434782608695654, 'rL_f1': 0.16733067729083664, 'bs_precision': 0.10426729917526245, 'bs_recall': 0.2848864197731018, 'bs_f1': 0.1893884241580963, 'bs_mnli_precision': 0.5007407665252686, 'bs_mnli_recall': 0.6077591180801392, 'bs_mnli_f1': 0.549083948135376, 'unique_bigram_ratio': 0.95, 'nid': -0.2108066273391691, 'grammatical_errors': 3, 'pegasus_entailment': 0.6326584994792939, 'gold_entailment': 0.670825645327568, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 499
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 73.55 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.45535714285714285, 'r1_recall': 0.53125, 'r1_f1': 0.4903846153846154, 'r2_precision': 0.2702702702702703, 'r2_recall': 0.3157894736842105, 'r2_f1': 0.2912621359223301, 'rL_precision': 0.32142857142857145, 'rL_recall': 0.375, 'rL_f1': 0.3461538461538462, 'bs_precision': 0.34453195333480835, 'bs_recall': 0.3508964478969574, 'bs_f1': 0.34993430972099304, 'bs_mnli_precision': 0.6696131229400635, 'bs_mnli_recall': 0.6750013828277588, 'bs_mnli_f1': 0.6722964644432068, 'unique_bigram_ratio': 0.9636363636363636, 'nid': -0.2436394820981187, 'grammatical_errors': 2, 'pegasus_entailment': 0.4870231717824936, 'gold_entailment': 0.4973963610827923, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 500
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.84 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.20652173913043478, 'r1_recall': 0.59375, 'r1_f1': 0.3064516129032258, 'r2_precision': 0.08743169398907104, 'r2_recall': 0.25396825396825395, 'r2_f1': 0.13008130081300814, 'rL_precision': 0.1358695652173913, 'rL_recall': 0.390625, 'rL_f1': 0.2016129032258064, 'bs_precision': 0.2060321867465973, 'bs_recall': 0.38623368740081787, 'bs_f1': 0.2913472056388855, 'bs_mnli_precision': 0.576061487197876, 'bs_mnli_recall': 0.6742078065872192, 'bs_mnli_f1': 0.6212823987007141, 'unique_bigram_ratio': 0.9447513812154696, 'nid': -0.24218333610984577, 'grammatical_errors': 0, 'pegasus_entailment': 0.5032635685056448, 'gold_entailment': 0.42304304242134094, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 501
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 35.54 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.18895348837209303, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.2988505747126437, 'r2_precision': 0.09037900874635568, 'r2_recall': 0.34444444444444444, 'r2_f1': 0.14318706697459585, 'rL_precision': 0.12790697674418605, 'rL_recall': 0.4835164835164835, 'rL_f1': 0.20229885057471264, 'bs_precision': 0.12350521236658096, 'bs_recall': 0.4064512252807617, 'bs_f1': 0.24926379323005676, 'bs_mnli_precision': 0.5321444869041443, 'bs_mnli_recall': 0.6863961219787598, 'bs_mnli_f1': 0.5995071530342102, 'unique_bigram_ratio': 0.9264705882352942, 'nid': -0.1954898128199587, 'grammatical_errors': 7, 'pegasus_entailment': 0.5897146219556982, 'gold_entailment': 0.31827666362126666, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 502
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 66.00 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4068965517241379, 'r1_recall': 0.6704545454545454, 'r1_f1': 0.5064377682403434, 'r2_precision': 0.2222222222222222, 'r2_recall': 0.367816091954023, 'r2_f1': 0.27705627705627706, 'rL_precision': 0.25517241379310346, 'rL_recall': 0.42045454545454547, 'rL_f1': 0.3175965665236052, 'bs_precision': 0.3826811909675598, 'bs_recall': 0.5395334362983704, 'bs_f1': 0.458196222782135, 'bs_mnli_precision': 0.6796059608459473, 'bs_mnli_recall': 0.7626080513000488, 'bs_mnli_f1': 0.7187185883522034, 'unique_bigram_ratio': 0.9432624113475178, 'nid': -0.2585002785796364, 'grammatical_errors': 0, 'pegasus_entailment': 0.46226899538721355, 'gold_entailment': 0.24842508360743523, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 503
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.68 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24880382775119617, 'r1_recall': 0.8387096774193549, 'r1_f1': 0.38376383763837635, 'r2_precision': 0.15384615384615385, 'r2_recall': 0.5245901639344263, 'r2_f1': 0.23791821561338292, 'rL_precision': 0.21052631578947367, 'rL_recall': 0.7096774193548387, 'rL_f1': 0.3247232472324723, 'bs_precision': 0.216156467795372, 'bs_recall': 0.5792222619056702, 'bs_f1': 0.37298646569252014, 'bs_mnli_precision': 0.5633590221405029, 'bs_mnli_recall': 0.7912838459014893, 'bs_mnli_f1': 0.6581467390060425, 'unique_bigram_ratio': 0.9447236180904522, 'nid': -0.260208559342767, 'grammatical_errors': 1, 'pegasus_entailment': 0.5400371054808298, 'gold_entailment': 0.6294926777482033, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 504
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 62.46 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5102040816326531, 'r1_recall': 0.7009345794392523, 'r1_f1': 0.5905511811023623, 'r2_precision': 0.3082191780821918, 'r2_recall': 0.42452830188679247, 'r2_f1': 0.3571428571428572, 'rL_precision': 0.41496598639455784, 'rL_recall': 0.5700934579439252, 'rL_f1': 0.4803149606299213, 'bs_precision': 0.5049542784690857, 'bs_recall': 0.5741522908210754, 'bs_f1': 0.5402535200119019, 'bs_mnli_precision': 0.7288561463356018, 'bs_mnli_recall': 0.7808319330215454, 'bs_mnli_f1': 0.7539492845535278, 'unique_bigram_ratio': 0.9513888888888888, 'nid': -0.23017347454382175, 'grammatical_errors': 3, 'pegasus_entailment': 0.41227415278553964, 'gold_entailment': 0.32122258841991425, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 505
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.91 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3007518796992481, 'r1_recall': 0.6349206349206349, 'r1_f1': 0.4081632653061224, 'r2_precision': 0.09848484848484848, 'r2_recall': 0.20967741935483872, 'r2_f1': 0.13402061855670103, 'rL_precision': 0.19548872180451127, 'rL_recall': 0.4126984126984127, 'rL_f1': 0.26530612244897955, 'bs_precision': 0.2606692612171173, 'bs_recall': 0.4687432050704956, 'bs_f1': 0.3578413128852844, 'bs_mnli_precision': 0.6117560267448425, 'bs_mnli_recall': 0.719433069229126, 'bs_mnli_f1': 0.6612396240234375, 'unique_bigram_ratio': 0.9844961240310077, 'nid': -0.2738957236981867, 'grammatical_errors': 2, 'pegasus_entailment': 0.4285366706550121, 'gold_entailment': 0.11602518707513809, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 506
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 37.96 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6896551724137931, 'r1_recall': 0.4528301886792453, 'r1_f1': 0.5466970387243736, 'r2_precision': 0.3583815028901734, 'r2_recall': 0.23484848484848486, 'r2_f1': 0.28375286041189934, 'rL_precision': 0.41954022988505746, 'rL_recall': 0.27547169811320754, 'rL_f1': 0.33257403189066065, 'bs_precision': 0.37809088826179504, 'bs_recall': 0.22845685482025146, 'bs_f1': 0.30073967576026917, 'bs_mnli_precision': 0.714661180973053, 'bs_mnli_recall': 0.6123576164245605, 'bs_mnli_f1': 0.6595659852027893, 'unique_bigram_ratio': 0.9467455621301775, 'nid': -0.2212992794076567, 'grammatical_errors': 4, 'pegasus_entailment': 0.42099863077913013, 'gold_entailment': 0.3550754487514496, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 507
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.32 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.22105263157894736, 'r1_recall': 0.65625, 'r1_f1': 0.3307086614173228, 'r2_precision': 0.07936507936507936, 'r2_recall': 0.23809523809523808, 'r2_f1': 0.11904761904761904, 'rL_precision': 0.12105263157894737, 'rL_recall': 0.359375, 'rL_f1': 0.18110236220472442, 'bs_precision': 0.23108388483524323, 'bs_recall': 0.4236755967140198, 'bs_f1': 0.321686714887619, 'bs_mnli_precision': 0.5724587440490723, 'bs_mnli_recall': 0.6599876880645752, 'bs_mnli_f1': 0.6131150722503662, 'unique_bigram_ratio': 0.9562841530054644, 'nid': -0.2545592488189752, 'grammatical_errors': 1, 'pegasus_entailment': 0.5234200775623321, 'gold_entailment': 0.3797053322196007, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 508
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.92 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2909090909090909, 'r1_recall': 0.5217391304347826, 'r1_f1': 0.37354085603112835, 'r2_precision': 0.10975609756097561, 'r2_recall': 0.1978021978021978, 'r2_f1': 0.1411764705882353, 'rL_precision': 0.17575757575757575, 'rL_recall': 0.31521739130434784, 'rL_f1': 0.22568093385214008, 'bs_precision': 0.28020551800727844, 'bs_recall': 0.3674302101135254, 'bs_f1': 0.3244822919368744, 'bs_mnli_precision': 0.5951277613639832, 'bs_mnli_recall': 0.6507320404052734, 'bs_mnli_f1': 0.6216890215873718, 'unique_bigram_ratio': 0.95, 'nid': -0.25248072661518406, 'grammatical_errors': 1, 'pegasus_entailment': 0.448161281645298, 'gold_entailment': 0.4621656596660614, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 509
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 70.93 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4732824427480916, 'r1_recall': 0.62, 'r1_f1': 0.5367965367965368, 'r2_precision': 0.2, 'r2_recall': 0.26262626262626265, 'r2_f1': 0.22707423580786026, 'rL_precision': 0.2595419847328244, 'rL_recall': 0.34, 'rL_f1': 0.29437229437229434, 'bs_precision': 0.361444890499115, 'bs_recall': 0.4078579545021057, 'bs_f1': 0.3863105773925781, 'bs_mnli_precision': 0.6665399074554443, 'bs_mnli_recall': 0.674331545829773, 'bs_mnli_f1': 0.670413076877594, 'unique_bigram_ratio': 0.9838709677419355, 'nid': -0.2678118319438769, 'grammatical_errors': 0, 'pegasus_entailment': 0.5798175573348999, 'gold_entailment': 0.6812441647052765, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 510
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.25 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.46987951807228917, 'r1_recall': 0.5571428571428572, 'r1_f1': 0.5098039215686274, 'r2_precision': 0.23030303030303031, 'r2_recall': 0.2733812949640288, 'r2_f1': 0.25000000000000006, 'rL_precision': 0.3132530120481928, 'rL_recall': 0.37142857142857144, 'rL_f1': 0.33986928104575165, 'bs_precision': 0.3407982587814331, 'bs_recall': 0.4614447057247162, 'bs_f1': 0.40021803975105286, 'bs_mnli_precision': 0.6530355215072632, 'bs_mnli_recall': 0.7158946990966797, 'bs_mnli_f1': 0.6830219030380249, 'unique_bigram_ratio': 0.967741935483871, 'nid': -0.24404292532343952, 'grammatical_errors': 3, 'pegasus_entailment': 0.7460392415523529, 'gold_entailment': 0.44654589891433716, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 511
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 72.06 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.44537815126050423, 'r1_recall': 0.5638297872340425, 'r1_f1': 0.49765258215962443, 'r2_precision': 0.2627118644067797, 'r2_recall': 0.3333333333333333, 'r2_f1': 0.2938388625592417, 'rL_precision': 0.29411764705882354, 'rL_recall': 0.3723404255319149, 'rL_f1': 0.32863849765258213, 'bs_precision': 0.4215560257434845, 'bs_recall': 0.4749746024608612, 'bs_f1': 0.44959259033203125, 'bs_mnli_precision': 0.6779685020446777, 'bs_mnli_recall': 0.7031735181808472, 'bs_mnli_f1': 0.6903409957885742, 'unique_bigram_ratio': 0.9391304347826087, 'nid': -0.23405515768290108, 'grammatical_errors': 0, 'pegasus_entailment': 0.612465962767601, 'gold_entailment': 0.3566570058465004, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 512
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.03 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4740740740740741, 'r1_recall': 0.5039370078740157, 'r1_f1': 0.48854961832061067, 'r2_precision': 0.1417910447761194, 'r2_recall': 0.15079365079365079, 'r2_f1': 0.14615384615384613, 'rL_precision': 0.2074074074074074, 'rL_recall': 0.2204724409448819, 'rL_f1': 0.21374045801526714, 'bs_precision': 0.36620795726776123, 'bs_recall': 0.3765268623828888, 'bs_f1': 0.3734930753707886, 'bs_mnli_precision': 0.6615135669708252, 'bs_mnli_recall': 0.6410374641418457, 'bs_mnli_f1': 0.6511145830154419, 'unique_bigram_ratio': 0.9606299212598425, 'nid': -0.30902105306048333, 'grammatical_errors': 5, 'pegasus_entailment': 0.36492038816213607, 'gold_entailment': 0.21152969868853688, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 513
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 40.19 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.1696969696969697, 'r1_recall': 0.7887323943661971, 'r1_f1': 0.2793017456359102, 'r2_precision': 0.06990881458966565, 'r2_recall': 0.32857142857142857, 'r2_f1': 0.11528822055137844, 'rL_precision': 0.10606060606060606, 'rL_recall': 0.49295774647887325, 'rL_f1': 0.1745635910224439, 'bs_precision': 0.10551106184720993, 'bs_recall': 0.4376242160797119, 'bs_f1': 0.24909886717796326, 'bs_mnli_precision': 0.532036304473877, 'bs_mnli_recall': 0.697287917137146, 'bs_mnli_f1': 0.6035552024841309, 'unique_bigram_ratio': 0.8348623853211009, 'nid': -0.1476682531464819, 'grammatical_errors': 3, 'pegasus_entailment': 0.42898345589637754, 'gold_entailment': 0.35650815069675446, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 514
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 76.40 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.37735849056603776, 'r1_recall': 0.425531914893617, 'r1_f1': 0.4, 'r2_precision': 0.1523809523809524, 'r2_recall': 0.17204301075268819, 'r2_f1': 0.16161616161616163, 'rL_precision': 0.2358490566037736, 'rL_recall': 0.26595744680851063, 'rL_f1': 0.24999999999999994, 'bs_precision': 0.3807258903980255, 'bs_recall': 0.38803184032440186, 'bs_f1': 0.38647136092185974, 'bs_mnli_precision': 0.6679295301437378, 'bs_mnli_recall': 0.6525239944458008, 'bs_mnli_f1': 0.660136878490448, 'unique_bigram_ratio': 0.9711538461538461, 'nid': -0.2771548150265428, 'grammatical_errors': 2, 'pegasus_entailment': 0.3739400442689657, 'gold_entailment': 0.2682844400405884, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 515
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.71 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2905405405405405, 'r1_recall': 0.5119047619047619, 'r1_f1': 0.37068965517241376, 'r2_precision': 0.14965986394557823, 'r2_recall': 0.26506024096385544, 'r2_f1': 0.19130434782608696, 'rL_precision': 0.20945945945945946, 'rL_recall': 0.36904761904761907, 'rL_f1': 0.26724137931034486, 'bs_precision': 0.25992968678474426, 'bs_recall': 0.4725533425807953, 'bs_f1': 0.35898423194885254, 'bs_mnli_precision': 0.621408998966217, 'bs_mnli_recall': 0.7051511406898499, 'bs_mnli_f1': 0.6606369018554688, 'unique_bigram_ratio': 0.9583333333333334, 'nid': -0.23712530452109282, 'grammatical_errors': 3, 'pegasus_entailment': 0.4202303886413574, 'gold_entailment': 0.3998180702328682, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 516
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 67.01 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.37142857142857144, 'r1_recall': 0.7027027027027027, 'r1_f1': 0.485981308411215, 'r2_precision': 0.2302158273381295, 'r2_recall': 0.4383561643835616, 'r2_f1': 0.30188679245283023, 'rL_precision': 0.2571428571428571, 'rL_recall': 0.4864864864864865, 'rL_f1': 0.33644859813084105, 'bs_precision': 0.3350740671157837, 'bs_recall': 0.5221434235572815, 'bs_f1': 0.4236278831958771, 'bs_mnli_precision': 0.6408767700195312, 'bs_mnli_recall': 0.7650860548019409, 'bs_mnli_f1': 0.6974948048591614, 'unique_bigram_ratio': 0.9481481481481482, 'nid': -0.24433379760130225, 'grammatical_errors': 0, 'pegasus_entailment': 0.42285477307935554, 'gold_entailment': 0.27444249857217073, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 517
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.71 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24489795918367346, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.3364485981308411, 'r2_precision': 0.06164383561643835, 'r2_recall': 0.13636363636363635, 'r2_f1': 0.08490566037735849, 'rL_precision': 0.17006802721088435, 'rL_recall': 0.373134328358209, 'rL_f1': 0.23364485981308408, 'bs_precision': 0.21278342604637146, 'bs_recall': 0.3696988523006439, 'bs_f1': 0.288185715675354, 'bs_mnli_precision': 0.5720614194869995, 'bs_mnli_recall': 0.6411983370780945, 'bs_mnli_f1': 0.6046600341796875, 'unique_bigram_ratio': 0.9722222222222222, 'nid': -0.2586901248957796, 'grammatical_errors': 1, 'pegasus_entailment': 0.4249218429128329, 'gold_entailment': 0.21959538012742996, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 518
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.54 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.22289156626506024, 'r1_recall': 0.578125, 'r1_f1': 0.32173913043478264, 'r2_precision': 0.07272727272727272, 'r2_recall': 0.19047619047619047, 'r2_f1': 0.10526315789473682, 'rL_precision': 0.1566265060240964, 'rL_recall': 0.40625, 'rL_f1': 0.22608695652173916, 'bs_precision': 0.20786477625370026, 'bs_recall': 0.4014480710029602, 'bs_f1': 0.2987968623638153, 'bs_mnli_precision': 0.5796114802360535, 'bs_mnli_recall': 0.6771266460418701, 'bs_mnli_f1': 0.624585747718811, 'unique_bigram_ratio': 0.90625, 'nid': -0.16566215590380007, 'grammatical_errors': 0, 'pegasus_entailment': 0.43251947065194446, 'gold_entailment': 0.29786908626556396, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 519
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.45 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5620437956204379, 'r1_recall': 0.44508670520231214, 'r1_f1': 0.49677419354838714, 'r2_precision': 0.3014705882352941, 'r2_recall': 0.23837209302325582, 'r2_f1': 0.2662337662337662, 'rL_precision': 0.44525547445255476, 'rL_recall': 0.35260115606936415, 'rL_f1': 0.39354838709677414, 'bs_precision': 0.48257750272750854, 'bs_recall': 0.4278732240200043, 'bs_f1': 0.4565088748931885, 'bs_mnli_precision': 0.7418583631515503, 'bs_mnli_recall': 0.7025571465492249, 'bs_mnli_f1': 0.7216730713844299, 'unique_bigram_ratio': 0.9398496240601504, 'nid': -0.24372340350178057, 'grammatical_errors': 0, 'pegasus_entailment': 0.3782518867935453, 'gold_entailment': 0.3415787826691355, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 520
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.82 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.49079754601226994, 'r1_recall': 0.48484848484848486, 'r1_f1': 0.4878048780487805, 'r2_precision': 0.20987654320987653, 'r2_recall': 0.2073170731707317, 'r2_f1': 0.20858895705521469, 'rL_precision': 0.26380368098159507, 'rL_recall': 0.2606060606060606, 'rL_f1': 0.2621951219512195, 'bs_precision': 0.30708783864974976, 'bs_recall': 0.26550811529159546, 'bs_f1': 0.288352906703949, 'bs_mnli_precision': 0.6213730573654175, 'bs_mnli_recall': 0.6196699142456055, 'bs_mnli_f1': 0.620520293712616, 'unique_bigram_ratio': 0.9683544303797469, 'nid': -0.28292429284207543, 'grammatical_errors': 6, 'pegasus_entailment': 0.5504431407898664, 'gold_entailment': 0.15479360410245135, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 521
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.81 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4294478527607362, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.5363984674329502, 'r2_precision': 0.2345679012345679, 'r2_recall': 0.3917525773195876, 'r2_f1': 0.2934362934362934, 'rL_precision': 0.3128834355828221, 'rL_recall': 0.5204081632653061, 'rL_f1': 0.3908045977011495, 'bs_precision': 0.3663470447063446, 'bs_recall': 0.5596945285797119, 'bs_f1': 0.4576466977596283, 'bs_mnli_precision': 0.6614006161689758, 'bs_mnli_recall': 0.7702868580818176, 'bs_mnli_f1': 0.7117030620574951, 'unique_bigram_ratio': 0.9554140127388535, 'nid': -0.24248649558108992, 'grammatical_errors': 4, 'pegasus_entailment': 0.662188958376646, 'gold_entailment': 0.5035301099220911, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 522
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.81 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4427083333333333, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.4485488126649076, 'r2_precision': 0.17277486910994763, 'r2_recall': 0.1774193548387097, 'r2_f1': 0.17506631299734748, 'rL_precision': 0.25, 'rL_recall': 0.25668449197860965, 'rL_f1': 0.2532981530343008, 'bs_precision': 0.3223111629486084, 'bs_recall': 0.3071863651275635, 'bs_f1': 0.3170412480831146, 'bs_mnli_precision': 0.6475483775138855, 'bs_mnli_recall': 0.6257851719856262, 'bs_mnli_f1': 0.6364808082580566, 'unique_bigram_ratio': 0.9513513513513514, 'nid': -0.24206526463990885, 'grammatical_errors': 2, 'pegasus_entailment': 0.4327404350042343, 'gold_entailment': 0.12477983571588994, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 523
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 71.28 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4339622641509434, 'r1_recall': 0.4842105263157895, 'r1_f1': 0.4577114427860696, 'r2_precision': 0.1619047619047619, 'r2_recall': 0.18085106382978725, 'r2_f1': 0.17085427135678394, 'rL_precision': 0.29245283018867924, 'rL_recall': 0.3263157894736842, 'rL_f1': 0.3084577114427861, 'bs_precision': 0.4043639600276947, 'bs_recall': 0.3646135628223419, 'bs_f1': 0.38626959919929504, 'bs_mnli_precision': 0.6615619659423828, 'bs_mnli_recall': 0.6620692014694214, 'bs_mnli_f1': 0.6618155241012573, 'unique_bigram_ratio': 0.9902912621359223, 'nid': -0.2980327347902807, 'grammatical_errors': 1, 'pegasus_entailment': 0.41152314096689224, 'gold_entailment': 0.18909392381707826, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 524
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.31 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.22362869198312235, 'r1_recall': 0.7361111111111112, 'r1_f1': 0.343042071197411, 'r2_precision': 0.11864406779661017, 'r2_recall': 0.39436619718309857, 'r2_f1': 0.18241042345276876, 'rL_precision': 0.17721518987341772, 'rL_recall': 0.5833333333333334, 'rL_f1': 0.27184466019417475, 'bs_precision': 0.25176987051963806, 'bs_recall': 0.5218002200126648, 'bs_f1': 0.3739418685436249, 'bs_mnli_precision': 0.5692179203033447, 'bs_mnli_recall': 0.7379549145698547, 'bs_mnli_f1': 0.6426956653594971, 'unique_bigram_ratio': 0.9344978165938864, 'nid': -0.21198067924889918, 'grammatical_errors': 2, 'pegasus_entailment': 0.2811618587002158, 'gold_entailment': 0.07007153704762459, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 525
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 72.55 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.25757575757575757, 'r1_recall': 0.6181818181818182, 'r1_f1': 0.36363636363636365, 'r2_precision': 0.15267175572519084, 'r2_recall': 0.37037037037037035, 'r2_f1': 0.2162162162162162, 'rL_precision': 0.20454545454545456, 'rL_recall': 0.4909090909090909, 'rL_f1': 0.2887700534759359, 'bs_precision': 0.33195942640304565, 'bs_recall': 0.5448228120803833, 'bs_f1': 0.43140342831611633, 'bs_mnli_precision': 0.6355763673782349, 'bs_mnli_recall': 0.7427558302879333, 'bs_mnli_f1': 0.6849989891052246, 'unique_bigram_ratio': 0.937007874015748, 'nid': -0.21566919481870217, 'grammatical_errors': 0, 'pegasus_entailment': 0.6102196872234344, 'gold_entailment': 0.4425209313631058, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 526
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 40.76 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.10431654676258993, 'r1_recall': 0.6904761904761905, 'r1_f1': 0.18125000000000002, 'r2_precision': 0.036101083032490974, 'r2_recall': 0.24390243902439024, 'r2_f1': 0.06289308176100629, 'rL_precision': 0.07913669064748201, 'rL_recall': 0.5238095238095238, 'rL_f1': 0.1375, 'bs_precision': 0.03388595953583717, 'bs_recall': 0.4454341530799866, 'bs_f1': 0.20279483497142792, 'bs_mnli_precision': 0.474674254655838, 'bs_mnli_recall': 0.7044472694396973, 'bs_mnli_f1': 0.5671730637550354, 'unique_bigram_ratio': 0.9522058823529411, 'nid': -0.22617992647080332, 'grammatical_errors': 3, 'pegasus_entailment': 0.41905169002711773, 'gold_entailment': 0.3323868438601494, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 527
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.95 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.27472527472527475, 'r1_recall': 0.704225352112676, 'r1_f1': 0.3952569169960474, 'r2_precision': 0.17679558011049723, 'r2_recall': 0.45714285714285713, 'r2_f1': 0.2549800796812749, 'rL_precision': 0.21978021978021978, 'rL_recall': 0.5633802816901409, 'rL_f1': 0.31620553359683795, 'bs_precision': 0.2373039871454239, 'bs_recall': 0.4724876582622528, 'bs_f1': 0.34546226263046265, 'bs_mnli_precision': 0.6076790690422058, 'bs_mnli_recall': 0.7574471831321716, 'bs_mnli_f1': 0.6743475794792175, 'unique_bigram_ratio': 0.9265536723163842, 'nid': -0.22736723595500852, 'grammatical_errors': 4, 'pegasus_entailment': 0.3547565226908773, 'gold_entailment': 0.3169579226523638, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 528
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 81.09 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.26881720430107525, 'r1_recall': 0.4807692307692308, 'r1_f1': 0.3448275862068965, 'r2_precision': 0.10869565217391304, 'r2_recall': 0.19607843137254902, 'r2_f1': 0.13986013986013987, 'rL_precision': 0.1827956989247312, 'rL_recall': 0.3269230769230769, 'rL_f1': 0.23448275862068965, 'bs_precision': 0.24278756976127625, 'bs_recall': 0.43083590269088745, 'bs_f1': 0.3315204381942749, 'bs_mnli_precision': 0.5815984010696411, 'bs_mnli_recall': 0.6423660516738892, 'bs_mnli_f1': 0.6104737520217896, 'unique_bigram_ratio': 0.9662921348314607, 'nid': -0.2800355611749319, 'grammatical_errors': 0, 'pegasus_entailment': 0.48253316432237625, 'gold_entailment': 0.5754444748163223, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 529
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 66.46 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.45794392523364486, 'r1_recall': 0.4188034188034188, 'r1_f1': 0.4375, 'r2_precision': 0.1320754716981132, 'r2_recall': 0.1206896551724138, 'r2_f1': 0.12612612612612611, 'rL_precision': 0.27102803738317754, 'rL_recall': 0.24786324786324787, 'rL_f1': 0.25892857142857145, 'bs_precision': 0.3567417860031128, 'bs_recall': 0.3733525276184082, 'bs_f1': 0.3671587407588959, 'bs_mnli_precision': 0.6382815837860107, 'bs_mnli_recall': 0.6407822370529175, 'bs_mnli_f1': 0.6395294666290283, 'unique_bigram_ratio': 1.0, 'nid': -0.2948294638696507, 'grammatical_errors': 0, 'pegasus_entailment': 0.32603659232457477, 'gold_entailment': 0.15381511226296424, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 530
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.84 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4935897435897436, 'r1_recall': 0.5877862595419847, 'r1_f1': 0.5365853658536585, 'r2_precision': 0.23870967741935484, 'r2_recall': 0.2846153846153846, 'r2_f1': 0.2596491228070176, 'rL_precision': 0.23076923076923078, 'rL_recall': 0.2748091603053435, 'rL_f1': 0.2508710801393728, 'bs_precision': 0.37020474672317505, 'bs_recall': 0.441170871257782, 'bs_f1': 0.4067007899284363, 'bs_mnli_precision': 0.646747350692749, 'bs_mnli_recall': 0.6833677291870117, 'bs_mnli_f1': 0.6645534038543701, 'unique_bigram_ratio': 0.9671052631578947, 'nid': -0.2893627536937382, 'grammatical_errors': 0, 'pegasus_entailment': 0.4456098943948746, 'gold_entailment': 0.32825301090876263, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 531
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.10 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.27722772277227725, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.39160839160839167, 'r2_precision': 0.14427860696517414, 'r2_recall': 0.3493975903614458, 'r2_f1': 0.2042253521126761, 'rL_precision': 0.2079207920792079, 'rL_recall': 0.5, 'rL_f1': 0.2937062937062937, 'bs_precision': 0.23772002756595612, 'bs_recall': 0.4356839060783386, 'bs_f1': 0.3305927813053131, 'bs_mnli_precision': 0.5964548587799072, 'bs_mnli_recall': 0.7141280174255371, 'bs_mnli_f1': 0.6500086784362793, 'unique_bigram_ratio': 0.9441624365482234, 'nid': -0.20964539084360223, 'grammatical_errors': 2, 'pegasus_entailment': 0.42346912291314864, 'gold_entailment': 0.5700631340344747, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 532
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.04 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.39908256880733944, 'r1_recall': 0.48333333333333334, 'r1_f1': 0.4371859296482412, 'r2_precision': 0.14285714285714285, 'r2_recall': 0.17318435754189945, 'r2_f1': 0.15656565656565655, 'rL_precision': 0.24770642201834864, 'rL_recall': 0.3, 'rL_f1': 0.271356783919598, 'bs_precision': 0.3727055788040161, 'bs_recall': 0.40082111954689026, 'bs_f1': 0.3886958658695221, 'bs_mnli_precision': 0.6545255184173584, 'bs_mnli_recall': 0.6646726727485657, 'bs_mnli_f1': 0.6595600843429565, 'unique_bigram_ratio': 0.95260663507109, 'nid': -0.2455754233994063, 'grammatical_errors': 2, 'pegasus_entailment': 0.5547909161874226, 'gold_entailment': 0.2705715286235015, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 533
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.06 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.46153846153846156, 'r1_recall': 0.6593406593406593, 'r1_f1': 0.5429864253393665, 'r2_precision': 0.26356589147286824, 'r2_recall': 0.37777777777777777, 'r2_f1': 0.3105022831050228, 'rL_precision': 0.33076923076923076, 'rL_recall': 0.4725274725274725, 'rL_f1': 0.3891402714932126, 'bs_precision': 0.41975638270378113, 'bs_recall': 0.5460258722305298, 'bs_f1': 0.4816284775733948, 'bs_mnli_precision': 0.684567391872406, 'bs_mnli_recall': 0.7652890086174011, 'bs_mnli_f1': 0.7226811051368713, 'unique_bigram_ratio': 0.968503937007874, 'nid': -0.2829276239241485, 'grammatical_errors': 3, 'pegasus_entailment': 0.5333924070000648, 'gold_entailment': 0.4673606852690379, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 534
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 67.43 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3925925925925926, 'r1_recall': 0.4818181818181818, 'r1_f1': 0.4326530612244898, 'r2_precision': 0.1791044776119403, 'r2_recall': 0.22018348623853212, 'r2_f1': 0.19753086419753085, 'rL_precision': 0.2222222222222222, 'rL_recall': 0.2727272727272727, 'rL_f1': 0.24489795918367346, 'bs_precision': 0.31106802821159363, 'bs_recall': 0.2529168128967285, 'bs_f1': 0.28369101881980896, 'bs_mnli_precision': 0.6364200115203857, 'bs_mnli_recall': 0.6033338308334351, 'bs_mnli_f1': 0.6194354295730591, 'unique_bigram_ratio': 0.937984496124031, 'nid': -0.19981763143348674, 'grammatical_errors': 1, 'pegasus_entailment': 0.6189494252204895, 'gold_entailment': 0.47072604671120644, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 535
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.39 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.41333333333333333, 'r1_recall': 0.6739130434782609, 'r1_f1': 0.512396694214876, 'r2_precision': 0.22818791946308725, 'r2_recall': 0.37362637362637363, 'r2_f1': 0.2833333333333333, 'rL_precision': 0.30666666666666664, 'rL_recall': 0.5, 'rL_f1': 0.3801652892561983, 'bs_precision': 0.35827288031578064, 'bs_recall': 0.5407319068908691, 'bs_f1': 0.44489529728889465, 'bs_mnli_precision': 0.6498209238052368, 'bs_mnli_recall': 0.751619279384613, 'bs_mnli_f1': 0.6970228552818298, 'unique_bigram_ratio': 0.9859154929577465, 'nid': -0.2917009429365105, 'grammatical_errors': 2, 'pegasus_entailment': 0.5886638849973679, 'gold_entailment': 0.5763682648539543, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 536
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 67.76 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4322033898305085, 'r1_recall': 0.51, 'r1_f1': 0.4678899082568808, 'r2_precision': 0.20512820512820512, 'r2_recall': 0.24242424242424243, 'r2_f1': 0.2222222222222222, 'rL_precision': 0.3220338983050847, 'rL_recall': 0.38, 'rL_f1': 0.3486238532110092, 'bs_precision': 0.38393813371658325, 'bs_recall': 0.4424091577529907, 'bs_f1': 0.41449156403541565, 'bs_mnli_precision': 0.667150616645813, 'bs_mnli_recall': 0.682999849319458, 'bs_mnli_f1': 0.6749821901321411, 'unique_bigram_ratio': 0.9818181818181818, 'nid': -0.30356933359091665, 'grammatical_errors': 1, 'pegasus_entailment': 0.5845984390803746, 'gold_entailment': 0.5274897962808609, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 537
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.28 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2028301886792453, 'r1_recall': 0.6231884057971014, 'r1_f1': 0.3060498220640569, 'r2_precision': 0.11374407582938388, 'r2_recall': 0.35294117647058826, 'r2_f1': 0.17204301075268816, 'rL_precision': 0.14150943396226415, 'rL_recall': 0.43478260869565216, 'rL_f1': 0.21352313167259784, 'bs_precision': 0.2226588875055313, 'bs_recall': 0.40954339504241943, 'bs_f1': 0.3108389973640442, 'bs_mnli_precision': 0.5983079075813293, 'bs_mnli_recall': 0.6803622245788574, 'bs_mnli_f1': 0.6367023587226868, 'unique_bigram_ratio': 0.9271844660194175, 'nid': -0.22229119876328363, 'grammatical_errors': 4, 'pegasus_entailment': 0.522534117102623, 'gold_entailment': 0.26286551356315613, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 538
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.82 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4393939393939394, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5296803652968037, 'r2_precision': 0.3053435114503817, 'r2_recall': 0.46511627906976744, 'r2_f1': 0.36866359447004604, 'rL_precision': 0.3333333333333333, 'rL_recall': 0.5057471264367817, 'rL_f1': 0.4018264840182649, 'bs_precision': 0.4353281557559967, 'bs_recall': 0.5151936411857605, 'bs_f1': 0.4758338928222656, 'bs_mnli_precision': 0.696384072303772, 'bs_mnli_recall': 0.740249752998352, 'bs_mnli_f1': 0.7176472544670105, 'unique_bigram_ratio': 0.9921259842519685, 'nid': -0.2615058677295776, 'grammatical_errors': 1, 'pegasus_entailment': 0.5237016335129738, 'gold_entailment': 0.34783651679754257, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 539
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.13 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3710691823899371, 'r1_recall': 0.5784313725490197, 'r1_f1': 0.4521072796934865, 'r2_precision': 0.189873417721519, 'r2_recall': 0.297029702970297, 'r2_f1': 0.23166023166023167, 'rL_precision': 0.2641509433962264, 'rL_recall': 0.4117647058823529, 'rL_f1': 0.32183908045977005, 'bs_precision': 0.36111873388290405, 'bs_recall': 0.44612741470336914, 'bs_f1': 0.4041984975337982, 'bs_mnli_precision': 0.6495927572250366, 'bs_mnli_recall': 0.7098081111907959, 'bs_mnli_f1': 0.6783667802810669, 'unique_bigram_ratio': 0.9675324675324676, 'nid': -0.2598087200737953, 'grammatical_errors': 1, 'pegasus_entailment': 0.5347735000153383, 'gold_entailment': 0.2925843708217144, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 540
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.91 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3373493975903614, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.4479999999999999, 'r2_precision': 0.16363636363636364, 'r2_recall': 0.3253012048192771, 'r2_f1': 0.21774193548387097, 'rL_precision': 0.21686746987951808, 'rL_recall': 0.42857142857142855, 'rL_f1': 0.28800000000000003, 'bs_precision': 0.26942968368530273, 'bs_recall': 0.45762017369270325, 'bs_f1': 0.35830041766166687, 'bs_mnli_precision': 0.620207667350769, 'bs_mnli_recall': 0.732633113861084, 'bs_mnli_f1': 0.6717489361763, 'unique_bigram_ratio': 0.9748427672955975, 'nid': -0.2676333298351923, 'grammatical_errors': 3, 'pegasus_entailment': 0.7297552015100207, 'gold_entailment': 0.47682545706629753, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 541
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.27 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.19594594594594594, 'r1_recall': 0.5576923076923077, 'r1_f1': 0.29, 'r2_precision': 0.047619047619047616, 'r2_recall': 0.13725490196078433, 'r2_f1': 0.0707070707070707, 'rL_precision': 0.12837837837837837, 'rL_recall': 0.36538461538461536, 'rL_f1': 0.19, 'bs_precision': 0.20014293491840363, 'bs_recall': 0.4470438063144684, 'bs_f1': 0.3127305209636688, 'bs_mnli_precision': 0.5434375405311584, 'bs_mnli_recall': 0.6748658418655396, 'bs_mnli_f1': 0.6020625233650208, 'unique_bigram_ratio': 0.9652777777777778, 'nid': -0.26257410761868494, 'grammatical_errors': 2, 'pegasus_entailment': 0.5558810323476792, 'gold_entailment': 0.4701860348383586, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 542
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.66 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.44242424242424244, 'r1_recall': 0.5104895104895105, 'r1_f1': 0.474025974025974, 'r2_precision': 0.23170731707317074, 'r2_recall': 0.2676056338028169, 'r2_f1': 0.24836601307189543, 'rL_precision': 0.3333333333333333, 'rL_recall': 0.38461538461538464, 'rL_f1': 0.3571428571428571, 'bs_precision': 0.39240437746047974, 'bs_recall': 0.43382784724235535, 'bs_f1': 0.41477617621421814, 'bs_mnli_precision': 0.6912071704864502, 'bs_mnli_recall': 0.7140148282051086, 'bs_mnli_f1': 0.7024259567260742, 'unique_bigram_ratio': 0.937888198757764, 'nid': -0.2135511985819749, 'grammatical_errors': 3, 'pegasus_entailment': 0.4387504309415817, 'gold_entailment': 0.330624520778656, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 543
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.80 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.329608938547486, 'r1_recall': 0.6781609195402298, 'r1_f1': 0.44360902255639095, 'r2_precision': 0.1853932584269663, 'r2_recall': 0.38372093023255816, 'r2_f1': 0.25, 'rL_precision': 0.24581005586592178, 'rL_recall': 0.5057471264367817, 'rL_f1': 0.3308270676691729, 'bs_precision': 0.3463340103626251, 'bs_recall': 0.5576447248458862, 'bs_f1': 0.4451776146888733, 'bs_mnli_precision': 0.6339392066001892, 'bs_mnli_recall': 0.7462779879570007, 'bs_mnli_f1': 0.6855368614196777, 'unique_bigram_ratio': 0.9655172413793104, 'nid': -0.2836460419251752, 'grammatical_errors': 1, 'pegasus_entailment': 0.6577905774116516, 'gold_entailment': 0.46428458392620087, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 544
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 76.03 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.325, 'r1_recall': 0.7222222222222222, 'r1_f1': 0.44827586206896547, 'r2_precision': 0.09243697478991597, 'r2_recall': 0.20754716981132076, 'r2_f1': 0.12790697674418605, 'rL_precision': 0.2, 'rL_recall': 0.4444444444444444, 'rL_f1': 0.2758620689655173, 'bs_precision': 0.274516761302948, 'bs_recall': 0.5129415988922119, 'bs_f1': 0.38421958684921265, 'bs_mnli_precision': 0.6101998090744019, 'bs_mnli_recall': 0.7260113954544067, 'bs_mnli_f1': 0.6630868315696716, 'unique_bigram_ratio': 0.9655172413793104, 'nid': -0.2734151552505779, 'grammatical_errors': 0, 'pegasus_entailment': 0.4323978990316391, 'gold_entailment': 0.6504714787006378, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 545
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.21 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.34759358288770054, 'r1_recall': 0.5371900826446281, 'r1_f1': 0.42207792207792205, 'r2_precision': 0.10215053763440861, 'r2_recall': 0.15833333333333333, 'r2_f1': 0.1241830065359477, 'rL_precision': 0.21390374331550802, 'rL_recall': 0.3305785123966942, 'rL_f1': 0.25974025974025977, 'bs_precision': 0.28886470198631287, 'bs_recall': 0.36076003313064575, 'bs_f1': 0.3260015547275543, 'bs_mnli_precision': 0.6115505695343018, 'bs_mnli_recall': 0.6500459313392639, 'bs_mnli_f1': 0.6302109360694885, 'unique_bigram_ratio': 0.9329608938547486, 'nid': -0.23422051797386345, 'grammatical_errors': 1, 'pegasus_entailment': 0.8180686756968498, 'gold_entailment': 0.48477450013160706, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 546
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.20 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.25443786982248523, 'r1_recall': 0.41346153846153844, 'r1_f1': 0.315018315018315, 'r2_precision': 0.09523809523809523, 'r2_recall': 0.1553398058252427, 'r2_f1': 0.1180811808118081, 'rL_precision': 0.13609467455621302, 'rL_recall': 0.22115384615384615, 'rL_f1': 0.16849816849816848, 'bs_precision': 0.22694429755210876, 'bs_recall': 0.3357732594013214, 'bs_f1': 0.2811550498008728, 'bs_mnli_precision': 0.5894837379455566, 'bs_mnli_recall': 0.6313000917434692, 'bs_mnli_f1': 0.6096757650375366, 'unique_bigram_ratio': 0.963855421686747, 'nid': -0.2544703054049593, 'grammatical_errors': 1, 'pegasus_entailment': 0.4561893969774246, 'gold_entailment': 0.30060525983572006, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 547
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.89 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.30412371134020616, 'r1_recall': 0.8428571428571429, 'r1_f1': 0.44696969696969696, 'r2_precision': 0.19689119170984457, 'r2_recall': 0.5507246376811594, 'r2_f1': 0.2900763358778626, 'rL_precision': 0.23711340206185566, 'rL_recall': 0.6571428571428571, 'rL_f1': 0.3484848484848485, 'bs_precision': 0.3211345076560974, 'bs_recall': 0.593268632888794, 'bs_f1': 0.4447142779827118, 'bs_mnli_precision': 0.6315871477127075, 'bs_mnli_recall': 0.7839028835296631, 'bs_mnli_f1': 0.6995499134063721, 'unique_bigram_ratio': 0.9358288770053476, 'nid': -0.23019325400656676, 'grammatical_errors': 0, 'pegasus_entailment': 0.4231676914625698, 'gold_entailment': 0.49973735958337784, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 548
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.94 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.25806451612903225, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.35242290748898675, 'r2_precision': 0.09090909090909091, 'r2_recall': 0.19718309859154928, 'r2_f1': 0.12444444444444445, 'rL_precision': 0.15483870967741936, 'rL_recall': 0.3333333333333333, 'rL_f1': 0.21145374449339208, 'bs_precision': 0.2668686509132385, 'bs_recall': 0.39119982719421387, 'bs_f1': 0.32799941301345825, 'bs_mnli_precision': 0.60830157995224, 'bs_mnli_recall': 0.6489943265914917, 'bs_mnli_f1': 0.6279894709587097, 'unique_bigram_ratio': 0.9731543624161074, 'nid': -0.2809060803822945, 'grammatical_errors': 4, 'pegasus_entailment': 0.5452913961240223, 'gold_entailment': 0.45335833231608075, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 549
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.24 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2857142857142857, 'r1_recall': 0.6067415730337079, 'r1_f1': 0.38848920863309355, 'r2_precision': 0.12234042553191489, 'r2_recall': 0.26136363636363635, 'r2_f1': 0.16666666666666666, 'rL_precision': 0.19047619047619047, 'rL_recall': 0.4044943820224719, 'rL_f1': 0.2589928057553957, 'bs_precision': 0.1561957448720932, 'bs_recall': 0.3141738772392273, 'bs_f1': 0.23195433616638184, 'bs_mnli_precision': 0.5505177974700928, 'bs_mnli_recall': 0.654918909072876, 'bs_mnli_f1': 0.598197340965271, 'unique_bigram_ratio': 0.9243243243243243, 'nid': -0.23200632089942852, 'grammatical_errors': 3, 'pegasus_entailment': 0.4250714243389666, 'gold_entailment': 0.5183017486706376, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 550
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 72.42 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.144, 'r1_recall': 0.4, 'r1_f1': 0.2117647058823529, 'r2_precision': 0.024193548387096774, 'r2_recall': 0.06818181818181818, 'r2_f1': 0.03571428571428571, 'rL_precision': 0.096, 'rL_recall': 0.26666666666666666, 'rL_f1': 0.1411764705882353, 'bs_precision': 0.22348584234714508, 'bs_recall': 0.37051376700401306, 'bs_f1': 0.2946174442768097, 'bs_mnli_precision': 0.5623483657836914, 'bs_mnli_recall': 0.6585546731948853, 'bs_mnli_f1': 0.6066610217094421, 'unique_bigram_ratio': 0.9583333333333334, 'nid': -0.25033814562392664, 'grammatical_errors': 1, 'pegasus_entailment': 0.3669909182935953, 'gold_entailment': 0.4246692657470703, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 551
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.25 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3165137614678899, 'r1_recall': 0.6699029126213593, 'r1_f1': 0.4299065420560748, 'r2_precision': 0.16589861751152074, 'r2_recall': 0.35294117647058826, 'r2_f1': 0.22570532915360503, 'rL_precision': 0.20642201834862386, 'rL_recall': 0.4368932038834951, 'rL_f1': 0.28037383177570097, 'bs_precision': 0.3038758933544159, 'bs_recall': 0.5474228858947754, 'bs_f1': 0.4158351421356201, 'bs_mnli_precision': 0.6117046475410461, 'bs_mnli_recall': 0.7533836364746094, 'bs_mnli_f1': 0.6751919388771057, 'unique_bigram_ratio': 0.9038461538461539, 'nid': -0.19114822987694646, 'grammatical_errors': 8, 'pegasus_entailment': 0.49408360322316486, 'gold_entailment': 0.5783223857482275, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 552
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.62 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.1038961038961039, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.16931216931216933, 'r2_precision': 0.026143790849673203, 'r2_recall': 0.11764705882352941, 'r2_f1': 0.04278074866310161, 'rL_precision': 0.08441558441558442, 'rL_recall': 0.37142857142857144, 'rL_f1': 0.1375661375661376, 'bs_precision': 0.09523788094520569, 'bs_recall': 0.3428216278553009, 'bs_f1': 0.207130566239357, 'bs_mnli_precision': 0.5181511044502258, 'bs_mnli_recall': 0.6482428312301636, 'bs_mnli_f1': 0.5759421586990356, 'unique_bigram_ratio': 0.9733333333333334, 'nid': -0.27008870715491273, 'grammatical_errors': 1, 'pegasus_entailment': 0.38469939927260083, 'gold_entailment': 0.29022910445928574, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 553
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 66.33 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.17088607594936708, 'r1_recall': 0.6, 'r1_f1': 0.2660098522167487, 'r2_precision': 0.044585987261146494, 'r2_recall': 0.1590909090909091, 'r2_f1': 0.06965174129353234, 'rL_precision': 0.12025316455696203, 'rL_recall': 0.4222222222222222, 'rL_f1': 0.18719211822660098, 'bs_precision': 0.10172916948795319, 'bs_recall': 0.3759973347187042, 'bs_f1': 0.2239200472831726, 'bs_mnli_precision': 0.5246120095252991, 'bs_mnli_recall': 0.646537721157074, 'bs_mnli_f1': 0.5792281627655029, 'unique_bigram_ratio': 0.9605263157894737, 'nid': -0.2662108491339634, 'grammatical_errors': 4, 'pegasus_entailment': 0.38250140349070233, 'gold_entailment': 0.7029179334640503, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 554
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 79.80 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2857142857142857, 'r1_recall': 0.7692307692307693, 'r1_f1': 0.41666666666666663, 'r2_precision': 0.17307692307692307, 'r2_recall': 0.47368421052631576, 'r2_f1': 0.2535211267605634, 'rL_precision': 0.23809523809523808, 'rL_recall': 0.6410256410256411, 'rL_f1': 0.34722222222222227, 'bs_precision': 0.3098410665988922, 'bs_recall': 0.5823957324028015, 'bs_f1': 0.4334997832775116, 'bs_mnli_precision': 0.6211426854133606, 'bs_mnli_recall': 0.7629970908164978, 'bs_mnli_f1': 0.6848008632659912, 'unique_bigram_ratio': 0.9900990099009901, 'nid': -0.2706258507683874, 'grammatical_errors': 5, 'pegasus_entailment': 0.4850245950122674, 'gold_entailment': 0.6193132996559143, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 555
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.52 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4106280193236715, 'r1_recall': 0.5743243243243243, 'r1_f1': 0.4788732394366197, 'r2_precision': 0.1650485436893204, 'r2_recall': 0.23129251700680273, 'r2_f1': 0.19263456090651557, 'rL_precision': 0.23671497584541062, 'rL_recall': 0.3310810810810811, 'rL_f1': 0.27605633802816903, 'bs_precision': 0.3132539391517639, 'bs_recall': 0.3370550870895386, 'bs_f1': 0.3273373246192932, 'bs_mnli_precision': 0.6205872297286987, 'bs_mnli_recall': 0.6625326871871948, 'bs_mnli_f1': 0.6408743858337402, 'unique_bigram_ratio': 0.9447236180904522, 'nid': -0.22079675097013363, 'grammatical_errors': 4, 'pegasus_entailment': 0.3474042718816135, 'gold_entailment': 0.09534826036542654, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 556
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 71.21 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5423728813559322, 'r1_recall': 0.5565217391304348, 'r1_f1': 0.5493562231759657, 'r2_precision': 0.28205128205128205, 'r2_recall': 0.2894736842105263, 'r2_f1': 0.28571428571428575, 'rL_precision': 0.3728813559322034, 'rL_recall': 0.3826086956521739, 'rL_f1': 0.3776824034334764, 'bs_precision': 0.42776086926460266, 'bs_recall': 0.45035645365715027, 'bs_f1': 0.4408743977546692, 'bs_mnli_precision': 0.6834186911582947, 'bs_mnli_recall': 0.7013152241706848, 'bs_mnli_f1': 0.6922513246536255, 'unique_bigram_ratio': 0.9655172413793104, 'nid': -0.27879066791919227, 'grammatical_errors': 1, 'pegasus_entailment': 0.649765382707119, 'gold_entailment': 0.32212302163243295, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 557
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 72.48 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.39316239316239315, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.431924882629108, 'r2_precision': 0.20689655172413793, 'r2_recall': 0.25263157894736843, 'r2_f1': 0.2274881516587678, 'rL_precision': 0.3076923076923077, 'rL_recall': 0.375, 'rL_f1': 0.3380281690140845, 'bs_precision': 0.32193833589553833, 'bs_recall': 0.38818544149398804, 'bs_f1': 0.3563404977321625, 'bs_mnli_precision': 0.6464632749557495, 'bs_mnli_recall': 0.6631690859794617, 'bs_mnli_f1': 0.6547096371650696, 'unique_bigram_ratio': 0.9912280701754386, 'nid': -0.3017012305442992, 'grammatical_errors': 1, 'pegasus_entailment': 0.4659656822681427, 'gold_entailment': 0.274075744052728, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 558
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 31.36 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.21674876847290642, 'r1_recall': 0.8073394495412844, 'r1_f1': 0.34174757281553403, 'r2_precision': 0.12839506172839507, 'r2_recall': 0.48148148148148145, 'r2_f1': 0.202729044834308, 'rL_precision': 0.13793103448275862, 'rL_recall': 0.5137614678899083, 'rL_f1': 0.21747572815533978, 'bs_precision': 0.17350398004055023, 'bs_recall': 0.4776778817176819, 'bs_f1': 0.3079378604888916, 'bs_mnli_precision': 0.5611230134963989, 'bs_mnli_recall': 0.7394185066223145, 'bs_mnli_f1': 0.6380491852760315, 'unique_bigram_ratio': 0.9045226130653267, 'nid': -0.1680956623892862, 'grammatical_errors': 4, 'pegasus_entailment': 0.5363984103004138, 'gold_entailment': 0.3690844190617402, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 23}
*** Analysing case 559
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.52 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4527363184079602, 'r1_recall': 0.6594202898550725, 'r1_f1': 0.5368731563421828, 'r2_precision': 0.24, 'r2_recall': 0.35036496350364965, 'r2_f1': 0.28486646884273, 'rL_precision': 0.31343283582089554, 'rL_recall': 0.45652173913043476, 'rL_f1': 0.37168141592920356, 'bs_precision': 0.3692554235458374, 'bs_recall': 0.4823864698410034, 'bs_f1': 0.4252398908138275, 'bs_mnli_precision': 0.6734011769294739, 'bs_mnli_recall': 0.716925859451294, 'bs_mnli_f1': 0.6944822669029236, 'unique_bigram_ratio': 0.9576719576719577, 'nid': -0.20260078741204546, 'grammatical_errors': 0, 'pegasus_entailment': 0.6848156318068505, 'gold_entailment': 0.6860607676208019, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 560
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 33.35 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.7785714285714286, 'r1_recall': 0.3096590909090909, 'r1_f1': 0.44308943089430886, 'r2_precision': 0.4028776978417266, 'r2_recall': 0.15954415954415954, 'r2_f1': 0.2285714285714286, 'rL_precision': 0.42857142857142855, 'rL_recall': 0.17045454545454544, 'rL_f1': 0.24390243902439024, 'bs_precision': 0.5000045299530029, 'bs_recall': 0.2402997761964798, 'bs_f1': 0.3583154082298279, 'bs_mnli_precision': 0.7283036708831787, 'bs_mnli_recall': 0.5877388715744019, 'bs_mnli_f1': 0.6505144834518433, 'unique_bigram_ratio': 0.9621212121212122, 'nid': -0.22275660240403572, 'grammatical_errors': 2, 'pegasus_entailment': 0.3774997020761172, 'gold_entailment': 0.37756687881691114, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 561
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 66.04 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.38235294117647056, 'r1_recall': 0.46846846846846846, 'r1_f1': 0.42105263157894735, 'r2_precision': 0.1259259259259259, 'r2_recall': 0.15454545454545454, 'r2_f1': 0.13877551020408166, 'rL_precision': 0.23529411764705882, 'rL_recall': 0.2882882882882883, 'rL_f1': 0.2591093117408907, 'bs_precision': 0.3478716313838959, 'bs_recall': 0.37720999121665955, 'bs_f1': 0.3645381033420563, 'bs_mnli_precision': 0.6420955657958984, 'bs_mnli_recall': 0.6615656614303589, 'bs_mnli_f1': 0.6516852378845215, 'unique_bigram_ratio': 0.9621212121212122, 'nid': -0.2715735576070799, 'grammatical_errors': 0, 'pegasus_entailment': 0.31089512684515547, 'gold_entailment': 0.2183391905389726, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 562
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.58 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.40764331210191085, 'r1_recall': 0.42953020134228187, 'r1_f1': 0.4183006535947713, 'r2_precision': 0.10897435897435898, 'r2_recall': 0.11486486486486487, 'r2_f1': 0.1118421052631579, 'rL_precision': 0.18471337579617833, 'rL_recall': 0.19463087248322147, 'rL_f1': 0.1895424836601307, 'bs_precision': 0.27566614747047424, 'bs_recall': 0.27001336216926575, 'bs_f1': 0.2753176689147949, 'bs_mnli_precision': 0.5969958901405334, 'bs_mnli_recall': 0.6098191142082214, 'bs_mnli_f1': 0.6033393740653992, 'unique_bigram_ratio': 0.9675324675324676, 'nid': -0.26744346706642563, 'grammatical_errors': 1, 'pegasus_entailment': 0.7389088034629822, 'gold_entailment': 0.3745744854211807, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 563
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 60.71 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5921052631578947, 'r1_recall': 0.6040268456375839, 'r1_f1': 0.5980066445182725, 'r2_precision': 0.31788079470198677, 'r2_recall': 0.32432432432432434, 'r2_f1': 0.3210702341137124, 'rL_precision': 0.39473684210526316, 'rL_recall': 0.40268456375838924, 'rL_f1': 0.39867109634551495, 'bs_precision': 0.4491214156150818, 'bs_recall': 0.4706656336784363, 'bs_f1': 0.4616486728191376, 'bs_mnli_precision': 0.703112006187439, 'bs_mnli_recall': 0.7147324681282043, 'bs_mnli_f1': 0.708874523639679, 'unique_bigram_ratio': 0.958041958041958, 'nid': -0.25924832663878683, 'grammatical_errors': 0, 'pegasus_entailment': 0.7639057735602061, 'gold_entailment': 0.6506434679031372, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 564
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 87.42 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3116883116883117, 'r1_recall': 0.4897959183673469, 'r1_f1': 0.38095238095238093, 'r2_precision': 0.07894736842105263, 'r2_recall': 0.125, 'r2_f1': 0.0967741935483871, 'rL_precision': 0.18181818181818182, 'rL_recall': 0.2857142857142857, 'rL_f1': 0.2222222222222222, 'bs_precision': 0.22604447603225708, 'bs_recall': 0.35193151235580444, 'bs_f1': 0.2878842353820801, 'bs_mnli_precision': 0.5849003791809082, 'bs_mnli_recall': 0.6390796899795532, 'bs_mnli_f1': 0.6107909083366394, 'unique_bigram_ratio': 1.0, 'nid': -0.3636573404686869, 'grammatical_errors': 0, 'pegasus_entailment': 0.47489871829748154, 'gold_entailment': 0.3299309064944585, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 565
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.45 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.31333333333333335, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.42342342342342343, 'r2_precision': 0.14093959731543623, 'r2_recall': 0.29577464788732394, 'r2_f1': 0.19090909090909092, 'rL_precision': 0.2, 'rL_recall': 0.4166666666666667, 'rL_f1': 0.2702702702702703, 'bs_precision': 0.3250931203365326, 'bs_recall': 0.4776741862297058, 'bs_f1': 0.3987135589122772, 'bs_mnli_precision': 0.6218975186347961, 'bs_mnli_recall': 0.6802002787590027, 'bs_mnli_f1': 0.6497436165809631, 'unique_bigram_ratio': 0.9722222222222222, 'nid': -0.2662072520091481, 'grammatical_errors': 0, 'pegasus_entailment': 0.4202777997901042, 'gold_entailment': 0.35887641956408817, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 566
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.97 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24537037037037038, 'r1_recall': 0.654320987654321, 'r1_f1': 0.35690235690235694, 'r2_precision': 0.07441860465116279, 'r2_recall': 0.2, 'r2_f1': 0.10847457627118644, 'rL_precision': 0.1527777777777778, 'rL_recall': 0.4074074074074074, 'rL_f1': 0.22222222222222227, 'bs_precision': 0.22919870913028717, 'bs_recall': 0.42242759466171265, 'bs_f1': 0.32006165385246277, 'bs_mnli_precision': 0.5732166767120361, 'bs_mnli_recall': 0.6777970194816589, 'bs_mnli_f1': 0.6211355328559875, 'unique_bigram_ratio': 0.9672897196261683, 'nid': -0.26969180456943853, 'grammatical_errors': 2, 'pegasus_entailment': 0.6424867510795593, 'gold_entailment': 0.1738449806968371, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 567
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.35 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5392670157068062, 'r1_recall': 0.6866666666666666, 'r1_f1': 0.6041055718475073, 'r2_precision': 0.3157894736842105, 'r2_recall': 0.40268456375838924, 'r2_f1': 0.35398230088495575, 'rL_precision': 0.33507853403141363, 'rL_recall': 0.4266666666666667, 'rL_f1': 0.37536656891495607, 'bs_precision': 0.4032742381095886, 'bs_recall': 0.4792085587978363, 'bs_f1': 0.44201794266700745, 'bs_mnli_precision': 0.6896340250968933, 'bs_mnli_recall': 0.7315508127212524, 'bs_mnli_f1': 0.7099743485450745, 'unique_bigram_ratio': 0.8972972972972973, 'nid': -0.18565216392664952, 'grammatical_errors': 3, 'pegasus_entailment': 0.39716571995190214, 'gold_entailment': 0.5637281388044357, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 568
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.76 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24102564102564103, 'r1_recall': 0.7014925373134329, 'r1_f1': 0.35877862595419846, 'r2_precision': 0.12371134020618557, 'r2_recall': 0.36363636363636365, 'r2_f1': 0.18461538461538463, 'rL_precision': 0.1794871794871795, 'rL_recall': 0.5223880597014925, 'rL_f1': 0.26717557251908397, 'bs_precision': 0.23312045633792877, 'bs_recall': 0.4352571666240692, 'bs_f1': 0.32771262526512146, 'bs_mnli_precision': 0.5836375951766968, 'bs_mnli_recall': 0.6990046501159668, 'bs_mnli_f1': 0.6361327767372131, 'unique_bigram_ratio': 0.9479166666666666, 'nid': -0.23246656676925537, 'grammatical_errors': 4, 'pegasus_entailment': 0.4351574740721844, 'gold_entailment': 0.11106549948453903, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 569
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.73 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4793814432989691, 'r1_recall': 0.5406976744186046, 'r1_f1': 0.5081967213114754, 'r2_precision': 0.21243523316062177, 'r2_recall': 0.23976608187134502, 'r2_f1': 0.22527472527472528, 'rL_precision': 0.30927835051546393, 'rL_recall': 0.3488372093023256, 'rL_f1': 0.3278688524590164, 'bs_precision': 0.4017604887485504, 'bs_recall': 0.4382050037384033, 'bs_f1': 0.42169874906539917, 'bs_mnli_precision': 0.67513507604599, 'bs_mnli_recall': 0.6836998462677002, 'bs_mnli_f1': 0.6793904304504395, 'unique_bigram_ratio': 0.9312169312169312, 'nid': -0.2240558147355869, 'grammatical_errors': 3, 'pegasus_entailment': 0.5389579321656909, 'gold_entailment': 0.174638569355011, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 570
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 64.47 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2838709677419355, 'r1_recall': 0.5945945945945946, 'r1_f1': 0.38427947598253276, 'r2_precision': 0.08441558441558442, 'r2_recall': 0.1780821917808219, 'r2_f1': 0.11453744493392068, 'rL_precision': 0.17419354838709677, 'rL_recall': 0.36486486486486486, 'rL_f1': 0.23580786026200876, 'bs_precision': 0.20894797146320343, 'bs_recall': 0.35683560371398926, 'bs_f1': 0.2804402709007263, 'bs_mnli_precision': 0.6010863780975342, 'bs_mnli_recall': 0.6729480028152466, 'bs_mnli_f1': 0.6349905133247375, 'unique_bigram_ratio': 0.9605263157894737, 'nid': -0.25871721571036677, 'grammatical_errors': 2, 'pegasus_entailment': 0.4263652520520346, 'gold_entailment': 0.43160124123096466, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 571
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.79 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2835820895522388, 'r1_recall': 0.4691358024691358, 'r1_f1': 0.3534883720930232, 'r2_precision': 0.09022556390977443, 'r2_recall': 0.15, 'r2_f1': 0.11267605633802816, 'rL_precision': 0.17164179104477612, 'rL_recall': 0.2839506172839506, 'rL_f1': 0.213953488372093, 'bs_precision': 0.22952596843242645, 'bs_recall': 0.3635006248950958, 'bs_f1': 0.294942170381546, 'bs_mnli_precision': 0.583844006061554, 'bs_mnli_recall': 0.6424738168716431, 'bs_mnli_f1': 0.6117573380470276, 'unique_bigram_ratio': 0.9922480620155039, 'nid': -0.30002183798571247, 'grammatical_errors': 2, 'pegasus_entailment': 0.6203325043121973, 'gold_entailment': 0.49200854698816937, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 572
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 37.53 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.26112759643916916, 'r1_recall': 0.624113475177305, 'r1_f1': 0.36820083682008375, 'r2_precision': 0.13988095238095238, 'r2_recall': 0.3357142857142857, 'r2_f1': 0.19747899159663865, 'rL_precision': 0.17804154302670624, 'rL_recall': 0.425531914893617, 'rL_f1': 0.2510460251046025, 'bs_precision': 0.22111950814723969, 'bs_recall': 0.4065611660480499, 'bs_f1': 0.30868786573410034, 'bs_mnli_precision': 0.590563178062439, 'bs_mnli_recall': 0.6769589185714722, 'bs_mnli_f1': 0.630816638469696, 'unique_bigram_ratio': 0.8888888888888888, 'nid': -0.15723916617275724, 'grammatical_errors': 7, 'pegasus_entailment': 0.6445589903742075, 'gold_entailment': 0.6191025177637736, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 573
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 46.55 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.29583333333333334, 'r1_recall': 0.5419847328244275, 'r1_f1': 0.38274932614555257, 'r2_precision': 0.08368200836820083, 'r2_recall': 0.15384615384615385, 'r2_f1': 0.10840108401084012, 'rL_precision': 0.17083333333333334, 'rL_recall': 0.31297709923664124, 'rL_f1': 0.2210242587601078, 'bs_precision': 0.22866180539131165, 'bs_recall': 0.2633533477783203, 'bs_f1': 0.2483038455247879, 'bs_mnli_precision': 0.6041079759597778, 'bs_mnli_recall': 0.6263350248336792, 'bs_mnli_f1': 0.615020751953125, 'unique_bigram_ratio': 0.9484978540772532, 'nid': -0.2086582334187015, 'grammatical_errors': 3, 'pegasus_entailment': 0.6456060176715255, 'gold_entailment': 0.4631905232866605, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 574
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.10 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.6016260162601627, 'r1_recall': 0.3474178403755869, 'r1_f1': 0.44047619047619047, 'r2_precision': 0.22131147540983606, 'r2_recall': 0.12735849056603774, 'r2_f1': 0.16167664670658682, 'rL_precision': 0.3008130081300813, 'rL_recall': 0.17370892018779344, 'rL_f1': 0.22023809523809523, 'bs_precision': 0.3575666546821594, 'bs_recall': 0.2438814640045166, 'bs_f1': 0.30027133226394653, 'bs_mnli_precision': 0.6678478717803955, 'bs_mnli_recall': 0.5941244959831238, 'bs_mnli_f1': 0.6288327574729919, 'unique_bigram_ratio': 0.9658119658119658, 'nid': -0.2655030368664917, 'grammatical_errors': 1, 'pegasus_entailment': 0.3790014538913965, 'gold_entailment': 0.2365587896534375, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 575
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.42 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.25462962962962965, 'r1_recall': 0.6111111111111112, 'r1_f1': 0.3594771241830066, 'r2_precision': 0.12558139534883722, 'r2_recall': 0.30337078651685395, 'r2_f1': 0.17763157894736842, 'rL_precision': 0.16203703703703703, 'rL_recall': 0.3888888888888889, 'rL_f1': 0.22875816993464052, 'bs_precision': 0.2528720498085022, 'bs_recall': 0.45845842361450195, 'bs_f1': 0.34897860884666443, 'bs_mnli_precision': 0.5930426716804504, 'bs_mnli_recall': 0.717343807220459, 'bs_mnli_f1': 0.6492977738380432, 'unique_bigram_ratio': 0.9333333333333333, 'nid': -0.18322278449002205, 'grammatical_errors': 7, 'pegasus_entailment': 0.6158984324761799, 'gold_entailment': 0.23851556330919266, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 576
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 72.32 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.31496062992125984, 'r1_recall': 0.7017543859649122, 'r1_f1': 0.4347826086956522, 'r2_precision': 0.14285714285714285, 'r2_recall': 0.32142857142857145, 'r2_f1': 0.1978021978021978, 'rL_precision': 0.1968503937007874, 'rL_recall': 0.43859649122807015, 'rL_f1': 0.2717391304347826, 'bs_precision': 0.31094270944595337, 'bs_recall': 0.4848936200141907, 'bs_f1': 0.3938301205635071, 'bs_mnli_precision': 0.5978877544403076, 'bs_mnli_recall': 0.7004451751708984, 'bs_mnli_f1': 0.6451159119606018, 'unique_bigram_ratio': 0.9838709677419355, 'nid': -0.2997637117335594, 'grammatical_errors': 2, 'pegasus_entailment': 0.4162193527445197, 'gold_entailment': 0.2585495002567768, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 577
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.12 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.46190476190476193, 'r1_recall': 0.5132275132275133, 'r1_f1': 0.4862155388471178, 'r2_precision': 0.18181818181818182, 'r2_recall': 0.20212765957446807, 'r2_f1': 0.19143576826196476, 'rL_precision': 0.2714285714285714, 'rL_recall': 0.30158730158730157, 'rL_f1': 0.2857142857142857, 'bs_precision': 0.26641005277633667, 'bs_recall': 0.3154175281524658, 'bs_f1': 0.2928009331226349, 'bs_mnli_precision': 0.632834792137146, 'bs_mnli_recall': 0.6426650285720825, 'bs_mnli_f1': 0.6377120018005371, 'unique_bigram_ratio': 0.9219512195121952, 'nid': -0.21413399612808282, 'grammatical_errors': 2, 'pegasus_entailment': 0.5431057848036289, 'gold_entailment': 0.5356035927931467, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 578
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 36.25 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.660377358490566, 'r1_recall': 0.4605263157894737, 'r1_f1': 0.5426356589147286, 'r2_precision': 0.3080568720379147, 'r2_recall': 0.2145214521452145, 'r2_f1': 0.2529182879377432, 'rL_precision': 0.3113207547169811, 'rL_recall': 0.21710526315789475, 'rL_f1': 0.2558139534883721, 'bs_precision': 0.4321613609790802, 'bs_recall': 0.3255014717578888, 'bs_f1': 0.3786138594150543, 'bs_mnli_precision': 0.6879216432571411, 'bs_mnli_recall': 0.634803295135498, 'bs_mnli_f1': 0.6602959036827087, 'unique_bigram_ratio': 0.9563106796116505, 'nid': -0.24171526899831863, 'grammatical_errors': 3, 'pegasus_entailment': 0.3149079413463672, 'gold_entailment': 0.2894848682400253, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 579
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.04 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.18493150684931506, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.2583732057416268, 'r2_precision': 0.027586206896551724, 'r2_recall': 0.06451612903225806, 'r2_f1': 0.03864734299516908, 'rL_precision': 0.136986301369863, 'rL_recall': 0.31746031746031744, 'rL_f1': 0.19138755980861244, 'bs_precision': 0.1594488024711609, 'bs_recall': 0.31470078229904175, 'bs_f1': 0.23404774069786072, 'bs_mnli_precision': 0.5111360549926758, 'bs_mnli_recall': 0.6353763341903687, 'bs_mnli_f1': 0.5665246248245239, 'unique_bigram_ratio': 0.9787234042553191, 'nid': -0.29634048330523677, 'grammatical_errors': 4, 'pegasus_entailment': 0.44152748882770537, 'gold_entailment': 0.1970982508112987, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 580
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.15 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3113207547169811, 'r1_recall': 0.6947368421052632, 'r1_f1': 0.42996742671009774, 'r2_precision': 0.16587677725118483, 'r2_recall': 0.3723404255319149, 'r2_f1': 0.22950819672131148, 'rL_precision': 0.16981132075471697, 'rL_recall': 0.37894736842105264, 'rL_f1': 0.23452768729641693, 'bs_precision': 0.26670926809310913, 'bs_recall': 0.48362836241722107, 'bs_f1': 0.3675692677497864, 'bs_mnli_precision': 0.6188438534736633, 'bs_mnli_recall': 0.7266857624053955, 'bs_mnli_f1': 0.6684431433677673, 'unique_bigram_ratio': 0.9611650485436893, 'nid': -0.24422673298640785, 'grammatical_errors': 2, 'pegasus_entailment': 0.46730286876360577, 'gold_entailment': 0.22384866047650576, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 581
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.38 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5126582278481012, 'r1_f1': 0.50625, 'r2_precision': 0.18633540372670807, 'r2_recall': 0.1910828025477707, 'r2_f1': 0.18867924528301888, 'rL_precision': 0.30864197530864196, 'rL_recall': 0.31645569620253167, 'rL_f1': 0.31250000000000006, 'bs_precision': 0.3549990952014923, 'bs_recall': 0.3270791471004486, 'bs_f1': 0.34312620759010315, 'bs_mnli_precision': 0.6571465730667114, 'bs_mnli_recall': 0.638579249382019, 'bs_mnli_f1': 0.6477298736572266, 'unique_bigram_ratio': 0.96875, 'nid': -0.23668812105676462, 'grammatical_errors': 1, 'pegasus_entailment': 0.530921770632267, 'gold_entailment': 0.4090668261051178, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 582
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 76.38 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24786324786324787, 'r1_recall': 0.5, 'r1_f1': 0.33142857142857146, 'r2_precision': 0.1206896551724138, 'r2_recall': 0.24561403508771928, 'r2_f1': 0.16184971098265896, 'rL_precision': 0.19658119658119658, 'rL_recall': 0.39655172413793105, 'rL_f1': 0.2628571428571429, 'bs_precision': 0.3203568458557129, 'bs_recall': 0.4336899518966675, 'bs_f1': 0.3764968514442444, 'bs_mnli_precision': 0.6085746884346008, 'bs_mnli_recall': 0.6684592962265015, 'bs_mnli_f1': 0.6371129155158997, 'unique_bigram_ratio': 0.9565217391304348, 'nid': -0.19952619920763182, 'grammatical_errors': 0, 'pegasus_entailment': 0.45425786450505257, 'gold_entailment': 0.3490772023797035, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 583
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 50.66 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.509090909090909, 'r1_recall': 0.46408839779005523, 'r1_f1': 0.4855491329479769, 'r2_precision': 0.21341463414634146, 'r2_recall': 0.19444444444444445, 'r2_f1': 0.20348837209302323, 'rL_precision': 0.2727272727272727, 'rL_recall': 0.24861878453038674, 'rL_f1': 0.26011560693641617, 'bs_precision': 0.38402509689331055, 'bs_recall': 0.2855062782764435, 'bs_f1': 0.3349672257900238, 'bs_mnli_precision': 0.6760022640228271, 'bs_mnli_recall': 0.6244592666625977, 'bs_mnli_f1': 0.6492093205451965, 'unique_bigram_ratio': 0.9259259259259259, 'nid': -0.2329914470822081, 'grammatical_errors': 3, 'pegasus_entailment': 0.3471868758400281, 'gold_entailment': 0.21656389865610334, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 584
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 49.52 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.42162162162162165, 'r1_recall': 0.5492957746478874, 'r1_f1': 0.47706422018348627, 'r2_precision': 0.16847826086956522, 'r2_recall': 0.2198581560283688, 'r2_f1': 0.19076923076923075, 'rL_precision': 0.22162162162162163, 'rL_recall': 0.2887323943661972, 'rL_f1': 0.2507645259938838, 'bs_precision': 0.30617043375968933, 'bs_recall': 0.3187582194805145, 'bs_f1': 0.31477880477905273, 'bs_mnli_precision': 0.6428187489509583, 'bs_mnli_recall': 0.6583527326583862, 'bs_mnli_f1': 0.6504929661750793, 'unique_bigram_ratio': 0.95, 'nid': -0.23218888872875176, 'grammatical_errors': 1, 'pegasus_entailment': 0.3366070954749982, 'gold_entailment': 0.12098119826987386, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 585
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.41 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.5052631578947369, 'r1_f1': 0.401673640167364, 'r2_precision': 0.17482517482517482, 'r2_recall': 0.26595744680851063, 'r2_f1': 0.21097046413502113, 'rL_precision': 0.25, 'rL_recall': 0.37894736842105264, 'rL_f1': 0.30125523012552297, 'bs_precision': 0.2829365134239197, 'bs_recall': 0.32498449087142944, 'bs_f1': 0.30594882369041443, 'bs_mnli_precision': 0.6118278503417969, 'bs_mnli_recall': 0.6190459132194519, 'bs_mnli_f1': 0.6154156923294067, 'unique_bigram_ratio': 0.9784172661870504, 'nid': -0.24813370245292177, 'grammatical_errors': 1, 'pegasus_entailment': 0.6060676698883375, 'gold_entailment': 0.4745305310934782, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 586
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 52.73 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.48404255319148937, 'r1_recall': 0.5290697674418605, 'r1_f1': 0.5055555555555555, 'r2_precision': 0.12834224598930483, 'r2_recall': 0.14035087719298245, 'r2_f1': 0.1340782122905028, 'rL_precision': 0.21808510638297873, 'rL_recall': 0.23837209302325582, 'rL_f1': 0.2277777777777778, 'bs_precision': 0.25400716066360474, 'bs_recall': 0.2265043407678604, 'bs_f1': 0.24267712235450745, 'bs_mnli_precision': 0.6006426215171814, 'bs_mnli_recall': 0.5869365334510803, 'bs_mnli_f1': 0.5937104821205139, 'unique_bigram_ratio': 0.9562841530054644, 'nid': -0.2321080320709219, 'grammatical_errors': 1, 'pegasus_entailment': 0.3059506740953241, 'gold_entailment': 0.19108952675014734, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 587
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 63.91 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.24489795918367346, 'r1_recall': 0.5070422535211268, 'r1_f1': 0.33027522935779813, 'r2_precision': 0.0821917808219178, 'r2_recall': 0.17142857142857143, 'r2_f1': 0.1111111111111111, 'rL_precision': 0.1836734693877551, 'rL_recall': 0.38028169014084506, 'rL_f1': 0.2477064220183486, 'bs_precision': 0.2722824215888977, 'bs_recall': 0.4460960030555725, 'bs_f1': 0.35504332184791565, 'bs_mnli_precision': 0.5925546884536743, 'bs_mnli_recall': 0.6668109893798828, 'bs_mnli_f1': 0.627493679523468, 'unique_bigram_ratio': 0.9577464788732394, 'nid': -0.26267977211834403, 'grammatical_errors': 2, 'pegasus_entailment': 0.4100573179977281, 'gold_entailment': 0.12777483959992728, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 588
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 47.23 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5738636363636364, 'r1_recall': 0.4855769230769231, 'r1_f1': 0.5260416666666666, 'r2_precision': 0.24, 'r2_recall': 0.2028985507246377, 'r2_f1': 0.21989528795811517, 'rL_precision': 0.3409090909090909, 'rL_recall': 0.28846153846153844, 'rL_f1': 0.31249999999999994, 'bs_precision': 0.3144661784172058, 'bs_recall': 0.23981215059757233, 'bs_f1': 0.27835872769355774, 'bs_mnli_precision': 0.6587992906570435, 'bs_mnli_recall': 0.6172409057617188, 'bs_mnli_f1': 0.6373433470726013, 'unique_bigram_ratio': 0.9470588235294117, 'nid': -0.20013353489274, 'grammatical_errors': 2, 'pegasus_entailment': 0.643115695565939, 'gold_entailment': 0.5481346677988768, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 589
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 58.55 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3160919540229885, 'r1_recall': 0.5913978494623656, 'r1_f1': 0.41198501872659177, 'r2_precision': 0.17341040462427745, 'r2_recall': 0.32608695652173914, 'r2_f1': 0.22641509433962265, 'rL_precision': 0.20689655172413793, 'rL_recall': 0.3870967741935484, 'rL_f1': 0.26966292134831465, 'bs_precision': 0.2910038232803345, 'bs_recall': 0.4782595634460449, 'bs_f1': 0.37953564524650574, 'bs_mnli_precision': 0.619432806968689, 'bs_mnli_recall': 0.7282352447509766, 'bs_mnli_f1': 0.6694419980049133, 'unique_bigram_ratio': 0.9473684210526315, 'nid': -0.2097391516539313, 'grammatical_errors': 1, 'pegasus_entailment': 0.3785050520673394, 'gold_entailment': 0.337505379319191, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 590
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 41.28 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.16040955631399317, 'r1_recall': 0.6266666666666667, 'r1_f1': 0.2554347826086957, 'r2_precision': 0.07876712328767123, 'r2_recall': 0.3108108108108108, 'r2_f1': 0.12568306010928962, 'rL_precision': 0.11604095563139932, 'rL_recall': 0.4533333333333333, 'rL_f1': 0.1847826086956522, 'bs_precision': 0.2039550393819809, 'bs_recall': 0.44480326771736145, 'bs_f1': 0.31415989995002747, 'bs_mnli_precision': 0.5665421485900879, 'bs_mnli_recall': 0.6870123147964478, 'bs_mnli_f1': 0.6209884881973267, 'unique_bigram_ratio': 0.9263157894736842, 'nid': -0.18595323401741592, 'grammatical_errors': 4, 'pegasus_entailment': 0.5920916023579511, 'gold_entailment': 0.34893616288900375, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 591
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.12 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.32919254658385094, 'r1_recall': 0.7464788732394366, 'r1_f1': 0.45689655172413796, 'r2_precision': 0.175, 'r2_recall': 0.4, 'r2_f1': 0.2434782608695652, 'rL_precision': 0.21739130434782608, 'rL_recall': 0.49295774647887325, 'rL_f1': 0.30172413793103453, 'bs_precision': 0.3198893368244171, 'bs_recall': 0.5545570254325867, 'bs_f1': 0.42831215262413025, 'bs_mnli_precision': 0.6377027034759521, 'bs_mnli_recall': 0.7649865746498108, 'bs_mnli_f1': 0.695569634437561, 'unique_bigram_ratio': 0.9044585987261147, 'nid': -0.1832441890478902, 'grammatical_errors': 0, 'pegasus_entailment': 0.4124875171110034, 'gold_entailment': 0.54204590121905, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 592
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 39.08 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.23711340206185566, 'r1_recall': 0.6831683168316832, 'r1_f1': 0.3520408163265306, 'r2_precision': 0.09655172413793103, 'r2_recall': 0.28, 'r2_f1': 0.1435897435897436, 'rL_precision': 0.13058419243986255, 'rL_recall': 0.37623762376237624, 'rL_f1': 0.19387755102040818, 'bs_precision': 0.09946984797716141, 'bs_recall': 0.39219430088996887, 'bs_f1': 0.22855474054813385, 'bs_mnli_precision': 0.5310946106910706, 'bs_mnli_recall': 0.6650243997573853, 'bs_mnli_f1': 0.5905613899230957, 'unique_bigram_ratio': 0.9392857142857143, 'nid': -0.22512938436803798, 'grammatical_errors': 3, 'pegasus_entailment': 0.41444093201841625, 'gold_entailment': 0.19682152941823006, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 593
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.66 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.47029702970297027, 'r1_recall': 0.45893719806763283, 'r1_f1': 0.46454767726161367, 'r2_precision': 0.18407960199004975, 'r2_recall': 0.1796116504854369, 'r2_f1': 0.18181818181818182, 'rL_precision': 0.26732673267326734, 'rL_recall': 0.2608695652173913, 'rL_f1': 0.2640586797066014, 'bs_precision': 0.3513962924480438, 'bs_recall': 0.36177533864974976, 'bs_f1': 0.3587614595890045, 'bs_mnli_precision': 0.6456722021102905, 'bs_mnli_recall': 0.6597541570663452, 'bs_mnli_f1': 0.652637243270874, 'unique_bigram_ratio': 0.958974358974359, 'nid': -0.25528622028361525, 'grammatical_errors': 8, 'pegasus_entailment': 0.7971553802490234, 'gold_entailment': 0.46615756303071976, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 594
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 69.18 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4435483870967742, 'r1_recall': 0.5392156862745098, 'r1_f1': 0.4867256637168142, 'r2_precision': 0.17073170731707318, 'r2_recall': 0.2079207920792079, 'r2_f1': 0.18750000000000003, 'rL_precision': 0.28225806451612906, 'rL_recall': 0.3431372549019608, 'rL_f1': 0.30973451327433627, 'bs_precision': 0.360762357711792, 'bs_recall': 0.4681895673274994, 'bs_f1': 0.41416269540786743, 'bs_mnli_precision': 0.6474001407623291, 'bs_mnli_recall': 0.7086196541786194, 'bs_mnli_f1': 0.6766279935836792, 'unique_bigram_ratio': 0.9661016949152542, 'nid': -0.2639612003007288, 'grammatical_errors': 2, 'pegasus_entailment': 0.38372448589652774, 'gold_entailment': 0.33757838904857634, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 595
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.09 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.23026315789473684, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.33018867924528306, 'r2_precision': 0.059602649006622516, 'r2_recall': 0.15254237288135594, 'r2_f1': 0.08571428571428572, 'rL_precision': 0.11842105263157894, 'rL_recall': 0.3, 'rL_f1': 0.169811320754717, 'bs_precision': 0.1679351031780243, 'bs_recall': 0.33186399936676025, 'bs_f1': 0.24625621736049652, 'bs_mnli_precision': 0.5570398569107056, 'bs_mnli_recall': 0.6338719129562378, 'bs_mnli_f1': 0.5929774641990662, 'unique_bigram_ratio': 0.9795918367346939, 'nid': -0.2682092892621717, 'grammatical_errors': 1, 'pegasus_entailment': 0.4879842042922974, 'gold_entailment': 0.4565088003873825, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 596
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.93 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.5652173913043478, 'r1_recall': 0.5112359550561798, 'r1_f1': 0.5368731563421828, 'r2_precision': 0.29375, 'r2_recall': 0.2655367231638418, 'r2_f1': 0.27893175074183973, 'rL_precision': 0.422360248447205, 'rL_recall': 0.38202247191011235, 'rL_f1': 0.4011799410029499, 'bs_precision': 0.4587513506412506, 'bs_recall': 0.37418708205223083, 'bs_f1': 0.4170371890068054, 'bs_mnli_precision': 0.6945235729217529, 'bs_mnli_recall': 0.6572797894477844, 'bs_mnli_f1': 0.6753886342048645, 'unique_bigram_ratio': 0.9299363057324841, 'nid': -0.18505412847999225, 'grammatical_errors': 2, 'pegasus_entailment': 0.34568009099790026, 'gold_entailment': 0.13206404315618178, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 597
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 72.03 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.35714285714285715, 'r1_recall': 0.6164383561643836, 'r1_f1': 0.45226130653266333, 'r2_precision': 0.16, 'r2_recall': 0.2777777777777778, 'r2_f1': 0.20304568527918782, 'rL_precision': 0.25396825396825395, 'rL_recall': 0.4383561643835616, 'rL_f1': 0.32160804020100503, 'bs_precision': 0.3288562297821045, 'bs_recall': 0.4594763517379761, 'bs_f1': 0.3927595019340515, 'bs_mnli_precision': 0.6721220016479492, 'bs_mnli_recall': 0.7283286452293396, 'bs_mnli_f1': 0.6990973949432373, 'unique_bigram_ratio': 0.9669421487603306, 'nid': -0.2185247756086064, 'grammatical_errors': 0, 'pegasus_entailment': 0.1578200600730876, 'gold_entailment': 0.041137644089758396, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 598
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.84 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2981366459627329, 'r1_recall': 0.631578947368421, 'r1_f1': 0.4050632911392405, 'r2_precision': 0.1375, 'r2_recall': 0.29333333333333333, 'r2_f1': 0.1872340425531915, 'rL_precision': 0.18012422360248448, 'rL_recall': 0.3815789473684211, 'rL_f1': 0.2447257383966245, 'bs_precision': 0.24595150351524353, 'bs_recall': 0.5008008480072021, 'bs_f1': 0.3620624542236328, 'bs_mnli_precision': 0.5944620370864868, 'bs_mnli_recall': 0.7105375528335571, 'bs_mnli_f1': 0.6473374962806702, 'unique_bigram_ratio': 0.9430379746835443, 'nid': -0.20007380970441968, 'grammatical_errors': 0, 'pegasus_entailment': 0.6029703489371708, 'gold_entailment': 0.5722774267196655, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 599
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 75.35 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4953271028037383, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.5353535353535354, 'r2_precision': 0.2641509433962264, 'r2_recall': 0.3111111111111111, 'r2_f1': 0.28571428571428575, 'rL_precision': 0.38317757009345793, 'rL_recall': 0.45054945054945056, 'rL_f1': 0.41414141414141414, 'bs_precision': 0.42404094338417053, 'bs_recall': 0.4892278015613556, 'bs_f1': 0.4576660394668579, 'bs_mnli_precision': 0.7067199945449829, 'bs_mnli_recall': 0.7326544523239136, 'bs_mnli_f1': 0.7194535732269287, 'unique_bigram_ratio': 0.9902912621359223, 'nid': -0.2718327643750309, 'grammatical_errors': 0, 'pegasus_entailment': 0.38778460696339606, 'gold_entailment': 0.3048767037689686, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 600
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 48.93 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3305084745762712, 'r1_recall': 0.65, 'r1_f1': 0.4382022471910112, 'r2_precision': 0.15319148936170213, 'r2_recall': 0.3025210084033613, 'r2_f1': 0.20338983050847456, 'rL_precision': 0.2288135593220339, 'rL_recall': 0.45, 'rL_f1': 0.30337078651685395, 'bs_precision': 0.28128913044929504, 'bs_recall': 0.49565282464027405, 'bs_f1': 0.38115763664245605, 'bs_mnli_precision': 0.6385204195976257, 'bs_mnli_recall': 0.7282527685165405, 'bs_mnli_f1': 0.6804410219192505, 'unique_bigram_ratio': 0.8973214285714286, 'nid': -0.16183169589227764, 'grammatical_errors': 3, 'pegasus_entailment': 0.5258304700255394, 'gold_entailment': 0.3486115410923958, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 601
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.06 seconds, 16.37 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.7623318385650224, 'r1_recall': 0.24113475177304963, 'r1_f1': 0.36637931034482757, 'r2_precision': 0.30180180180180183, 'r2_recall': 0.09517045454545454, 'r2_f1': 0.1447084233261339, 'rL_precision': 0.3991031390134529, 'rL_recall': 0.12624113475177304, 'rL_f1': 0.19181034482758616, 'bs_precision': 0.33759668469429016, 'bs_recall': 0.2527024447917938, 'bs_f1': 0.2959662675857544, 'bs_mnli_precision': 0.6598995327949524, 'bs_mnli_recall': 0.5712846517562866, 'bs_mnli_f1': 0.6124030351638794, 'unique_bigram_ratio': 0.9495412844036697, 'nid': -0.23426514473189508, 'grammatical_errors': 2, 'pegasus_entailment': 0.5741427391767502, 'gold_entailment': 0.3101008484478701, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 602
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 55.32 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4692737430167598, 'r1_recall': 0.5915492957746479, 'r1_f1': 0.5233644859813084, 'r2_precision': 0.21348314606741572, 'r2_recall': 0.2695035460992908, 'r2_f1': 0.23824451410658307, 'rL_precision': 0.2737430167597765, 'rL_recall': 0.34507042253521125, 'rL_f1': 0.3052959501557632, 'bs_precision': 0.3111540973186493, 'bs_recall': 0.36212465167045593, 'bs_f1': 0.338349312543869, 'bs_mnli_precision': 0.6297883987426758, 'bs_mnli_recall': 0.6747631430625916, 'bs_mnli_f1': 0.6515004634857178, 'unique_bigram_ratio': 0.9476744186046512, 'nid': -0.2439359265044101, 'grammatical_errors': 5, 'pegasus_entailment': 0.6000556788510747, 'gold_entailment': 0.5281100235879421, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 603
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.03 seconds, 38.02 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.38390092879256965, 'r1_recall': 0.6775956284153005, 'r1_f1': 0.4901185770750988, 'r2_precision': 0.19875776397515527, 'r2_recall': 0.3516483516483517, 'r2_f1': 0.25396825396825395, 'rL_precision': 0.20123839009287925, 'rL_recall': 0.3551912568306011, 'rL_f1': 0.2569169960474308, 'bs_precision': 0.2733934223651886, 'bs_recall': 0.38666895031929016, 'bs_f1': 0.32956042885780334, 'bs_mnli_precision': 0.6214188933372498, 'bs_mnli_recall': 0.6825966238975525, 'bs_mnli_f1': 0.6505727171897888, 'unique_bigram_ratio': 0.8971061093247589, 'nid': -0.16257712413863, 'grammatical_errors': 9, 'pegasus_entailment': 0.4342702478170395, 'gold_entailment': 0.34434356008257183, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 604
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 65.32 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3971631205673759, 'r1_recall': 0.6021505376344086, 'r1_f1': 0.47863247863247865, 'r2_precision': 0.16428571428571428, 'r2_recall': 0.25, 'r2_f1': 0.19827586206896552, 'rL_precision': 0.19148936170212766, 'rL_recall': 0.2903225806451613, 'rL_f1': 0.23076923076923078, 'bs_precision': 0.28834056854248047, 'bs_recall': 0.4172745645046234, 'bs_f1': 0.35151273012161255, 'bs_mnli_precision': 0.6360770463943481, 'bs_mnli_recall': 0.6923823356628418, 'bs_mnli_f1': 0.6630364656448364, 'unique_bigram_ratio': 0.9782608695652174, 'nid': -0.28495485330698767, 'grammatical_errors': 1, 'pegasus_entailment': 0.5026864260435104, 'gold_entailment': 0.3513530343770981, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 605
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.56 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.4166666666666667, 'r1_recall': 0.6896551724137931, 'r1_f1': 0.5194805194805195, 'r2_precision': 0.24083769633507854, 'r2_recall': 0.4, 'r2_f1': 0.3006535947712418, 'rL_precision': 0.2760416666666667, 'rL_recall': 0.45689655172413796, 'rL_f1': 0.34415584415584416, 'bs_precision': 0.3710854947566986, 'bs_recall': 0.4922018349170685, 'bs_f1': 0.4306849539279938, 'bs_mnli_precision': 0.6779406070709229, 'bs_mnli_recall': 0.7497913837432861, 'bs_mnli_f1': 0.7120580077171326, 'unique_bigram_ratio': 0.9621621621621622, 'nid': -0.22505676866478264, 'grammatical_errors': 1, 'pegasus_entailment': 0.4155152216553688, 'gold_entailment': 0.4557977085933089, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 606
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 61.32 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2922077922077922, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.410958904109589, 'r2_precision': 0.1568627450980392, 'r2_recall': 0.375, 'r2_f1': 0.22119815668202764, 'rL_precision': 0.2532467532467532, 'rL_recall': 0.6, 'rL_f1': 0.3561643835616438, 'bs_precision': 0.2483198046684265, 'bs_recall': 0.5503464341163635, 'bs_f1': 0.3828892409801483, 'bs_mnli_precision': 0.6034854054450989, 'bs_mnli_recall': 0.7774059772491455, 'bs_mnli_f1': 0.679493248462677, 'unique_bigram_ratio': 0.9602649006622517, 'nid': -0.2346006038893167, 'grammatical_errors': 0, 'pegasus_entailment': 0.6192195316155752, 'gold_entailment': 0.46583520621061325, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 607
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 45.16 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.35, 'r1_recall': 0.535031847133758, 'r1_f1': 0.42317380352644834, 'r2_precision': 0.1506276150627615, 'r2_recall': 0.23076923076923078, 'r2_f1': 0.18227848101265823, 'rL_precision': 0.23333333333333334, 'rL_recall': 0.35668789808917195, 'rL_f1': 0.28211586901763225, 'bs_precision': 0.23399768769741058, 'bs_recall': 0.3326747417449951, 'bs_f1': 0.2836020886898041, 'bs_mnli_precision': 0.5979621410369873, 'bs_mnli_recall': 0.646170973777771, 'bs_mnli_f1': 0.621132493019104, 'unique_bigram_ratio': 0.8978723404255319, 'nid': -0.1960513476965875, 'grammatical_errors': 3, 'pegasus_entailment': 0.6223371856742435, 'gold_entailment': 0.18325070344976016, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 608
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 57.94 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.14705882352941177, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.2293577981651376, 'r2_precision': 0.047337278106508875, 'r2_recall': 0.1702127659574468, 'r2_f1': 0.07407407407407407, 'rL_precision': 0.10588235294117647, 'rL_recall': 0.375, 'rL_f1': 0.16513761467889906, 'bs_precision': 0.09168178588151932, 'bs_recall': 0.33546310663223267, 'bs_f1': 0.20206187665462494, 'bs_mnli_precision': 0.49437496066093445, 'bs_mnli_recall': 0.6349620223045349, 'bs_mnli_f1': 0.5559179186820984, 'unique_bigram_ratio': 0.9761904761904762, 'nid': -0.2646639732824303, 'grammatical_errors': 7, 'pegasus_entailment': 0.3904448561370373, 'gold_entailment': 0.45523446798324585, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 609
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.00 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.2623762376237624, 'r1_recall': 0.5463917525773195, 'r1_f1': 0.35451505016722407, 'r2_precision': 0.11940298507462686, 'r2_recall': 0.25, 'r2_f1': 0.1616161616161616, 'rL_precision': 0.15346534653465346, 'rL_recall': 0.31958762886597936, 'rL_f1': 0.20735785953177258, 'bs_precision': 0.2130158692598343, 'bs_recall': 0.4036560654640198, 'bs_f1': 0.3027380704879761, 'bs_mnli_precision': 0.5642901659011841, 'bs_mnli_recall': 0.6813927888870239, 'bs_mnli_f1': 0.6173372268676758, 'unique_bigram_ratio': 0.964824120603015, 'nid': -0.26120108194671166, 'grammatical_errors': 2, 'pegasus_entailment': 0.40641107223927975, 'gold_entailment': 0.13541306229308248, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 610
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 75.62 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.09734513274336283, 'r1_recall': 0.3142857142857143, 'r1_f1': 0.14864864864864866, 'r2_precision': 0.017857142857142856, 'r2_recall': 0.058823529411764705, 'r2_f1': 0.0273972602739726, 'rL_precision': 0.07079646017699115, 'rL_recall': 0.22857142857142856, 'rL_f1': 0.10810810810810811, 'bs_precision': 0.18082964420318604, 'bs_recall': 0.35630694031715393, 'bs_f1': 0.26407739520072937, 'bs_mnli_precision': 0.5311281681060791, 'bs_mnli_recall': 0.6144319772720337, 'bs_mnli_f1': 0.5697512030601501, 'unique_bigram_ratio': 0.9727272727272728, 'nid': -0.26253359702966295, 'grammatical_errors': 0, 'pegasus_entailment': 0.31744971722364423, 'gold_entailment': 0.3222190737724304, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 611
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 53.12 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.305, 'r1_recall': 0.6288659793814433, 'r1_f1': 0.4107744107744108, 'r2_precision': 0.11557788944723618, 'r2_recall': 0.23958333333333334, 'r2_f1': 0.15593220338983052, 'rL_precision': 0.185, 'rL_recall': 0.38144329896907214, 'rL_f1': 0.2491582491582491, 'bs_precision': 0.26978376507759094, 'bs_recall': 0.5122340321540833, 'bs_f1': 0.3810877501964569, 'bs_mnli_precision': 0.6066610813140869, 'bs_mnli_recall': 0.7246500253677368, 'bs_mnli_f1': 0.6604270935058594, 'unique_bigram_ratio': 0.9540816326530612, 'nid': -0.248744753269168, 'grammatical_errors': 1, 'pegasus_entailment': 0.7608453631401062, 'gold_entailment': 0.6242699846625328, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 612
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 51.36 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.3026315789473684, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.40469208211143687, 'r2_precision': 0.1277533039647577, 'r2_recall': 0.25892857142857145, 'r2_f1': 0.1710914454277286, 'rL_precision': 0.18421052631578946, 'rL_recall': 0.37168141592920356, 'rL_f1': 0.24633431085043986, 'bs_precision': 0.1450648456811905, 'bs_recall': 0.3095604181289673, 'bs_f1': 0.22356997430324554, 'bs_mnli_precision': 0.5783702731132507, 'bs_mnli_recall': 0.6667768955230713, 'bs_mnli_f1': 0.6194350719451904, 'unique_bigram_ratio': 0.9282511210762332, 'nid': -0.16832048697079793, 'grammatical_errors': 1, 'pegasus_entailment': 0.2309811239441236, 'gold_entailment': 0.22707098722457886, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 613
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 54.70 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.48947368421052634, 'r1_recall': 0.6888888888888889, 'r1_f1': 0.5723076923076924, 'r2_precision': 0.23809523809523808, 'r2_recall': 0.3358208955223881, 'r2_f1': 0.2786377708978328, 'rL_precision': 0.2736842105263158, 'rL_recall': 0.3851851851851852, 'rL_f1': 0.32, 'bs_precision': 0.34951919317245483, 'bs_recall': 0.41300201416015625, 'bs_f1': 0.38254353404045105, 'bs_mnli_precision': 0.6863034963607788, 'bs_mnli_recall': 0.7040340900421143, 'bs_mnli_f1': 0.6950557231903076, 'unique_bigram_ratio': 0.9358288770053476, 'nid': -0.23426361890333602, 'grammatical_errors': 0, 'pegasus_entailment': 0.4524879852930705, 'gold_entailment': 0.3711143136024475, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 614
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.01 seconds, 67.62 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.16296296296296298, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.23280423280423276, 'r2_precision': 0.07462686567164178, 'r2_recall': 0.18867924528301888, 'r2_f1': 0.10695187165775401, 'rL_precision': 0.1111111111111111, 'rL_recall': 0.2777777777777778, 'rL_f1': 0.15873015873015872, 'bs_precision': 0.16507190465927124, 'bs_recall': 0.321269154548645, 'bs_f1': 0.24008625745773315, 'bs_mnli_precision': 0.5520303249359131, 'bs_mnli_recall': 0.6172674894332886, 'bs_mnli_f1': 0.5828290581703186, 'unique_bigram_ratio': 0.9541984732824428, 'nid': -0.287558424182371, 'grammatical_errors': 4, 'pegasus_entailment': 0.5706404617854527, 'gold_entailment': 0.30733245611190796, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 615
** ROUGE...
** BERTScore...
calculating scores...
computing bert embedding.
computing greedy matching.
done in 0.02 seconds, 56.79 sentences/sec
** Unique bigram...
** Normalised inverse of diversity...
** Grammaticality...
** Entailment...
** Readability....
{'r1_precision': 0.31891891891891894, 'r1_recall': 0.59, 'r1_f1': 0.4140350877192983, 'r2_precision': 0.07608695652173914, 'r2_recall': 0.1414141414141414, 'r2_f1': 0.09893992932862192, 'rL_precision': 0.1891891891891892, 'rL_recall': 0.35, 'rL_f1': 0.24561403508771934, 'bs_precision': 0.25856003165245056, 'bs_recall': 0.3588190972805023, 'bs_f1': 0.3088485598564148, 'bs_mnli_precision': 0.5884376764297485, 'bs_mnli_recall': 0.6421689391136169, 'bs_mnli_f1': 0.6141303181648254, 'unique_bigram_ratio': 0.9281767955801105, 'nid': -0.1864734317141601, 'grammatical_errors': 1, 'pegasus_entailment': 0.7343744718366199, 'gold_entailment': 0.5867327054341634, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.08683473389355742
MEAN
0.3727632991934572
MAX
0.8205128205128205
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.1839080459770115
MEAN
0.5757446658954036
MAX
0.8709677419354839
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.14864864864864866
MEAN
0.4276504485800091
MAX
0.624390243902439
** Analysing column: r2_precision



r2_precision
Length after nones removed
616
MIN
0.016
MEAN
0.16587732225298846
MAX
0.4152542372881356
** Analysing column: r2_recall



r2_recall
Length after nones removed
616
MIN
0.03508771929824561
MEAN
0.2578511604931787
MAX
0.5555555555555556
** Analysing column: r2_f1



r2_f1
Length after nones removed
616
MIN
0.021978021978021976
MEAN
0.19084319058015048
MAX
0.3842364532019704
** Analysing column: rL_precision



rL_precision
Length after nones removed
616
MIN
0.06162464985994398
MEAN
0.23530848159562157
MAX
0.5299145299145299
** Analysing column: rL_recall



rL_recall
Length after nones removed
616
MIN
0.11877394636015326
MEAN
0.3719149139817995
MAX
0.7241379310344828
** Analysing column: rL_f1



rL_f1
Length after nones removed
616
MIN
0.10810810810810811
MEAN
0.2724575522756804
MAX
0.5000000000000001
** Analysing column: bs_precision



bs_precision
Length after nones removed
616
MIN
0.027084169909358025
MEAN
0.29707117154650003
MAX
0.6086773872375488
** Analysing column: bs_recall



bs_recall
Length after nones removed
616
MIN
0.10232003778219223
MEAN
0.4063487679564527
MAX
0.6866580247879028
** Analysing column: bs_f1



bs_f1
Length after nones removed
616
MIN
0.10975168645381927
MEAN
0.3481011782809124
MAX
0.5935631990432739
** Analysing column: bs_mnli_precision



bs_mnli_precision
Length after nones removed
616
MIN
0.474674254655838
MEAN
0.6227902122712755
MAX
0.7811177968978882
** Analysing column: bs_mnli_recall



bs_mnli_recall
Length after nones removed
616
MIN
0.5301294326782227
MEAN
0.6813008464969598
MAX
0.8486118316650391
** Analysing column: bs_mnli_f1



bs_mnli_f1
Length after nones removed
616
MIN
0.5246601700782776
MEAN
0.6489050278996492
MAX
0.7752787470817566
** Analysing column: unique_bigram_ratio



unique_bigram_ratio
Length after nones removed
616
MIN
0.8348623853211009
MEAN
0.951524937955461
MAX
1.0
** Analysing column: nid



nid
Length after nones removed
616
MIN
-0.3636573404686869
MEAN
-0.24078117783959405
MAX
-0.13354072630025327
** Analysing column: grammatical_errors



grammatical_errors
Length after nones removed
616
MIN
0
MEAN
1
MAX
11
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.016542993907933123
MEAN
0.4953706406287123
MAX
0.845883771777153
** Analysing column: gold_entailment



gold_entailment
Length after nones removed
616
MIN
0.009347605790632466
MEAN
0.3581829873507316
MAX
0.8428828517595927
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
12
MEAN
17
MAX
29
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
13
MEAN
17
MAX
24
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
14
MEAN
21
MAX
35
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
14
MEAN
18
MAX
27
{}
