(base) fsuser@recakcsskvzdtnsqw:~/dissertation/230731_fs_eval$ ./21_eval.sh
bash: /home/fsuser/miniconda3/lib/libtinfo.so.6: no version information available (required by bash)
Mon Jul 31 13:45:42 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA RTX A6000    On   | 00000000:05:00.0 Off |                  Off |
| 30%   29C    P8    15W / 300W |      5MiB / 49140MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A       937      G   /usr/lib/xorg/Xorg                  4MiB |
+-----------------------------------------------------------------------------+
Entered file!
Imports done!
*** RUN *** 
eval_1cO
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 13:45:46.164767: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 13:45:46.732726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/1cO_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48175182481751827, 'r1_recall': 0.6, 'r1_f1': 0.5344129554655871, 'pegasus_entailment': 0.18178536805013815, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7692307692307693, 'r1_recall': 0.4046242774566474, 'r1_f1': 0.5303030303030304, 'pegasus_entailment': 0.5297707840800285, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 20}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29411764705882354, 'r1_recall': 0.6896551724137931, 'r1_f1': 0.41237113402061853, 'pegasus_entailment': 0.5508156545460224, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6951219512195121, 'r1_recall': 0.4418604651162791, 'r1_f1': 0.5402843601895735, 'pegasus_entailment': 0.2669356878226002, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7448979591836735, 'r1_recall': 0.41954022988505746, 'r1_f1': 0.5367647058823529, 'pegasus_entailment': 0.15087692425586283, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5063291139240507, 'r1_recall': 0.3076923076923077, 'r1_f1': 0.3827751196172249, 'pegasus_entailment': 0.8677401741345724, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16666666666666666, 'r1_recall': 0.53125, 'r1_f1': 0.2537313432835821, 'pegasus_entailment': 0.4110431563109159, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2987012987012987, 'r1_recall': 0.7419354838709677, 'r1_f1': 0.4259259259259259, 'pegasus_entailment': 0.42918085555235547, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7529411764705882, 'r1_recall': 0.42953020134228187, 'r1_f1': 0.547008547008547, 'pegasus_entailment': 0.9811601837476095, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6099290780141844, 'r1_recall': 0.6231884057971014, 'r1_f1': 0.6164874551971327, 'pegasus_entailment': 0.39599873423576354, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7682926829268293, 'r1_recall': 0.42, 'r1_f1': 0.5431034482758621, 'pegasus_entailment': 0.3210448037832975, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6455696202531646, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.5151515151515151, 'pegasus_entailment': 0.5012285029515624, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 16}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7945205479452054, 'r1_recall': 0.5420560747663551, 'r1_f1': 0.6444444444444444, 'pegasus_entailment': 0.9614620606104533, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.684931506849315, 'r1_recall': 0.5681818181818182, 'r1_f1': 0.6211180124223602, 'pegasus_entailment': 0.3117890707217157, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8875, 'r1_recall': 0.3697916666666667, 'r1_f1': 0.5220588235294118, 'pegasus_entailment': 0.4304343710343043, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25225225225225223, 'r1_recall': 0.4745762711864407, 'r1_f1': 0.32941176470588235, 'pegasus_entailment': 0.6622668355703354, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 18, 'pegasus_ari': 35, 'pegasus_smog': 23}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43661971830985913, 'r1_recall': 0.31313131313131315, 'r1_f1': 0.3647058823529412, 'pegasus_entailment': 0.21777700881163278, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8454545454545455, 'r1_recall': 0.31208053691275167, 'r1_f1': 0.4558823529411764, 'pegasus_entailment': 0.554664871096611, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6446280991735537, 'r1_recall': 0.484472049689441, 'r1_f1': 0.5531914893617021, 'pegasus_entailment': 0.6262162402272224, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5569620253164557, 'r1_recall': 0.5057471264367817, 'r1_f1': 0.5301204819277108, 'pegasus_entailment': 0.050799655728042126, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6521739130434783, 'r1_recall': 0.32967032967032966, 'r1_f1': 0.43795620437956206, 'pegasus_entailment': 0.6870786212384701, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.5343511450381679, 'pegasus_entailment': 0.6007582941092551, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.627906976744186, 'r1_recall': 0.25, 'r1_f1': 0.3576158940397351, 'pegasus_entailment': 0.6701377630233765, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.578125, 'r1_recall': 0.27205882352941174, 'r1_f1': 0.37, 'pegasus_entailment': 0.3163067203713581, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4583333333333333, 'r1_recall': 0.44, 'r1_f1': 0.4489795918367347, 'pegasus_entailment': 0.6612414494156837, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7096774193548387, 'r1_recall': 0.582010582010582, 'r1_f1': 0.6395348837209301, 'pegasus_entailment': 0.8597082644701004, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6632653061224489, 'r1_recall': 0.4744525547445255, 'r1_f1': 0.5531914893617021, 'pegasus_entailment': 0.115182538703084, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8533333333333334, 'r1_recall': 0.23880597014925373, 'r1_f1': 0.3731778425655977, 'pegasus_entailment': 0.5342993557453155, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6216216216216216, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.6133333333333333, 'pegasus_entailment': 0.5430801436305046, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6511627906976745, 'r1_recall': 0.24778761061946902, 'r1_f1': 0.358974358974359, 'pegasus_entailment': 0.7990411917368571, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4766355140186916, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.5257731958762886, 'pegasus_entailment': 0.6982113420963287, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6971428571428572, 'r1_recall': 0.6069651741293532, 'r1_f1': 0.648936170212766, 'pegasus_entailment': 0.6563763978580633, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3879310344827586, 'r1_recall': 0.4368932038834951, 'r1_f1': 0.410958904109589, 'pegasus_entailment': 0.1928290418931283, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5875, 'r1_recall': 0.4845360824742268, 'r1_f1': 0.5310734463276836, 'pegasus_entailment': 0.28477739600930363, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41414141414141414, 'r1_recall': 0.4880952380952381, 'r1_f1': 0.44808743169398907, 'pegasus_entailment': 0.13945735269226134, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6376811594202898, 'r1_recall': 0.3793103448275862, 'r1_f1': 0.4756756756756757, 'pegasus_entailment': 0.49522723505894345, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5591397849462365, 'r1_recall': 0.7536231884057971, 'r1_f1': 0.6419753086419753, 'pegasus_entailment': 0.25826055871584686, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35, 'r1_recall': 0.5147058823529411, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.020772657939232886, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3626373626373626, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.4852941176470589, 'pegasus_entailment': 0.604122057557106, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6403508771929824, 'r1_recall': 0.4397590361445783, 'r1_f1': 0.5214285714285714, 'pegasus_entailment': 0.19038020819425583, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 18, 'pegasus_ari': 36, 'pegasus_smog': 25}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6947368421052632, 'r1_recall': 0.4125, 'r1_f1': 0.5176470588235293, 'pegasus_entailment': 0.3180138866882771, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.631578947368421, 'r1_recall': 0.4675324675324675, 'r1_f1': 0.5373134328358209, 'pegasus_entailment': 0.34851029763619107, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.2054794520547945, 'r1_f1': 0.30927835051546393, 'pegasus_entailment': 0.11054343295594056, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 23, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.638095238095238, 'r1_recall': 0.5447154471544715, 'r1_f1': 0.587719298245614, 'pegasus_entailment': 0.6081371173262596, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5972222222222222, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.5733333333333334, 'pegasus_entailment': 0.4570208316047986, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.6, 'r1_f1': 0.576923076923077, 'pegasus_entailment': 0.7413633565107981, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 19, 'pegasus_ari': 35, 'pegasus_smog': 24}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6388888888888888, 'r1_recall': 0.19491525423728814, 'r1_f1': 0.2987012987012987, 'pegasus_entailment': 0.894045352935791, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 18, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5041322314049587, 'r1_recall': 0.5495495495495496, 'r1_f1': 0.5258620689655172, 'pegasus_entailment': 0.9390382915735245, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47619047619047616, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.48763107461854815, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47368421052631576, 'r1_recall': 0.34615384615384615, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.324445441365242, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28313253012048195, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.3916666666666667, 'pegasus_entailment': 0.7201154232025146, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.275, 'r1_recall': 0.6470588235294118, 'r1_f1': 0.3859649122807018, 'pegasus_entailment': 0.36115710546728225, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43119266055045874, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.5136612021857924, 'pegasus_entailment': 0.42472778578909737, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6024844720496895, 'r1_recall': 0.5480225988700564, 'r1_f1': 0.5739644970414202, 'pegasus_entailment': 0.42442747950553894, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.75, 'r1_recall': 0.42134831460674155, 'r1_f1': 0.539568345323741, 'pegasus_entailment': 0.47062842063605786, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44642857142857145, 'r1_recall': 0.6944444444444444, 'r1_f1': 0.5434782608695653, 'pegasus_entailment': 0.7175350273028016, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8411214953271028, 'r1_recall': 0.35856573705179284, 'r1_f1': 0.5027932960893855, 'pegasus_entailment': 0.38889935861031216, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3779527559055118, 'r1_recall': 0.75, 'r1_f1': 0.5026178010471204, 'pegasus_entailment': 0.4372549284307752, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6752136752136753, 'r1_recall': 0.6528925619834711, 'r1_f1': 0.6638655462184875, 'pegasus_entailment': 0.5254844288807362, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7317073170731707, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.641711229946524, 'pegasus_entailment': 0.4256434179842472, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5652173913043478, 'r1_recall': 0.5909090909090909, 'r1_f1': 0.5777777777777778, 'pegasus_entailment': 0.9505124489466349, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5135135135135135, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.5205479452054794, 'pegasus_entailment': 0.014486105103666583, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.675, 'r1_recall': 0.32142857142857145, 'r1_f1': 0.435483870967742, 'pegasus_entailment': 0.602344791094462, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.631578947368421, 'r1_recall': 0.4948453608247423, 'r1_f1': 0.5549132947976879, 'pegasus_entailment': 0.5945390667766333, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5098039215686274, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.5252525252525253, 'pegasus_entailment': 0.22580873547121882, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 13}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7, 'r1_recall': 0.49606299212598426, 'r1_f1': 0.5806451612903225, 'pegasus_entailment': 0.8900693535804749, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4420289855072464, 'r1_recall': 0.5754716981132075, 'r1_f1': 0.5, 'pegasus_entailment': 0.5563710439833812, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6438356164383562, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.5562130177514792, 'pegasus_entailment': 0.5339444611066332, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5495495495495496, 'r1_recall': 0.5304347826086957, 'r1_f1': 0.5398230088495576, 'pegasus_entailment': 0.287658934306819, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6818181818181818, 'r1_recall': 0.4411764705882353, 'r1_f1': 0.5357142857142857, 'pegasus_entailment': 0.2811031835299218, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5630252100840336, 'r1_recall': 0.4036144578313253, 'r1_f1': 0.47017543859649125, 'pegasus_entailment': 0.43587724468670785, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43, 'r1_recall': 0.6323529411764706, 'r1_f1': 0.511904761904762, 'pegasus_entailment': 0.28296943604946134, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.509090909090909, 'r1_recall': 0.42424242424242425, 'r1_f1': 0.46280991735537186, 'pegasus_entailment': 0.5353816617280245, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 20}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.9259259259259259, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.5535055350553506, 'pegasus_entailment': 0.6907937129338583, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2894736842105263, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.3548387096774194, 'pegasus_entailment': 0.5304952128790319, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6818181818181818, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.5960264900662252, 'pegasus_entailment': 0.435140423476696, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44285714285714284, 'r1_recall': 0.484375, 'r1_f1': 0.4626865671641791, 'pegasus_entailment': 0.3599080489948392, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7045454545454546, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.6458333333333334, 'pegasus_entailment': 0.8204518556594849, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5089285714285714, 'r1_recall': 0.6627906976744186, 'r1_f1': 0.5757575757575757, 'pegasus_entailment': 0.2142426606733352, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6935483870967742, 'r1_recall': 0.6417910447761194, 'r1_f1': 0.6666666666666666, 'pegasus_entailment': 0.4379569838444392, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5584415584415584, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.5548387096774194, 'pegasus_entailment': 0.48704378062393516, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.9285714285714286, 'r1_recall': 0.5048543689320388, 'r1_f1': 0.6540880503144654, 'pegasus_entailment': 0.9514749050140381, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3942307692307692, 'r1_recall': 0.6307692307692307, 'r1_f1': 0.485207100591716, 'pegasus_entailment': 0.9346030354499817, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5529411764705883, 'r1_recall': 0.5402298850574713, 'r1_f1': 0.5465116279069768, 'pegasus_entailment': 0.1555082550039515, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5161290322580645, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.5925925925925926, 'pegasus_entailment': 0.19918043399229646, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37272727272727274, 'r1_recall': 0.47126436781609193, 'r1_f1': 0.416243654822335, 'pegasus_entailment': 0.025691937480587512, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5217391304347826, 'r1_recall': 0.3076923076923077, 'r1_f1': 0.3870967741935484, 'pegasus_entailment': 0.7383507490158081, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32989690721649484, 'r1_recall': 0.7111111111111111, 'r1_f1': 0.45070422535211263, 'pegasus_entailment': 0.7822010308504105, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7912087912087912, 'r1_recall': 0.34615384615384615, 'r1_f1': 0.4816053511705685, 'pegasus_entailment': 0.5755564719438553, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5571428571428572, 'r1_f1': 0.5270270270270271, 'pegasus_entailment': 0.5006761844269931, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.652542372881356, 'r1_recall': 0.4010416666666667, 'r1_f1': 0.4967741935483871, 'pegasus_entailment': 0.49457064643502235, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 26}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5102040816326531, 'r1_recall': 0.373134328358209, 'r1_f1': 0.4310344827586207, 'pegasus_entailment': 0.617621099948883, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43902439024390244, 'r1_recall': 0.7397260273972602, 'r1_f1': 0.5510204081632653, 'pegasus_entailment': 0.4546136357676005, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5662650602409639, 'r1_recall': 0.4017094017094017, 'r1_f1': 0.47000000000000003, 'pegasus_entailment': 0.48831429627413553, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2872340425531915, 'r1_recall': 0.27835051546391754, 'r1_f1': 0.28272251308900526, 'pegasus_entailment': 0.0005805986935835487, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 14}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7176470588235294, 'r1_recall': 0.3446327683615819, 'r1_f1': 0.4656488549618321, 'pegasus_entailment': 0.5262224525213242, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4945054945054945, 'r1_recall': 0.4639175257731959, 'r1_f1': 0.4787234042553192, 'pegasus_entailment': 0.6347532837341229, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5514018691588785, 'r1_recall': 0.46825396825396826, 'r1_f1': 0.5064377682403433, 'pegasus_entailment': 0.7043420188128948, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3619047619047619, 'r1_recall': 0.5846153846153846, 'r1_f1': 0.4470588235294118, 'pegasus_entailment': 0.5252441428601742, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5252525252525253, 'r1_recall': 0.4642857142857143, 'r1_f1': 0.49289099526066354, 'pegasus_entailment': 0.7093105858657509, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3902439024390244, 'r1_recall': 0.5245901639344263, 'r1_f1': 0.4475524475524476, 'pegasus_entailment': 0.006841100206656847, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5588235294117647, 'r1_recall': 0.40425531914893614, 'r1_f1': 0.4691358024691358, 'pegasus_entailment': 0.2356725912541151, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5736434108527132, 'r1_recall': 0.6434782608695652, 'r1_f1': 0.6065573770491803, 'pegasus_entailment': 0.5820010732859373, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45384615384615384, 'r1_recall': 0.5267857142857143, 'r1_f1': 0.48760330578512395, 'pegasus_entailment': 0.9632653743028641, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4566929133858268, 'r1_recall': 0.725, 'r1_f1': 0.5603864734299516, 'pegasus_entailment': 0.8017744362354279, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.3875968992248062, 'r1_f1': 0.4901960784313725, 'pegasus_entailment': 0.4897066717036068, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.5381165919282511, 'pegasus_entailment': 0.4143504405704637, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5891472868217055, 'r1_recall': 0.475, 'r1_f1': 0.5259515570934257, 'pegasus_entailment': 0.887201209863027, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4606741573033708, 'r1_recall': 0.5466666666666666, 'r1_f1': 0.5, 'pegasus_entailment': 0.2017803080379963, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 15, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44, 'r1_recall': 0.55, 'r1_f1': 0.48888888888888893, 'pegasus_entailment': 0.29920753557235, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7962962962962963, 'r1_recall': 0.6231884057971014, 'r1_f1': 0.6991869918699186, 'pegasus_entailment': 0.7021621316671371, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6578947368421053, 'r1_recall': 0.5639097744360902, 'r1_f1': 0.6072874493927126, 'pegasus_entailment': 0.3579535230528563, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.550561797752809, 'r1_recall': 0.620253164556962, 'r1_f1': 0.5833333333333334, 'pegasus_entailment': 0.2737341605592519, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5490196078431373, 'r1_recall': 0.6292134831460674, 'r1_f1': 0.5863874345549738, 'pegasus_entailment': 0.32439310926323134, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.671875, 'r1_recall': 0.33076923076923076, 'r1_f1': 0.44329896907216493, 'pegasus_entailment': 0.5969335613772273, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7931034482758621, 'r1_recall': 0.38764044943820225, 'r1_f1': 0.5207547169811321, 'pegasus_entailment': 0.5260416748235002, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8854166666666666, 'r1_recall': 0.48295454545454547, 'r1_f1': 0.625, 'pegasus_entailment': 0.6347041474655271, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.580952380952381, 'r1_recall': 0.4552238805970149, 'r1_f1': 0.5104602510460251, 'pegasus_entailment': 0.5528987122452236, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41304347826086957, 'r1_recall': 0.6063829787234043, 'r1_f1': 0.49137931034482757, 'pegasus_entailment': 0.18965284483662495, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6774193548387096, 'r1_recall': 0.49606299212598426, 'r1_f1': 0.5727272727272728, 'pegasus_entailment': 0.725162866152823, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7066666666666667, 'r1_recall': 0.6022727272727273, 'r1_f1': 0.6503067484662576, 'pegasus_entailment': 0.850172221660614, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5185185185185185, 'r1_recall': 0.48695652173913045, 'r1_f1': 0.5022421524663677, 'pegasus_entailment': 0.5767028058568636, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4742268041237113, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.5317919075144509, 'pegasus_entailment': 0.02144444799341727, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25, 'r1_recall': 0.4883720930232558, 'r1_f1': 0.3307086614173228, 'pegasus_entailment': 0.799594558775425, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.6964285714285714, 'r1_f1': 0.6446280991735538, 'pegasus_entailment': 0.7132963877666043, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6774193548387096, 'r1_recall': 0.6412213740458015, 'r1_f1': 0.6588235294117646, 'pegasus_entailment': 0.8474135249853134, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53125, 'r1_recall': 0.6375, 'r1_f1': 0.5795454545454545, 'pegasus_entailment': 0.20344213396310806, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5686274509803921, 'r1_recall': 0.49572649572649574, 'r1_f1': 0.5296803652968037, 'pegasus_entailment': 0.7655135989189148, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 23}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48148148148148145, 'r1_recall': 0.6724137931034483, 'r1_f1': 0.5611510791366906, 'pegasus_entailment': 0.9657464981079101, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34375, 'r1_recall': 0.7457627118644068, 'r1_f1': 0.4705882352941176, 'pegasus_entailment': 0.4929047065787017, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.77, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.532871972318339, 'pegasus_entailment': 0.3773427919174234, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7307692307692307, 'r1_recall': 0.47107438016528924, 'r1_f1': 0.5728643216080401, 'pegasus_entailment': 0.5818921029567719, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6511627906976745, 'r1_recall': 0.5419354838709678, 'r1_f1': 0.591549295774648, 'pegasus_entailment': 0.5777065825648606, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6442307692307693, 'r1_recall': 0.4110429447852761, 'r1_f1': 0.50187265917603, 'pegasus_entailment': 0.40919795017689464, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6268656716417911, 'r1_recall': 0.4158415841584158, 'r1_f1': 0.5, 'pegasus_entailment': 0.8048814932505289, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6293103448275862, 'r1_recall': 0.6033057851239669, 'r1_f1': 0.6160337552742615, 'pegasus_entailment': 0.6233444482088089, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.5376344086021505, 'r1_f1': 0.4926108374384236, 'pegasus_entailment': 0.05360198058770038, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.652542372881356, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.6135458167330677, 'pegasus_entailment': 0.5840281501412392, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6474358974358975, 'r1_recall': 0.5459459459459459, 'r1_f1': 0.5923753665689149, 'pegasus_entailment': 0.612423574924469, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5116279069767442, 'r1_recall': 0.3793103448275862, 'r1_f1': 0.43564356435643564, 'pegasus_entailment': 0.28054939170833676, 'pegasus_flesch_kincaid': 9, 'pegasus_coleman_liau': 13, 'pegasus_ari': 10, 'pegasus_smog': 13}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4435483870967742, 'r1_recall': 0.625, 'r1_f1': 0.5188679245283019, 'pegasus_entailment': 0.4855717221895854, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 23}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46464646464646464, 'r1_recall': 0.4946236559139785, 'r1_f1': 0.47916666666666663, 'pegasus_entailment': 0.7202407022317251, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5043478260869565, 'r1_recall': 0.5132743362831859, 'r1_f1': 0.5087719298245613, 'pegasus_entailment': 0.38198481537401674, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6329113924050633, 'r1_recall': 0.625, 'r1_f1': 0.6289308176100629, 'pegasus_entailment': 0.44419862143695354, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.5833333333333334, 'pegasus_entailment': 0.3856965935168167, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7920792079207921, 'r1_recall': 0.3827751196172249, 'r1_f1': 0.5161290322580645, 'pegasus_entailment': 0.9681071639060974, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 19, 'pegasus_ari': 33, 'pegasus_smog': 26}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7413793103448276, 'r1_recall': 0.47513812154696133, 'r1_f1': 0.579124579124579, 'pegasus_entailment': 0.7001461517065763, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4189189189189189, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.46616541353383456, 'pegasus_entailment': 0.5384326167404652, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7971014492753623, 'r1_recall': 0.3395061728395062, 'r1_f1': 0.4761904761904762, 'pegasus_entailment': 0.43049867264926434, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.375886524822695, 'r1_recall': 0.6463414634146342, 'r1_f1': 0.4753363228699551, 'pegasus_entailment': 0.8130142241716385, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5145631067961165, 'r1_recall': 0.5520833333333334, 'r1_f1': 0.5326633165829147, 'pegasus_entailment': 0.4409090995322913, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.746268656716418, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.6289308176100628, 'pegasus_entailment': 0.4352599476114847, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7068965517241379, 'r1_recall': 0.422680412371134, 'r1_f1': 0.529032258064516, 'pegasus_entailment': 0.42314238101243973, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5786163522012578, 'r1_recall': 0.5542168674698795, 'r1_f1': 0.5661538461538461, 'pegasus_entailment': 0.3734171912074089, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3524590163934426, 'r1_recall': 0.7288135593220338, 'r1_f1': 0.47513812154696133, 'pegasus_entailment': 0.10246949456632137, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6615384615384615, 'r1_recall': 0.49710982658959535, 'r1_f1': 0.5676567656765676, 'pegasus_entailment': 0.5550262483302504, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36363636363636365, 'r1_recall': 0.49382716049382713, 'r1_f1': 0.418848167539267, 'pegasus_entailment': 0.20356799320628247, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.37583892617449666, 'r1_f1': 0.46666666666666673, 'pegasus_entailment': 0.47941884491592646, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.463768115942029, 'r1_recall': 0.6881720430107527, 'r1_f1': 0.5541125541125541, 'pegasus_entailment': 0.1678030776383821, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.631578947368421, 'r1_recall': 0.37267080745341613, 'r1_f1': 0.46874999999999994, 'pegasus_entailment': 0.46970735024660826, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.20930232558139536, 'r1_recall': 0.23684210526315788, 'r1_f1': 0.2222222222222222, 'pegasus_entailment': 0.7681211233139038, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 31, 'pegasus_smog': 25}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5526315789473685, 'r1_recall': 0.7777777777777778, 'r1_f1': 0.6461538461538462, 'pegasus_entailment': 0.33698047725483776, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.49382716049382713, 'pegasus_entailment': 0.4743861917522736, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5779816513761468, 'r1_recall': 0.38650306748466257, 'r1_f1': 0.463235294117647, 'pegasus_entailment': 0.35307550492386025, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6565656565656566, 'r1_recall': 0.5963302752293578, 'r1_f1': 0.625, 'pegasus_entailment': 0.2895719207444927, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6788990825688074, 'r1_recall': 0.42045454545454547, 'r1_f1': 0.5192982456140351, 'pegasus_entailment': 0.6654799059033394, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7307692307692307, 'r1_recall': 0.38, 'r1_f1': 0.5, 'pegasus_entailment': 0.5129775378853083, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.5236363636363637, 'pegasus_entailment': 0.5439522240000466, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6355140186915887, 'r1_recall': 0.4563758389261745, 'r1_f1': 0.5312500000000001, 'pegasus_entailment': 0.817920446395874, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 14}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47572815533980584, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5051546391752576, 'pegasus_entailment': 0.6750752491255602, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3902439024390244, 'r1_recall': 0.6233766233766234, 'r1_f1': 0.4799999999999999, 'pegasus_entailment': 0.6136297757426897, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5753424657534246, 'r1_f1': 0.5350318471337578, 'pegasus_entailment': 0.2615992260107305, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8283582089552238, 'r1_recall': 0.3016304347826087, 'r1_f1': 0.44223107569721115, 'pegasus_entailment': 0.7848821779092153, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4411764705882353, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.4878048780487804, 'pegasus_entailment': 0.5848982608877122, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46616541353383456, 'r1_recall': 0.5, 'r1_f1': 0.48249027237354086, 'pegasus_entailment': 0.5858209684491158, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5161290322580645, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5245901639344263, 'pegasus_entailment': 0.37224212698638437, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.712, 'r1_recall': 0.37872340425531914, 'r1_f1': 0.4944444444444444, 'pegasus_entailment': 0.5476447565015405, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5384615384615384, 'r1_recall': 0.4605263157894737, 'r1_f1': 0.49645390070921985, 'pegasus_entailment': 0.3292924801353365, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5376344086021505, 'r1_recall': 0.5813953488372093, 'r1_f1': 0.5586592178770949, 'pegasus_entailment': 0.6451246105134487, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40816326530612246, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.4624277456647399, 'pegasus_entailment': 0.33054607221856713, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.6, 'r1_f1': 0.5714285714285713, 'pegasus_entailment': 0.980827271938324, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.75, 'r1_recall': 0.43902439024390244, 'r1_f1': 0.5538461538461539, 'pegasus_entailment': 0.6932511751850446, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7603305785123967, 'r1_recall': 0.3205574912891986, 'r1_f1': 0.4509803921568627, 'pegasus_entailment': 0.37868129027386505, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8285714285714286, 'r1_recall': 0.3240223463687151, 'r1_f1': 0.46586345381526106, 'pegasus_entailment': 0.6217206075477103, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7227722772277227, 'r1_recall': 0.6403508771929824, 'r1_f1': 0.6790697674418604, 'pegasus_entailment': 0.6891281423158944, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7205882352941176, 'r1_recall': 0.3769230769230769, 'r1_f1': 0.49494949494949486, 'pegasus_entailment': 0.5500873321667313, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43859649122807015, 'r1_recall': 0.4807692307692308, 'r1_f1': 0.4587155963302752, 'pegasus_entailment': 0.5025365278124809, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5053763440860215, 'r1_recall': 0.5595238095238095, 'r1_f1': 0.5310734463276836, 'pegasus_entailment': 0.2519184873284151, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7474747474747475, 'r1_recall': 0.4567901234567901, 'r1_f1': 0.5670498084291188, 'pegasus_entailment': 0.7673285827040672, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5362318840579711, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.5068493150684933, 'pegasus_entailment': 0.26276704523479566, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8255813953488372, 'r1_recall': 0.4930555555555556, 'r1_f1': 0.6173913043478262, 'pegasus_entailment': 0.1721124886535108, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6447368421052632, 'r1_recall': 0.6533333333333333, 'r1_f1': 0.6490066225165563, 'pegasus_entailment': 0.48598835337907076, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5352112676056338, 'r1_recall': 0.3140495867768595, 'r1_f1': 0.3958333333333333, 'pegasus_entailment': 0.795929471651713, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8382352941176471, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.6368715083798883, 'pegasus_entailment': 0.3392493070969067, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 22, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5306122448979592, 'r1_recall': 0.4785276073619632, 'r1_f1': 0.503225806451613, 'pegasus_entailment': 0.3982768716911475, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4962962962962963, 'r1_recall': 0.3806818181818182, 'r1_f1': 0.4308681672025723, 'pegasus_entailment': 0.48916769089798134, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6818181818181818, 'r1_recall': 0.75, 'r1_f1': 0.7142857142857143, 'pegasus_entailment': 0.44986320519819856, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4189189189189189, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.46268656716417905, 'pegasus_entailment': 0.5097693314310163, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 20}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3181818181818182, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4117647058823529, 'pegasus_entailment': 0.243674186617136, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.423728813559322, 'r1_recall': 0.5102040816326531, 'r1_f1': 0.46296296296296297, 'pegasus_entailment': 0.16534906178712844, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6170212765957447, 'r1_recall': 0.6692307692307692, 'r1_f1': 0.6420664206642066, 'pegasus_entailment': 0.5695380562101491, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34444444444444444, 'r1_recall': 0.6739130434782609, 'r1_f1': 0.45588235294117646, 'pegasus_entailment': 0.281889091944322, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5363636363636364, 'r1_recall': 0.5175438596491229, 'r1_f1': 0.5267857142857143, 'pegasus_entailment': 0.6375877883595725, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5433070866141733, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.5798319327731093, 'pegasus_entailment': 0.23082588923474154, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.743421052631579, 'r1_recall': 0.5159817351598174, 'r1_f1': 0.6091644204851753, 'pegasus_entailment': 0.6555523946881294, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5603448275862069, 'r1_recall': 0.7926829268292683, 'r1_f1': 0.6565656565656566, 'pegasus_entailment': 0.262993637326872, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4224137931034483, 'r1_recall': 0.5568181818181818, 'r1_f1': 0.48039215686274506, 'pegasus_entailment': 0.5990305364131927, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5673076923076923, 'r1_recall': 0.5841584158415841, 'r1_f1': 0.575609756097561, 'pegasus_entailment': 0.48912263922393323, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5876288659793815, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.5560975609756098, 'pegasus_entailment': 0.6370003238320351, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30392156862745096, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.41333333333333333, 'pegasus_entailment': 0.22253310400992632, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7027027027027027, 'r1_recall': 0.26262626262626265, 'r1_f1': 0.3823529411764706, 'pegasus_entailment': 0.602169968187809, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 19, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5769230769230769, 'r1_recall': 0.47468354430379744, 'r1_f1': 0.5208333333333333, 'pegasus_entailment': 0.6719934217631817, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6173913043478261, 'r1_recall': 0.44936708860759494, 'r1_f1': 0.5201465201465202, 'pegasus_entailment': 0.2733655528863892, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5304347826086957, 'r1_recall': 0.3160621761658031, 'r1_f1': 0.3961038961038961, 'pegasus_entailment': 0.7078131586313248, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7281553398058253, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.7211538461538461, 'pegasus_entailment': 0.4994008175563067, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 21, 'pegasus_ari': 35, 'pegasus_smog': 25}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5681818181818182, 'r1_recall': 0.4, 'r1_f1': 0.4694835680751174, 'pegasus_entailment': 0.5878954206903776, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35294117647058826, 'r1_recall': 0.23076923076923078, 'r1_f1': 0.2790697674418605, 'pegasus_entailment': 0.8728303710619608, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 23, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4189189189189189, 'r1_recall': 0.5081967213114754, 'r1_f1': 0.45925925925925926, 'pegasus_entailment': 0.18777691821257272, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3069306930693069, 'r1_recall': 0.5, 'r1_f1': 0.38036809815950917, 'pegasus_entailment': 0.20025359685532748, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43636363636363634, 'r1_recall': 0.4067796610169492, 'r1_f1': 0.4210526315789474, 'pegasus_entailment': 0.5251989712317785, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5230769230769231, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.5573770491803279, 'pegasus_entailment': 0.754004979133606, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.47619047619047616, 'pegasus_entailment': 0.1242806821440657, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2524271844660194, 'r1_recall': 0.65, 'r1_f1': 0.3636363636363636, 'pegasus_entailment': 0.4592316187918186, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6974789915966386, 'r1_recall': 0.4797687861271676, 'r1_f1': 0.5684931506849316, 'pegasus_entailment': 0.7932569533586502, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5888888888888889, 'r1_recall': 0.6625, 'r1_f1': 0.6235294117647059, 'pegasus_entailment': 0.05460089935271147, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7473684210526316, 'r1_recall': 0.398876404494382, 'r1_f1': 0.5201465201465201, 'pegasus_entailment': 0.216259041801095, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7777777777777778, 'r1_recall': 0.30434782608695654, 'r1_f1': 0.43750000000000006, 'pegasus_entailment': 0.751456211010615, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6352941176470588, 'r1_recall': 0.40298507462686567, 'r1_f1': 0.4931506849315068, 'pegasus_entailment': 0.46946863387711346, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7244897959183674, 'r1_recall': 0.29218106995884774, 'r1_f1': 0.4164222873900293, 'pegasus_entailment': 0.7199756443500519, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3902439024390244, 'r1_recall': 0.3902439024390244, 'r1_f1': 0.3902439024390244, 'pegasus_entailment': 0.898977980017662, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7246376811594203, 'r1_recall': 0.32894736842105265, 'r1_f1': 0.4524886877828054, 'pegasus_entailment': 0.5160205413897833, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3977272727272727, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.4375, 'pegasus_entailment': 0.5160830318927765, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8018018018018018, 'r1_recall': 0.3991031390134529, 'r1_f1': 0.5329341317365269, 'pegasus_entailment': 0.08134023026408006, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42424242424242425, 'r1_recall': 0.24778761061946902, 'r1_f1': 0.3128491620111732, 'pegasus_entailment': 0.24558495730161667, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35714285714285715, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.43103448275862066, 'pegasus_entailment': 0.8656584322452545, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7340425531914894, 'r1_recall': 0.3812154696132597, 'r1_f1': 0.5018181818181818, 'pegasus_entailment': 0.40783558785915375, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7596153846153846, 'r1_recall': 0.4463276836158192, 'r1_f1': 0.5622775800711743, 'pegasus_entailment': 0.6763238708178202, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.625, 'r1_f1': 0.6122448979591836, 'pegasus_entailment': 0.7927062118736407, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6166666666666667, 'r1_recall': 0.5103448275862069, 'r1_f1': 0.5584905660377358, 'pegasus_entailment': 0.43855541412319454, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18072289156626506, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.2702702702702703, 'pegasus_entailment': 0.00815879578779762, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.3291139240506329, 'pegasus_entailment': 0.33787208423018456, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5903614457831325, 'r1_recall': 0.4117647058823529, 'r1_f1': 0.4851485148514851, 'pegasus_entailment': 0.2902673247808707, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6065573770491803, 'r1_recall': 0.5211267605633803, 'r1_f1': 0.5606060606060606, 'pegasus_entailment': 0.8487038016319275, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38461538461538464, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.4794520547945205, 'pegasus_entailment': 0.08801694173598662, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4647887323943662, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.43421052631578944, 'pegasus_entailment': 0.7160237232844034, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7142857142857143, 'r1_recall': 0.6172839506172839, 'r1_f1': 0.662251655629139, 'pegasus_entailment': 0.48573107889387757, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6197183098591549, 'r1_recall': 0.5301204819277109, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.7194520325574558, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6122448979591837, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.5741626794258374, 'pegasus_entailment': 0.20429670034354785, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7521367521367521, 'r1_recall': 0.2619047619047619, 'r1_f1': 0.3885209713024283, 'pegasus_entailment': 0.670480215549469, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6987951807228916, 'r1_recall': 0.26126126126126126, 'r1_f1': 0.380327868852459, 'pegasus_entailment': 0.4263632893562317, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5964912280701754, 'r1_recall': 0.4358974358974359, 'r1_f1': 0.5037037037037038, 'pegasus_entailment': 0.9336917996406555, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 12}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7195121951219512, 'r1_recall': 0.5673076923076923, 'r1_f1': 0.6344086021505376, 'pegasus_entailment': 0.40403237864375113, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3018867924528302, 'r1_recall': 0.4383561643835616, 'r1_f1': 0.35754189944134085, 'pegasus_entailment': 0.6582596702501178, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5416666666666666, 'r1_recall': 0.6, 'r1_f1': 0.5693430656934306, 'pegasus_entailment': 0.006132937269285321, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 16}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6049382716049383, 'r1_recall': 0.6805555555555556, 'r1_f1': 0.6405228758169934, 'pegasus_entailment': 0.5643481274601072, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5578947368421052, 'r1_recall': 0.654320987654321, 'r1_f1': 0.6022727272727273, 'pegasus_entailment': 0.34203640022315085, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5189873417721519, 'r1_recall': 0.5394736842105263, 'r1_f1': 0.5290322580645163, 'pegasus_entailment': 0.1465138370792071, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5909090909090909, 'r1_recall': 0.4642857142857143, 'r1_f1': 0.52, 'pegasus_entailment': 0.1258727590320632, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7604166666666666, 'r1_recall': 0.46496815286624205, 'r1_f1': 0.5770750988142292, 'pegasus_entailment': 0.30608674173709005, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7789473684210526, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.6192468619246861, 'pegasus_entailment': 0.49823063164949416, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5051546391752577, 'r1_recall': 0.5212765957446809, 'r1_f1': 0.5130890052356021, 'pegasus_entailment': 0.4960579574108124, 'pegasus_flesch_kincaid': 45, 'pegasus_coleman_liau': 18, 'pegasus_ari': 55, 'pegasus_smog': 28}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6727272727272727, 'r1_recall': 0.581151832460733, 'r1_f1': 0.6235955056179774, 'pegasus_entailment': 0.4022718380826215, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.6530612244897959, 'r1_f1': 0.547008547008547, 'pegasus_entailment': 0.7487787008285522, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4588235294117647, 'r1_recall': 0.46987951807228917, 'r1_f1': 0.4642857142857143, 'pegasus_entailment': 0.8259239494800568, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7066666666666667, 'r1_recall': 0.6794871794871795, 'r1_f1': 0.6928104575163399, 'pegasus_entailment': 0.056996120198164135, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 11}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.6790123456790124, 'r1_f1': 0.6432748538011697, 'pegasus_entailment': 0.2773915040306747, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6990291262135923, 'r1_recall': 0.5255474452554745, 'r1_f1': 0.6000000000000001, 'pegasus_entailment': 0.6405126377940178, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25806451612903225, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.3503649635036496, 'pegasus_entailment': 0.23564434486130872, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43636363636363634, 'r1_recall': 0.4067796610169492, 'r1_f1': 0.4210526315789474, 'pegasus_entailment': 0.8837871849536896, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.631578947368421, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.5806451612903225, 'pegasus_entailment': 0.2944067592965439, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.556390977443609, 'r1_recall': 0.47435897435897434, 'r1_f1': 0.5121107266435986, 'pegasus_entailment': 0.2006383672511826, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4260869565217391, 'r1_recall': 0.7538461538461538, 'r1_f1': 0.5444444444444445, 'pegasus_entailment': 0.7904357016086578, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5789473684210527, 'r1_recall': 0.375, 'r1_f1': 0.45517241379310347, 'pegasus_entailment': 0.6187712773680687, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.2246352918446064, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4444444444444444, 'r1_recall': 0.6233766233766234, 'r1_f1': 0.518918918918919, 'pegasus_entailment': 0.09650830049067735, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4247787610619469, 'r1_recall': 0.6, 'r1_f1': 0.4974093264248705, 'pegasus_entailment': 0.4580438952893019, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.5, 'pegasus_entailment': 0.5660878885537386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 19}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4482758620689655, 'r1_recall': 0.5131578947368421, 'r1_f1': 0.47852760736196326, 'pegasus_entailment': 0.38575074076652527, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4336283185840708, 'r1_recall': 0.5764705882352941, 'r1_f1': 0.4949494949494949, 'pegasus_entailment': 0.6352870106697083, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5942028985507246, 'r1_recall': 0.6259541984732825, 'r1_f1': 0.6096654275092938, 'pegasus_entailment': 0.6841803242762884, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 32, 'pegasus_smog': 22}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4125, 'r1_recall': 0.3113207547169811, 'r1_f1': 0.3548387096774193, 'pegasus_entailment': 0.26143373918603174, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7604166666666666, 'r1_recall': 0.3989071038251366, 'r1_f1': 0.5232974910394265, 'pegasus_entailment': 0.5598664935678244, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49382716049382713, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5095541401273886, 'pegasus_entailment': 0.29495545228322345, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6097560975609756, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.5747126436781609, 'pegasus_entailment': 0.5878821043588687, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7538461538461538, 'r1_recall': 0.4537037037037037, 'r1_f1': 0.5664739884393063, 'pegasus_entailment': 0.6170497536659241, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5046728971962616, 'r1_recall': 0.5346534653465347, 'r1_f1': 0.5192307692307693, 'pegasus_entailment': 0.15290266481461004, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5727272727272728, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.6057692307692308, 'pegasus_entailment': 0.094654880464077, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5373134328358209, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.5255474452554744, 'pegasus_entailment': 0.24073971901088953, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8113207547169812, 'r1_recall': 0.6466165413533834, 'r1_f1': 0.7196652719665273, 'pegasus_entailment': 0.5281308628618717, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5913978494623656, 'r1_recall': 0.6111111111111112, 'r1_f1': 0.6010928961748635, 'pegasus_entailment': 0.32750848432381946, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 13}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7362637362637363, 'r1_recall': 0.5826086956521739, 'r1_f1': 0.6504854368932038, 'pegasus_entailment': 0.6616340180238088, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 24}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.5194805194805195, 'pegasus_entailment': 0.4427349840601285, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.9210526315789473, 'r1_recall': 0.5072463768115942, 'r1_f1': 0.6542056074766355, 'pegasus_entailment': 0.9252457320690155, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.176, 'r1_recall': 0.44, 'r1_f1': 0.2514285714285714, 'pegasus_entailment': 0.5020774362928933, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23369565217391305, 'r1_recall': 0.7678571428571429, 'r1_f1': 0.3583333333333334, 'pegasus_entailment': 0.13103171344846487, 'pegasus_flesch_kincaid': 32, 'pegasus_coleman_liau': 20, 'pegasus_ari': 39, 'pegasus_smog': 26}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23076923076923078, 'r1_recall': 0.3191489361702128, 'r1_f1': 0.2678571428571429, 'pegasus_entailment': 0.6236653923988342, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48148148148148145, 'r1_recall': 0.36619718309859156, 'r1_f1': 0.416, 'pegasus_entailment': 0.395742295930783, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7093023255813954, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.4535315985130111, 'pegasus_entailment': 0.6374862889448801, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 14, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5909090909090909, 'r1_recall': 0.5693430656934306, 'r1_f1': 0.5799256505576208, 'pegasus_entailment': 0.5371318521598974, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7391304347826086, 'r1_recall': 0.5604395604395604, 'r1_f1': 0.6375, 'pegasus_entailment': 0.8968136608600616, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5688073394495413, 'r1_recall': 0.46616541353383456, 'r1_f1': 0.5123966942148761, 'pegasus_entailment': 0.8533709347248077, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.780952380952381, 'r1_recall': 0.5, 'r1_f1': 0.6096654275092938, 'pegasus_entailment': 0.23764581009745597, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6724137931034483, 'r1_recall': 0.582089552238806, 'r1_f1': 0.624, 'pegasus_entailment': 0.5350146691004435, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4423076923076923, 'r1_recall': 0.46, 'r1_f1': 0.4509803921568628, 'pegasus_entailment': 0.6031006034463644, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.5625, 'r1_f1': 0.5, 'pegasus_entailment': 0.4810639382340014, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5862068965517241, 'r1_recall': 0.4146341463414634, 'r1_f1': 0.48571428571428565, 'pegasus_entailment': 0.4998279809951782, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22340425531914893, 'r1_recall': 0.4375, 'r1_f1': 0.295774647887324, 'pegasus_entailment': 0.0941219142638147, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.391304347826087, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.4645161290322581, 'pegasus_entailment': 0.3402019952889532, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3181818181818182, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.42000000000000004, 'pegasus_entailment': 0.12679536803625524, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5256410256410257, 'r1_recall': 0.5394736842105263, 'r1_f1': 0.5324675324675324, 'pegasus_entailment': 0.5190983125551915, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7786885245901639, 'r1_recall': 0.5163043478260869, 'r1_f1': 0.6209150326797385, 'pegasus_entailment': 0.5905992612242699, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47761194029850745, 'r1_recall': 0.47761194029850745, 'r1_f1': 0.47761194029850745, 'pegasus_entailment': 0.4521008829275767, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7087378640776699, 'r1_recall': 0.43452380952380953, 'r1_f1': 0.5387453874538746, 'pegasus_entailment': 0.4984510079026222, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.552, 'r1_recall': 0.5227272727272727, 'r1_f1': 0.5369649805447471, 'pegasus_entailment': 0.7675888737042745, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8271604938271605, 'r1_recall': 0.4240506329113924, 'r1_f1': 0.5606694560669456, 'pegasus_entailment': 0.5261592318614324, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 22}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7692307692307693, 'r1_recall': 0.2702702702702703, 'r1_f1': 0.4, 'pegasus_entailment': 0.8665445446968079, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3359375, 'r1_recall': 0.7818181818181819, 'r1_f1': 0.46994535519125685, 'pegasus_entailment': 0.5805074632167816, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7128712871287128, 'r1_recall': 0.36548223350253806, 'r1_f1': 0.4832214765100671, 'pegasus_entailment': 0.5660738249619802, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6086956521739131, 'r1_recall': 0.23333333333333334, 'r1_f1': 0.3373493975903614, 'pegasus_entailment': 0.45539774000644684, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6542056074766355, 'r1_recall': 0.5691056910569106, 'r1_f1': 0.608695652173913, 'pegasus_entailment': 0.8143491347630819, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7272727272727273, 'r1_recall': 0.6095238095238096, 'r1_f1': 0.6632124352331606, 'pegasus_entailment': 0.4795482226036256, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7647058823529411, 'r1_recall': 0.4961832061068702, 'r1_f1': 0.6018518518518519, 'pegasus_entailment': 0.39050119668245314, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3770491803278688, 'r1_recall': 0.6865671641791045, 'r1_f1': 0.48677248677248675, 'pegasus_entailment': 0.2327062984307607, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4025974025974026, 'r1_recall': 0.543859649122807, 'r1_f1': 0.4626865671641791, 'pegasus_entailment': 0.35773088596761227, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30578512396694213, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.41573033707865165, 'pegasus_entailment': 0.1199556349311024, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.782051282051282, 'r1_recall': 0.4765625, 'r1_f1': 0.5922330097087379, 'pegasus_entailment': 0.6229246333241463, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7433628318584071, 'r1_recall': 0.47191011235955055, 'r1_f1': 0.5773195876288659, 'pegasus_entailment': 0.6796540468931198, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6771653543307087, 'r1_recall': 0.5276073619631901, 'r1_f1': 0.593103448275862, 'pegasus_entailment': 0.78120356798172, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.631578947368421, 'r1_recall': 0.37305699481865284, 'r1_f1': 0.46905537459283386, 'pegasus_entailment': 0.6570470677688718, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5604395604395604, 'r1_recall': 0.504950495049505, 'r1_f1': 0.53125, 'pegasus_entailment': 0.4491119459271431, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4406779661016949, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.5148514851485149, 'pegasus_entailment': 0.4642395251430571, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5142857142857142, 'r1_recall': 0.4, 'r1_f1': 0.45, 'pegasus_entailment': 0.11117073590867221, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4745762711864407, 'r1_recall': 0.5490196078431373, 'r1_f1': 0.5090909090909091, 'pegasus_entailment': 0.2947807766031474, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.725, 'r1_recall': 0.5878378378378378, 'r1_f1': 0.6492537313432836, 'pegasus_entailment': 0.4778098426759243, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5818181818181818, 'r1_recall': 0.48854961832061067, 'r1_f1': 0.5311203319502075, 'pegasus_entailment': 0.3682476137764752, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 14}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.59, 'r1_recall': 0.5, 'r1_f1': 0.5412844036697249, 'pegasus_entailment': 0.4319249603431672, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6260869565217392, 'r1_recall': 0.5538461538461539, 'r1_f1': 0.5877551020408163, 'pegasus_entailment': 0.5042111653601751, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43356643356643354, 'r1_recall': 0.5210084033613446, 'r1_f1': 0.4732824427480916, 'pegasus_entailment': 0.3478018407477066, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7263157894736842, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.5774058577405858, 'pegasus_entailment': 0.37836961417924614, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6825396825396826, 'r1_recall': 0.4777777777777778, 'r1_f1': 0.5620915032679739, 'pegasus_entailment': 0.6016083558400472, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5402298850574713, 'r1_recall': 0.3533834586466165, 'r1_f1': 0.42727272727272725, 'pegasus_entailment': 0.028844032323831925, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6461538461538462, 'r1_recall': 0.39622641509433965, 'r1_f1': 0.4912280701754387, 'pegasus_entailment': 0.6675587147474289, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.54, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.5046728971962616, 'pegasus_entailment': 0.7527267634868622, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6129032258064516, 'r1_recall': 0.4453125, 'r1_f1': 0.5158371040723982, 'pegasus_entailment': 0.18200385527597973, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3717948717948718, 'r1_recall': 0.5087719298245614, 'r1_f1': 0.42962962962962964, 'pegasus_entailment': 0.3351079416461289, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7019867549668874, 'r1_recall': 0.5549738219895288, 'r1_f1': 0.6198830409356725, 'pegasus_entailment': 0.6309217046946287, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6790123456790124, 'r1_recall': 0.3741496598639456, 'r1_f1': 0.4824561403508772, 'pegasus_entailment': 0.7921883165836334, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5838509316770186, 'r1_recall': 0.6103896103896104, 'r1_f1': 0.5968253968253967, 'pegasus_entailment': 0.5411360956262797, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5102040816326531, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5780346820809249, 'pegasus_entailment': 0.7546318769454956, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6283185840707964, 'r1_recall': 0.6173913043478261, 'r1_f1': 0.6228070175438597, 'pegasus_entailment': 0.22404377863858826, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6888888888888889, 'r1_recall': 0.40522875816993464, 'r1_f1': 0.5102880658436214, 'pegasus_entailment': 0.3734349850565195, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5445544554455446, 'r1_recall': 0.5392156862745098, 'r1_f1': 0.5418719211822661, 'pegasus_entailment': 0.4909207866585348, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 13, 'pegasus_ari': 16, 'pegasus_smog': 11}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32941176470588235, 'r1_recall': 0.49122807017543857, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.469983721151948, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.390625, 'r1_f1': 0.4807692307692308, 'pegasus_entailment': 0.7120684087276459, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 23, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.660377358490566, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.546875, 'pegasus_entailment': 0.9052218496799469, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4639175257731959, 'r1_recall': 0.8490566037735849, 'r1_f1': 0.6, 'pegasus_entailment': 0.505066389683634, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6559139784946236, 'r1_recall': 0.6559139784946236, 'r1_f1': 0.6559139784946236, 'pegasus_entailment': 0.436427965760231, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6266666666666667, 'r1_recall': 0.8103448275862069, 'r1_f1': 0.706766917293233, 'pegasus_entailment': 0.41610150085762143, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6857142857142857, 'r1_recall': 0.7058823529411765, 'r1_f1': 0.6956521739130436, 'pegasus_entailment': 0.7652232520282268, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5966386554621849, 'r1_recall': 0.44936708860759494, 'r1_f1': 0.5126353790613719, 'pegasus_entailment': 0.7038217902183532, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4069767441860465, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.48951048951048953, 'pegasus_entailment': 0.279714023694396, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5925925925925926, 'r1_recall': 0.5369127516778524, 'r1_f1': 0.5633802816901408, 'pegasus_entailment': 0.541371887922287, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7088607594936709, 'r1_recall': 0.40875912408759124, 'r1_f1': 0.5185185185185185, 'pegasus_entailment': 0.5181742280721664, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6197183098591549, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6423357664233577, 'pegasus_entailment': 0.5996604352258146, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.675, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.5654450261780104, 'pegasus_entailment': 0.5291013207286597, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43434343434343436, 'r1_recall': 0.5375, 'r1_f1': 0.48044692737430167, 'pegasus_entailment': 0.7869200507799784, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6764705882352942, 'r1_recall': 0.36220472440944884, 'r1_f1': 0.47179487179487184, 'pegasus_entailment': 0.49316704118003446, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6776859504132231, 'r1_recall': 0.41624365482233505, 'r1_f1': 0.5157232704402515, 'pegasus_entailment': 0.36211913901691634, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7203389830508474, 'r1_recall': 0.3497942386831276, 'r1_f1': 0.4709141274238227, 'pegasus_entailment': 0.38203488166133565, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7361111111111112, 'r1_recall': 0.381294964028777, 'r1_f1': 0.5023696682464455, 'pegasus_entailment': 0.8390110731124878, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.06666666666666667, 'r1_recall': 0.0410958904109589, 'r1_f1': 0.05084745762711865, 'pegasus_entailment': 0.9551213383674622, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 0, 'pegasus_ari': 16, 'pegasus_smog': 8}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32432432432432434, 'r1_recall': 0.39344262295081966, 'r1_f1': 0.3555555555555555, 'pegasus_entailment': 0.01903404953191057, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6923076923076923, 'r1_recall': 0.313953488372093, 'r1_f1': 0.43200000000000005, 'pegasus_entailment': 0.6090950518846512, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 25, 'pegasus_ari': 23, 'pegasus_smog': 23}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.5070422535211269, 'pegasus_entailment': 0.2527882878979047, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7692307692307693, 'r1_recall': 0.45977011494252873, 'r1_f1': 0.5755395683453237, 'pegasus_entailment': 0.4173222954074542, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5535714285714286, 'r1_recall': 0.4305555555555556, 'r1_f1': 0.484375, 'pegasus_entailment': 0.3040982659906149, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.654320987654321, 'r1_recall': 0.5435897435897435, 'r1_f1': 0.5938375350140055, 'pegasus_entailment': 0.689051728695631, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5606060606060606, 'r1_recall': 0.5068493150684932, 'r1_f1': 0.5323741007194245, 'pegasus_entailment': 0.0718043209053576, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4594594594594595, 'r1_recall': 0.68, 'r1_f1': 0.5483870967741935, 'pegasus_entailment': 0.6689626284642145, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5377358490566038, 'r1_recall': 0.5, 'r1_f1': 0.5181818181818182, 'pegasus_entailment': 0.5875349505804479, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.803921568627451, 'r1_recall': 0.3271276595744681, 'r1_f1': 0.46502835538752363, 'pegasus_entailment': 0.4420715455586712, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6226415094339622, 'r1_recall': 0.559322033898305, 'r1_f1': 0.5892857142857142, 'pegasus_entailment': 0.1588039305061102, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6422764227642277, 'r1_recall': 0.47023809523809523, 'r1_f1': 0.5429553264604812, 'pegasus_entailment': 0.657431403795878, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5130434782608696, 'r1_recall': 0.4573643410852713, 'r1_f1': 0.48360655737704916, 'pegasus_entailment': 0.5010573611652944, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.3624161073825503, 'r1_f1': 0.4518828451882845, 'pegasus_entailment': 0.4130391702055931, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.5798816568047337, 'r1_f1': 0.5816023738872403, 'pegasus_entailment': 0.43446122854948044, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5979381443298969, 'r1_recall': 0.44274809160305345, 'r1_f1': 0.5087719298245614, 'pegasus_entailment': 0.3314763270318508, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4608695652173913, 'r1_recall': 0.4274193548387097, 'r1_f1': 0.4435146443514644, 'pegasus_entailment': 0.5156310442835093, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4453125, 'r1_recall': 0.6867469879518072, 'r1_f1': 0.5402843601895735, 'pegasus_entailment': 0.7802543044090271, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2692307692307692, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.3589743589743589, 'pegasus_entailment': 0.30100649897940457, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7702702702702703, 'r1_recall': 0.49137931034482757, 'r1_f1': 0.6000000000000001, 'pegasus_entailment': 0.1285467520938255, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7528089887640449, 'r1_recall': 0.3621621621621622, 'r1_f1': 0.489051094890511, 'pegasus_entailment': 0.2543713478371501, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8888888888888888, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.48484848484848486, 'pegasus_entailment': 0.9620025157928467, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 25, 'pegasus_ari': 31, 'pegasus_smog': 27}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6947368421052632, 'r1_recall': 0.34285714285714286, 'r1_f1': 0.45913043478260873, 'pegasus_entailment': 0.5830815409620603, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6513761467889908, 'r1_recall': 0.4930555555555556, 'r1_f1': 0.5612648221343872, 'pegasus_entailment': 0.8594472706317902, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34579439252336447, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.43023255813953487, 'pegasus_entailment': 0.2351005698243777, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4318181818181818, 'r1_recall': 0.6333333333333333, 'r1_f1': 0.5135135135135135, 'pegasus_entailment': 0.14356283490390828, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.2345679012345679, 'r1_f1': 0.319327731092437, 'pegasus_entailment': 0.54438266903162, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 22, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6071428571428571, 'r1_recall': 0.49038461538461536, 'r1_f1': 0.5425531914893617, 'pegasus_entailment': 0.23501949990168214, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4520547945205479, 'r1_recall': 0.38372093023255816, 'r1_f1': 0.41509433962264153, 'pegasus_entailment': 0.5947982420523962, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 23}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.5072463768115941, 'pegasus_entailment': 0.8038830012083054, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7156862745098039, 'r1_recall': 0.44242424242424244, 'r1_f1': 0.5468164794007491, 'pegasus_entailment': 0.4935950506478548, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4827586206896552, 'r1_recall': 0.45901639344262296, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.921246349811554, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6017699115044248, 'r1_recall': 0.4533333333333333, 'r1_f1': 0.5171102661596958, 'pegasus_entailment': 0.5308939442038536, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 14}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5287356321839081, 'r1_recall': 0.5054945054945055, 'r1_f1': 0.5168539325842697, 'pegasus_entailment': 0.24530571336799767, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7272727272727273, 'r1_recall': 0.42748091603053434, 'r1_f1': 0.5384615384615384, 'pegasus_entailment': 0.5581103162840009, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4418604651162791, 'r1_recall': 0.6263736263736264, 'r1_f1': 0.5181818181818182, 'pegasus_entailment': 0.47054384152094525, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.5806451612903226, 'pegasus_entailment': 0.8511746376752853, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.7397260273972602, 'r1_f1': 0.7012987012987013, 'pegasus_entailment': 0.5545966029167175, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4883720930232558, 'r1_recall': 0.336, 'r1_f1': 0.3981042654028436, 'pegasus_entailment': 0.0865540656959638, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 13}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6162790697674418, 'r1_recall': 0.4649122807017544, 'r1_f1': 0.5299999999999999, 'pegasus_entailment': 0.6809664559550583, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4421052631578947, 'r1_recall': 0.47191011235955055, 'r1_f1': 0.45652173913043476, 'pegasus_entailment': 0.27584634501254185, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.4186046511627907, 'r1_f1': 0.42352941176470593, 'pegasus_entailment': 0.4247867092490196, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 18, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7068965517241379, 'r1_recall': 0.37104072398190047, 'r1_f1': 0.486646884272997, 'pegasus_entailment': 0.4308069184422493, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6601941747572816, 'r1_recall': 0.6017699115044248, 'r1_f1': 0.6296296296296297, 'pegasus_entailment': 0.49680881202220917, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 34, 'pegasus_smog': 22}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24615384615384617, 'r1_recall': 0.43243243243243246, 'r1_f1': 0.3137254901960784, 'pegasus_entailment': 0.33339310344308615, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.5121951219512195, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.7277114614844322, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5942028985507246, 'r1_recall': 0.38317757009345793, 'r1_f1': 0.46590909090909094, 'pegasus_entailment': 0.6449274234473705, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5094339622641509, 'r1_recall': 0.75, 'r1_f1': 0.6067415730337078, 'pegasus_entailment': 0.3627637289464474, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4731182795698925, 'r1_recall': 0.5, 'r1_f1': 0.48618784530386744, 'pegasus_entailment': 0.6506766527891159, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 30, 'pegasus_smog': 21}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6705882352941176, 'r1_recall': 0.6404494382022472, 'r1_f1': 0.6551724137931035, 'pegasus_entailment': 0.47334501296281817, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4186046511627907, 'r1_recall': 0.6101694915254238, 'r1_f1': 0.496551724137931, 'pegasus_entailment': 0.6563360942139601, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6438356164383562, 'r1_recall': 0.47474747474747475, 'r1_f1': 0.5465116279069767, 'pegasus_entailment': 0.6489680310090383, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6792452830188679, 'r1_recall': 0.375, 'r1_f1': 0.4832214765100672, 'pegasus_entailment': 0.34240482391032856, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5869565217391305, 'r1_recall': 0.574468085106383, 'r1_f1': 0.5806451612903226, 'pegasus_entailment': 0.2924678991548717, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.89937106918239, 'r1_recall': 0.2739463601532567, 'r1_f1': 0.41997063142437596, 'pegasus_entailment': 0.7042092587798834, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7657657657657657, 'r1_recall': 0.425, 'r1_f1': 0.5466237942122185, 'pegasus_entailment': 0.8043527662754059, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2631578947368421, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.33175355450236965, 'pegasus_entailment': 0.2162172528582492, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5855855855855856, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.6018518518518519, 'pegasus_entailment': 0.3761373112599055, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7471264367816092, 'r1_recall': 0.47794117647058826, 'r1_f1': 0.5829596412556054, 'pegasus_entailment': 0.8111821264028549, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5862068965517241, 'r1_recall': 0.6017699115044248, 'r1_f1': 0.593886462882096, 'pegasus_entailment': 0.432747317571193, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5862068965517241, 'r1_recall': 0.6, 'r1_f1': 0.5930232558139535, 'pegasus_entailment': 0.5963955819606781, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4823529411764706, 'r1_recall': 0.6212121212121212, 'r1_f1': 0.543046357615894, 'pegasus_entailment': 0.6258522073427836, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6714285714285714, 'r1_recall': 0.5108695652173914, 'r1_f1': 0.5802469135802468, 'pegasus_entailment': 0.3212683601304889, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5714285714285714, 'r1_recall': 0.43373493975903615, 'r1_f1': 0.4931506849315068, 'pegasus_entailment': 0.4744282681494951, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7692307692307693, 'r1_recall': 0.3968253968253968, 'r1_f1': 0.5235602094240838, 'pegasus_entailment': 0.11953641846776009, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.559322033898305, 'r1_recall': 0.3235294117647059, 'r1_f1': 0.40993788819875776, 'pegasus_entailment': 0.3829929046332836, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7674418604651163, 'r1_recall': 0.40993788819875776, 'r1_f1': 0.534412955465587, 'pegasus_entailment': 0.6425683200359344, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39325842696629215, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.4794520547945206, 'pegasus_entailment': 0.25073991615014773, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7371794871794872, 'r1_recall': 0.5088495575221239, 'r1_f1': 0.6020942408376964, 'pegasus_entailment': 0.3790850059594959, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.023244236401903134, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 17}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5596330275229358, 'r1_recall': 0.6039603960396039, 'r1_f1': 0.5809523809523809, 'pegasus_entailment': 0.3254898674786091, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2920353982300885, 'r1_recall': 0.673469387755102, 'r1_f1': 0.4074074074074074, 'pegasus_entailment': 0.5195352993905544, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21333333333333335, 'r1_recall': 0.34782608695652173, 'r1_f1': 0.2644628099173553, 'pegasus_entailment': 0.2407829195726663, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6583333333333333, 'r1_recall': 0.541095890410959, 'r1_f1': 0.5939849624060151, 'pegasus_entailment': 0.7520666066557169, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6491228070175439, 'r1_recall': 0.3854166666666667, 'r1_f1': 0.4836601307189542, 'pegasus_entailment': 0.7147587314248085, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6744186046511628, 'r1_recall': 0.3918918918918919, 'r1_f1': 0.49572649572649563, 'pegasus_entailment': 0.4653277573330949, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5915492957746479, 'r1_recall': 0.42424242424242425, 'r1_f1': 0.49411764705882355, 'pegasus_entailment': 0.11606937111355364, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48214285714285715, 'r1_recall': 0.6506024096385542, 'r1_f1': 0.5538461538461539, 'pegasus_entailment': 0.41578550409394666, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5257731958762887, 'r1_recall': 0.7183098591549296, 'r1_f1': 0.6071428571428571, 'pegasus_entailment': 0.8208841323852539, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5546218487394958, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.5641025641025642, 'pegasus_entailment': 0.25596804994468886, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6173913043478261, 'r1_recall': 0.4226190476190476, 'r1_f1': 0.5017667844522967, 'pegasus_entailment': 0.7767510563135147, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36619718309859156, 'r1_recall': 0.49056603773584906, 'r1_f1': 0.4193548387096774, 'pegasus_entailment': 0.6492298804223537, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7866666666666666, 'r1_recall': 0.5462962962962963, 'r1_f1': 0.644808743169399, 'pegasus_entailment': 0.4390016744534175, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.4336283185840708, 'r1_f1': 0.49746192893401014, 'pegasus_entailment': 0.3670660451898584, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39823008849557523, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.4891304347826088, 'pegasus_entailment': 0.061990017304196954, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6635514018691588, 'r1_recall': 0.3242009132420091, 'r1_f1': 0.43558282208588955, 'pegasus_entailment': 0.7128753014840186, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3142857142857143, 'r1_recall': 0.3142857142857143, 'r1_f1': 0.3142857142857143, 'pegasus_entailment': 0.9527797102928162, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 19}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47368421052631576, 'r1_recall': 0.7590361445783133, 'r1_f1': 0.5833333333333333, 'pegasus_entailment': 0.32734239590354264, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3409090909090909, 'r1_recall': 0.6122448979591837, 'r1_f1': 0.43795620437956206, 'pegasus_entailment': 0.27393093627567094, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.865979381443299, 'r1_recall': 0.49411764705882355, 'r1_f1': 0.6292134831460674, 'pegasus_entailment': 0.8337986171245575, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6204379562043796, 'r1_recall': 0.6589147286821705, 'r1_f1': 0.6390977443609023, 'pegasus_entailment': 0.44479179981863126, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.632183908045977, 'r1_f1': 0.5913978494623656, 'pegasus_entailment': 0.06764651872217656, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6966292134831461, 'r1_recall': 0.46616541353383456, 'r1_f1': 0.5585585585585585, 'pegasus_entailment': 0.4522191832462947, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5887096774193549, 'r1_recall': 0.6576576576576577, 'r1_f1': 0.6212765957446809, 'pegasus_entailment': 0.5083883376792073, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3787878787878788, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.43859649122807015, 'pegasus_entailment': 0.47334716375917196, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7261904761904762, 'r1_recall': 0.4357142857142857, 'r1_f1': 0.5446428571428572, 'pegasus_entailment': 0.9514151612917582, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7586206896551724, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.6330755278468132, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.5569620253164557, 'pegasus_entailment': 0.7285392845515162, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6458333333333334, 'r1_recall': 0.6019417475728155, 'r1_f1': 0.6231155778894473, 'pegasus_entailment': 0.4641721496979396, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35135135135135137, 'r1_recall': 0.582089552238806, 'r1_f1': 0.43820224719101125, 'pegasus_entailment': 0.28838587179780006, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5208333333333334, 'r1_recall': 0.5494505494505495, 'r1_f1': 0.5347593582887702, 'pegasus_entailment': 0.8290705382823944, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6764705882352942, 'r1_recall': 0.4825174825174825, 'r1_f1': 0.563265306122449, 'pegasus_entailment': 0.6520704853658875, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7532467532467533, 'r1_recall': 0.47540983606557374, 'r1_f1': 0.5829145728643216, 'pegasus_entailment': 0.1526496398728341, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6311475409836066, 'r1_recall': 0.463855421686747, 'r1_f1': 0.5347222222222221, 'pegasus_entailment': 0.2034175742107133, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5849056603773585, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.5740740740740741, 'pegasus_entailment': 0.4711110226344317, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43333333333333335, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.3880597014925374, 'pegasus_entailment': 0.7511650398373604, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7833333333333333, 'r1_recall': 0.46078431372549017, 'r1_f1': 0.5802469135802469, 'pegasus_entailment': 0.6352169997990131, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6893939393939394, 'r1_recall': 0.4212962962962963, 'r1_f1': 0.5229885057471264, 'pegasus_entailment': 0.5508205071091652, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6629213483146067, 'r1_recall': 0.48760330578512395, 'r1_f1': 0.5619047619047619, 'pegasus_entailment': 0.22380004605899254, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7108433734939759, 'r1_recall': 0.4125874125874126, 'r1_f1': 0.5221238938053098, 'pegasus_entailment': 0.25358527537900954, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4351145038167939, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.5229357798165137, 'pegasus_entailment': 0.4361530840396881, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4827586206896552, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5410628019323672, 'pegasus_entailment': 0.4297314465317565, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6417910447761194, 'r1_recall': 0.4215686274509804, 'r1_f1': 0.5088757396449705, 'pegasus_entailment': 0.25683648822208244, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 11, 'pegasus_ari': 11, 'pegasus_smog': 15}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5733333333333334, 'r1_recall': 0.37719298245614036, 'r1_f1': 0.45502645502645506, 'pegasus_entailment': 0.34887588035780936, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46226415094339623, 'r1_recall': 0.494949494949495, 'r1_f1': 0.47804878048780486, 'pegasus_entailment': 0.5656932145357132, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37362637362637363, 'r1_recall': 0.38202247191011235, 'r1_f1': 0.3777777777777777, 'pegasus_entailment': 0.2449243306182325, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8070175438596491, 'r1_recall': 0.5644171779141104, 'r1_f1': 0.6642599277978338, 'pegasus_entailment': 0.37195661664009094, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5784313725490197, 'r1_recall': 0.3241758241758242, 'r1_f1': 0.4154929577464789, 'pegasus_entailment': 0.7008368015289307, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7692307692307693, 'r1_recall': 0.21818181818181817, 'r1_f1': 0.33994334277620397, 'pegasus_entailment': 0.35753364814445376, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5037037037037037, 'r1_recall': 0.6238532110091743, 'r1_f1': 0.5573770491803278, 'pegasus_entailment': 0.6107790188863873, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425, 'r1_recall': 0.29310344827586204, 'r1_f1': 0.3469387755102041, 'pegasus_entailment': 0.8935857713222504, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 22, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6222222222222222, 'r1_recall': 0.30939226519337015, 'r1_f1': 0.4132841328413284, 'pegasus_entailment': 0.2361676240572706, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5161290322580645, 'r1_recall': 0.4155844155844156, 'r1_f1': 0.46043165467625896, 'pegasus_entailment': 0.1308608406689018, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 13, 'pegasus_ari': 12, 'pegasus_smog': 13}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.525, 'r1_f1': 0.5874125874125874, 'pegasus_entailment': 0.8259854912757874, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6483516483516484, 'r1_recall': 0.6344086021505376, 'r1_f1': 0.641304347826087, 'pegasus_entailment': 0.48925476521253586, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.375, 'r1_recall': 0.6296296296296297, 'r1_f1': 0.47004608294930866, 'pegasus_entailment': 0.2052067093512354, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49, 'r1_recall': 0.5444444444444444, 'r1_f1': 0.5157894736842104, 'pegasus_entailment': 0.38907412998378277, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36470588235294116, 'r1_recall': 0.4492753623188406, 'r1_f1': 0.40259740259740256, 'pegasus_entailment': 0.49971011135494336, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5714285714285714, 'r1_recall': 0.625, 'r1_f1': 0.5970149253731343, 'pegasus_entailment': 0.19274014770053327, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4222222222222222, 'r1_recall': 0.59375, 'r1_f1': 0.49350649350649345, 'pegasus_entailment': 0.8070272356271744, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3173076923076923, 'r1_recall': 0.7252747252747253, 'r1_f1': 0.44147157190635455, 'pegasus_entailment': 0.7414791931708654, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5135135135135135, 'r1_recall': 0.6477272727272727, 'r1_f1': 0.5728643216080402, 'pegasus_entailment': 0.39091730263317004, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39669421487603307, 'r1_recall': 0.7741935483870968, 'r1_f1': 0.5245901639344261, 'pegasus_entailment': 0.041545146593957076, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5081967213114754, 'r1_recall': 0.5794392523364486, 'r1_f1': 0.5414847161572052, 'pegasus_entailment': 0.5196079603396356, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4246575342465753, 'r1_recall': 0.49206349206349204, 'r1_f1': 0.45588235294117646, 'pegasus_entailment': 0.21510338020743802, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.784, 'r1_recall': 0.36981132075471695, 'r1_f1': 0.5025641025641026, 'pegasus_entailment': 0.38774944717685383, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 16, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4153846153846154, 'r1_recall': 0.421875, 'r1_f1': 0.4186046511627907, 'pegasus_entailment': 0.33093268796801567, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4367816091954023, 'r1_recall': 0.41304347826086957, 'r1_f1': 0.42458100558659223, 'pegasus_entailment': 0.28802012698724866, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.525, 'r1_recall': 0.63, 'r1_f1': 0.5727272727272728, 'pegasus_entailment': 0.5315403267741203, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 19}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5528455284552846, 'r1_recall': 0.4857142857142857, 'r1_f1': 0.5171102661596958, 'pegasus_entailment': 0.5712202663222948, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.582089552238806, 'r1_recall': 0.4148936170212766, 'r1_f1': 0.48447204968944096, 'pegasus_entailment': 0.2531167816370726, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.2125984251968504, 'r1_f1': 0.30857142857142855, 'pegasus_entailment': 0.8755706946055094, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 24, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37398373983739835, 'r1_recall': 0.647887323943662, 'r1_f1': 0.4742268041237113, 'pegasus_entailment': 0.5045976997353137, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.6382978723404256, 'r1_f1': 0.5172413793103449, 'pegasus_entailment': 0.37132522530321566, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5113636363636364, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.5232558139534884, 'pegasus_entailment': 0.3845200907671824, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37037037037037035, 'r1_recall': 0.6756756756756757, 'r1_f1': 0.478468899521531, 'pegasus_entailment': 0.31655394413974136, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.5669291338582678, 'pegasus_entailment': 0.2681337147951126, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36363636363636365, 'r1_recall': 0.625, 'r1_f1': 0.4597701149425288, 'pegasus_entailment': 0.2532407520338893, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.75, 'r1_recall': 0.4508670520231214, 'r1_f1': 0.5631768953068591, 'pegasus_entailment': 0.500275832414627, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7383177570093458, 'r1_recall': 0.47878787878787876, 'r1_f1': 0.5808823529411764, 'pegasus_entailment': 0.18498627468943596, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7142857142857143, 'r1_recall': 0.5612244897959183, 'r1_f1': 0.6285714285714286, 'pegasus_entailment': 0.40244511266549426, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5609756097560976, 'r1_recall': 0.12299465240641712, 'r1_f1': 0.2017543859649123, 'pegasus_entailment': 0.24831663817167282, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4880952380952381, 'r1_recall': 0.43157894736842106, 'r1_f1': 0.45810055865921784, 'pegasus_entailment': 0.5056429728865623, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49473684210526314, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.5628742514970059, 'pegasus_entailment': 0.4214203875511885, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4864864864864865, 'r1_recall': 0.32727272727272727, 'r1_f1': 0.391304347826087, 'pegasus_entailment': 0.8033253848552704, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24193548387096775, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.3614457831325301, 'pegasus_entailment': 0.32128898072987794, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5074626865671642, 'r1_recall': 0.4788732394366197, 'r1_f1': 0.4927536231884058, 'pegasus_entailment': 0.7767657041549683, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.4078947368421053, 'pegasus_entailment': 0.24570647033397108, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.3247863247863248, 'r1_f1': 0.39378238341968913, 'pegasus_entailment': 0.2409830091346521, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6302521008403361, 'r1_recall': 0.5725190839694656, 'r1_f1': 0.6, 'pegasus_entailment': 0.8497944623231888, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.589041095890411, 'r1_recall': 0.5119047619047619, 'r1_f1': 0.5477707006369427, 'pegasus_entailment': 0.4903647396713495, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 12}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6435643564356436, 'r1_recall': 0.3611111111111111, 'r1_f1': 0.4626334519572954, 'pegasus_entailment': 0.8977799713611603, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.5274725274725275, 'r1_f1': 0.4729064039408867, 'pegasus_entailment': 0.2593546151700947, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 15}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4264705882352941, 'r1_recall': 0.5272727272727272, 'r1_f1': 0.47154471544715443, 'pegasus_entailment': 0.6995634129270911, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6463414634146342, 'r1_recall': 0.5760869565217391, 'r1_f1': 0.6091954022988506, 'pegasus_entailment': 0.4071351333986968, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5866666666666667, 'r1_recall': 0.44, 'r1_f1': 0.5028571428571429, 'pegasus_entailment': 0.48848887253552675, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3888888888888889, 'r1_recall': 0.4057971014492754, 'r1_f1': 0.3971631205673759, 'pegasus_entailment': 0.5224158763885498, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5816326530612245, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.6162162162162163, 'pegasus_entailment': 0.5990487847477197, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6835443037974683, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.5966850828729282, 'pegasus_entailment': 0.5439601700151494, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.573170731707317, 'r1_recall': 0.5595238095238095, 'r1_f1': 0.5662650602409639, 'pegasus_entailment': 0.8950785398483276, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 18}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2549019607843137, 'r1_recall': 0.5, 'r1_f1': 0.33766233766233766, 'pegasus_entailment': 0.46063996118027717, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5615384615384615, 'r1_recall': 0.5104895104895105, 'r1_f1': 0.5347985347985347, 'pegasus_entailment': 0.322127893473953, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5365853658536586, 'r1_recall': 0.5057471264367817, 'r1_f1': 0.5207100591715976, 'pegasus_entailment': 0.9645131528377533, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 31, 'pegasus_smog': 25}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4897959183673469, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.46601941747572817, 'pegasus_entailment': 0.32837930725266534, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6063829787234043, 'r1_recall': 0.47107438016528924, 'r1_f1': 0.5302325581395348, 'pegasus_entailment': 0.5988380461931229, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.23076923076923078, 'r1_f1': 0.3243243243243243, 'pegasus_entailment': 0.8898718059062958, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 11, 'pegasus_smog': 15}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4752475247524752, 'r1_recall': 0.6857142857142857, 'r1_f1': 0.5614035087719298, 'pegasus_entailment': 0.4611890882253647, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4909090909090909, 'r1_recall': 0.375, 'r1_f1': 0.42519685039370075, 'pegasus_entailment': 0.6144258217148794, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4297520661157025, 'r1_recall': 0.5842696629213483, 'r1_f1': 0.4952380952380952, 'pegasus_entailment': 0.43418838347618777, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 15, 'pegasus_ari': 25, 'pegasus_smog': 17}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22448979591836735, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.3076923076923077, 'pegasus_entailment': 0.44074883429372375, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 13, 'pegasus_ari': 12, 'pegasus_smog': 13}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6551724137931034, 'r1_recall': 0.5533980582524272, 'r1_f1': 0.6, 'pegasus_entailment': 0.3662293450906873, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.14432989690721648, 'r1_recall': 0.4, 'r1_f1': 0.21212121212121207, 'pegasus_entailment': 0.3022824336294434, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.4827586206896552, 'pegasus_entailment': 0.9366413354873657, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 23, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3225806451612903, 'r1_recall': 0.7692307692307693, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.4895753338932991, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6379310344827587, 'r1_recall': 0.5, 'r1_f1': 0.5606060606060607, 'pegasus_entailment': 0.6354804734388987, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.6086956521739131, 'r1_f1': 0.6363636363636365, 'pegasus_entailment': 0.7016553059220314, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5042016806722689, 'r1_recall': 0.625, 'r1_f1': 0.5581395348837209, 'pegasus_entailment': 0.9331622918446859, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6261682242990654, 'r1_recall': 0.6146788990825688, 'r1_f1': 0.6203703703703702, 'pegasus_entailment': 0.8648368120193481, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7012987012987013, 'r1_recall': 0.391304347826087, 'r1_f1': 0.5023255813953489, 'pegasus_entailment': 0.2698058497044258, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8380952380952381, 'r1_recall': 0.25, 'r1_f1': 0.38512035010940915, 'pegasus_entailment': 0.5128796985372901, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.424, 'r1_recall': 0.4774774774774775, 'r1_f1': 0.4491525423728814, 'pegasus_entailment': 0.4073688543285243, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6746987951807228, 'r1_recall': 0.37583892617449666, 'r1_f1': 0.48275862068965525, 'pegasus_entailment': 0.5435478371800855, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7349397590361446, 'r1_recall': 0.40939597315436244, 'r1_f1': 0.5258620689655173, 'pegasus_entailment': 0.44174059107899666, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32, 'r1_recall': 0.32653061224489793, 'r1_f1': 0.3232323232323232, 'pegasus_entailment': 0.9052064418792725, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 13, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44761904761904764, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.5310734463276836, 'pegasus_entailment': 0.6588467806577682, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39655172413793105, 'r1_recall': 0.5679012345679012, 'r1_f1': 0.467005076142132, 'pegasus_entailment': 0.5701973494142294, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8378378378378378, 'r1_recall': 0.62, 'r1_f1': 0.7126436781609196, 'pegasus_entailment': 0.8976007997989655, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 19, 'pegasus_ari': 36, 'pegasus_smog': 25}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34513274336283184, 'r1_recall': 0.582089552238806, 'r1_f1': 0.4333333333333333, 'pegasus_entailment': 0.1518300213618204, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.717741935483871, 'r1_recall': 0.5174418604651163, 'r1_f1': 0.6013513513513514, 'pegasus_entailment': 0.650734084735935, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4457831325301205, 'r1_recall': 0.5, 'r1_f1': 0.4713375796178344, 'pegasus_entailment': 0.733650783697764, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5428571428571428, 'r1_recall': 0.4691358024691358, 'r1_f1': 0.5033112582781456, 'pegasus_entailment': 0.6449265076468388, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.646551724137931, 'r1_recall': 0.5319148936170213, 'r1_f1': 0.5836575875486382, 'pegasus_entailment': 0.1291865708772093, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3701923076923077, 'r1_recall': 0.5877862595419847, 'r1_f1': 0.4542772861356932, 'pegasus_entailment': 0.27673125080764294, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7058823529411765, 'r1_recall': 0.3380281690140845, 'r1_f1': 0.45714285714285713, 'pegasus_entailment': 0.4063834042754024, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 21}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6344086021505376, 'r1_recall': 0.6555555555555556, 'r1_f1': 0.644808743169399, 'pegasus_entailment': 0.8155909925699234, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.559322033898305, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.5689655172413793, 'pegasus_entailment': 0.4899814873933792, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.620253164556962, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.5648414985590778, 'pegasus_entailment': 0.3187099186082681, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6741573033707865, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.49792531120331956, 'pegasus_entailment': 0.7874514162540436, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.313953488372093, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.36241610738255037, 'pegasus_entailment': 0.6088342405855656, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5128205128205128, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.4624277456647398, 'pegasus_entailment': 0.7491100629170736, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7340425531914894, 'r1_recall': 0.43670886075949367, 'r1_f1': 0.5476190476190477, 'pegasus_entailment': 0.47331980150192976, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27710843373493976, 'r1_recall': 0.39655172413793105, 'r1_f1': 0.326241134751773, 'pegasus_entailment': 0.38975664461031556, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7692307692307693, 'r1_recall': 0.3314917127071823, 'r1_f1': 0.46332046332046334, 'pegasus_entailment': 0.6808736212551594, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5357142857142857, 'r1_recall': 0.31690140845070425, 'r1_f1': 0.39823008849557523, 'pegasus_entailment': 0.20682667405344546, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 13, 'pegasus_ari': 12, 'pegasus_smog': 11}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48484848484848486, 'r1_recall': 0.5052631578947369, 'r1_f1': 0.4948453608247423, 'pegasus_entailment': 0.18699574889615178, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6764705882352942, 'r1_recall': 0.4011627906976744, 'r1_f1': 0.5036496350364963, 'pegasus_entailment': 0.7458545863628387, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4807692307692308, 'r1_recall': 0.704225352112676, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.44807681627571583, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8571428571428571, 'r1_recall': 0.28846153846153844, 'r1_f1': 0.43165467625899273, 'pegasus_entailment': 0.10517142293974757, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5972222222222222, 'r1_recall': 0.46236559139784944, 'r1_f1': 0.5212121212121212, 'pegasus_entailment': 0.8259005770087242, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.68, 'r1_f1': 0.5257731958762887, 'pegasus_entailment': 0.31506797298789024, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6428571428571429, 'r1_recall': 0.5070422535211268, 'r1_f1': 0.5669291338582677, 'pegasus_entailment': 0.6545993636051813, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6086956521739131, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.5803108808290156, 'pegasus_entailment': 0.11026632506400347, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7941176470588235, 'r1_recall': 0.391304347826087, 'r1_f1': 0.5242718446601942, 'pegasus_entailment': 0.7438056270281473, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.5128205128205129, 'pegasus_entailment': 0.16541087557561696, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2717391304347826, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.32894736842105265, 'pegasus_entailment': 0.17491885212560496, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7364341085271318, 'r1_recall': 0.5337078651685393, 'r1_f1': 0.6188925081433224, 'pegasus_entailment': 0.443511168162028, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 22}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5172413793103449, 'r1_recall': 0.6164383561643836, 'r1_f1': 0.5624999999999999, 'pegasus_entailment': 0.23928909545065835, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5463917525773195, 'r1_recall': 0.6973684210526315, 'r1_f1': 0.6127167630057804, 'pegasus_entailment': 0.6560074491426349, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4369747899159664, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.49523809523809526, 'pegasus_entailment': 0.5227942019701004, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7361111111111112, 'r1_recall': 0.44166666666666665, 'r1_f1': 0.5520833333333333, 'pegasus_entailment': 0.2774569122120738, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.871244635193133, 'r1_recall': 0.28794326241134754, 'r1_f1': 0.4328358208955224, 'pegasus_entailment': 0.7379837152030733, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.528169014084507, 'r1_f1': 0.5725190839694656, 'pegasus_entailment': 0.5466727018356323, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8494623655913979, 'r1_recall': 0.43169398907103823, 'r1_f1': 0.5724637681159421, 'pegasus_entailment': 0.6834742486476898, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5416666666666666, 'r1_recall': 0.5591397849462365, 'r1_f1': 0.5502645502645503, 'pegasus_entailment': 0.8104002475738525, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6260869565217392, 'r1_recall': 0.6206896551724138, 'r1_f1': 0.6233766233766235, 'pegasus_entailment': 0.24366525728255511, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6231884057971014, 'r1_recall': 0.6615384615384615, 'r1_f1': 0.6417910447761194, 'pegasus_entailment': 0.30567327539029066, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6120689655172413, 'r1_recall': 0.45222929936305734, 'r1_f1': 0.5201465201465202, 'pegasus_entailment': 0.806418165564537, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29245283018867924, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.4025974025974026, 'pegasus_entailment': 0.3114537294954062, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5368421052631579, 'r1_recall': 0.5257731958762887, 'r1_f1': 0.5312500000000001, 'pegasus_entailment': 0.9617355465888977, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 33, 'pegasus_smog': 25}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2465753424657534, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.33333333333333326, 'pegasus_entailment': 0.30431996037562686, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5233644859813084, 'r1_recall': 0.5773195876288659, 'r1_f1': 0.5490196078431373, 'pegasus_entailment': 0.4914714887738228, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6309523809523809, 'r1_recall': 0.4690265486725664, 'r1_f1': 0.5380710659898477, 'pegasus_entailment': 0.7116579462599475, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6224489795918368, 'r1_recall': 0.45185185185185184, 'r1_f1': 0.5236051502145923, 'pegasus_entailment': 0.6703876396641135, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3157894736842105, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.40268456375838924, 'pegasus_entailment': 0.15304428292438388, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7058823529411765, 'r1_recall': 0.36, 'r1_f1': 0.4768211920529802, 'pegasus_entailment': 0.7677253186702728, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.06666666666666667
MEAN
0.564375831603636
MAX
0.9285714285714286
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.0410958904109589
MEAN
0.5031559286432151
MAX
0.8490566037735849
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.05084745762711865
MEAN
0.5099035607234765
MAX
0.7211538461538461
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.0005805986935835487
MEAN
0.4914886250206213
MAX
0.9811601837476095
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
9
MEAN
16
MAX
45
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
0
MEAN
17
MAX
25
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
10
MEAN
19
MAX
55
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
8
MEAN
18
MAX
28
{}
Entered file!
Imports done!
*** RUN *** 
eval_2cO
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 13:47:14.158692: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 13:47:14.720578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/2cO_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5050505050505051, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.4784688995215311, 'pegasus_entailment': 0.3170867725275457, 'gold_entailment': 0.27184711713343856, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7040816326530612, 'r1_recall': 0.3988439306358382, 'r1_f1': 0.5092250922509225, 'pegasus_entailment': 0.4195907348766923, 'gold_entailment': 0.3833744790671127, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3412698412698413, 'r1_recall': 0.7413793103448276, 'r1_f1': 0.46739130434782616, 'pegasus_entailment': 0.6626736801117659, 'gold_entailment': 0.6273262435570359, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7078651685393258, 'r1_recall': 0.4883720930232558, 'r1_f1': 0.5779816513761468, 'pegasus_entailment': 0.33988311886787415, 'gold_entailment': 0.09712515934370458, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7285714285714285, 'r1_recall': 0.29310344827586204, 'r1_f1': 0.41803278688524587, 'pegasus_entailment': 0.7605021893978119, 'gold_entailment': 0.03534186357380046, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4722222222222222, 'r1_recall': 0.5230769230769231, 'r1_f1': 0.49635036496350365, 'pegasus_entailment': 0.5040050923824311, 'gold_entailment': 0.0632066939258948, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2236842105263158, 'r1_recall': 0.53125, 'r1_f1': 0.3148148148148148, 'pegasus_entailment': 0.3452184371029337, 'gold_entailment': 0.2296201316154717, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23711340206185566, 'r1_recall': 0.7419354838709677, 'r1_f1': 0.359375, 'pegasus_entailment': 0.4897610011830693, 'gold_entailment': 0.18818309903144836, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7142857142857143, 'r1_recall': 0.5369127516778524, 'r1_f1': 0.6130268199233717, 'pegasus_entailment': 0.5997948911972344, 'gold_entailment': 0.5198998253659478, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6343283582089553, 'r1_recall': 0.6159420289855072, 'r1_f1': 0.625, 'pegasus_entailment': 0.49599183946847913, 'gold_entailment': 0.0058994410404314595, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8, 'r1_recall': 0.4266666666666667, 'r1_f1': 0.5565217391304348, 'pegasus_entailment': 0.29330845084041357, 'gold_entailment': 0.2410739276558161, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6049382716049383, 'r1_recall': 0.4117647058823529, 'r1_f1': 0.49000000000000005, 'pegasus_entailment': 0.6461077382167181, 'gold_entailment': 0.33383334865793585, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7361111111111112, 'r1_recall': 0.4953271028037383, 'r1_f1': 0.5921787709497207, 'pegasus_entailment': 0.6622808252771696, 'gold_entailment': 0.24892175957211293, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6716417910447762, 'r1_recall': 0.5113636363636364, 'r1_f1': 0.5806451612903226, 'pegasus_entailment': 0.3492705039680004, 'gold_entailment': 0.11534677639428992, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8409090909090909, 'r1_recall': 0.3854166666666667, 'r1_f1': 0.5285714285714287, 'pegasus_entailment': 0.3682900983840227, 'gold_entailment': 0.20341195809305646, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38461538461538464, 'r1_recall': 0.423728813559322, 'r1_f1': 0.40322580645161293, 'pegasus_entailment': 0.9381141662597656, 'gold_entailment': 0.0003276811621617526, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5416666666666666, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.45614035087719296, 'pegasus_entailment': 0.13534753606654704, 'gold_entailment': 0.1037522890449812, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8118811881188119, 'r1_recall': 0.2751677852348993, 'r1_f1': 0.4110275689223058, 'pegasus_entailment': 0.5978349934642514, 'gold_entailment': 0.4596173033118248, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6739130434782609, 'r1_recall': 0.38509316770186336, 'r1_f1': 0.4901185770750988, 'pegasus_entailment': 0.49808559318383533, 'gold_entailment': 0.32508217237357584, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5185185185185185, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.5, 'pegasus_entailment': 0.7835957556962967, 'gold_entailment': 0.20145725272595882, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7023809523809523, 'r1_recall': 0.3241758241758242, 'r1_f1': 0.443609022556391, 'pegasus_entailment': 0.6204971894621849, 'gold_entailment': 0.041316829388961196, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.696969696969697, 'r1_recall': 0.46, 'r1_f1': 0.5542168674698795, 'pegasus_entailment': 0.9013744990030924, 'gold_entailment': 0.2593975472263992, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6463414634146342, 'r1_recall': 0.49074074074074076, 'r1_f1': 0.5578947368421053, 'pegasus_entailment': 0.5657961765925089, 'gold_entailment': 0.2734217985998839, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6633663366336634, 'r1_recall': 0.49264705882352944, 'r1_f1': 0.5654008438818565, 'pegasus_entailment': 0.3529177657328546, 'gold_entailment': 0.17460141237825155, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38461538461538464, 'r1_recall': 0.5, 'r1_f1': 0.4347826086956522, 'pegasus_entailment': 0.5100319772958756, 'gold_entailment': 0.12756222405005246, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7246376811594203, 'r1_recall': 0.5291005291005291, 'r1_f1': 0.6116207951070337, 'pegasus_entailment': 0.5950342059135437, 'gold_entailment': 0.39929242683574556, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.696969696969697, 'r1_recall': 0.5036496350364964, 'r1_f1': 0.5847457627118645, 'pegasus_entailment': 0.44190860725939274, 'gold_entailment': 0.1501747589558363, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7479674796747967, 'r1_recall': 0.34328358208955223, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.5013272818177938, 'gold_entailment': 0.32211712205951865, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.723404255319149, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.5528455284552847, 'pegasus_entailment': 0.6135177612304688, 'gold_entailment': 0.015590564503024021, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5504587155963303, 'r1_recall': 0.5309734513274337, 'r1_f1': 0.5405405405405406, 'pegasus_entailment': 0.7386201322078705, 'gold_entailment': 0.4633611608296633, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44166666666666665, 'r1_recall': 0.6091954022988506, 'r1_f1': 0.5120772946859904, 'pegasus_entailment': 0.4403233550838195, 'gold_entailment': 0.2997277876129374, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6838235294117647, 'r1_recall': 0.4626865671641791, 'r1_f1': 0.5519287833827894, 'pegasus_entailment': 0.7105206362903118, 'gold_entailment': 0.28242774109821767, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4380952380952381, 'r1_recall': 0.44660194174757284, 'r1_f1': 0.44230769230769235, 'pegasus_entailment': 0.07702879328280687, 'gold_entailment': 0.1647224822663702, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5376344086021505, 'r1_recall': 0.5154639175257731, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.8210054636001587, 'gold_entailment': 0.009270836832001805, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5339805825242718, 'r1_recall': 0.6547619047619048, 'r1_f1': 0.588235294117647, 'pegasus_entailment': 0.26652376614511014, 'gold_entailment': 0.011503692638749877, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5818181818181818, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.5663716814159292, 'pegasus_entailment': 0.3323156824335456, 'gold_entailment': 0.015909091525827534, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5974025974025974, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6301369863013698, 'pegasus_entailment': 0.29274866605798405, 'gold_entailment': 0.10079107837130626, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36470588235294116, 'r1_recall': 0.45588235294117646, 'r1_f1': 0.40522875816993464, 'pegasus_entailment': 0.24636570087750442, 'gold_entailment': 0.019919478756492026, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25217391304347825, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.3625, 'pegasus_entailment': 0.5313576405557493, 'gold_entailment': 0.46168379206210375, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5982905982905983, 'r1_recall': 0.42168674698795183, 'r1_f1': 0.49469964664310956, 'pegasus_entailment': 0.49531365434328717, 'gold_entailment': 0.005923802001052536, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7252747252747253, 'r1_recall': 0.4125, 'r1_f1': 0.5258964143426295, 'pegasus_entailment': 0.5512466629346212, 'gold_entailment': 0.41545692551881075, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5569620253164557, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.564102564102564, 'pegasus_entailment': 0.5825880076736212, 'gold_entailment': 0.22569418224156834, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5245901639344263, 'r1_recall': 0.4383561643835616, 'r1_f1': 0.47761194029850745, 'pegasus_entailment': 0.24018908972114636, 'gold_entailment': 0.0009346187289338559, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6029411764705882, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6332046332046332, 'pegasus_entailment': 0.561814434826374, 'gold_entailment': 0.02868825690044711, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5853658536585366, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.6, 'pegasus_entailment': 0.32735804468393326, 'gold_entailment': 0.08203304000198841, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4608294930875576, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.544959128065395, 'pegasus_entailment': 0.503326739370823, 'gold_entailment': 0.6357300877571106, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7638888888888888, 'r1_recall': 0.4661016949152542, 'r1_f1': 0.5789473684210525, 'pegasus_entailment': 0.7269394596417745, 'gold_entailment': 0.2092414831276983, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.509090909090909, 'r1_recall': 0.5045045045045045, 'r1_f1': 0.5067873303167421, 'pegasus_entailment': 0.7547014802694321, 'gold_entailment': 0.5063202772289515, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45689655172413796, 'r1_recall': 0.6309523809523809, 'r1_f1': 0.53, 'pegasus_entailment': 0.5483205223456025, 'gold_entailment': 0.44545257464051247, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.527027027027027, 'r1_recall': 0.375, 'r1_f1': 0.4382022471910112, 'pegasus_entailment': 0.29867425995568436, 'gold_entailment': 0.06647606457894047, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2807017543859649, 'r1_recall': 0.6486486486486487, 'r1_f1': 0.3918367346938776, 'pegasus_entailment': 0.6150045692920685, 'gold_entailment': 0.314837325985233, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25165562913907286, 'r1_recall': 0.7450980392156863, 'r1_f1': 0.3762376237623763, 'pegasus_entailment': 0.37299355305731297, 'gold_entailment': 0.00880358976428397, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4423076923076923, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.5168539325842696, 'pegasus_entailment': 0.34105840558186173, 'gold_entailment': 0.05889389842438201, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6989247311827957, 'r1_recall': 0.3672316384180791, 'r1_f1': 0.48148148148148145, 'pegasus_entailment': 0.5865783393383026, 'gold_entailment': 0.09212624710053205, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6694915254237288, 'r1_recall': 0.4438202247191011, 'r1_f1': 0.5337837837837837, 'pegasus_entailment': 0.4492697725072503, 'gold_entailment': 0.2924854462700231, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.625, 'r1_f1': 0.5732484076433121, 'pegasus_entailment': 0.14292586495867, 'gold_entailment': 0.2425501582523187, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.9298245614035088, 'r1_recall': 0.42231075697211157, 'r1_f1': 0.5808219178082191, 'pegasus_entailment': 0.44152803998440504, 'gold_entailment': 0.3670838716524569, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40540540540540543, 'r1_recall': 0.703125, 'r1_f1': 0.5142857142857143, 'pegasus_entailment': 0.3397351960651577, 'gold_entailment': 0.022712807054631412, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7087378640776699, 'r1_recall': 0.6033057851239669, 'r1_f1': 0.6517857142857142, 'pegasus_entailment': 0.692383247493126, 'gold_entailment': 0.4545588319451781, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5825242718446602, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5769230769230769, 'pegasus_entailment': 0.3738078557886183, 'gold_entailment': 0.05911136232316494, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5616438356164384, 'r1_recall': 0.4659090909090909, 'r1_f1': 0.5093167701863354, 'pegasus_entailment': 0.7020054906606674, 'gold_entailment': 0.36400512466207147, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4868421052631579, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.5, 'pegasus_entailment': 0.3484719673288055, 'gold_entailment': 0.007288120803423226, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7529411764705882, 'r1_recall': 0.38095238095238093, 'r1_f1': 0.5059288537549407, 'pegasus_entailment': 0.7780295461416245, 'gold_entailment': 0.20192795037291944, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6190476190476191, 'r1_recall': 0.5360824742268041, 'r1_f1': 0.574585635359116, 'pegasus_entailment': 0.5696635650238022, 'gold_entailment': 0.19540500900863358, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44, 'r1_recall': 0.6875, 'r1_f1': 0.5365853658536586, 'pegasus_entailment': 0.2889507133513689, 'gold_entailment': 0.24933623957137266, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7363636363636363, 'r1_recall': 0.6377952755905512, 'r1_f1': 0.6835443037974683, 'pegasus_entailment': 0.7058078125119209, 'gold_entailment': 0.2336283908225596, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5447154471544715, 'r1_recall': 0.6320754716981132, 'r1_f1': 0.5851528384279476, 'pegasus_entailment': 0.380093393009156, 'gold_entailment': 0.1951410264126025, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7662337662337663, 'r1_recall': 0.6145833333333334, 'r1_f1': 0.6820809248554913, 'pegasus_entailment': 0.5399165550867716, 'gold_entailment': 0.4020008137449622, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5259259259259259, 'r1_recall': 0.6173913043478261, 'r1_f1': 0.568, 'pegasus_entailment': 0.18948536304136118, 'gold_entailment': 0.33032303786603734, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6811594202898551, 'r1_recall': 0.46078431372549017, 'r1_f1': 0.5497076023391813, 'pegasus_entailment': 0.36910679171948385, 'gold_entailment': 0.01248880939965602, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.559322033898305, 'r1_recall': 0.39759036144578314, 'r1_f1': 0.4647887323943662, 'pegasus_entailment': 0.5723185690119863, 'gold_entailment': 0.2526556717431439, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4215686274509804, 'r1_recall': 0.6323529411764706, 'r1_f1': 0.5058823529411763, 'pegasus_entailment': 0.38552734795957805, 'gold_entailment': 0.025902056600898504, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5178571428571429, 'r1_recall': 0.4393939393939394, 'r1_f1': 0.47540983606557385, 'pegasus_entailment': 0.7842700779438019, 'gold_entailment': 0.05159015627577901, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 22}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8653846153846154, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.6122448979591837, 'pegasus_entailment': 0.6706927660852671, 'gold_entailment': 0.3598772197195406, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37606837606837606, 'r1_recall': 0.6111111111111112, 'r1_f1': 0.46560846560846564, 'pegasus_entailment': 0.3426515594124794, 'gold_entailment': 0.3130271037419637, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6197183098591549, 'r1_recall': 0.5176470588235295, 'r1_f1': 0.5641025641025641, 'pegasus_entailment': 0.4139571227133274, 'gold_entailment': 0.09931672131642699, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3178294573643411, 'r1_recall': 0.640625, 'r1_f1': 0.42487046632124353, 'pegasus_entailment': 0.2634296084825809, 'gold_entailment': 0.11777572860592045, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5147058823529411, 'r1_recall': 0.6730769230769231, 'r1_f1': 0.5833333333333334, 'pegasus_entailment': 0.2854803739464842, 'gold_entailment': 0.3214790391502902, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6538461538461539, 'r1_recall': 0.5930232558139535, 'r1_f1': 0.6219512195121951, 'pegasus_entailment': 0.3653844428093483, 'gold_entailment': 0.22774043946992606, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7049180327868853, 'r1_recall': 0.6417910447761194, 'r1_f1': 0.671875, 'pegasus_entailment': 0.423384428024292, 'gold_entailment': 0.31417627912014723, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46296296296296297, 'r1_recall': 0.6410256410256411, 'r1_f1': 0.5376344086021506, 'pegasus_entailment': 0.5045976460911333, 'gold_entailment': 0.3548802741376373, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.9104477611940298, 'r1_recall': 0.5922330097087378, 'r1_f1': 0.7176470588235293, 'pegasus_entailment': 0.6033501625061035, 'gold_entailment': 0.0025268626729181656, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3592233009708738, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.44047619047619047, 'pegasus_entailment': 0.8590383728345236, 'gold_entailment': 0.32636222693448264, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6557377049180327, 'r1_recall': 0.45977011494252873, 'r1_f1': 0.5405405405405406, 'pegasus_entailment': 0.029823641991242766, 'gold_entailment': 0.010584096191450953, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.6530612244897959, 'pegasus_entailment': 0.25717579014599323, 'gold_entailment': 0.27278909320011735, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4175824175824176, 'r1_recall': 0.4367816091954023, 'r1_f1': 0.4269662921348315, 'pegasus_entailment': 0.2010851345025003, 'gold_entailment': 0.005081803281791508, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2631578947368421, 'r1_recall': 0.32051282051282054, 'r1_f1': 0.28901734104046245, 'pegasus_entailment': 0.22827236462035216, 'gold_entailment': 0.08139360696077347, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31521739130434784, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.4233576642335767, 'pegasus_entailment': 0.4004605885129422, 'gold_entailment': 0.4921080159256235, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6781609195402298, 'r1_recall': 0.5673076923076923, 'r1_f1': 0.6178010471204188, 'pegasus_entailment': 0.2937048524618149, 'gold_entailment': 0.07382150056461494, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38461538461538464, 'r1_recall': 0.5, 'r1_f1': 0.4347826086956522, 'pegasus_entailment': 0.3983436788742741, 'gold_entailment': 0.014722920022904873, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6011560693641619, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.5698630136986301, 'pegasus_entailment': 0.6018160656094551, 'gold_entailment': 0.25031177792698145, 'pegasus_flesch_kincaid': 31, 'pegasus_coleman_liau': 20, 'pegasus_ari': 37, 'pegasus_smog': 28}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5192307692307693, 'r1_recall': 0.40298507462686567, 'r1_f1': 0.45378151260504207, 'pegasus_entailment': 0.689310439995357, 'gold_entailment': 0.24760632477700711, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46846846846846846, 'r1_recall': 0.7123287671232876, 'r1_f1': 0.5652173913043479, 'pegasus_entailment': 0.280494255683152, 'gold_entailment': 0.09261110844090581, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5425531914893617, 'r1_recall': 0.4358974358974359, 'r1_f1': 0.4834123222748815, 'pegasus_entailment': 0.37187854130752385, 'gold_entailment': 0.30740623342959833, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53125, 'r1_recall': 0.17525773195876287, 'r1_f1': 0.2635658914728682, 'pegasus_entailment': 0.8310293555259705, 'gold_entailment': 0.0010206935439782683, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 8}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6607142857142857, 'r1_recall': 0.4180790960451977, 'r1_f1': 0.5121107266435986, 'pegasus_entailment': 0.3343992312438786, 'gold_entailment': 0.10215407703071833, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5697674418604651, 'r1_recall': 0.5051546391752577, 'r1_f1': 0.53551912568306, 'pegasus_entailment': 0.38485937035875395, 'gold_entailment': 0.2072153844346758, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.5079365079365079, 'r1_f1': 0.48854961832061067, 'pegasus_entailment': 0.7780658364295959, 'gold_entailment': 0.27509483670084073, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3458646616541353, 'r1_recall': 0.7076923076923077, 'r1_f1': 0.46464646464646464, 'pegasus_entailment': 0.508605902393659, 'gold_entailment': 0.14007700545092425, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.4017857142857143, 'r1_f1': 0.46632124352331605, 'pegasus_entailment': 0.4487468209117651, 'gold_entailment': 0.2106939643029667, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.4918032786885246, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.3365622299024835, 'gold_entailment': 0.16289969899420007, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5789473684210527, 'r1_recall': 0.5851063829787234, 'r1_f1': 0.582010582010582, 'pegasus_entailment': 0.23877327889204025, 'gold_entailment': 0.24424410810752306, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5234899328859061, 'r1_recall': 0.6782608695652174, 'r1_f1': 0.5909090909090909, 'pegasus_entailment': 0.7629892900586128, 'gold_entailment': 0.5398162460769527, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5346534653465347, 'r1_recall': 0.48214285714285715, 'r1_f1': 0.5070422535211268, 'pegasus_entailment': 0.44093731947941706, 'gold_entailment': 0.18405530814197846, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.484375, 'r1_recall': 0.775, 'r1_f1': 0.5961538461538463, 'pegasus_entailment': 0.8966404795646667, 'gold_entailment': 0.24583088629879057, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 14, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6805555555555556, 'r1_recall': 0.3798449612403101, 'r1_f1': 0.4875621890547264, 'pegasus_entailment': 0.5789312332868576, 'gold_entailment': 0.3232078010623809, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 14}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.56, 'r1_recall': 0.5436893203883495, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.3965406793480118, 'gold_entailment': 0.19325701035559179, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6090909090909091, 'r1_recall': 0.41875, 'r1_f1': 0.4962962962962963, 'pegasus_entailment': 0.9215968400239944, 'gold_entailment': 0.37028427643235773, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.411214953271028, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.48351648351648346, 'pegasus_entailment': 0.30902766516166075, 'gold_entailment': 0.0054777064942754805, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 12, 'pegasus_smog': 15}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36666666666666664, 'r1_recall': 0.55, 'r1_f1': 0.43999999999999995, 'pegasus_entailment': 0.3399213250959292, 'gold_entailment': 0.2879380777303595, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7796610169491526, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.71875, 'pegasus_entailment': 0.5240619778633118, 'gold_entailment': 0.0028005311420808234, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6210526315789474, 'r1_recall': 0.44360902255639095, 'r1_f1': 0.5175438596491229, 'pegasus_entailment': 0.1293617055285722, 'gold_entailment': 0.2606157793973883, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5666666666666667, 'r1_recall': 0.6455696202531646, 'r1_f1': 0.6035502958579881, 'pegasus_entailment': 0.19906429497641512, 'gold_entailment': 0.027625810558674857, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5045871559633027, 'r1_recall': 0.6179775280898876, 'r1_f1': 0.5555555555555556, 'pegasus_entailment': 0.5277330800890923, 'gold_entailment': 0.2803387891035527, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5595238095238095, 'r1_recall': 0.36153846153846153, 'r1_f1': 0.4392523364485981, 'pegasus_entailment': 0.5890341326594353, 'gold_entailment': 0.051035483328936, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7857142857142857, 'r1_recall': 0.43258426966292135, 'r1_f1': 0.5579710144927537, 'pegasus_entailment': 0.26311596334562637, 'gold_entailment': 0.24687484792749664, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7704918032786885, 'r1_recall': 0.5340909090909091, 'r1_f1': 0.6308724832214765, 'pegasus_entailment': 0.6499330081045628, 'gold_entailment': 0.2433036213208522, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6619718309859155, 'r1_recall': 0.35074626865671643, 'r1_f1': 0.4585365853658537, 'pegasus_entailment': 0.5880276188254356, 'gold_entailment': 0.27043046251734876, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5779816513761468, 'r1_recall': 0.6702127659574468, 'r1_f1': 0.6206896551724137, 'pegasus_entailment': 0.35390414234716444, 'gold_entailment': 0.24935442340211011, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6597938144329897, 'r1_recall': 0.5039370078740157, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.721829253481701, 'gold_entailment': 0.22070375189650804, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.6818181818181818, 'r1_f1': 0.6382978723404256, 'pegasus_entailment': 0.9416256427764893, 'gold_entailment': 0.21524390609314045, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5362318840579711, 'r1_recall': 0.6434782608695652, 'r1_f1': 0.5849802371541502, 'pegasus_entailment': 0.5366210609674453, 'gold_entailment': 0.3702662718482316, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5043478260869565, 'r1_recall': 0.7631578947368421, 'r1_f1': 0.6073298429319371, 'pegasus_entailment': 0.48745249658168177, 'gold_entailment': 0.3554566759848967, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2716049382716049, 'r1_recall': 0.5116279069767442, 'r1_f1': 0.3548387096774193, 'pegasus_entailment': 0.562460158020258, 'gold_entailment': 0.01464249286800623, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5757575757575758, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.6229508196721312, 'pegasus_entailment': 0.5993808594648726, 'gold_entailment': 0.3292876113555394, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.71, 'r1_recall': 0.5419847328244275, 'r1_f1': 0.6147186147186147, 'pegasus_entailment': 0.6962699145078659, 'gold_entailment': 0.41731602310513455, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5753424657534246, 'r1_recall': 0.525, 'r1_f1': 0.5490196078431373, 'pegasus_entailment': 0.3251475626602769, 'gold_entailment': 0.027341503649950027, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6046511627906976, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6341463414634145, 'pegasus_entailment': 0.5917298505082726, 'gold_entailment': 0.0948668682637314, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5892857142857143, 'r1_recall': 0.5689655172413793, 'r1_f1': 0.5789473684210527, 'pegasus_entailment': 0.654145411370943, 'gold_entailment': 0.33560684342713404, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37606837606837606, 'r1_recall': 0.7457627118644068, 'r1_f1': 0.5, 'pegasus_entailment': 0.43481184873380696, 'gold_entailment': 0.010135449934750795, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6752136752136753, 'r1_recall': 0.41798941798941797, 'r1_f1': 0.5163398692810458, 'pegasus_entailment': 0.4193103783763945, 'gold_entailment': 0.31414767587557435, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6979166666666666, 'r1_recall': 0.5537190082644629, 'r1_f1': 0.6175115207373272, 'pegasus_entailment': 0.34355782584752886, 'gold_entailment': 0.021695081299791735, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 19}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8089887640449438, 'r1_recall': 0.4645161290322581, 'r1_f1': 0.5901639344262295, 'pegasus_entailment': 0.3588978385552764, 'gold_entailment': 0.3934296232847763, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.4785276073619632, 'r1_f1': 0.5571428571428572, 'pegasus_entailment': 0.3505717325024307, 'gold_entailment': 0.3253201162442565, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6521739130434783, 'r1_recall': 0.44554455445544555, 'r1_f1': 0.5294117647058824, 'pegasus_entailment': 0.80759729941686, 'gold_entailment': 0.06252948252949864, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6333333333333333, 'r1_recall': 0.628099173553719, 'r1_f1': 0.6307053941908712, 'pegasus_entailment': 0.3746421579271555, 'gold_entailment': 0.33295263536274433, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5742574257425742, 'r1_recall': 0.6236559139784946, 'r1_f1': 0.5979381443298969, 'pegasus_entailment': 0.25476562953554094, 'gold_entailment': 0.022056845351471566, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.639344262295082, 'r1_recall': 0.5864661654135338, 'r1_f1': 0.611764705882353, 'pegasus_entailment': 0.72725685313344, 'gold_entailment': 0.27616727259010077, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6737588652482269, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.5828220858895706, 'pegasus_entailment': 0.6758889885885375, 'gold_entailment': 0.4200023238857587, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4393939393939394, 'r1_recall': 0.5, 'r1_f1': 0.46774193548387094, 'pegasus_entailment': 0.26392701498116367, 'gold_entailment': 0.005274812923744321, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4351145038167939, 'r1_recall': 0.6477272727272727, 'r1_f1': 0.5205479452054794, 'pegasus_entailment': 0.44826247077435255, 'gold_entailment': 0.3115156617326041, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.4838709677419355, 'r1_f1': 0.4918032786885246, 'pegasus_entailment': 0.07375580945517868, 'gold_entailment': 0.02143715093067537, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44525547445255476, 'r1_recall': 0.5398230088495575, 'r1_f1': 0.488, 'pegasus_entailment': 0.7651241533458233, 'gold_entailment': 0.15978559599413225, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7093023255813954, 'r1_recall': 0.7625, 'r1_f1': 0.7349397590361445, 'pegasus_entailment': 0.7659208625555038, 'gold_entailment': 0.5342138476669789, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5681818181818182, 'r1_recall': 0.49504950495049505, 'r1_f1': 0.5291005291005291, 'pegasus_entailment': 0.43404220665494603, 'gold_entailment': 0.06302082385601741, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7790697674418605, 'r1_recall': 0.32057416267942584, 'r1_f1': 0.4542372881355932, 'pegasus_entailment': 0.9673373401165009, 'gold_entailment': 0.38009447427466514, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7404580152671756, 'r1_recall': 0.5359116022099447, 'r1_f1': 0.6217948717948717, 'pegasus_entailment': 0.7057377227715084, 'gold_entailment': 0.3671376517042518, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39705882352941174, 'r1_recall': 0.4576271186440678, 'r1_f1': 0.42519685039370075, 'pegasus_entailment': 0.9423661530017853, 'gold_entailment': 0.13886075606569648, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8904109589041096, 'r1_recall': 0.4012345679012346, 'r1_f1': 0.5531914893617021, 'pegasus_entailment': 0.7128929098447164, 'gold_entailment': 0.33443761414382606, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3680555555555556, 'r1_recall': 0.6463414634146342, 'r1_f1': 0.46902654867256643, 'pegasus_entailment': 0.6511203348636627, 'gold_entailment': 0.663445753355821, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4791666666666667, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.4791666666666667, 'pegasus_entailment': 0.5257234312593937, 'gold_entailment': 0.198974754428491, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6447368421052632, 'r1_recall': 0.532608695652174, 'r1_f1': 0.5833333333333334, 'pegasus_entailment': 0.3774135500813524, 'gold_entailment': 0.04241593601182103, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7572815533980582, 'r1_recall': 0.4020618556701031, 'r1_f1': 0.5252525252525252, 'pegasus_entailment': 0.6101529039442539, 'gold_entailment': 0.15586982534400054, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6783216783216783, 'r1_recall': 0.5843373493975904, 'r1_f1': 0.627831715210356, 'pegasus_entailment': 0.3041992075741291, 'gold_entailment': 0.20085423492959567, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38, 'r1_recall': 0.6440677966101694, 'r1_f1': 0.47798742138364775, 'pegasus_entailment': 0.21964321448467672, 'gold_entailment': 0.002972567919641733, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7355371900826446, 'r1_recall': 0.5144508670520231, 'r1_f1': 0.6054421768707483, 'pegasus_entailment': 0.4642699871212244, 'gold_entailment': 0.1839782089394118, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5061728395061729, 'r1_recall': 0.5061728395061729, 'r1_f1': 0.5061728395061729, 'pegasus_entailment': 0.1746000498533249, 'gold_entailment': 0.3589815981686115, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5686274509803921, 'r1_recall': 0.38926174496644295, 'r1_f1': 0.46215139442231074, 'pegasus_entailment': 0.3325631931424141, 'gold_entailment': 0.08266813094087411, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5411764705882353, 'r1_recall': 0.4946236559139785, 'r1_f1': 0.5168539325842697, 'pegasus_entailment': 0.6236615212013324, 'gold_entailment': 0.2584891891456209, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6134453781512605, 'r1_recall': 0.453416149068323, 'r1_f1': 0.5214285714285714, 'pegasus_entailment': 0.18703127776583037, 'gold_entailment': 0.06287483279205237, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.20930232558139536, 'r1_recall': 0.23684210526315788, 'r1_f1': 0.2222222222222222, 'pegasus_entailment': 0.5882313549518585, 'gold_entailment': 0.0002462119737174362, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6388888888888888, 'r1_recall': 0.6388888888888888, 'r1_f1': 0.6388888888888888, 'pegasus_entailment': 0.4943700722651556, 'gold_entailment': 0.33109264184410375, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6176470588235294, 'r1_recall': 0.6116504854368932, 'r1_f1': 0.6146341463414634, 'pegasus_entailment': 0.43753035895497305, 'gold_entailment': 0.28686609491705894, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5573770491803278, 'r1_recall': 0.4171779141104294, 'r1_f1': 0.4771929824561403, 'pegasus_entailment': 0.37455300979282974, 'gold_entailment': 0.1394978474272648, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6907216494845361, 'r1_recall': 0.6146788990825688, 'r1_f1': 0.6504854368932039, 'pegasus_entailment': 0.7094156950712204, 'gold_entailment': 0.5645411745645106, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6048387096774194, 'r1_recall': 0.42613636363636365, 'r1_f1': 0.5, 'pegasus_entailment': 0.5305121809244155, 'gold_entailment': 0.1590146694332361, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6875, 'r1_recall': 0.44, 'r1_f1': 0.5365853658536586, 'pegasus_entailment': 0.46977350730448963, 'gold_entailment': 0.22371671320870518, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6097560975609756, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.5703422053231939, 'pegasus_entailment': 0.5972712238629659, 'gold_entailment': 0.4046614480515321, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 19}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6228070175438597, 'r1_recall': 0.47651006711409394, 'r1_f1': 0.5399239543726236, 'pegasus_entailment': 0.6848507449030876, 'gold_entailment': 0.34883356392383574, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5308641975308642, 'r1_recall': 0.4725274725274725, 'r1_f1': 0.5, 'pegasus_entailment': 0.6755855840941271, 'gold_entailment': 0.5677311271429062, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44696969696969696, 'r1_recall': 0.7662337662337663, 'r1_f1': 0.5645933014354068, 'pegasus_entailment': 0.9044992923736572, 'gold_entailment': 0.0814288374191771, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 16, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5168539325842697, 'r1_recall': 0.6301369863013698, 'r1_f1': 0.5679012345679012, 'pegasus_entailment': 0.03807492763735354, 'gold_entailment': 0.02381990826688707, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7682926829268293, 'r1_recall': 0.3423913043478261, 'r1_f1': 0.4736842105263158, 'pegasus_entailment': 0.6411250059803327, 'gold_entailment': 0.54771210367863, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4228187919463087, 'r1_recall': 0.5727272727272728, 'r1_f1': 0.4864864864864865, 'pegasus_entailment': 0.3249283842742443, 'gold_entailment': 0.001808253660177191, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4752475247524752, 'r1_recall': 0.3870967741935484, 'r1_f1': 0.42666666666666664, 'pegasus_entailment': 0.31718048662878573, 'gold_entailment': 0.5580400824546814, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4892086330935252, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.5250965250965252, 'pegasus_entailment': 0.5070431732262174, 'gold_entailment': 0.22619591635884717, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8195488721804511, 'r1_recall': 0.46382978723404256, 'r1_f1': 0.5923913043478262, 'pegasus_entailment': 0.5229136869311333, 'gold_entailment': 0.38160161301493645, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5357142857142857, 'r1_recall': 0.4934210526315789, 'r1_f1': 0.5136986301369864, 'pegasus_entailment': 0.3612188698723912, 'gold_entailment': 0.05874744094908237, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5882352941176471, 'r1_recall': 0.5813953488372093, 'r1_f1': 0.5847953216374269, 'pegasus_entailment': 0.6307509578764439, 'gold_entailment': 0.02096173178870231, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5057471264367817, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.54320987654321, 'pegasus_entailment': 0.07273960392922163, 'gold_entailment': 0.20032430983458957, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53, 'r1_recall': 0.5888888888888889, 'r1_f1': 0.5578947368421053, 'pegasus_entailment': 0.9850848714510599, 'gold_entailment': 0.504080613454183, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7345132743362832, 'r1_recall': 0.5060975609756098, 'r1_f1': 0.5992779783393501, 'pegasus_entailment': 0.6830789617129734, 'gold_entailment': 0.339770695194602, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 18}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7583892617449665, 'r1_recall': 0.39372822299651566, 'r1_f1': 0.518348623853211, 'pegasus_entailment': 0.3225774536175387, 'gold_entailment': 0.23181276426961026, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8235294117647058, 'r1_recall': 0.3128491620111732, 'r1_f1': 0.4534412955465587, 'pegasus_entailment': 0.6246784276639422, 'gold_entailment': 0.03074419335462153, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7439024390243902, 'r1_recall': 0.5350877192982456, 'r1_f1': 0.6224489795918368, 'pegasus_entailment': 0.479183021991048, 'gold_entailment': 0.25848491934593765, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6862745098039216, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.6034482758620688, 'pegasus_entailment': 0.516090142307803, 'gold_entailment': 0.5533336125314235, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4818181818181818, 'r1_recall': 0.5096153846153846, 'r1_f1': 0.4953271028037383, 'pegasus_entailment': 0.5400607526302338, 'gold_entailment': 0.0710173062980175, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.415929203539823, 'r1_recall': 0.5595238095238095, 'r1_f1': 0.47715736040609136, 'pegasus_entailment': 0.8129773736000061, 'gold_entailment': 0.19302948378026485, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8269230769230769, 'r1_recall': 0.5308641975308642, 'r1_f1': 0.6466165413533835, 'pegasus_entailment': 0.7102408945560456, 'gold_entailment': 0.49500663485378027, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5436893203883495, 'r1_recall': 0.7272727272727273, 'r1_f1': 0.6222222222222222, 'pegasus_entailment': 0.22741158184362575, 'gold_entailment': 0.003454604040598497, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.75, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.6562499999999999, 'pegasus_entailment': 0.6127104905899614, 'gold_entailment': 0.35575533541850746, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6024096385542169, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6329113924050633, 'pegasus_entailment': 0.62901762931142, 'gold_entailment': 0.38311329390853643, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5495495495495496, 'r1_recall': 0.5041322314049587, 'r1_f1': 0.5258620689655172, 'pegasus_entailment': 0.7160491431131959, 'gold_entailment': 0.20544776605674997, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7261904761904762, 'r1_recall': 0.5495495495495496, 'r1_f1': 0.6256410256410256, 'pegasus_entailment': 0.29928617243422195, 'gold_entailment': 0.3137748767621815, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5496688741721855, 'r1_recall': 0.50920245398773, 'r1_f1': 0.5286624203821655, 'pegasus_entailment': 0.381175072863698, 'gold_entailment': 0.021201242537548144, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49696969696969695, 'r1_recall': 0.4659090909090909, 'r1_f1': 0.48093841642228735, 'pegasus_entailment': 0.3516460880637169, 'gold_entailment': 0.23394982190802693, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.5625, 'r1_f1': 0.5625, 'pegasus_entailment': 0.28509345394559205, 'gold_entailment': 0.3005784136087944, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4264705882352941, 'r1_recall': 0.48333333333333334, 'r1_f1': 0.453125, 'pegasus_entailment': 0.39957867879420517, 'gold_entailment': 0.003603041041060351, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 19}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3153153153153153, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.40935672514619886, 'pegasus_entailment': 0.33621001647770754, 'gold_entailment': 0.0018994855345226824, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40939597315436244, 'r1_recall': 0.6224489795918368, 'r1_f1': 0.4939271255060728, 'pegasus_entailment': 0.19197821733541787, 'gold_entailment': 0.05680684093385935, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.56, 'r1_recall': 0.6461538461538462, 'r1_f1': 0.6000000000000002, 'pegasus_entailment': 0.6020321011543274, 'gold_entailment': 0.2639408547464492, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32978723404255317, 'r1_recall': 0.6739130434782609, 'r1_f1': 0.4428571428571428, 'pegasus_entailment': 0.45462280831998214, 'gold_entailment': 0.4225430488586426, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6179775280898876, 'r1_recall': 0.4824561403508772, 'r1_f1': 0.541871921182266, 'pegasus_entailment': 0.42267968284431845, 'gold_entailment': 0.3352835906203836, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4676258992805755, 'r1_recall': 0.5855855855855856, 'r1_f1': 0.52, 'pegasus_entailment': 0.2980055453787957, 'gold_entailment': 0.1415576322137245, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7577639751552795, 'r1_recall': 0.5570776255707762, 'r1_f1': 0.6421052631578947, 'pegasus_entailment': 0.6625527501106262, 'gold_entailment': 0.3365282346494496, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7105263157894737, 'r1_recall': 0.6585365853658537, 'r1_f1': 0.6835443037974684, 'pegasus_entailment': 0.340712308883667, 'gold_entailment': 0.5634128160454566, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44166666666666665, 'r1_recall': 0.6022727272727273, 'r1_f1': 0.5096153846153846, 'pegasus_entailment': 0.211235089157708, 'gold_entailment': 0.03001552473870106, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5876288659793815, 'r1_recall': 0.5643564356435643, 'r1_f1': 0.5757575757575757, 'pegasus_entailment': 0.40095954822997254, 'gold_entailment': 0.18287195661105216, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5412844036697247, 'r1_recall': 0.5462962962962963, 'r1_f1': 0.543778801843318, 'pegasus_entailment': 0.7857366442680359, 'gold_entailment': 0.30934562472005683, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2727272727272727, 'r1_recall': 0.625, 'r1_f1': 0.37974683544303794, 'pegasus_entailment': 0.3567398935556412, 'gold_entailment': 0.04509264696389437, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7285714285714285, 'r1_recall': 0.5151515151515151, 'r1_f1': 0.603550295857988, 'pegasus_entailment': 0.8290129780769349, 'gold_entailment': 0.311695466004312, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.555, 'r1_recall': 0.7025316455696202, 'r1_f1': 0.6201117318435755, 'pegasus_entailment': 0.5589731499552727, 'gold_entailment': 0.08243136868501703, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6373626373626373, 'r1_recall': 0.3670886075949367, 'r1_f1': 0.46586345381526106, 'pegasus_entailment': 0.28746329445857555, 'gold_entailment': 0.2680985786020756, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5735294117647058, 'r1_recall': 0.40414507772020725, 'r1_f1': 0.4741641337386018, 'pegasus_entailment': 0.6155424788594246, 'gold_entailment': 0.43964486651950413, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7333333333333333, 'r1_recall': 0.6285714285714286, 'r1_f1': 0.6769230769230768, 'pegasus_entailment': 0.4965590584324673, 'gold_entailment': 0.32979611528571695, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 22, 'pegasus_ari': 33, 'pegasus_smog': 25}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6274509803921569, 'r1_recall': 0.512, 'r1_f1': 0.5638766519823789, 'pegasus_entailment': 0.43384451046586037, 'gold_entailment': 0.08927983427420258, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.23076923076923078, 'r1_f1': 0.27272727272727276, 'pegasus_entailment': 0.7482120196024576, 'gold_entailment': 0.0036184138928850493, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 23, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4603174603174603, 'r1_recall': 0.47540983606557374, 'r1_f1': 0.4677419354838709, 'pegasus_entailment': 0.33668629731982946, 'gold_entailment': 0.10906377496818702, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43010752688172044, 'r1_recall': 0.6451612903225806, 'r1_f1': 0.5161290322580645, 'pegasus_entailment': 0.007378987516858615, 'gold_entailment': 0.38358987448737025, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40350877192982454, 'r1_recall': 0.3898305084745763, 'r1_f1': 0.39655172413793105, 'pegasus_entailment': 0.6874921303242445, 'gold_entailment': 0.0031891451799310744, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44025157232704404, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.5128205128205129, 'pegasus_entailment': 0.6429469244820731, 'gold_entailment': 0.5800268699725469, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5185185185185185, 'r1_recall': 0.42424242424242425, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.46867324016056955, 'gold_entailment': 0.057610757454919316, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19672131147540983, 'r1_recall': 0.6, 'r1_f1': 0.2962962962962963, 'pegasus_entailment': 0.4252420935081318, 'gold_entailment': 0.42836131097283214, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.711864406779661, 'r1_recall': 0.48554913294797686, 'r1_f1': 0.577319587628866, 'pegasus_entailment': 0.6476539503782988, 'gold_entailment': 0.12457424309104681, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6162790697674418, 'r1_recall': 0.6625, 'r1_f1': 0.6385542168674699, 'pegasus_entailment': 0.044392283918568864, 'gold_entailment': 0.03427665197887109, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7945205479452054, 'r1_recall': 0.3258426966292135, 'r1_f1': 0.4621513944223108, 'pegasus_entailment': 0.31593575049191713, 'gold_entailment': 0.09884997582994401, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7530864197530864, 'r1_recall': 0.37888198757763975, 'r1_f1': 0.5041322314049587, 'pegasus_entailment': 0.7950907945632935, 'gold_entailment': 0.15516045350315316, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6463414634146342, 'r1_recall': 0.39552238805970147, 'r1_f1': 0.4907407407407407, 'pegasus_entailment': 0.6314116376452148, 'gold_entailment': 0.06730668067466468, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 13, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7672413793103449, 'r1_recall': 0.3662551440329218, 'r1_f1': 0.4958217270194986, 'pegasus_entailment': 0.6292814873158932, 'gold_entailment': 0.27112308647483585, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39166666666666666, 'r1_recall': 0.573170731707317, 'r1_f1': 0.46534653465346526, 'pegasus_entailment': 0.5208515226840973, 'gold_entailment': 0.5294595460096995, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7662337662337663, 'r1_recall': 0.3881578947368421, 'r1_f1': 0.5152838427947598, 'pegasus_entailment': 0.4992707297205925, 'gold_entailment': 0.06761881533020642, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34513274336283184, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.4216216216216216, 'pegasus_entailment': 0.4195217625470832, 'gold_entailment': 0.22670593694783747, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7870370370370371, 'r1_recall': 0.3811659192825112, 'r1_f1': 0.5135951661631419, 'pegasus_entailment': 0.17035223173055178, 'gold_entailment': 0.1073622293452817, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36666666666666664, 'r1_recall': 0.2920353982300885, 'r1_f1': 0.32512315270935954, 'pegasus_entailment': 0.21574172377586365, 'gold_entailment': 0.07191874622367322, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.352112676056338, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.42735042735042733, 'pegasus_entailment': 0.8414978086948395, 'gold_entailment': 0.4974274029639976, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6842105263157895, 'r1_recall': 0.430939226519337, 'r1_f1': 0.528813559322034, 'pegasus_entailment': 0.24076170176267625, 'gold_entailment': 0.08180488791549578, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7207207207207207, 'r1_recall': 0.4519774011299435, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.5474029749631881, 'gold_entailment': 0.15600617180461995, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7108433734939759, 'r1_recall': 0.6145833333333334, 'r1_f1': 0.659217877094972, 'pegasus_entailment': 0.7607777441851795, 'gold_entailment': 0.3479201185517013, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5981308411214953, 'r1_recall': 0.4413793103448276, 'r1_f1': 0.5079365079365079, 'pegasus_entailment': 0.5041871730770383, 'gold_entailment': 0.40805146523884367, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.14736842105263157, 'r1_recall': 0.5, 'r1_f1': 0.2276422764227642, 'pegasus_entailment': 0.014449869137024507, 'gold_entailment': 0.003302033437648788, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2328767123287671, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.33333333333333337, 'pegasus_entailment': 0.4366711188107729, 'gold_entailment': 0.09184245759388432, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5074626865671642, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5375494071146245, 'pegasus_entailment': 0.011335398943629116, 'gold_entailment': 0.03343511426161664, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.532608695652174, 'r1_recall': 0.6901408450704225, 'r1_f1': 0.6012269938650308, 'pegasus_entailment': 0.8663382679224014, 'gold_entailment': 0.6479703333849708, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2978723404255319, 'r1_recall': 0.509090909090909, 'r1_f1': 0.37583892617449666, 'pegasus_entailment': 0.22369944884849247, 'gold_entailment': 0.25635356111160945, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3360655737704918, 'r1_recall': 0.5061728395061729, 'r1_f1': 0.4039408866995074, 'pegasus_entailment': 0.4580624238587916, 'gold_entailment': 0.14271074713906273, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5974025974025974, 'r1_recall': 0.5679012345679012, 'r1_f1': 0.5822784810126583, 'pegasus_entailment': 0.008928001237412294, 'gold_entailment': 0.2478017013054341, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5875, 'r1_recall': 0.5662650602409639, 'r1_f1': 0.5766871165644172, 'pegasus_entailment': 0.9564090371131897, 'gold_entailment': 0.29496601323383703, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5630252100840336, 'r1_recall': 0.6036036036036037, 'r1_f1': 0.582608695652174, 'pegasus_entailment': 0.48437426998862065, 'gold_entailment': 0.3301144435070455, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7523809523809524, 'r1_recall': 0.23511904761904762, 'r1_f1': 0.3582766439909297, 'pegasus_entailment': 0.841810142993927, 'gold_entailment': 0.08264255163852464, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6835443037974683, 'r1_recall': 0.24324324324324326, 'r1_f1': 0.3588039867109634, 'pegasus_entailment': 0.3130762013606727, 'gold_entailment': 0.3371740136295557, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5774647887323944, 'r1_recall': 0.5256410256410257, 'r1_f1': 0.5503355704697986, 'pegasus_entailment': 0.3849268506746739, 'gold_entailment': 0.05554160289466381, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6732673267326733, 'r1_recall': 0.6538461538461539, 'r1_f1': 0.6634146341463415, 'pegasus_entailment': 0.6319401562213898, 'gold_entailment': 0.1625473378226161, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2644628099173554, 'r1_recall': 0.4383561643835616, 'r1_f1': 0.32989690721649484, 'pegasus_entailment': 0.7314768563956022, 'gold_entailment': 0.17788732913322747, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4117647058823529, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.06955501798074692, 'gold_entailment': 0.21420522220432758, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5168539325842697, 'r1_recall': 0.6388888888888888, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.3347167316824198, 'gold_entailment': 0.3212378239259124, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5434782608695652, 'r1_recall': 0.6172839506172839, 'r1_f1': 0.5780346820809249, 'pegasus_entailment': 0.5380321651076277, 'gold_entailment': 0.28543193395307753, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5970149253731343, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5594405594405594, 'pegasus_entailment': 0.5394322052598, 'gold_entailment': 0.44018124463036656, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5882352941176471, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.08547811198513955, 'gold_entailment': 0.2685792502947152, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7777777777777778, 'r1_recall': 0.35668789808917195, 'r1_f1': 0.48908296943231433, 'pegasus_entailment': 0.7039915521939596, 'gold_entailment': 0.3599003533932513, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7395833333333334, 'r1_recall': 0.4930555555555556, 'r1_f1': 0.5916666666666668, 'pegasus_entailment': 0.42822985351085663, 'gold_entailment': 0.44106532353907824, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45038167938931295, 'r1_recall': 0.6276595744680851, 'r1_f1': 0.5244444444444445, 'pegasus_entailment': 0.40645865475138027, 'gold_entailment': 0.0017215791449416429, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7094594594594594, 'r1_recall': 0.5497382198952879, 'r1_f1': 0.6194690265486725, 'pegasus_entailment': 0.3697031501214951, 'gold_entailment': 0.09731114338501357, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3253012048192771, 'r1_recall': 0.5510204081632653, 'r1_f1': 0.409090909090909, 'pegasus_entailment': 0.5650121122598648, 'gold_entailment': 0.00023849141143728048, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5571428571428572, 'r1_recall': 0.46987951807228917, 'r1_f1': 0.5098039215686274, 'pegasus_entailment': 0.624326890334487, 'gold_entailment': 0.5929678529500961, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 12, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5445544554455446, 'r1_recall': 0.7051282051282052, 'r1_f1': 0.6145251396648044, 'pegasus_entailment': 0.013665193959604948, 'gold_entailment': 0.014386487723095342, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 12}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6857142857142857, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.6357615894039735, 'pegasus_entailment': 0.26649860391626135, 'gold_entailment': 0.1039759695995599, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.673469387755102, 'r1_recall': 0.48175182481751827, 'r1_f1': 0.5617021276595745, 'pegasus_entailment': 0.7614093005657196, 'gold_entailment': 0.03222642242908478, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24731182795698925, 'r1_recall': 0.5227272727272727, 'r1_f1': 0.3357664233576642, 'pegasus_entailment': 0.31458551265920204, 'gold_entailment': 0.019062668085098267, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.391304347826087, 'r1_recall': 0.4576271186440678, 'r1_f1': 0.42187499999999994, 'pegasus_entailment': 0.30805302287141484, 'gold_entailment': 0.0034421124146319926, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5982142857142857, 'r1_recall': 0.5, 'r1_f1': 0.5447154471544716, 'pegasus_entailment': 0.6165195412933826, 'gold_entailment': 0.09716415498405695, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5905511811023622, 'r1_recall': 0.4807692307692308, 'r1_f1': 0.5300353356890459, 'pegasus_entailment': 0.26607830170542, 'gold_entailment': 0.1018463154323399, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47706422018348627, 'r1_recall': 0.8, 'r1_f1': 0.5977011494252874, 'pegasus_entailment': 0.7697935104370117, 'gold_entailment': 0.22090823482722044, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48, 'r1_recall': 0.4090909090909091, 'r1_f1': 0.44171779141104295, 'pegasus_entailment': 0.300572800822556, 'gold_entailment': 0.191440761196039, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4791666666666667, 'r1_recall': 0.5476190476190477, 'r1_f1': 0.5111111111111111, 'pegasus_entailment': 0.12117414238552253, 'gold_entailment': 0.18969687803958854, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5529411764705883, 'r1_recall': 0.6103896103896104, 'r1_f1': 0.580246913580247, 'pegasus_entailment': 0.17832360393367708, 'gold_entailment': 0.24578517892708382, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3221476510067114, 'r1_recall': 0.6, 'r1_f1': 0.4192139737991266, 'pegasus_entailment': 0.17699069413356483, 'gold_entailment': 0.10468763982256253, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6333333333333333, 'r1_recall': 0.6089743589743589, 'r1_f1': 0.6209150326797385, 'pegasus_entailment': 0.6460923582315445, 'gold_entailment': 0.29913101717829704, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4479166666666667, 'r1_recall': 0.5657894736842105, 'r1_f1': 0.5, 'pegasus_entailment': 0.6381045629580816, 'gold_entailment': 0.27206460510691005, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4387755102040816, 'r1_recall': 0.5058823529411764, 'r1_f1': 0.46994535519125685, 'pegasus_entailment': 0.7569282501935959, 'gold_entailment': 0.4563592907041311, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6173913043478261, 'r1_recall': 0.5419847328244275, 'r1_f1': 0.5772357723577235, 'pegasus_entailment': 0.3799628489650786, 'gold_entailment': 0.33324718770260614, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43373493975903615, 'r1_recall': 0.33962264150943394, 'r1_f1': 0.38095238095238093, 'pegasus_entailment': 0.06881974426505622, 'gold_entailment': 0.03509427944663912, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7863247863247863, 'r1_recall': 0.5027322404371585, 'r1_f1': 0.6133333333333333, 'pegasus_entailment': 0.5134050771594048, 'gold_entailment': 0.19662720896303654, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.525, 'r1_recall': 0.5526315789473685, 'r1_f1': 0.5384615384615385, 'pegasus_entailment': 0.5130241041382154, 'gold_entailment': 0.16649230499751866, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5096153846153846, 'r1_recall': 0.5760869565217391, 'r1_f1': 0.5408163265306122, 'pegasus_entailment': 0.3536387160420418, 'gold_entailment': 0.016274707779909175, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7421875, 'r1_recall': 0.4398148148148148, 'r1_f1': 0.5523255813953488, 'pegasus_entailment': 0.5199919670820237, 'gold_entailment': 0.3492555374590059, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.5445544554455446, 'r1_f1': 0.49549549549549543, 'pegasus_entailment': 0.2542641279986128, 'gold_entailment': 0.007100868911948055, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5603448275862069, 'r1_recall': 0.6632653061224489, 'r1_f1': 0.6074766355140186, 'pegasus_entailment': 0.4275352228432894, 'gold_entailment': 0.06982249487191439, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49411764705882355, 'r1_recall': 0.6, 'r1_f1': 0.5419354838709677, 'pegasus_entailment': 0.11379037595664461, 'gold_entailment': 0.004340019174075375, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6181818181818182, 'r1_recall': 0.7669172932330827, 'r1_f1': 0.6845637583892618, 'pegasus_entailment': 0.3101883081586233, 'gold_entailment': 0.5384520422667265, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.65625, 'r1_recall': 0.7, 'r1_f1': 0.6774193548387096, 'pegasus_entailment': 0.5553869891911745, 'gold_entailment': 0.04944873166580995, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5802469135802469, 'r1_recall': 0.40869565217391307, 'r1_f1': 0.47959183673469397, 'pegasus_entailment': 0.6172795618573824, 'gold_entailment': 0.322126754373312, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40601503759398494, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.4426229508196721, 'pegasus_entailment': 0.40322832718957213, 'gold_entailment': 0.2284281748967866, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.935064935064935, 'r1_recall': 0.5217391304347826, 'r1_f1': 0.6697674418604651, 'pegasus_entailment': 0.9135077446699142, 'gold_entailment': 0.49132075704013306, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23275862068965517, 'r1_recall': 0.54, 'r1_f1': 0.3253012048192771, 'pegasus_entailment': 0.20506709729379508, 'gold_entailment': 0.033270104351686314, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29927007299270075, 'r1_recall': 0.7321428571428571, 'r1_f1': 0.4248704663212435, 'pegasus_entailment': 0.20295782574248733, 'gold_entailment': 0.3894663726290067, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.15126050420168066, 'r1_recall': 0.3829787234042553, 'r1_f1': 0.21686746987951805, 'pegasus_entailment': 0.4087790506891906, 'gold_entailment': 0.05974087864160538, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39759036144578314, 'r1_recall': 0.4647887323943662, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.15273900772444904, 'gold_entailment': 0.07257843950792449, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7415730337078652, 'r1_recall': 0.36065573770491804, 'r1_f1': 0.4852941176470588, 'pegasus_entailment': 0.6114680195848147, 'gold_entailment': 0.3595136635703966, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5352112676056338, 'r1_recall': 0.5547445255474452, 'r1_f1': 0.5448028673835126, 'pegasus_entailment': 0.4301548186922446, 'gold_entailment': 0.018543070744878303, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6987951807228916, 'r1_recall': 0.6373626373626373, 'r1_f1': 0.6666666666666666, 'pegasus_entailment': 0.6084757387482872, 'gold_entailment': 0.32995553775981534, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5815602836879432, 'r1_recall': 0.6165413533834586, 'r1_f1': 0.5985401459854015, 'pegasus_entailment': 0.4900493021899213, 'gold_entailment': 0.4894671340783437, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6875, 'r1_recall': 0.4695121951219512, 'r1_f1': 0.5579710144927535, 'pegasus_entailment': 0.42838725447654724, 'gold_entailment': 0.21958612324669957, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7391304347826086, 'r1_recall': 0.5074626865671642, 'r1_f1': 0.6017699115044248, 'pegasus_entailment': 0.48101693236579496, 'gold_entailment': 0.3624255567168196, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34558823529411764, 'r1_recall': 0.47, 'r1_f1': 0.3983050847457627, 'pegasus_entailment': 0.332940137013793, 'gold_entailment': 0.03602945369978746, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6615384615384615, 'r1_recall': 0.5375, 'r1_f1': 0.593103448275862, 'pegasus_entailment': 0.0220918661604325, 'gold_entailment': 0.043864124454557896, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6774193548387096, 'r1_recall': 0.5121951219512195, 'r1_f1': 0.5833333333333334, 'pegasus_entailment': 0.5693212896585464, 'gold_entailment': 0.008730391062272247, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2072072072072072, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.289308176100629, 'pegasus_entailment': 0.2925321144672732, 'gold_entailment': 0.06484437889109056, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 18}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4105263157894737, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.4936708860759494, 'pegasus_entailment': 0.4521104885614477, 'gold_entailment': 0.12604882513793805, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19736842105263158, 'r1_recall': 0.4411764705882353, 'r1_f1': 0.2727272727272727, 'pegasus_entailment': 0.22550597437657416, 'gold_entailment': 0.007895000693679322, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.4605263157894737, 'r1_f1': 0.457516339869281, 'pegasus_entailment': 0.009925096295773983, 'gold_entailment': 0.008627533912658691, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8018018018018018, 'r1_recall': 0.483695652173913, 'r1_f1': 0.6033898305084746, 'pegasus_entailment': 0.5835837237536907, 'gold_entailment': 0.08730431264266372, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.40298507462686567, 'r1_f1': 0.4251968503937008, 'pegasus_entailment': 0.8028506934642792, 'gold_entailment': 0.13309763146874806, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6938775510204082, 'r1_recall': 0.40476190476190477, 'r1_f1': 0.5112781954887218, 'pegasus_entailment': 0.5078324843198061, 'gold_entailment': 0.16341962960238257, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5562913907284768, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.5936395759717313, 'pegasus_entailment': 0.9217479825019836, 'gold_entailment': 0.5102828908711672, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7586206896551724, 'r1_recall': 0.5569620253164557, 'r1_f1': 0.6423357664233575, 'pegasus_entailment': 0.6683099269866943, 'gold_entailment': 0.4830569811165333, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7222222222222222, 'r1_recall': 0.2635135135135135, 'r1_f1': 0.3861386138613861, 'pegasus_entailment': 0.7562012374401093, 'gold_entailment': 0.335116885154723, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34545454545454546, 'r1_recall': 0.6909090909090909, 'r1_f1': 0.4606060606060606, 'pegasus_entailment': 0.48927875235676765, 'gold_entailment': 0.2762047511059791, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7, 'r1_recall': 0.5329949238578681, 'r1_f1': 0.6051873198847262, 'pegasus_entailment': 0.7373112857341766, 'gold_entailment': 0.30916015803813934, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5135135135135135, 'r1_recall': 0.31666666666666665, 'r1_f1': 0.39175257731958757, 'pegasus_entailment': 0.5306415458520254, 'gold_entailment': 0.0028350454522296786, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 22, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6371681415929203, 'r1_recall': 0.5853658536585366, 'r1_f1': 0.6101694915254237, 'pegasus_entailment': 0.4025506295263767, 'gold_entailment': 0.3039946195203811, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6391752577319587, 'r1_recall': 0.5904761904761905, 'r1_f1': 0.6138613861386139, 'pegasus_entailment': 0.7241009793360718, 'gold_entailment': 0.5934552873174349, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8041237113402062, 'r1_recall': 0.5954198473282443, 'r1_f1': 0.6842105263157895, 'pegasus_entailment': 0.4616026684641838, 'gold_entailment': 0.01529293196896712, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3853211009174312, 'r1_recall': 0.6268656716417911, 'r1_f1': 0.4772727272727274, 'pegasus_entailment': 0.1505046091042459, 'gold_entailment': 0.2621919290783505, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36893203883495146, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.47500000000000003, 'pegasus_entailment': 0.8251513441403707, 'gold_entailment': 0.39315385231748223, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33035714285714285, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.43786982248520717, 'pegasus_entailment': 0.10865482408553362, 'gold_entailment': 0.3960107322782278, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6551724137931034, 'r1_recall': 0.4453125, 'r1_f1': 0.5302325581395348, 'pegasus_entailment': 0.7454186715185642, 'gold_entailment': 0.21364042349159718, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7678571428571429, 'r1_recall': 0.48314606741573035, 'r1_f1': 0.5931034482758621, 'pegasus_entailment': 0.493725199252367, 'gold_entailment': 0.3485401004552841, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6637931034482759, 'r1_recall': 0.4723926380368098, 'r1_f1': 0.5519713261648745, 'pegasus_entailment': 0.6601459756493568, 'gold_entailment': 0.19638435672968627, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.676923076923077, 'r1_recall': 0.45595854922279794, 'r1_f1': 0.544891640866873, 'pegasus_entailment': 0.49986285183113066, 'gold_entailment': 0.20636484482222134, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5897435897435898, 'r1_recall': 0.45544554455445546, 'r1_f1': 0.5139664804469273, 'pegasus_entailment': 0.43791602849960326, 'gold_entailment': 0.009734045481309295, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.494949494949495, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.5355191256830601, 'pegasus_entailment': 0.2020428419113159, 'gold_entailment': 0.06650870339944959, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.5, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.4377435821807012, 'gold_entailment': 0.5365389038439995, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3516483516483517, 'r1_recall': 0.6274509803921569, 'r1_f1': 0.4507042253521127, 'pegasus_entailment': 0.4691862586187199, 'gold_entailment': 0.4102429151535034, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7551020408163265, 'r1_recall': 0.5, 'r1_f1': 0.6016260162601625, 'pegasus_entailment': 0.3773625008761883, 'gold_entailment': 0.3028912581503391, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6476190476190476, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.5762711864406781, 'pegasus_entailment': 0.281088078316922, 'gold_entailment': 0.1479058557190001, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5350877192982456, 'r1_recall': 0.5169491525423728, 'r1_f1': 0.5258620689655171, 'pegasus_entailment': 0.33342452968160313, 'gold_entailment': 0.004463987454073504, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7526881720430108, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.6278026905829596, 'pegasus_entailment': 0.5470662505055467, 'gold_entailment': 0.3186143227852881, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4326241134751773, 'r1_recall': 0.5126050420168067, 'r1_f1': 0.4692307692307692, 'pegasus_entailment': 0.38487866781651975, 'gold_entailment': 0.37985506653785706, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.5, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.2914136458809177, 'gold_entailment': 0.23022046429105103, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6818181818181818, 'r1_recall': 0.5, 'r1_f1': 0.576923076923077, 'pegasus_entailment': 0.5403454899787903, 'gold_entailment': 0.4377744797966443, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.550561797752809, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.4414414414414414, 'pegasus_entailment': 0.017311825370416044, 'gold_entailment': 0.02788297738879919, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.37735849056603776, 'r1_f1': 0.4819277108433735, 'pegasus_entailment': 0.4929810049012303, 'gold_entailment': 0.26936403922736646, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.410958904109589, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.4693959802389145, 'gold_entailment': 0.5621156692504883, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.75, 'r1_recall': 0.3515625, 'r1_f1': 0.4787234042553192, 'pegasus_entailment': 0.7569457292556763, 'gold_entailment': 0.18613631455227733, 'pegasus_flesch_kincaid': 31, 'pegasus_coleman_liau': 19, 'pegasus_ari': 38, 'pegasus_smog': 25}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44285714285714284, 'r1_recall': 0.543859649122807, 'r1_f1': 0.4881889763779528, 'pegasus_entailment': 0.657495848989735, 'gold_entailment': 0.004421204386744648, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7203389830508474, 'r1_recall': 0.44502617801047123, 'r1_f1': 0.5501618122977346, 'pegasus_entailment': 0.3446551989763975, 'gold_entailment': 0.41863762653831926, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6951219512195121, 'r1_recall': 0.3877551020408163, 'r1_f1': 0.4978165938864629, 'pegasus_entailment': 0.7730105221271515, 'gold_entailment': 0.15275063703302294, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6788990825688074, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.5627376425855514, 'pegasus_entailment': 0.40121156634995714, 'gold_entailment': 0.20866176895797253, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.64, 'r1_f1': 0.5818181818181818, 'pegasus_entailment': 0.45801215960333747, 'gold_entailment': 0.28606791369384155, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5735294117647058, 'r1_recall': 0.6782608695652174, 'r1_f1': 0.6215139442231076, 'pegasus_entailment': 0.3941519633866847, 'gold_entailment': 0.20497417757287623, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6048387096774194, 'r1_recall': 0.49019607843137253, 'r1_f1': 0.5415162454873647, 'pegasus_entailment': 0.42456541024148464, 'gold_entailment': 0.17706958390772343, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6091954022988506, 'r1_recall': 0.5196078431372549, 'r1_f1': 0.5608465608465608, 'pegasus_entailment': 0.6636466408769289, 'gold_entailment': 0.07135312891477952, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 14}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31, 'r1_recall': 0.543859649122807, 'r1_f1': 0.39490445859872614, 'pegasus_entailment': 0.4691180124878883, 'gold_entailment': 0.06093579912946249, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5517241379310345, 'r1_recall': 0.5, 'r1_f1': 0.5245901639344263, 'pegasus_entailment': 0.447273638099432, 'gold_entailment': 0.23429794579715235, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3979591836734694, 'r1_recall': 0.52, 'r1_f1': 0.4508670520231214, 'pegasus_entailment': 0.6578834503889084, 'gold_entailment': 0.13507085829041898, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46153846153846156, 'r1_recall': 0.7924528301886793, 'r1_f1': 0.5833333333333334, 'pegasus_entailment': 0.5724204331636429, 'gold_entailment': 0.2366949290735647, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5876288659793815, 'r1_recall': 0.6129032258064516, 'r1_f1': 0.6, 'pegasus_entailment': 0.4244995042681694, 'gold_entailment': 0.017434625909663735, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6351351351351351, 'r1_recall': 0.8103448275862069, 'r1_f1': 0.712121212121212, 'pegasus_entailment': 0.42034045653417706, 'gold_entailment': 0.533761260099709, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6551724137931034, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.6031746031746031, 'pegasus_entailment': 0.5682404243387282, 'gold_entailment': 0.6138817667961121, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6050420168067226, 'r1_recall': 0.45569620253164556, 'r1_f1': 0.5198555956678701, 'pegasus_entailment': 0.6855692118406296, 'gold_entailment': 0.46252023205161097, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36607142857142855, 'r1_recall': 0.7192982456140351, 'r1_f1': 0.4852071005917159, 'pegasus_entailment': 0.2431899466086179, 'gold_entailment': 0.1166214682161808, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5933333333333334, 'r1_recall': 0.5973154362416108, 'r1_f1': 0.5953177257525084, 'pegasus_entailment': 0.48457507682698114, 'gold_entailment': 0.47096786797046664, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 19}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7362637362637363, 'r1_recall': 0.48905109489051096, 'r1_f1': 0.5877192982456141, 'pegasus_entailment': 0.5984733924269676, 'gold_entailment': 0.07730279117822647, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4421052631578947, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.5217391304347826, 'pegasus_entailment': 0.28537997798994186, 'gold_entailment': 0.011346000401924053, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6951219512195121, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.5906735751295337, 'pegasus_entailment': 0.8476126864552498, 'gold_entailment': 0.2911683209706098, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4148936170212766, 'r1_recall': 0.4875, 'r1_f1': 0.4482758620689655, 'pegasus_entailment': 0.8267292380332947, 'gold_entailment': 0.2351113448748947, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7014925373134329, 'r1_recall': 0.3700787401574803, 'r1_f1': 0.4845360824742268, 'pegasus_entailment': 0.5392704160573581, 'gold_entailment': 0.3503357556848122, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7909090909090909, 'r1_recall': 0.4416243654822335, 'r1_f1': 0.5667752442996743, 'pegasus_entailment': 0.14345702591041723, 'gold_entailment': 0.17499375021725427, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6758620689655173, 'r1_recall': 0.40329218106995884, 'r1_f1': 0.5051546391752578, 'pegasus_entailment': 0.33580511156469584, 'gold_entailment': 0.12473260215483606, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7608695652173914, 'r1_recall': 0.5035971223021583, 'r1_f1': 0.6060606060606061, 'pegasus_entailment': 0.4140630394103937, 'gold_entailment': 0.1532944312057225, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 20}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2, 'r1_recall': 0.3287671232876712, 'r1_f1': 0.24870466321243523, 'pegasus_entailment': 0.0012959077139385045, 'gold_entailment': 0.0017740587451650451, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35106382978723405, 'r1_recall': 0.5409836065573771, 'r1_f1': 0.4258064516129032, 'pegasus_entailment': 0.05481597548350692, 'gold_entailment': 0.0732674374691366, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5930232558139535, 'r1_f1': 0.5425531914893617, 'pegasus_entailment': 0.29232569311570844, 'gold_entailment': 0.05802927309802423, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4019607843137255, 'r1_recall': 0.5540540540540541, 'r1_f1': 0.4659090909090909, 'pegasus_entailment': 0.34726016360218637, 'gold_entailment': 0.11895750241819769, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7719298245614035, 'r1_recall': 0.5057471264367817, 'r1_f1': 0.611111111111111, 'pegasus_entailment': 0.602601170539856, 'gold_entailment': 0.2823891385924071, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6022727272727273, 'r1_recall': 0.3680555555555556, 'r1_f1': 0.45689655172413796, 'pegasus_entailment': 0.37671080604195595, 'gold_entailment': 0.1178905664011836, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7105263157894737, 'r1_recall': 0.4153846153846154, 'r1_f1': 0.5242718446601942, 'pegasus_entailment': 0.7481401026248932, 'gold_entailment': 0.5296811981126666, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6081081081081081, 'r1_recall': 0.6164383561643836, 'r1_f1': 0.6122448979591837, 'pegasus_entailment': 0.30444856888304156, 'gold_entailment': 0.3054398912936449, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4732142857142857, 'r1_recall': 0.7066666666666667, 'r1_f1': 0.5668449197860962, 'pegasus_entailment': 0.43148627971095266, 'gold_entailment': 0.301190262970825, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4626865671641791, 'r1_recall': 0.543859649122807, 'r1_f1': 0.5, 'pegasus_entailment': 0.26459065172821283, 'gold_entailment': 0.3312344877049327, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7321428571428571, 'r1_recall': 0.43617021276595747, 'r1_f1': 0.5466666666666665, 'pegasus_entailment': 0.6367796908598393, 'gold_entailment': 0.36487999971723184, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43859649122807015, 'r1_recall': 0.423728813559322, 'r1_f1': 0.43103448275862066, 'pegasus_entailment': 0.41789332032203674, 'gold_entailment': 0.05494316667318344, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6940298507462687, 'r1_recall': 0.5535714285714286, 'r1_f1': 0.6158940397350994, 'pegasus_entailment': 0.46540903419788393, 'gold_entailment': 0.31155732879415154, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5092592592592593, 'r1_recall': 0.4263565891472868, 'r1_f1': 0.4641350210970464, 'pegasus_entailment': 0.3180327375885099, 'gold_entailment': 0.18433656902052462, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5943396226415094, 'r1_recall': 0.4228187919463087, 'r1_f1': 0.4941176470588235, 'pegasus_entailment': 0.5734830591827631, 'gold_entailment': 0.251318355401357, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5637583892617449, 'r1_recall': 0.4970414201183432, 'r1_f1': 0.5283018867924528, 'pegasus_entailment': 0.3240923161307971, 'gold_entailment': 0.21202405941273486, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6082474226804123, 'r1_recall': 0.45038167938931295, 'r1_f1': 0.5175438596491228, 'pegasus_entailment': 0.27459233738482, 'gold_entailment': 0.10078872246667743, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5393258426966292, 'r1_recall': 0.3870967741935484, 'r1_f1': 0.4507042253521127, 'pegasus_entailment': 0.46114567579934373, 'gold_entailment': 0.12406516113939385, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3684210526315789, 'r1_recall': 0.6746987951807228, 'r1_f1': 0.47659574468085103, 'pegasus_entailment': 0.26541749518364666, 'gold_entailment': 0.038541849392155804, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2839506172839506, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.3833333333333333, 'pegasus_entailment': 0.3669658333528787, 'gold_entailment': 0.09149280481506139, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6835443037974683, 'r1_recall': 0.46551724137931033, 'r1_f1': 0.5538461538461538, 'pegasus_entailment': 0.24930338077247144, 'gold_entailment': 0.21475662211499488, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7878787878787878, 'r1_recall': 0.42162162162162165, 'r1_f1': 0.5492957746478874, 'pegasus_entailment': 0.6205744367092848, 'gold_entailment': 0.24687653353612404, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7755102040816326, 'r1_recall': 0.3958333333333333, 'r1_f1': 0.5241379310344828, 'pegasus_entailment': 0.8818435668945312, 'gold_entailment': 0.200362704480843, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7098445595854922, 'r1_recall': 0.35584415584415585, 'r1_f1': 0.4740484429065744, 'pegasus_entailment': 0.41861010023525785, 'gold_entailment': 0.3434397775460692, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7525773195876289, 'r1_recall': 0.5069444444444444, 'r1_f1': 0.6058091286307054, 'pegasus_entailment': 0.7181213982403278, 'gold_entailment': 0.5239621990670761, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3541666666666667, 'r1_recall': 0.5230769230769231, 'r1_f1': 0.422360248447205, 'pegasus_entailment': 0.22951429234817625, 'gold_entailment': 0.31901837699115276, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.6, 'r1_f1': 0.5, 'pegasus_entailment': 0.07862851695972495, 'gold_entailment': 0.0056098719748357935, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45652173913043476, 'r1_recall': 0.25925925925925924, 'r1_f1': 0.3307086614173228, 'pegasus_entailment': 0.4987290755379945, 'gold_entailment': 0.056258964075823314, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 23, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5795454545454546, 'r1_recall': 0.49038461538461536, 'r1_f1': 0.53125, 'pegasus_entailment': 0.29310221690684557, 'gold_entailment': 0.4290822272654623, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42168674698795183, 'r1_recall': 0.4069767441860465, 'r1_f1': 0.41420118343195267, 'pegasus_entailment': 0.32364519871771336, 'gold_entailment': 0.06730458701495082, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5620437956204379, 'r1_recall': 0.4935897435897436, 'r1_f1': 0.5255972696245733, 'pegasus_entailment': 0.6173220759723336, 'gold_entailment': 0.26542463495362817, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6756756756756757, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.5434782608695652, 'pegasus_entailment': 0.48982260935008526, 'gold_entailment': 0.20032561988773523, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4788732394366197, 'r1_recall': 0.5573770491803278, 'r1_f1': 0.5151515151515151, 'pegasus_entailment': 0.2606958064328258, 'gold_entailment': 0.07918645079917042, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5748031496062992, 'r1_recall': 0.4866666666666667, 'r1_f1': 0.5270758122743683, 'pegasus_entailment': 0.6323113515973091, 'gold_entailment': 0.22143880468502175, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5353535353535354, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.5578947368421052, 'pegasus_entailment': 0.4128331057727337, 'gold_entailment': 0.027912243269383907, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7966101694915254, 'r1_recall': 0.35877862595419846, 'r1_f1': 0.4947368421052632, 'pegasus_entailment': 0.7690123915672302, 'gold_entailment': 0.25729031368973665, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.56, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5863874345549739, 'pegasus_entailment': 0.6572776053633008, 'gold_entailment': 0.24686278332956135, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.64, 'r1_recall': 0.6095238095238096, 'r1_f1': 0.624390243902439, 'pegasus_entailment': 0.6194403916597366, 'gold_entailment': 0.22541621048003435, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3375796178343949, 'r1_recall': 0.726027397260274, 'r1_f1': 0.4608695652173913, 'pegasus_entailment': 0.23965445874879757, 'gold_entailment': 0.5739438327339789, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5142857142857142, 'r1_recall': 0.288, 'r1_f1': 0.3692307692307692, 'pegasus_entailment': 0.16350153693929315, 'gold_entailment': 0.07577159810170997, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6463414634146342, 'r1_recall': 0.4649122807017544, 'r1_f1': 0.5408163265306123, 'pegasus_entailment': 0.6454929659763972, 'gold_entailment': 0.01584522146731615, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4842105263157895, 'r1_recall': 0.5168539325842697, 'r1_f1': 0.5, 'pegasus_entailment': 0.2515044577594381, 'gold_entailment': 0.2530433860956691, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.4883720930232558, 'r1_f1': 0.47727272727272724, 'pegasus_entailment': 0.3343628204893321, 'gold_entailment': 0.5479292124509811, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 13}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7162162162162162, 'r1_recall': 0.4796380090497738, 'r1_f1': 0.5745257452574526, 'pegasus_entailment': 0.5144817477890423, 'gold_entailment': 0.22757531671474376, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6571428571428571, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6330275229357798, 'pegasus_entailment': 0.4087427332997322, 'gold_entailment': 0.04275958484504372, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 22}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2727272727272727, 'r1_recall': 0.5675675675675675, 'r1_f1': 0.3684210526315789, 'pegasus_entailment': 0.4693809320839743, 'gold_entailment': 0.005541250575333834, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5857142857142857, 'r1_recall': 0.5, 'r1_f1': 0.5394736842105263, 'pegasus_entailment': 0.7683110311627388, 'gold_entailment': 0.12792886211536825, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6923076923076923, 'r1_recall': 0.4205607476635514, 'r1_f1': 0.5232558139534884, 'pegasus_entailment': 0.6680228100158274, 'gold_entailment': 0.003895527170971036, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4690265486725664, 'r1_recall': 0.7361111111111112, 'r1_f1': 0.572972972972973, 'pegasus_entailment': 0.1585218264372088, 'gold_entailment': 0.06028685594598452, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5092592592592593, 'r1_recall': 0.625, 'r1_f1': 0.5612244897959184, 'pegasus_entailment': 0.3935063504613936, 'gold_entailment': 0.06630142458379851, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6901408450704225, 'r1_recall': 0.550561797752809, 'r1_f1': 0.6124999999999999, 'pegasus_entailment': 0.2850616924464703, 'gold_entailment': 0.289751964310805, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.6101694915254238, 'r1_f1': 0.5034965034965035, 'pegasus_entailment': 0.6230672895908356, 'gold_entailment': 0.03583412438941499, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6410256410256411, 'r1_recall': 0.5050505050505051, 'r1_f1': 0.5649717514124294, 'pegasus_entailment': 0.4596318304538727, 'gold_entailment': 0.45479965955018997, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6511627906976745, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.6153846153846155, 'pegasus_entailment': 0.20232937205582857, 'gold_entailment': 0.4533602565061301, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5478260869565217, 'r1_recall': 0.6702127659574468, 'r1_f1': 0.6028708133971291, 'pegasus_entailment': 0.24979469515383243, 'gold_entailment': 0.26527870213612914, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.9, 'r1_recall': 0.3448275862068966, 'r1_f1': 0.4986149584487534, 'pegasus_entailment': 0.5221239186357707, 'gold_entailment': 0.3970197169110179, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6605504587155964, 'r1_recall': 0.36, 'r1_f1': 0.46601941747572817, 'pegasus_entailment': 0.494015157555363, 'gold_entailment': 0.23301903208872923, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27607361963190186, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.37344398340248963, 'pegasus_entailment': 0.12423653408768587, 'gold_entailment': 0.09538603154942393, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.65625, 'r1_recall': 0.6, 'r1_f1': 0.626865671641791, 'pegasus_entailment': 0.5734027326107025, 'gold_entailment': 0.35475025736377575, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7547169811320755, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.6611570247933886, 'pegasus_entailment': 0.8230000734329224, 'gold_entailment': 0.6585713028907776, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6122448979591837, 'r1_recall': 0.5309734513274337, 'r1_f1': 0.5687203791469194, 'pegasus_entailment': 0.38777593793929555, 'gold_entailment': 0.007521222112700343, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5617977528089888, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.5747126436781609, 'pegasus_entailment': 0.4484330415725708, 'gold_entailment': 0.38559915125370026, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4523809523809524, 'r1_recall': 0.5757575757575758, 'r1_f1': 0.5066666666666667, 'pegasus_entailment': 0.47681674058549106, 'gold_entailment': 0.008747341809794307, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5975609756097561, 'r1_recall': 0.532608695652174, 'r1_f1': 0.5632183908045977, 'pegasus_entailment': 0.3136589368805289, 'gold_entailment': 0.33394429956873256, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49107142857142855, 'r1_recall': 0.6626506024096386, 'r1_f1': 0.564102564102564, 'pegasus_entailment': 0.25832140468992293, 'gold_entailment': 0.32633774851759273, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7377049180327869, 'r1_recall': 0.35714285714285715, 'r1_f1': 0.4812834224598931, 'pegasus_entailment': 0.06432850379496813, 'gold_entailment': 0.13294725492596626, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5882352941176471, 'r1_recall': 0.49019607843137253, 'r1_f1': 0.5347593582887701, 'pegasus_entailment': 0.541261799633503, 'gold_entailment': 0.2426740323814253, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7471264367816092, 'r1_recall': 0.40372670807453415, 'r1_f1': 0.5241935483870968, 'pegasus_entailment': 0.4705338649218902, 'gold_entailment': 0.31517953872680665, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43037974683544306, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.5, 'pegasus_entailment': 0.2537951633955042, 'gold_entailment': 0.006991999107412994, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7411764705882353, 'r1_recall': 0.5575221238938053, 'r1_f1': 0.6363636363636364, 'pegasus_entailment': 0.5376231409609318, 'gold_entailment': 0.1610454363482339, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 16, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3486238532110092, 'r1_recall': 0.6333333333333333, 'r1_f1': 0.4497041420118343, 'pegasus_entailment': 0.04315405342495069, 'gold_entailment': 0.003667238066555001, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5631067961165048, 'r1_recall': 0.5742574257425742, 'r1_f1': 0.5686274509803921, 'pegasus_entailment': 0.38986685778945684, 'gold_entailment': 0.26261345483362675, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.6938775510204082, 'r1_f1': 0.5074626865671642, 'pegasus_entailment': 0.323516474571079, 'gold_entailment': 0.42344098910689354, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23684210526315788, 'r1_recall': 0.391304347826087, 'r1_f1': 0.2950819672131147, 'pegasus_entailment': 0.26318135679078597, 'gold_entailment': 0.039445586735382676, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7264150943396226, 'r1_recall': 0.5273972602739726, 'r1_f1': 0.611111111111111, 'pegasus_entailment': 0.6889925648768743, 'gold_entailment': 0.35652265589063364, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.62, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.6326530612244898, 'pegasus_entailment': 0.6841741374560765, 'gold_entailment': 0.17754987130562463, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.559322033898305, 'r1_recall': 0.44594594594594594, 'r1_f1': 0.49624060150375937, 'pegasus_entailment': 0.2199983201920986, 'gold_entailment': 0.03511326480656862, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5168539325842697, 'r1_recall': 0.46464646464646464, 'r1_f1': 0.4893617021276596, 'pegasus_entailment': 0.4103715798119083, 'gold_entailment': 0.03689542399176086, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5225225225225225, 'r1_recall': 0.6987951807228916, 'r1_f1': 0.5979381443298969, 'pegasus_entailment': 0.8434797763824463, 'gold_entailment': 0.03361797798424959, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44642857142857145, 'r1_recall': 0.704225352112676, 'r1_f1': 0.546448087431694, 'pegasus_entailment': 0.853176474571228, 'gold_entailment': 0.42490024119615555, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6741573033707865, 'r1_recall': 0.5217391304347826, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.5281471590666721, 'gold_entailment': 0.017525898583699018, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5967741935483871, 'r1_recall': 0.44047619047619047, 'r1_f1': 0.5068493150684931, 'pegasus_entailment': 0.7691988199949265, 'gold_entailment': 0.32350572092192514, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.297029702970297, 'r1_recall': 0.5660377358490566, 'r1_f1': 0.3896103896103896, 'pegasus_entailment': 0.0031408221499683955, 'gold_entailment': 0.22772828020970337, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.6292134831460674, 'pegasus_entailment': 0.5385168095429739, 'gold_entailment': 0.01399561611469835, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6436781609195402, 'r1_recall': 0.49557522123893805, 'r1_f1': 0.56, 'pegasus_entailment': 0.3602396350033814, 'gold_entailment': 0.23831285809137626, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4891304347826087, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.5521472392638037, 'pegasus_entailment': 0.42463361397385596, 'gold_entailment': 0.040825056843459606, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6914893617021277, 'r1_recall': 0.2968036529680365, 'r1_f1': 0.4153354632587859, 'pegasus_entailment': 0.6738239849607149, 'gold_entailment': 0.3762656103612648, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3235294117647059, 'r1_recall': 0.3142857142857143, 'r1_f1': 0.31884057971014496, 'pegasus_entailment': 0.9806057810783386, 'gold_entailment': 0.6413019706184665, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 19}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.7590361445783133, 'r1_f1': 0.6596858638743456, 'pegasus_entailment': 0.2598778235842474, 'gold_entailment': 0.43779476440977305, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.358974358974359, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.4409448818897638, 'pegasus_entailment': 0.25848794321063906, 'gold_entailment': 0.08657163829775527, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7596899224806202, 'r1_recall': 0.5764705882352941, 'r1_f1': 0.6555183946488294, 'pegasus_entailment': 0.6480400636792183, 'gold_entailment': 0.05712282611057162, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7142857142857143, 'r1_recall': 0.5426356589147286, 'r1_f1': 0.6167400881057268, 'pegasus_entailment': 0.5231247902847826, 'gold_entailment': 0.36380859166383744, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.6206896551724138, 'r1_f1': 0.5901639344262296, 'pegasus_entailment': 0.09125800745096058, 'gold_entailment': 0.24369578948244452, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6790123456790124, 'r1_recall': 0.41353383458646614, 'r1_f1': 0.514018691588785, 'pegasus_entailment': 0.4714369736611843, 'gold_entailment': 0.00739892284036614, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5373134328358209, 'r1_recall': 0.6486486486486487, 'r1_f1': 0.5877551020408163, 'pegasus_entailment': 0.35140023082494737, 'gold_entailment': 0.040810249047353864, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4434782608695652, 'r1_recall': 0.53125, 'r1_f1': 0.4834123222748815, 'pegasus_entailment': 0.38318085049589473, 'gold_entailment': 0.0051177082932554185, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7340425531914894, 'r1_recall': 0.4928571428571429, 'r1_f1': 0.5897435897435898, 'pegasus_entailment': 0.12202900027235349, 'gold_entailment': 0.18948714695870877, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5666666666666667, 'r1_recall': 0.3541666666666667, 'r1_f1': 0.4358974358974359, 'pegasus_entailment': 0.44196179540206987, 'gold_entailment': 0.26670426487301785, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.573170731707317, 'r1_recall': 0.5108695652173914, 'r1_f1': 0.5402298850574713, 'pegasus_entailment': 0.7184546140488237, 'gold_entailment': 0.1862858117892756, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7283950617283951, 'r1_recall': 0.5728155339805825, 'r1_f1': 0.641304347826087, 'pegasus_entailment': 0.480955908074975, 'gold_entailment': 0.23179101794958115, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3434343434343434, 'r1_recall': 0.5074626865671642, 'r1_f1': 0.4096385542168675, 'pegasus_entailment': 0.2642174169421196, 'gold_entailment': 0.28832835510062677, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5955056179775281, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.5888888888888889, 'pegasus_entailment': 0.8416590988636017, 'gold_entailment': 0.43356029264396057, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6576576576576577, 'r1_recall': 0.5104895104895105, 'r1_f1': 0.5748031496062992, 'pegasus_entailment': 0.7141806393919978, 'gold_entailment': 0.183653075248003, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.75, 'r1_recall': 0.4180327868852459, 'r1_f1': 0.5368421052631578, 'pegasus_entailment': 0.23900336329825222, 'gold_entailment': 0.2195815402723383, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6370370370370371, 'r1_recall': 0.5180722891566265, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.2935559995472431, 'gold_entailment': 0.27346445471048353, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47368421052631576, 'r1_recall': 0.6545454545454545, 'r1_f1': 0.549618320610687, 'pegasus_entailment': 0.008067938411841169, 'gold_entailment': 0.007348199462285265, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5657894736842105, 'r1_recall': 0.581081081081081, 'r1_f1': 0.5733333333333333, 'pegasus_entailment': 0.8830757141113281, 'gold_entailment': 0.25997038977220654, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.75, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.5783132530120481, 'pegasus_entailment': 0.7762353897094727, 'gold_entailment': 0.30866069860187256, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7142857142857143, 'r1_recall': 0.46296296296296297, 'r1_f1': 0.5617977528089888, 'pegasus_entailment': 0.5013834655284881, 'gold_entailment': 0.23671125146211125, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7432432432432432, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.5641025641025641, 'pegasus_entailment': 0.1250649824117621, 'gold_entailment': 0.036458072174961366, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6728971962616822, 'r1_recall': 0.5034965034965035, 'r1_f1': 0.5760000000000001, 'pegasus_entailment': 0.3718735249713063, 'gold_entailment': 0.3167720571759024, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.52, 'r1_recall': 0.5977011494252874, 'r1_f1': 0.5561497326203209, 'pegasus_entailment': 0.6292357656639069, 'gold_entailment': 0.011107163814206919, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4918032786885246, 'r1_recall': 0.6593406593406593, 'r1_f1': 0.5633802816901409, 'pegasus_entailment': 0.4375397254480049, 'gold_entailment': 0.11035742602568159, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6455696202531646, 'r1_recall': 0.5, 'r1_f1': 0.56353591160221, 'pegasus_entailment': 0.20196303570992313, 'gold_entailment': 0.008357226179214194, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6376811594202898, 'r1_recall': 0.38596491228070173, 'r1_f1': 0.48087431693989063, 'pegasus_entailment': 0.6328254444524646, 'gold_entailment': 0.1759697290835902, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6097560975609756, 'r1_recall': 0.5050505050505051, 'r1_f1': 0.5524861878453039, 'pegasus_entailment': 0.4966510757803917, 'gold_entailment': 0.18310490250587463, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34965034965034963, 'r1_recall': 0.5617977528089888, 'r1_f1': 0.4310344827586207, 'pegasus_entailment': 0.3573061438277364, 'gold_entailment': 0.2278321934863925, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7803030303030303, 'r1_recall': 0.6319018404907976, 'r1_f1': 0.6983050847457628, 'pegasus_entailment': 0.26541246970494586, 'gold_entailment': 0.2940447007616361, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6181818181818182, 'r1_recall': 0.37362637362637363, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.6932601351290941, 'gold_entailment': 0.022131455053264897, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7184466019417476, 'r1_recall': 0.2690909090909091, 'r1_f1': 0.3915343915343915, 'pegasus_entailment': 0.41845248887936276, 'gold_entailment': 0.16960465509651435, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 24}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5178571428571429, 'r1_recall': 0.5321100917431193, 'r1_f1': 0.5248868778280543, 'pegasus_entailment': 0.40059069320559504, 'gold_entailment': 0.27095210179686546, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3013698630136986, 'r1_recall': 0.3793103448275862, 'r1_f1': 0.33587786259541985, 'pegasus_entailment': 0.3134253786993213, 'gold_entailment': 0.25118414824828506, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.65, 'r1_recall': 0.287292817679558, 'r1_f1': 0.39846743295019155, 'pegasus_entailment': 0.2551009929011343, 'gold_entailment': 0.0035752830968704074, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42696629213483145, 'r1_recall': 0.4935064935064935, 'r1_f1': 0.4578313253012048, 'pegasus_entailment': 0.10820974598027533, 'gold_entailment': 0.011902345955604687, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6984126984126984, 'r1_recall': 0.55, 'r1_f1': 0.6153846153846154, 'pegasus_entailment': 0.9282869497934977, 'gold_entailment': 0.12510247766040267, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6354166666666666, 'r1_recall': 0.6559139784946236, 'r1_f1': 0.6455026455026455, 'pegasus_entailment': 0.6675986312329769, 'gold_entailment': 0.22797605003870558, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5476190476190477, 'r1_recall': 0.5679012345679012, 'r1_f1': 0.5575757575757575, 'pegasus_entailment': 0.3688951681833714, 'gold_entailment': 0.22743361495668069, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5641025641025641, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.5238095238095238, 'pegasus_entailment': 0.24890682696423028, 'gold_entailment': 0.013653046713443473, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34831460674157305, 'r1_recall': 0.4492753623188406, 'r1_f1': 0.3924050632911393, 'pegasus_entailment': 0.2249279152136296, 'gold_entailment': 0.008822516116197221, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6428571428571429, 'r1_recall': 0.65625, 'r1_f1': 0.6494845360824744, 'pegasus_entailment': 0.525868965126574, 'gold_entailment': 0.4520595259964466, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47368421052631576, 'r1_recall': 0.5625, 'r1_f1': 0.5142857142857142, 'pegasus_entailment': 0.7930988868077596, 'gold_entailment': 0.19542659097351134, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3157894736842105, 'r1_recall': 0.6593406593406593, 'r1_f1': 0.4270462633451957, 'pegasus_entailment': 0.6980641543865204, 'gold_entailment': 0.19484356604516506, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.6136363636363636, 'r1_f1': 0.6067415730337078, 'pegasus_entailment': 0.587289871647954, 'gold_entailment': 0.3566784510738216, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5053763440860215, 'r1_recall': 0.7580645161290323, 'r1_f1': 0.6064516129032258, 'pegasus_entailment': 0.12446091053009566, 'gold_entailment': 0.043026701954659075, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5431034482758621, 'r1_recall': 0.5887850467289719, 'r1_f1': 0.5650224215246636, 'pegasus_entailment': 0.4125022510997951, 'gold_entailment': 0.29463194999843834, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48148148148148145, 'r1_recall': 0.4126984126984127, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.08312448463402689, 'gold_entailment': 0.10719609260559082, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8299319727891157, 'r1_recall': 0.46037735849056605, 'r1_f1': 0.5922330097087379, 'pegasus_entailment': 0.4840257324278355, 'gold_entailment': 0.22853730219815457, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.421875, 'r1_recall': 0.421875, 'r1_f1': 0.421875, 'pegasus_entailment': 0.32858366798609495, 'gold_entailment': 0.345560904359445, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5063291139240507, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.46783625730994155, 'pegasus_entailment': 0.3629457429051399, 'gold_entailment': 0.17623622715473175, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5816326530612245, 'r1_recall': 0.57, 'r1_f1': 0.5757575757575758, 'pegasus_entailment': 0.6879626363515854, 'gold_entailment': 0.07516897283494473, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49700598802395207, 'r1_recall': 0.5928571428571429, 'r1_f1': 0.5407166123778502, 'pegasus_entailment': 0.5119740711525083, 'gold_entailment': 0.3872545560201009, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6451612903225806, 'r1_recall': 0.6382978723404256, 'r1_f1': 0.641711229946524, 'pegasus_entailment': 0.37924228856960934, 'gold_entailment': 0.035361176977554955, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5957446808510638, 'r1_recall': 0.2204724409448819, 'r1_f1': 0.32183908045977005, 'pegasus_entailment': 0.8736948370933533, 'gold_entailment': 0.24524882059631636, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 22, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37168141592920356, 'r1_recall': 0.5915492957746479, 'r1_f1': 0.4565217391304348, 'pegasus_entailment': 0.4610772989690304, 'gold_entailment': 0.017437647096812725, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.464, 'r1_recall': 0.6170212765957447, 'r1_f1': 0.5296803652968036, 'pegasus_entailment': 0.6605424523353577, 'gold_entailment': 0.30548591232703376, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48314606741573035, 'r1_recall': 0.5119047619047619, 'r1_f1': 0.4971098265895953, 'pegasus_entailment': 0.3386093395917366, 'gold_entailment': 0.17902480461634696, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5517241379310345, 'r1_recall': 0.6486486486486487, 'r1_f1': 0.5962732919254659, 'pegasus_entailment': 0.1595332263968885, 'gold_entailment': 0.010092939788592048, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41, 'r1_recall': 0.6119402985074627, 'r1_f1': 0.49101796407185627, 'pegasus_entailment': 0.48609003871679307, 'gold_entailment': 0.030645718798041344, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.319672131147541, 'r1_recall': 0.609375, 'r1_f1': 0.41935483870967744, 'pegasus_entailment': 0.4273448876726131, 'gold_entailment': 0.421585351228714, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6933333333333334, 'r1_recall': 0.30057803468208094, 'r1_f1': 0.41935483870967744, 'pegasus_entailment': 0.6629682630300522, 'gold_entailment': 0.28243220118539675, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7864077669902912, 'r1_recall': 0.4909090909090909, 'r1_f1': 0.6044776119402985, 'pegasus_entailment': 0.3293402064591646, 'gold_entailment': 0.3043470475822687, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7945205479452054, 'r1_recall': 0.5918367346938775, 'r1_f1': 0.6783625730994152, 'pegasus_entailment': 0.5633308216929436, 'gold_entailment': 0.1725493484021475, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5565217391304348, 'r1_recall': 0.3422459893048128, 'r1_f1': 0.423841059602649, 'pegasus_entailment': 0.26066732581239194, 'gold_entailment': 0.008347435732139275, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4875, 'r1_recall': 0.4105263157894737, 'r1_f1': 0.4457142857142857, 'pegasus_entailment': 0.2723806475502594, 'gold_entailment': 0.09887290551948051, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.29529842517028254, 'gold_entailment': 0.01604765570179249, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41333333333333333, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.47692307692307695, 'pegasus_entailment': 0.3473587790504098, 'gold_entailment': 0.028786607086658478, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.4545454545454545, 'pegasus_entailment': 0.39373133510816843, 'gold_entailment': 0.3634319891571067, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5368421052631579, 'r1_recall': 0.7183098591549296, 'r1_f1': 0.6144578313253012, 'pegasus_entailment': 0.7778737743695577, 'gold_entailment': 0.04220751824323088, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3709677419354839, 'r1_recall': 0.4423076923076923, 'r1_f1': 0.4035087719298246, 'pegasus_entailment': 0.21678378980141133, 'gold_entailment': 0.06188227981328964, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5873015873015873, 'r1_recall': 0.3162393162393162, 'r1_f1': 0.4111111111111111, 'pegasus_entailment': 0.35009337961673737, 'gold_entailment': 0.0624655983003322, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6134453781512605, 'r1_recall': 0.5572519083969466, 'r1_f1': 0.5840000000000001, 'pegasus_entailment': 0.6381998814642429, 'gold_entailment': 0.35816083910564583, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4396551724137931, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.51, 'pegasus_entailment': 0.47908449452370405, 'gold_entailment': 0.04755777423270047, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 16}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5873015873015873, 'r1_recall': 0.4111111111111111, 'r1_f1': 0.48366013071895425, 'pegasus_entailment': 0.8517606973648071, 'gold_entailment': 0.39818930400845903, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36428571428571427, 'r1_recall': 0.5604395604395604, 'r1_f1': 0.44155844155844154, 'pegasus_entailment': 0.4647873668000102, 'gold_entailment': 0.15598536220689616, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5048543689320388, 'r1_recall': 0.4727272727272727, 'r1_f1': 0.4882629107981221, 'pegasus_entailment': 0.5111523396335542, 'gold_entailment': 0.20204653695691377, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.704225352112676, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.6134969325153373, 'pegasus_entailment': 0.5239903635811061, 'gold_entailment': 0.36044286106334766, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5735294117647058, 'r1_recall': 0.39, 'r1_f1': 0.46428571428571425, 'pegasus_entailment': 0.49546031560748816, 'gold_entailment': 0.2267099916934967, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4057971014492754, 'r1_recall': 0.4057971014492754, 'r1_f1': 0.4057971014492754, 'pegasus_entailment': 0.30210470567302156, 'gold_entailment': 0.010641462868079543, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.59375, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.6229508196721311, 'pegasus_entailment': 0.5557770796120167, 'gold_entailment': 0.04850038420408964, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6375, 'r1_recall': 0.5, 'r1_f1': 0.5604395604395604, 'pegasus_entailment': 0.3106218483299017, 'gold_entailment': 0.1955536333261989, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5319148936170213, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.5617977528089887, 'pegasus_entailment': 0.913903146982193, 'gold_entailment': 0.16368453021277674, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 32, 'pegasus_smog': 21}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25217391304347825, 'r1_recall': 0.5576923076923077, 'r1_f1': 0.34730538922155685, 'pegasus_entailment': 0.3298088485219826, 'gold_entailment': 0.012086637007693449, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5785123966942148, 'r1_recall': 0.48951048951048953, 'r1_f1': 0.5303030303030303, 'pegasus_entailment': 0.3690960228443146, 'gold_entailment': 0.4072048753499985, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.5649717514124294, 'pegasus_entailment': 0.47415355569683015, 'gold_entailment': 0.08335887506837025, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4339622641509434, 'r1_recall': 0.42592592592592593, 'r1_f1': 0.4299065420560748, 'pegasus_entailment': 0.48910169831166667, 'gold_entailment': 0.008842060939059593, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6086956521739131, 'r1_recall': 0.4628099173553719, 'r1_f1': 0.5258215962441315, 'pegasus_entailment': 0.46484872698783875, 'gold_entailment': 0.1305055858434311, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.23076923076923078, 'r1_f1': 0.3243243243243243, 'pegasus_entailment': 0.8898718059062958, 'gold_entailment': 0.008136293074736992, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 11, 'pegasus_smog': 15}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4642857142857143, 'r1_recall': 0.7428571428571429, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.3284038841724396, 'gold_entailment': 0.2568829034765561, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34579439252336447, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.4134078212290503, 'pegasus_entailment': 0.4921722486615181, 'gold_entailment': 0.00219037476927042, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5411764705882353, 'r1_recall': 0.5168539325842697, 'r1_f1': 0.5287356321839081, 'pegasus_entailment': 0.4980105559031169, 'gold_entailment': 0.15422443408169784, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2191780821917808, 'r1_recall': 0.35555555555555557, 'r1_f1': 0.27118644067796605, 'pegasus_entailment': 0.35318354664680857, 'gold_entailment': 0.0016082852962426841, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7073170731707317, 'r1_recall': 0.5631067961165048, 'r1_f1': 0.627027027027027, 'pegasus_entailment': 0.1850177536252886, 'gold_entailment': 0.24527579049269357, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18604651162790697, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.2644628099173553, 'pegasus_entailment': 0.23487634416669606, 'gold_entailment': 0.005675496271578595, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.4827586206896552, 'pegasus_entailment': 0.9366413354873657, 'gold_entailment': 0.009465303970500827, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 23, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2627118644067797, 'r1_recall': 0.7948717948717948, 'r1_f1': 0.39490445859872614, 'pegasus_entailment': 0.6135494684179624, 'gold_entailment': 0.9665668308734894, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6521739130434783, 'r1_recall': 0.6081081081081081, 'r1_f1': 0.6293706293706294, 'pegasus_entailment': 0.5549054505924383, 'gold_entailment': 0.24746280748929297, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5934959349593496, 'r1_recall': 0.6347826086956522, 'r1_f1': 0.6134453781512604, 'pegasus_entailment': 0.5793969352962449, 'gold_entailment': 0.2768212218186818, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5118110236220472, 'r1_recall': 0.6770833333333334, 'r1_f1': 0.5829596412556054, 'pegasus_entailment': 0.7870889703432719, 'gold_entailment': 0.054155819195633136, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6274509803921569, 'r1_recall': 0.5871559633027523, 'r1_f1': 0.6066350710900474, 'pegasus_entailment': 0.6559497475624084, 'gold_entailment': 0.30713412119075656, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6753246753246753, 'r1_recall': 0.37681159420289856, 'r1_f1': 0.4837209302325581, 'pegasus_entailment': 0.24669867439661175, 'gold_entailment': 0.3220448629163002, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8208955223880597, 'r1_recall': 0.3125, 'r1_f1': 0.4526748971193416, 'pegasus_entailment': 0.4926741451025009, 'gold_entailment': 0.39623687213419806, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39766081871345027, 'r1_recall': 0.6126126126126126, 'r1_f1': 0.48226950354609927, 'pegasus_entailment': 0.8899742960929871, 'gold_entailment': 0.33534100092947483, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6708860759493671, 'r1_recall': 0.35570469798657717, 'r1_f1': 0.46491228070175433, 'pegasus_entailment': 0.5881495264358818, 'gold_entailment': 0.14060573996976017, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7701149425287356, 'r1_recall': 0.44966442953020136, 'r1_f1': 0.5677966101694916, 'pegasus_entailment': 0.38981424768765766, 'gold_entailment': 0.4273678451776505, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2972972972972973, 'r1_recall': 0.4489795918367347, 'r1_f1': 0.35772357723577236, 'pegasus_entailment': 0.7222437858581543, 'gold_entailment': 0.1427827340036553, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4883720930232558, 'pegasus_entailment': 0.37692776570717496, 'gold_entailment': 0.4238335640790562, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42424242424242425, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.6150649413466454, 'gold_entailment': 0.06680675440778334, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8053097345132744, 'r1_recall': 0.6066666666666667, 'r1_f1': 0.6920152091254754, 'pegasus_entailment': 0.8658610184987386, 'gold_entailment': 0.6931761026382446, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39080459770114945, 'r1_recall': 0.5074626865671642, 'r1_f1': 0.44155844155844154, 'pegasus_entailment': 0.10269458654026191, 'gold_entailment': 0.0034799910499714315, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7651515151515151, 'r1_recall': 0.5872093023255814, 'r1_f1': 0.6644736842105263, 'pegasus_entailment': 0.5947803317685612, 'gold_entailment': 0.29988638013310265, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.4367816091954023, 'pegasus_entailment': 0.6721809878945351, 'gold_entailment': 0.19934969954192638, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53125, 'r1_recall': 0.6296296296296297, 'r1_f1': 0.5762711864406779, 'pegasus_entailment': 0.48333941400051117, 'gold_entailment': 0.3586513064801693, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6031746031746031, 'r1_recall': 0.5390070921985816, 'r1_f1': 0.5692883895131086, 'pegasus_entailment': 0.17376012559980153, 'gold_entailment': 0.11073687362174194, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38190954773869346, 'r1_recall': 0.5801526717557252, 'r1_f1': 0.4606060606060606, 'pegasus_entailment': 0.17886106502264737, 'gold_entailment': 0.24617355262550214, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6699029126213593, 'r1_recall': 0.323943661971831, 'r1_f1': 0.4367088607594937, 'pegasus_entailment': 0.0966281204794844, 'gold_entailment': 0.262417432602628, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5175438596491229, 'r1_recall': 0.6555555555555556, 'r1_f1': 0.5784313725490198, 'pegasus_entailment': 0.542615326034138, 'gold_entailment': 0.1260138573901107, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4675324675324675, 'r1_recall': 0.631578947368421, 'r1_f1': 0.5373134328358209, 'pegasus_entailment': 0.23224416808225215, 'gold_entailment': 0.058098971436265856, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7444444444444445, 'r1_recall': 0.3544973544973545, 'r1_f1': 0.48028673835125446, 'pegasus_entailment': 0.52415612898767, 'gold_entailment': 0.28096816564599675, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6972972972972973, 'r1_recall': 0.4243421052631579, 'r1_f1': 0.5276073619631902, 'pegasus_entailment': 0.8152580459912618, 'gold_entailment': 0.5141631603861848, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31868131868131866, 'r1_recall': 0.4603174603174603, 'r1_f1': 0.37662337662337664, 'pegasus_entailment': 0.5978337575991949, 'gold_entailment': 0.1895207658332462, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5686274509803921, 'r1_recall': 0.6105263157894737, 'r1_f1': 0.5888324873096447, 'pegasus_entailment': 0.4821453450786066, 'gold_entailment': 0.060063050310418475, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8450704225352113, 'r1_recall': 0.379746835443038, 'r1_f1': 0.5240174672489083, 'pegasus_entailment': 0.3220015987753868, 'gold_entailment': 0.29939741967245936, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3283582089552239, 'r1_recall': 0.3793103448275862, 'r1_f1': 0.35200000000000004, 'pegasus_entailment': 0.31179304063941043, 'gold_entailment': 0.2616088520735502, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7560975609756098, 'r1_recall': 0.3425414364640884, 'r1_f1': 0.4714828897338403, 'pegasus_entailment': 0.6939568221569061, 'gold_entailment': 0.4343235517024166, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5802469135802469, 'r1_recall': 0.33098591549295775, 'r1_f1': 0.4215246636771301, 'pegasus_entailment': 0.26451093005016446, 'gold_entailment': 0.07062033370129939, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6133333333333333, 'r1_recall': 0.4842105263157895, 'r1_f1': 0.5411764705882353, 'pegasus_entailment': 0.48058173805475235, 'gold_entailment': 0.07760626260035981, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6597938144329897, 'r1_recall': 0.37209302325581395, 'r1_f1': 0.4758364312267657, 'pegasus_entailment': 0.6313366517424583, 'gold_entailment': 0.1552409135038033, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5113636363636364, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.5660377358490567, 'pegasus_entailment': 0.7105760909616947, 'gold_entailment': 0.24674090867241225, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8714285714285714, 'r1_recall': 0.2932692307692308, 'r1_f1': 0.4388489208633094, 'pegasus_entailment': 0.21176046691834927, 'gold_entailment': 0.07717976670755888, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6078431372549019, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6358974358974359, 'pegasus_entailment': 0.6651178020983934, 'gold_entailment': 0.7074314130935818, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4838709677419355, 'r1_recall': 0.6, 'r1_f1': 0.5357142857142857, 'pegasus_entailment': 0.07648428116226569, 'gold_entailment': 0.13910233601927757, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7, 'r1_recall': 0.49295774647887325, 'r1_f1': 0.5785123966942148, 'pegasus_entailment': 0.9180505275726318, 'gold_entailment': 0.034516213461756706, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5660377358490566, 'r1_recall': 0.594059405940594, 'r1_f1': 0.5797101449275361, 'pegasus_entailment': 0.18962066085077822, 'gold_entailment': 0.32303407427389175, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8, 'r1_recall': 0.4057971014492754, 'r1_f1': 0.5384615384615384, 'pegasus_entailment': 0.7308410108089447, 'gold_entailment': 0.379718161188066, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.48484848484848486, 'pegasus_entailment': 0.7020678992848843, 'gold_entailment': 0.29199710856191813, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28, 'r1_recall': 0.35, 'r1_f1': 0.3111111111111111, 'pegasus_entailment': 0.14270382995406786, 'gold_entailment': 0.09762512519955635, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8214285714285714, 'r1_recall': 0.5168539325842697, 'r1_f1': 0.6344827586206896, 'pegasus_entailment': 0.4130782832702001, 'gold_entailment': 0.22036104113794863, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5542168674698795, 'r1_recall': 0.6301369863013698, 'r1_f1': 0.5897435897435898, 'pegasus_entailment': 0.289337923633866, 'gold_entailment': 0.023308962350711226, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5402298850574713, 'r1_recall': 0.618421052631579, 'r1_f1': 0.5766871165644173, 'pegasus_entailment': 0.22291471033046642, 'gold_entailment': 0.5025063852469126, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4634146341463415, 'r1_recall': 0.6263736263736264, 'r1_f1': 0.5327102803738318, 'pegasus_entailment': 0.3463135531172156, 'gold_entailment': 0.15328119741752744, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7361111111111112, 'r1_recall': 0.44166666666666665, 'r1_f1': 0.5520833333333333, 'pegasus_entailment': 0.2918962715193629, 'gold_entailment': 0.11743890424259007, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8618421052631579, 'r1_recall': 0.37163120567375885, 'r1_f1': 0.5193260654112983, 'pegasus_entailment': 0.6230969841663654, 'gold_entailment': 0.4889790862798691, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.616822429906542, 'r1_recall': 0.4647887323943662, 'r1_f1': 0.5301204819277109, 'pegasus_entailment': 0.3929691582918167, 'gold_entailment': 0.3052329934434965, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8679245283018868, 'r1_recall': 0.5027322404371585, 'r1_f1': 0.6366782006920415, 'pegasus_entailment': 0.6230376124382019, 'gold_entailment': 0.33338041909571203, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.43010752688172044, 'r1_f1': 0.4761904761904762, 'pegasus_entailment': 0.744729628165563, 'gold_entailment': 0.19529477506875992, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7019230769230769, 'r1_recall': 0.6293103448275862, 'r1_f1': 0.6636363636363637, 'pegasus_entailment': 0.29046009201556444, 'gold_entailment': 0.35136879270430654, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5443037974683544, 'r1_recall': 0.6615384615384615, 'r1_f1': 0.5972222222222222, 'pegasus_entailment': 0.0010813877840215962, 'gold_entailment': 0.002659202495124191, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4888888888888889, 'r1_recall': 0.5605095541401274, 'r1_f1': 0.5222551928783383, 'pegasus_entailment': 0.7882148325443268, 'gold_entailment': 0.16189659786011493, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3069306930693069, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.41610738255033564, 'pegasus_entailment': 0.8206717371940613, 'gold_entailment': 0.06935154055827297, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5866666666666667, 'r1_recall': 0.4536082474226804, 'r1_f1': 0.5116279069767442, 'pegasus_entailment': 0.9857164621353149, 'gold_entailment': 0.09592802443512483, 'pegasus_flesch_kincaid': 38, 'pegasus_coleman_liau': 19, 'pegasus_ari': 45, 'pegasus_smog': 29}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2465753424657534, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.33333333333333326, 'pegasus_entailment': 0.31735015163818997, 'gold_entailment': 0.00934230355778709, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6363636363636364, 'r1_recall': 0.5051546391752577, 'r1_f1': 0.5632183908045978, 'pegasus_entailment': 0.5152123423293233, 'gold_entailment': 0.2945763113675639, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6146788990825688, 'r1_recall': 0.5929203539823009, 'r1_f1': 0.6036036036036037, 'pegasus_entailment': 0.47973431064747274, 'gold_entailment': 0.10843513126019388, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5789473684210527, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.5301204819277109, 'pegasus_entailment': 0.47816837835125625, 'gold_entailment': 0.06696471065515652, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.4166666666666667, 'pegasus_entailment': 0.21650009090080857, 'gold_entailment': 0.193747878074646, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5925925925925926, 'r1_recall': 0.32, 'r1_f1': 0.41558441558441556, 'pegasus_entailment': 0.10445785894989967, 'gold_entailment': 0.1726630056897799, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.14736842105263157
MEAN
0.5628183361103839
MAX
0.935064935064935
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.17525773195876287
MEAN
0.5219453301151812
MAX
0.8103448275862069
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.21686746987951805
MEAN
0.5210191303093665
MAX
0.7349397590361445
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.0010813877840215962
MEAN
0.46798170307807
MAX
0.9857164621353149
** Analysing column: gold_entailment



gold_entailment
Length after nones removed
616
MIN
0.00023849141143728048
MEAN
0.21220810943247564
MAX
0.9665668308734894
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
16
MAX
38
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
12
MEAN
17
MAX
23
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
11
MEAN
19
MAX
45
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
8
MEAN
18
MAX
29
{}
Entered file!
Imports done!
*** RUN *** 
eval_3cO
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 13:50:12.099276: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 13:50:12.655308: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/3cO_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5084745762711864, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.6728895008563995, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6907216494845361, 'r1_recall': 0.3872832369942196, 'r1_f1': 0.4962962962962963, 'pegasus_entailment': 0.563499025379618, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34545454545454546, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.4523809523809524, 'pegasus_entailment': 0.5667998902499676, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.725, 'r1_recall': 0.4496124031007752, 'r1_f1': 0.5550239234449761, 'pegasus_entailment': 0.39818019171555835, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7922077922077922, 'r1_recall': 0.3505747126436782, 'r1_f1': 0.4860557768924303, 'pegasus_entailment': 0.43272560462355614, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5338983050847458, 'r1_recall': 0.4846153846153846, 'r1_f1': 0.5080645161290324, 'pegasus_entailment': 0.6904839336872101, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20481927710843373, 'r1_recall': 0.53125, 'r1_f1': 0.29565217391304344, 'pegasus_entailment': 0.30055899638682604, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2823529411764706, 'r1_recall': 0.7741935483870968, 'r1_f1': 0.41379310344827586, 'pegasus_entailment': 0.6532909355591983, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7093023255813954, 'r1_recall': 0.40939597315436244, 'r1_f1': 0.5191489361702127, 'pegasus_entailment': 0.49635203287471086, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6216216216216216, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6433566433566433, 'pegasus_entailment': 0.397638552589342, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6813186813186813, 'r1_recall': 0.41333333333333333, 'r1_f1': 0.5145228215767634, 'pegasus_entailment': 0.2611034633591771, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5544554455445545, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.509090909090909, 'pegasus_entailment': 0.6742792750398318, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6962025316455697, 'r1_recall': 0.514018691588785, 'r1_f1': 0.5913978494623655, 'pegasus_entailment': 0.6570263306299845, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6447368421052632, 'r1_recall': 0.5568181818181818, 'r1_f1': 0.5975609756097561, 'pegasus_entailment': 0.4803968509659171, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7631578947368421, 'r1_recall': 0.453125, 'r1_f1': 0.5686274509803922, 'pegasus_entailment': 0.6411979481577873, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.24545454545454545, 'r1_recall': 0.4576271186440678, 'r1_f1': 0.31952662721893493, 'pegasus_entailment': 0.6570335403084755, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40425531914893614, 'r1_recall': 0.3838383838383838, 'r1_f1': 0.3937823834196891, 'pegasus_entailment': 0.1458160483078765, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7835820895522388, 'r1_recall': 0.3523489932885906, 'r1_f1': 0.48611111111111105, 'pegasus_entailment': 0.4958099400003751, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5977011494252874, 'r1_recall': 0.32298136645962733, 'r1_f1': 0.41935483870967744, 'pegasus_entailment': 0.4853263795375824, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49523809523809526, 'r1_recall': 0.5977011494252874, 'r1_f1': 0.5416666666666666, 'pegasus_entailment': 0.40044041629880667, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6145833333333334, 'r1_recall': 0.3241758241758242, 'r1_f1': 0.42446043165467623, 'pegasus_entailment': 0.6067161340266466, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7333333333333333, 'r1_recall': 0.44, 'r1_f1': 0.5499999999999999, 'pegasus_entailment': 0.6958393653233846, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 24, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7023809523809523, 'r1_recall': 0.5462962962962963, 'r1_f1': 0.6145833333333334, 'pegasus_entailment': 0.49721175283193586, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5904761904761905, 'r1_recall': 0.45588235294117646, 'r1_f1': 0.5145228215767634, 'pegasus_entailment': 0.46655195485800505, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4166666666666667, 'r1_recall': 0.5, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.5753415897488594, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7672413793103449, 'r1_recall': 0.4708994708994709, 'r1_f1': 0.5836065573770491, 'pegasus_entailment': 0.5935098511399701, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5179856115107914, 'r1_recall': 0.5255474452554745, 'r1_f1': 0.5217391304347826, 'pegasus_entailment': 0.3755088460942109, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7045454545454546, 'r1_recall': 0.34701492537313433, 'r1_f1': 0.465, 'pegasus_entailment': 0.49354386925697324, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4342105263157895, 'r1_f1': 0.4647887323943662, 'pegasus_entailment': 0.2416396364569664, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5952380952380952, 'r1_recall': 0.4424778761061947, 'r1_f1': 0.5076142131979696, 'pegasus_entailment': 0.6516101825982332, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.6436781609195402, 'r1_f1': 0.5258215962441315, 'pegasus_entailment': 0.23102790091070347, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7706422018348624, 'r1_recall': 0.417910447761194, 'r1_f1': 0.5419354838709677, 'pegasus_entailment': 0.8112007081508636, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4095238095238095, 'r1_recall': 0.4174757281553398, 'r1_f1': 0.4134615384615385, 'pegasus_entailment': 0.24400661629624665, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49411764705882355, 'r1_recall': 0.4329896907216495, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.6113862693309784, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40404040404040403, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.4371584699453551, 'pegasus_entailment': 0.033608833141624925, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6307692307692307, 'r1_recall': 0.35344827586206895, 'r1_f1': 0.4530386740331491, 'pegasus_entailment': 0.2789660170674324, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4188034188034188, 'r1_recall': 0.7101449275362319, 'r1_f1': 0.5268817204301075, 'pegasus_entailment': 0.2746028364927042, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4931506849315068, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.5106382978723404, 'pegasus_entailment': 0.10549156825679044, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30985915492957744, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.3793103448275862, 'pegasus_entailment': 0.6182864877628163, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6583333333333333, 'r1_recall': 0.4759036144578313, 'r1_f1': 0.5524475524475524, 'pegasus_entailment': 0.2753049859777093, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6578947368421053, 'r1_recall': 0.3125, 'r1_f1': 0.42372881355932207, 'pegasus_entailment': 0.8087471822897593, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4672897196261682, 'r1_recall': 0.6493506493506493, 'r1_f1': 0.5434782608695652, 'pegasus_entailment': 0.6232298314571381, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4307692307692308, 'r1_recall': 0.3835616438356164, 'r1_f1': 0.40579710144927533, 'pegasus_entailment': 0.0865792654415903, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.532258064516129, 'r1_recall': 0.5365853658536586, 'r1_f1': 0.534412955465587, 'pegasus_entailment': 0.8206859230995178, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4823529411764706, 'r1_recall': 0.5256410256410257, 'r1_f1': 0.5030674846625767, 'pegasus_entailment': 0.35956796794198453, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4947916666666667, 'r1_recall': 0.6333333333333333, 'r1_f1': 0.5555555555555556, 'pegasus_entailment': 0.6679202429950237, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 19, 'pegasus_ari': 32, 'pegasus_smog': 23}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6727272727272727, 'r1_recall': 0.3135593220338983, 'r1_f1': 0.42774566473988446, 'pegasus_entailment': 0.6752556886640377, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3933333333333333, 'r1_recall': 0.5315315315315315, 'r1_f1': 0.4521072796934866, 'pegasus_entailment': 0.6005184891012808, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4818181818181818, 'r1_recall': 0.6309523809523809, 'r1_f1': 0.5463917525773195, 'pegasus_entailment': 0.34342296281829476, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4125, 'r1_recall': 0.3173076923076923, 'r1_f1': 0.358695652173913, 'pegasus_entailment': 0.17105534905567765, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28368794326241137, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.37209302325581395, 'pegasus_entailment': 0.26277469331398606, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26548672566371684, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.36585365853658536, 'pegasus_entailment': 0.47579747579584364, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4418604651162791, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.47500000000000003, 'pegasus_entailment': 0.4287616442888975, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6372549019607843, 'r1_recall': 0.3672316384180791, 'r1_f1': 0.4659498207885304, 'pegasus_entailment': 0.19135347877939543, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6851851851851852, 'r1_recall': 0.4157303370786517, 'r1_f1': 0.5174825174825175, 'pegasus_entailment': 0.3237384788226336, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42342342342342343, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.5136612021857924, 'pegasus_entailment': 0.5800165764987468, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.9357798165137615, 'r1_recall': 0.4063745019920319, 'r1_f1': 0.5666666666666668, 'pegasus_entailment': 0.5369794126600027, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5285714285714286, 'r1_recall': 0.578125, 'r1_f1': 0.5522388059701493, 'pegasus_entailment': 0.3247617844026536, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6545454545454545, 'r1_recall': 0.5950413223140496, 'r1_f1': 0.6233766233766234, 'pegasus_entailment': 0.4272975826606853, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5076923076923077, 'r1_recall': 0.6285714285714286, 'r1_f1': 0.5617021276595745, 'pegasus_entailment': 0.4305640904698521, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5662650602409639, 'r1_recall': 0.5340909090909091, 'r1_f1': 0.5497076023391813, 'pegasus_entailment': 0.9045725166797638, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4696969696969697, 'r1_recall': 0.4305555555555556, 'r1_f1': 0.44927536231884063, 'pegasus_entailment': 0.005929701573525866, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7640449438202247, 'r1_recall': 0.40476190476190477, 'r1_f1': 0.5291828793774319, 'pegasus_entailment': 0.4097829646198079, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6133333333333333, 'r1_recall': 0.4742268041237113, 'r1_f1': 0.5348837209302325, 'pegasus_entailment': 0.5331262352410704, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.325, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.40624999999999994, 'pegasus_entailment': 0.3676941868616268, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6551724137931034, 'r1_recall': 0.5984251968503937, 'r1_f1': 0.625514403292181, 'pegasus_entailment': 0.7999638319015503, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5283018867924528, 'r1_recall': 0.5283018867924528, 'r1_f1': 0.5283018867924528, 'pegasus_entailment': 0.3862673798343167, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6056338028169014, 'r1_recall': 0.4479166666666667, 'r1_f1': 0.5149700598802396, 'pegasus_entailment': 0.5708935151730353, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5263157894736842, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.47619047619047616, 'pegasus_entailment': 0.17667017942294477, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6790123456790124, 'r1_recall': 0.5392156862745098, 'r1_f1': 0.6010928961748634, 'pegasus_entailment': 0.19933045803918503, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5824175824175825, 'r1_recall': 0.3192771084337349, 'r1_f1': 0.41245136186770426, 'pegasus_entailment': 0.5407300582155585, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43617021276595747, 'r1_recall': 0.6029411764705882, 'r1_f1': 0.5061728395061729, 'pegasus_entailment': 0.2692204313352704, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 13}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4105263157894737, 'r1_recall': 0.5909090909090909, 'r1_f1': 0.484472049689441, 'pegasus_entailment': 0.26765706622973084, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8230088495575221, 'r1_recall': 0.48947368421052634, 'r1_f1': 0.613861386138614, 'pegasus_entailment': 0.8490425646305084, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32167832167832167, 'r1_recall': 0.6388888888888888, 'r1_f1': 0.42790697674418604, 'pegasus_entailment': 0.3563600505391757, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6197183098591549, 'r1_recall': 0.5176470588235295, 'r1_f1': 0.5641025641025641, 'pegasus_entailment': 0.47142335524161655, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37373737373737376, 'r1_recall': 0.578125, 'r1_f1': 0.45398773006134974, 'pegasus_entailment': 0.2360789842544667, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4044943820224719, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.5106382978723405, 'pegasus_entailment': 0.5210725301876664, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5625, 'r1_recall': 0.627906976744186, 'r1_f1': 0.5934065934065934, 'pegasus_entailment': 0.006855641646931569, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5263157894736842, 'r1_recall': 0.5970149253731343, 'r1_f1': 0.5594405594405594, 'pegasus_entailment': 0.2527947826310992, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.6025641025641025, 'r1_f1': 0.4292237442922374, 'pegasus_entailment': 0.3726871384307742, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7402597402597403, 'r1_recall': 0.5533980582524272, 'r1_f1': 0.6333333333333333, 'pegasus_entailment': 0.33171678639094654, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4019607843137255, 'r1_recall': 0.6307692307692307, 'r1_f1': 0.4910179640718563, 'pegasus_entailment': 0.645894301434358, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 21, 'pegasus_ari': 35, 'pegasus_smog': 26}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.55, 'r1_recall': 0.5057471264367817, 'r1_f1': 0.5269461077844312, 'pegasus_entailment': 0.24158075074665247, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5344827586206896, 'r1_recall': 0.6739130434782609, 'r1_f1': 0.5961538461538461, 'pegasus_entailment': 0.43551715165376664, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39215686274509803, 'r1_recall': 0.45977011494252873, 'r1_f1': 0.42328042328042326, 'pegasus_entailment': 0.053962199337547645, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2920353982300885, 'r1_recall': 0.4230769230769231, 'r1_f1': 0.34554973821989526, 'pegasus_entailment': 0.10218100619968026, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2882882882882883, 'r1_recall': 0.7111111111111111, 'r1_f1': 0.41025641025641024, 'pegasus_entailment': 0.7262706259886423, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6842105263157895, 'r1_recall': 0.5, 'r1_f1': 0.5777777777777778, 'pegasus_entailment': 0.43928745202720165, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43209876543209874, 'r1_recall': 0.5, 'r1_f1': 0.4635761589403974, 'pegasus_entailment': 0.4155514161102474, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6233766233766234, 'r1_recall': 0.5, 'r1_f1': 0.5549132947976878, 'pegasus_entailment': 0.4494427274912596, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 25}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.3582089552238806, 'r1_f1': 0.4403669724770642, 'pegasus_entailment': 0.46985431388020515, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.5753424657534246, 'r1_f1': 0.4912280701754386, 'pegasus_entailment': 0.2948992622065513, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5211267605633803, 'r1_recall': 0.3162393162393162, 'r1_f1': 0.3936170212765957, 'pegasus_entailment': 0.41345118675380943, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4262295081967213, 'r1_recall': 0.26804123711340205, 'r1_f1': 0.3291139240506329, 'pegasus_entailment': 0.0008791161235421896, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5905511811023622, 'r1_recall': 0.423728813559322, 'r1_f1': 0.4934210526315788, 'pegasus_entailment': 0.2831490308046341, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.52, 'r1_recall': 0.5360824742268041, 'r1_f1': 0.5279187817258884, 'pegasus_entailment': 0.48953921943902967, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4583333333333333, 'r1_recall': 0.4365079365079365, 'r1_f1': 0.4471544715447155, 'pegasus_entailment': 0.47362574966003496, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35353535353535354, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.426829268292683, 'pegasus_entailment': 0.2886510118842125, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5268817204301075, 'r1_recall': 0.4375, 'r1_f1': 0.47804878048780486, 'pegasus_entailment': 0.29115817649289966, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4057971014492754, 'r1_recall': 0.45901639344262296, 'r1_f1': 0.4307692307692308, 'pegasus_entailment': 0.6002917174870769, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5063291139240507, 'r1_recall': 0.425531914893617, 'r1_f1': 0.46242774566473993, 'pegasus_entailment': 0.27510573466618854, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.524822695035461, 'r1_recall': 0.6434782608695652, 'r1_f1': 0.578125, 'pegasus_entailment': 0.7092788852751255, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5225225225225225, 'r1_recall': 0.5178571428571429, 'r1_f1': 0.5201793721973095, 'pegasus_entailment': 0.4311447440995835, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6082474226804123, 'r1_recall': 0.7375, 'r1_f1': 0.6666666666666667, 'pegasus_entailment': 0.8922759890556335, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7352941176470589, 'r1_recall': 0.3875968992248062, 'r1_f1': 0.5076142131979695, 'pegasus_entailment': 0.8824296295642853, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4460431654676259, 'r1_recall': 0.6019417475728155, 'r1_f1': 0.512396694214876, 'pegasus_entailment': 0.312608110155755, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5630252100840336, 'r1_recall': 0.41875, 'r1_f1': 0.4802867383512545, 'pegasus_entailment': 0.929780900478363, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3253968253968254, 'r1_recall': 0.5466666666666666, 'r1_f1': 0.4079601990049751, 'pegasus_entailment': 0.23708111704327167, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4117647058823529, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4827586206896552, 'pegasus_entailment': 0.577480566338636, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41904761904761906, 'r1_recall': 0.6376811594202898, 'r1_f1': 0.5057471264367815, 'pegasus_entailment': 0.2309357394806284, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5979381443298969, 'r1_recall': 0.43609022556390975, 'r1_f1': 0.5043478260869565, 'pegasus_entailment': 0.3265634826384485, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5616438356164384, 'r1_recall': 0.5189873417721519, 'r1_f1': 0.5394736842105262, 'pegasus_entailment': 0.2484870305925142, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48514851485148514, 'r1_recall': 0.550561797752809, 'r1_f1': 0.5157894736842105, 'pegasus_entailment': 0.7007120748360952, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5423728813559322, 'r1_recall': 0.24615384615384617, 'r1_f1': 0.3386243386243386, 'pegasus_entailment': 0.493379894644022, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 22, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6551724137931034, 'r1_recall': 0.3202247191011236, 'r1_f1': 0.43018867924528303, 'pegasus_entailment': 0.19790250490186737, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8913043478260869, 'r1_recall': 0.4659090909090909, 'r1_f1': 0.6119402985074627, 'pegasus_entailment': 0.6700959627827009, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4830508474576271, 'r1_recall': 0.4253731343283582, 'r1_f1': 0.45238095238095233, 'pegasus_entailment': 0.3710053404793143, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 15, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5280898876404494, 'r1_recall': 0.5, 'r1_f1': 0.5136612021857924, 'pegasus_entailment': 0.11297679071625073, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47297297297297297, 'r1_recall': 0.5511811023622047, 'r1_f1': 0.5090909090909091, 'pegasus_entailment': 0.7167321098968387, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5180722891566265, 'r1_recall': 0.48863636363636365, 'r1_f1': 0.5029239766081872, 'pegasus_entailment': 0.9743112126986185, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3619047619047619, 'r1_recall': 0.6608695652173913, 'r1_f1': 0.46769230769230763, 'pegasus_entailment': 0.27010217117559576, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4576271186440678, 'r1_recall': 0.7105263157894737, 'r1_f1': 0.5567010309278351, 'pegasus_entailment': 0.5396963265549857, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3170731707317073, 'r1_recall': 0.6046511627906976, 'r1_f1': 0.4159999999999999, 'pegasus_entailment': 0.6122270375490189, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 25}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6612903225806451, 'r1_recall': 0.7321428571428571, 'r1_f1': 0.6949152542372881, 'pegasus_entailment': 0.7275459571974352, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6388888888888888, 'r1_recall': 0.5267175572519084, 'r1_f1': 0.5774058577405857, 'pegasus_entailment': 0.9001575857400894, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 23}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7254901960784313, 'r1_recall': 0.4625, 'r1_f1': 0.5648854961832062, 'pegasus_entailment': 0.4037696210046609, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5801526717557252, 'r1_recall': 0.6495726495726496, 'r1_f1': 0.6129032258064516, 'pegasus_entailment': 0.5935545763932168, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3384615384615385, 'r1_recall': 0.5689655172413793, 'r1_f1': 0.4244372990353698, 'pegasus_entailment': 0.590149165984864, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 16, 'pegasus_ari': 30, 'pegasus_smog': 21}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37362637362637363, 'r1_recall': 0.576271186440678, 'r1_f1': 0.4533333333333333, 'pegasus_entailment': 0.13358024565386586, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7226890756302521, 'r1_recall': 0.455026455026455, 'r1_f1': 0.5584415584415584, 'pegasus_entailment': 0.494156817595164, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6736842105263158, 'r1_recall': 0.5289256198347108, 'r1_f1': 0.5925925925925927, 'pegasus_entailment': 0.5897099025314674, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7536231884057971, 'r1_recall': 0.33548387096774196, 'r1_f1': 0.4642857142857143, 'pegasus_entailment': 0.4193739788606763, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6504854368932039, 'r1_recall': 0.4110429447852761, 'r1_f1': 0.5037593984962406, 'pegasus_entailment': 0.3949920702725649, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.59375, 'r1_recall': 0.37623762376237624, 'r1_f1': 0.46060606060606063, 'pegasus_entailment': 0.5390050479521354, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5765765765765766, 'r1_recall': 0.5289256198347108, 'r1_f1': 0.5517241379310346, 'pegasus_entailment': 0.6340674161911011, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4666666666666667, 'r1_recall': 0.6021505376344086, 'r1_f1': 0.5258215962441315, 'pegasus_entailment': 0.1599062101200356, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.6062992125984253, 'pegasus_entailment': 0.9383245507876078, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7, 'r1_recall': 0.3027027027027027, 'r1_f1': 0.4226415094339623, 'pegasus_entailment': 0.7113926013310751, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3855421686746988, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.45390070921985815, 'pegasus_entailment': 0.19851951838548607, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5543478260869565, 'r1_recall': 0.5795454545454546, 'r1_f1': 0.5666666666666668, 'pegasus_entailment': 0.37880341266281903, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41414141414141414, 'r1_recall': 0.44086021505376344, 'r1_f1': 0.4270833333333333, 'pegasus_entailment': 0.006702508466939132, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4880952380952381, 'r1_recall': 0.36283185840707965, 'r1_f1': 0.4162436548223351, 'pegasus_entailment': 0.5612882723410925, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6164383561643836, 'r1_recall': 0.5625, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.4897824567742646, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6265060240963856, 'r1_recall': 0.5148514851485149, 'r1_f1': 0.5652173913043479, 'pegasus_entailment': 0.4712063918511073, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.009569377990430622, 'r1_f1': 0.018779342723004692, 'pegasus_entailment': 0.04381856322288513, 'pegasus_flesch_kincaid': 9, 'pegasus_coleman_liau': 5, 'pegasus_ari': 4, 'pegasus_smog': 14}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7368421052631579, 'r1_recall': 0.5414364640883977, 'r1_f1': 0.6242038216560509, 'pegasus_entailment': 0.7033334672451019, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42105263157894735, 'r1_recall': 0.4067796610169492, 'r1_f1': 0.4137931034482759, 'pegasus_entailment': 0.9503402709960938, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8051948051948052, 'r1_recall': 0.38271604938271603, 'r1_f1': 0.5188284518828452, 'pegasus_entailment': 0.4761297330260277, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3684210526315789, 'r1_recall': 0.5975609756097561, 'r1_f1': 0.4558139534883721, 'pegasus_entailment': 0.6322395093739033, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5072463768115942, 'r1_recall': 0.3645833333333333, 'r1_f1': 0.42424242424242425, 'pegasus_entailment': 0.7009024322032928, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5471698113207547, 'r1_recall': 0.6304347826086957, 'r1_f1': 0.5858585858585859, 'pegasus_entailment': 0.43423555633053185, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7471264367816092, 'r1_recall': 0.33505154639175255, 'r1_f1': 0.4626334519572953, 'pegasus_entailment': 0.5085309954981009, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5850340136054422, 'r1_recall': 0.5180722891566265, 'r1_f1': 0.549520766773163, 'pegasus_entailment': 0.3071603982576302, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5135135135135135, 'r1_recall': 0.6440677966101694, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.230946100045306, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7289719626168224, 'r1_recall': 0.4508670520231214, 'r1_f1': 0.5571428571428572, 'pegasus_entailment': 0.33919193828478456, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.1728395061728395, 'r1_f1': 0.2616822429906542, 'pegasus_entailment': 0.2775226831436157, 'pegasus_flesch_kincaid': 9, 'pegasus_coleman_liau': 13, 'pegasus_ari': 11, 'pegasus_smog': 14}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5217391304347826, 'r1_recall': 0.40268456375838924, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.27290676580742, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5225225225225225, 'r1_recall': 0.6236559139784946, 'r1_f1': 0.5686274509803921, 'pegasus_entailment': 0.35347376513042644, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5340909090909091, 'r1_recall': 0.2919254658385093, 'r1_f1': 0.37751004016064255, 'pegasus_entailment': 0.7665983438491821, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2463768115942029, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.3177570093457944, 'pegasus_entailment': 0.42127834632992744, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6829268292682927, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.5894736842105263, 'pegasus_entailment': 0.5665781253948807, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5825242718446602, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.5825242718446602, 'pegasus_entailment': 0.35576010836909217, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5980392156862745, 'r1_recall': 0.37423312883435583, 'r1_f1': 0.4603773584905661, 'pegasus_entailment': 0.30409608331198495, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5921052631578947, 'r1_recall': 0.41284403669724773, 'r1_f1': 0.4864864864864865, 'pegasus_entailment': 0.27819985430687666, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5573770491803278, 'r1_recall': 0.5795454545454546, 'r1_f1': 0.5682451253481894, 'pegasus_entailment': 0.8680182456970215, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7252747252747253, 'r1_recall': 0.44, 'r1_f1': 0.5477178423236514, 'pegasus_entailment': 0.4796169796027243, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6923076923076923, 'r1_recall': 0.38571428571428573, 'r1_f1': 0.4954128440366973, 'pegasus_entailment': 0.8629885017871857, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.3825503355704698, 'r1_f1': 0.4672131147540983, 'pegasus_entailment': 0.8503113985061646, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.475, 'r1_recall': 0.6263736263736264, 'r1_f1': 0.5402843601895734, 'pegasus_entailment': 0.7713856473565102, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44525547445255476, 'r1_recall': 0.7922077922077922, 'r1_f1': 0.5700934579439252, 'pegasus_entailment': 0.7581160966772587, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43243243243243246, 'r1_recall': 0.6575342465753424, 'r1_f1': 0.5217391304347826, 'pegasus_entailment': 0.0036948596437772117, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.86, 'r1_recall': 0.11684782608695653, 'r1_f1': 0.20574162679425836, 'pegasus_entailment': 0.7503732144832611, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4316546762589928, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.4819277108433735, 'pegasus_entailment': 0.6372146171149021, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3283582089552239, 'r1_recall': 0.532258064516129, 'r1_f1': 0.4061538461538461, 'pegasus_entailment': 0.21692603665204452, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5283018867924528, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.49557522123893805, 'pegasus_entailment': 0.38722116748491925, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8297872340425532, 'r1_recall': 0.4978723404255319, 'r1_f1': 0.6223404255319149, 'pegasus_entailment': 0.4709802311845124, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5819672131147541, 'r1_recall': 0.46710526315789475, 'r1_f1': 0.5182481751824817, 'pegasus_entailment': 0.39324041083455086, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4895833333333333, 'r1_recall': 0.5465116279069767, 'r1_f1': 0.5164835164835165, 'pegasus_entailment': 0.5974390804767609, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43373493975903615, 'r1_recall': 0.48, 'r1_f1': 0.45569620253164556, 'pegasus_entailment': 0.12284686090424657, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5256410256410257, 'r1_recall': 0.45555555555555555, 'r1_f1': 0.488095238095238, 'pegasus_entailment': 0.4691694378852844, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.75, 'r1_recall': 0.38414634146341464, 'r1_f1': 0.5080645161290321, 'pegasus_entailment': 0.8259425262610117, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 15}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8041237113402062, 'r1_recall': 0.27177700348432055, 'r1_f1': 0.40625, 'pegasus_entailment': 0.33051976561546326, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.819672131147541, 'r1_recall': 0.27932960893854747, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.5527493432164192, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7887323943661971, 'r1_recall': 0.49122807017543857, 'r1_f1': 0.6054054054054053, 'pegasus_entailment': 0.32676858998214203, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6935483870967742, 'r1_recall': 0.33076923076923076, 'r1_f1': 0.44791666666666674, 'pegasus_entailment': 0.41338715720921754, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46875, 'r1_recall': 0.4326923076923077, 'r1_f1': 0.45, 'pegasus_entailment': 0.5570867856343588, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3937007874015748, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.4739336492890995, 'pegasus_entailment': 0.607019017636776, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7363636363636363, 'r1_recall': 0.5, 'r1_f1': 0.5955882352941176, 'pegasus_entailment': 0.4628658056259155, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48717948717948717, 'r1_recall': 0.4935064935064935, 'r1_f1': 0.49032258064516127, 'pegasus_entailment': 0.23237503327254672, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6232876712328768, 'r1_recall': 0.6319444444444444, 'r1_f1': 0.6275862068965518, 'pegasus_entailment': 0.5073481969535351, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5813953488372093, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6211180124223603, 'pegasus_entailment': 0.6031192919472232, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.512, 'r1_recall': 0.5289256198347108, 'r1_f1': 0.5203252032520326, 'pegasus_entailment': 0.48184294775128367, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8309859154929577, 'r1_recall': 0.5315315315315315, 'r1_f1': 0.6483516483516483, 'pegasus_entailment': 0.32569869588284445, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 23, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5142857142857142, 'r1_recall': 0.3312883435582822, 'r1_f1': 0.40298507462686567, 'pegasus_entailment': 0.5049446254968644, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5163934426229508, 'r1_recall': 0.35795454545454547, 'r1_f1': 0.4228187919463088, 'pegasus_entailment': 0.5885769102190223, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4791666666666667, 'r1_recall': 0.575, 'r1_f1': 0.5227272727272727, 'pegasus_entailment': 0.3473479475651402, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2966101694915254, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.39325842696629215, 'pegasus_entailment': 0.5254730319914719, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31313131313131315, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.389937106918239, 'pegasus_entailment': 0.6317064557224512, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39436619718309857, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.3659938402473927, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6311475409836066, 'r1_recall': 0.5923076923076923, 'r1_f1': 0.611111111111111, 'pegasus_entailment': 0.5552512152120471, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3375, 'r1_recall': 0.5869565217391305, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.4182456815227245, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47580645161290325, 'r1_recall': 0.5175438596491229, 'r1_f1': 0.4957983193277311, 'pegasus_entailment': 0.42182464301586153, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48739495798319327, 'r1_recall': 0.5225225225225225, 'r1_f1': 0.5043478260869565, 'pegasus_entailment': 0.36999326509733993, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7142857142857143, 'r1_recall': 0.502283105022831, 'r1_f1': 0.5898123324396782, 'pegasus_entailment': 0.6145646333694458, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6753246753246753, 'r1_recall': 0.6341463414634146, 'r1_f1': 0.6540880503144655, 'pegasus_entailment': 0.39766840473748744, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4132231404958678, 'r1_recall': 0.5681818181818182, 'r1_f1': 0.4784688995215311, 'pegasus_entailment': 0.44522366020828485, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5434782608695652, 'r1_recall': 0.49504950495049505, 'r1_f1': 0.5181347150259067, 'pegasus_entailment': 0.44447878934442997, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.37037037037037035, 'r1_f1': 0.4624277456647399, 'pegasus_entailment': 0.6163609866052866, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.27350427350427353, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.3878787878787879, 'pegasus_entailment': 0.15339014921337366, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7592592592592593, 'r1_recall': 0.41414141414141414, 'r1_f1': 0.5359477124183006, 'pegasus_entailment': 0.5814662675062815, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5602094240837696, 'r1_recall': 0.6772151898734177, 'r1_f1': 0.6131805157593124, 'pegasus_entailment': 0.58315091393888, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6124031007751938, 'r1_recall': 0.5, 'r1_f1': 0.5505226480836237, 'pegasus_entailment': 0.32574225403368473, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5833333333333334, 'r1_recall': 0.32642487046632124, 'r1_f1': 0.4186046511627907, 'pegasus_entailment': 0.6828175708651543, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7681159420289855, 'r1_recall': 0.5047619047619047, 'r1_f1': 0.6091954022988506, 'pegasus_entailment': 0.6460544376944503, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 22, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.625, 'r1_recall': 0.4, 'r1_f1': 0.48780487804878053, 'pegasus_entailment': 0.19952405069489032, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3170731707317073, 'r1_recall': 0.25, 'r1_f1': 0.27956989247311825, 'pegasus_entailment': 0.81263068318367, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.35555555555555557, 'r1_recall': 0.5245901639344263, 'r1_f1': 0.42384105960264906, 'pegasus_entailment': 0.2622223153710365, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42168674698795183, 'r1_recall': 0.5645161290322581, 'r1_f1': 0.4827586206896552, 'pegasus_entailment': 0.018417672768312816, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2716049382716049, 'r1_recall': 0.3728813559322034, 'r1_f1': 0.3142857142857143, 'pegasus_entailment': 0.022833467795862816, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4666666666666667, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.5303030303030304, 'pegasus_entailment': 0.6971390595038732, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.35353535353535354, 'r1_f1': 0.4142011834319526, 'pegasus_entailment': 0.00485221209237352, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3, 'r1_recall': 0.525, 'r1_f1': 0.38181818181818183, 'pegasus_entailment': 0.8606120347976685, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7241379310344828, 'r1_recall': 0.48554913294797686, 'r1_f1': 0.5813148788927336, 'pegasus_entailment': 0.6539939027279615, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5972222222222222, 'r1_recall': 0.5375, 'r1_f1': 0.5657894736842105, 'pegasus_entailment': 0.2397682619812258, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7945205479452054, 'r1_recall': 0.3258426966292135, 'r1_f1': 0.4621513944223108, 'pegasus_entailment': 0.37780439977844554, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6220472440944882, 'r1_recall': 0.4906832298136646, 'r1_f1': 0.5486111111111112, 'pegasus_entailment': 0.24384690138200918, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.625, 'r1_recall': 0.41044776119402987, 'r1_f1': 0.49549549549549554, 'pegasus_entailment': 0.3548286462125058, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 23}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7520661157024794, 'r1_recall': 0.37448559670781895, 'r1_f1': 0.5, 'pegasus_entailment': 0.5050360336899757, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4782608695652174, 'r1_recall': 0.5365853658536586, 'r1_f1': 0.5057471264367817, 'pegasus_entailment': 0.6087054908275604, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6962025316455697, 'r1_recall': 0.3618421052631579, 'r1_f1': 0.4761904761904762, 'pegasus_entailment': 0.32414950989186764, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3978494623655914, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.44848484848484843, 'pegasus_entailment': 0.5270882481709123, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8809523809523809, 'r1_recall': 0.33183856502242154, 'r1_f1': 0.4820846905537459, 'pegasus_entailment': 0.19670202905399492, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3287671232876712, 'r1_recall': 0.21238938053097345, 'r1_f1': 0.25806451612903225, 'pegasus_entailment': 0.051634457583228745, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43023255813953487, 'r1_recall': 0.8043478260869565, 'r1_f1': 0.5606060606060607, 'pegasus_entailment': 0.6390805592139562, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7363636363636363, 'r1_recall': 0.44751381215469616, 'r1_f1': 0.5567010309278351, 'pegasus_entailment': 0.3811046709971769, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6311475409836066, 'r1_recall': 0.4350282485875706, 'r1_f1': 0.5150501672240803, 'pegasus_entailment': 0.4662367105484009, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5096153846153846, 'r1_recall': 0.5520833333333334, 'r1_f1': 0.5299999999999999, 'pegasus_entailment': 0.6957642883062363, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5370370370370371, 'r1_recall': 0.4, 'r1_f1': 0.45849802371541504, 'pegasus_entailment': 0.4870034058888753, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21621621621621623, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.3137254901960784, 'pegasus_entailment': 0.009523091022856534, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 14, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20915032679738563, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.3033175355450237, 'pegasus_entailment': 0.5167493261396885, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.625, 'r1_recall': 0.46218487394957986, 'r1_f1': 0.5314009661835749, 'pegasus_entailment': 0.09142833593068644, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3902439024390244, 'r1_recall': 0.676056338028169, 'r1_f1': 0.4948453608247423, 'pegasus_entailment': 0.7851681254804135, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2803738317757009, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.3703703703703703, 'pegasus_entailment': 0.12946362998336552, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 12, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35, 'r1_recall': 0.43209876543209874, 'r1_f1': 0.38674033149171266, 'pegasus_entailment': 0.3006874732673168, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6615384615384615, 'r1_recall': 0.5308641975308642, 'r1_f1': 0.589041095890411, 'pegasus_entailment': 0.46926599022117443, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5357142857142857, 'r1_recall': 0.5421686746987951, 'r1_f1': 0.5389221556886228, 'pegasus_entailment': 0.22207428107503802, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5317460317460317, 'r1_recall': 0.6036036036036037, 'r1_f1': 0.5654008438818566, 'pegasus_entailment': 0.6162647787714377, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7441860465116279, 'r1_recall': 0.2857142857142857, 'r1_f1': 0.4129032258064516, 'pegasus_entailment': 0.4521645374596119, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6494845360824743, 'r1_recall': 0.28378378378378377, 'r1_f1': 0.3949843260188088, 'pegasus_entailment': 0.5918774232268333, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5476190476190477, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.5679012345679013, 'pegasus_entailment': 0.5898627969436347, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6372549019607843, 'r1_recall': 0.625, 'r1_f1': 0.6310679611650485, 'pegasus_entailment': 0.6412309401979049, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23529411764705882, 'r1_recall': 0.4383561643835616, 'r1_f1': 0.3062200956937799, 'pegasus_entailment': 0.5252031632699072, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4307692307692308, 'r1_f1': 0.4628099173553719, 'pegasus_entailment': 0.002443032688461244, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2824427480916031, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.3645320197044335, 'pegasus_entailment': 0.5897321932017803, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5882352941176471, 'r1_recall': 0.6172839506172839, 'r1_f1': 0.6024096385542168, 'pegasus_entailment': 0.3634260769855852, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7857142857142857, 'r1_recall': 0.4342105263157895, 'r1_f1': 0.5593220338983051, 'pegasus_entailment': 0.527837410569191, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47560975609756095, 'r1_recall': 0.4642857142857143, 'r1_f1': 0.4698795180722891, 'pegasus_entailment': 0.5168249271700915, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7368421052631579, 'r1_recall': 0.445859872611465, 'r1_f1': 0.5555555555555556, 'pegasus_entailment': 0.4126359253190458, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7450980392156863, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.6178861788617886, 'pegasus_entailment': 0.5163672994822264, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.5212765957446809, 'r1_f1': 0.5297297297297296, 'pegasus_entailment': 0.5713474079966545, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 20}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5988700564971752, 'r1_recall': 0.5549738219895288, 'r1_f1': 0.5760869565217391, 'pegasus_entailment': 0.24236544221639633, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2517482517482518, 'r1_recall': 0.7346938775510204, 'r1_f1': 0.37500000000000006, 'pegasus_entailment': 0.3343942161649466, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6101694915254238, 'r1_recall': 0.43373493975903615, 'r1_f1': 0.5070422535211268, 'pegasus_entailment': 0.9000137746334076, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5048543689320388, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.574585635359116, 'pegasus_entailment': 0.22166043768811505, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 13}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6265060240963856, 'r1_recall': 0.6419753086419753, 'r1_f1': 0.6341463414634146, 'pegasus_entailment': 0.1859098735731095, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6907216494845361, 'r1_recall': 0.48905109489051096, 'r1_f1': 0.5726495726495726, 'pegasus_entailment': 0.7295566171407699, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2727272727272727, 'r1_recall': 0.4090909090909091, 'r1_f1': 0.32727272727272727, 'pegasus_entailment': 0.27148693753406405, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5238095238095238, 'r1_recall': 0.3728813559322034, 'r1_f1': 0.43564356435643564, 'pegasus_entailment': 0.3642224694291751, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7051282051282052, 'r1_recall': 0.41044776119402987, 'r1_f1': 0.5188679245283019, 'pegasus_entailment': 0.6956525668501854, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5982905982905983, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.5128205128205128, 'pegasus_entailment': 0.29580276863028604, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4380952380952381, 'r1_recall': 0.7076923076923077, 'r1_f1': 0.5411764705882354, 'pegasus_entailment': 0.24248418915085496, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5079365079365079, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.423841059602649, 'pegasus_entailment': 0.7031274126842618, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 12, 'pegasus_smog': 15}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5369127516778524, 'pegasus_entailment': 0.2841788111254573, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4659090909090909, 'r1_recall': 0.5324675324675324, 'r1_f1': 0.4969696969696969, 'pegasus_entailment': 0.08601669484050944, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31896551724137934, 'r1_recall': 0.4625, 'r1_f1': 0.3775510204081633, 'pegasus_entailment': 0.3668498620390892, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7063492063492064, 'r1_recall': 0.5705128205128205, 'r1_f1': 0.6312056737588653, 'pegasus_entailment': 0.6667110125223795, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4157303370786517, 'r1_recall': 0.4868421052631579, 'r1_f1': 0.44848484848484854, 'pegasus_entailment': 0.24011984653770924, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5268817204301075, 'r1_recall': 0.5764705882352941, 'r1_f1': 0.550561797752809, 'pegasus_entailment': 0.5473282150924206, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.632183908045977, 'r1_recall': 0.4198473282442748, 'r1_f1': 0.5045871559633027, 'pegasus_entailment': 0.3021370689384639, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4536082474226804, 'r1_recall': 0.41509433962264153, 'r1_f1': 0.43349753694581283, 'pegasus_entailment': 0.4988373853266239, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7474747474747475, 'r1_recall': 0.40437158469945356, 'r1_f1': 0.5248226950354611, 'pegasus_entailment': 0.5990232964977622, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.45, 'pegasus_entailment': 0.3090154053643346, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4777777777777778, 'r1_recall': 0.4673913043478261, 'r1_f1': 0.4725274725274725, 'pegasus_entailment': 0.24155476301287612, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.693069306930693, 'r1_recall': 0.32407407407407407, 'r1_f1': 0.4416403785488958, 'pegasus_entailment': 0.48448825236409904, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4642857142857143, 'r1_recall': 0.5148514851485149, 'r1_f1': 0.48826291079812206, 'pegasus_entailment': 0.3987276189029217, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44680851063829785, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.5271966527196653, 'pegasus_entailment': 0.403316530585289, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4642857142857143, 'r1_recall': 0.37142857142857144, 'r1_f1': 0.41269841269841273, 'pegasus_entailment': 0.2923597455956042, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6615384615384615, 'r1_recall': 0.6466165413533834, 'r1_f1': 0.6539923954372624, 'pegasus_entailment': 0.3959765105973929, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.574468085106383, 'r1_recall': 0.6, 'r1_f1': 0.5869565217391305, 'pegasus_entailment': 0.23587309770906964, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6979166666666666, 'r1_recall': 0.5826086956521739, 'r1_f1': 0.6350710900473933, 'pegasus_entailment': 0.8633118669191996, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 24}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.52, 'r1_recall': 0.46846846846846846, 'r1_f1': 0.49289099526066354, 'pegasus_entailment': 0.25828572968021035, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7727272727272727, 'r1_recall': 0.4927536231884058, 'r1_f1': 0.6017699115044248, 'pegasus_entailment': 0.7710251837968827, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22608695652173913, 'r1_recall': 0.52, 'r1_f1': 0.3151515151515151, 'pegasus_entailment': 0.3887583549367264, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2932330827067669, 'r1_recall': 0.6964285714285714, 'r1_f1': 0.41269841269841273, 'pegasus_entailment': 0.6125596161000431, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.15315315315315314, 'r1_recall': 0.3617021276595745, 'r1_f1': 0.21518987341772153, 'pegasus_entailment': 0.5068240626715124, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3974358974358974, 'r1_recall': 0.43661971830985913, 'r1_f1': 0.4161073825503355, 'pegasus_entailment': 0.015835069740811985, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.723404255319149, 'r1_recall': 0.37158469945355194, 'r1_f1': 0.49097472924187724, 'pegasus_entailment': 0.6949610095471144, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5192307692307693, 'r1_recall': 0.5912408759124088, 'r1_f1': 0.5529010238907851, 'pegasus_entailment': 0.28678900255666423, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5833333333333334, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5989304812834224, 'pegasus_entailment': 0.4234033572138287, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5079365079365079, 'r1_recall': 0.7218045112781954, 'r1_f1': 0.5962732919254659, 'pegasus_entailment': 0.6810521290171891, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7777777777777778, 'r1_recall': 0.4268292682926829, 'r1_f1': 0.5511811023622046, 'pegasus_entailment': 0.39959906538327533, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6962962962962963, 'r1_recall': 0.46766169154228854, 'r1_f1': 0.5595238095238095, 'pegasus_entailment': 0.6409192934632302, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36363636363636365, 'r1_recall': 0.44, 'r1_f1': 0.39819004524886875, 'pegasus_entailment': 0.3644533269107342, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3813559322033898, 'r1_recall': 0.5625, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.5963963617570698, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6206896551724138, 'r1_recall': 0.43902439024390244, 'r1_f1': 0.5142857142857142, 'pegasus_entailment': 0.2426238026819192, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3230769230769231, 'r1_recall': 0.4375, 'r1_f1': 0.37168141592920356, 'pegasus_entailment': 0.3397041132673621, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42696629213483145, 'r1_recall': 0.6031746031746031, 'r1_f1': 0.5, 'pegasus_entailment': 0.32451289403252304, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23170731707317074, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.3275862068965517, 'pegasus_entailment': 0.4555931935707728, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5227272727272727, 'r1_recall': 0.3026315789473684, 'r1_f1': 0.38333333333333336, 'pegasus_entailment': 0.5287428349256516, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 16, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7419354838709677, 'r1_recall': 0.375, 'r1_f1': 0.4981949458483754, 'pegasus_entailment': 0.7844629635413488, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.43283582089552236, 'r1_f1': 0.464, 'pegasus_entailment': 0.005585210397839546, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6705882352941176, 'r1_recall': 0.3392857142857143, 'r1_f1': 0.4505928853754941, 'pegasus_entailment': 0.5535250976681709, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6476190476190476, 'r1_recall': 0.5151515151515151, 'r1_f1': 0.5738396624472575, 'pegasus_entailment': 0.8972742358843485, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6781609195402298, 'r1_recall': 0.37341772151898733, 'r1_f1': 0.4816326530612245, 'pegasus_entailment': 0.2524039942305535, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6981132075471698, 'r1_recall': 0.375, 'r1_f1': 0.48791208791208784, 'pegasus_entailment': 0.8363253474235535, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3282442748091603, 'r1_recall': 0.7818181818181819, 'r1_f1': 0.46236559139784944, 'pegasus_entailment': 0.5326094118257364, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6829268292682927, 'r1_recall': 0.4263959390862944, 'r1_f1': 0.525, 'pegasus_entailment': 0.8444543033838272, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 23, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.44871794871794873, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.5072463768115941, 'pegasus_entailment': 0.11398171171701203, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5161290322580645, 'r1_recall': 0.5203252032520326, 'r1_f1': 0.5182186234817813, 'pegasus_entailment': 0.7741638749837876, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.632183908045977, 'r1_recall': 0.5238095238095238, 'r1_f1': 0.5729166666666667, 'pegasus_entailment': 0.31877674370480236, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.75, 'r1_recall': 0.5725190839694656, 'r1_f1': 0.6493506493506493, 'pegasus_entailment': 0.4991263102274388, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.5179856115107914, 'pegasus_entailment': 0.34656743456919986, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46551724137931033, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.46956521739130436, 'pegasus_entailment': 0.04694033577106893, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35135135135135137, 'r1_recall': 0.6842105263157895, 'r1_f1': 0.4642857142857143, 'pegasus_entailment': 0.5180169721134007, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6511627906976745, 'r1_recall': 0.4375, 'r1_f1': 0.5233644859813084, 'pegasus_entailment': 0.5112457970778147, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.744, 'r1_recall': 0.5224719101123596, 'r1_f1': 0.6138613861386139, 'pegasus_entailment': 0.5325293354690075, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6206896551724138, 'r1_recall': 0.44171779141104295, 'r1_f1': 0.5161290322580645, 'pegasus_entailment': 0.4526503668166697, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6504854368932039, 'r1_recall': 0.3471502590673575, 'r1_f1': 0.45270270270270274, 'pegasus_entailment': 0.6141397620085627, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.3564356435643564, 'r1_f1': 0.4472049689440994, 'pegasus_entailment': 0.30173321906477213, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5204081632653061, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.5604395604395606, 'pegasus_entailment': 0.6174996718764305, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5443037974683544, 'r1_recall': 0.4777777777777778, 'r1_f1': 0.5088757396449705, 'pegasus_entailment': 0.3212402639425515, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4727272727272727, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.49056603773584906, 'pegasus_entailment': 0.3772078255812327, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6717557251908397, 'r1_recall': 0.5945945945945946, 'r1_f1': 0.6308243727598567, 'pegasus_entailment': 0.49690157423416775, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.4122137404580153, 'r1_f1': 0.4886877828054298, 'pegasus_entailment': 0.31527110941048403, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7258064516129032, 'r1_recall': 0.3813559322033898, 'r1_f1': 0.4999999999999999, 'pegasus_entailment': 0.6685884197552999, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6931818181818182, 'r1_recall': 0.46923076923076923, 'r1_f1': 0.5596330275229358, 'pegasus_entailment': 0.5203952516118685, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4520547945205479, 'r1_recall': 0.5546218487394958, 'r1_f1': 0.4981132075471698, 'pegasus_entailment': 0.4186559500172734, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5606060606060606, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.5362318840579711, 'pegasus_entailment': 0.25088548256705206, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.5828571428571429, 'pegasus_entailment': 0.5879462584853172, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4857142857142857, 'r1_recall': 0.38345864661654133, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.04500210442347452, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6330935251798561, 'r1_recall': 0.41509433962264153, 'r1_f1': 0.5014245014245015, 'pegasus_entailment': 0.4717162388066451, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.49122807017543857, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.11511536656568448, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5978260869565217, 'r1_recall': 0.4296875, 'r1_f1': 0.5, 'pegasus_entailment': 0.639054499566555, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34375, 'r1_recall': 0.38596491228070173, 'r1_f1': 0.36363636363636365, 'pegasus_entailment': 0.3215348254113148, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6891891891891891, 'r1_recall': 0.5340314136125655, 'r1_f1': 0.6017699115044247, 'pegasus_entailment': 0.51384636759758, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6813186813186813, 'r1_recall': 0.4217687074829932, 'r1_f1': 0.5210084033613446, 'pegasus_entailment': 0.5611959605012089, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6952380952380952, 'r1_recall': 0.474025974025974, 'r1_f1': 0.5637065637065637, 'pegasus_entailment': 0.36438874222221784, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5333333333333333, 'r1_recall': 0.64, 'r1_f1': 0.5818181818181818, 'pegasus_entailment': 0.45801215960333747, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5289256198347108, 'r1_recall': 0.5565217391304348, 'r1_f1': 0.5423728813559323, 'pegasus_entailment': 0.4849089258350432, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6160714285714286, 'r1_recall': 0.45098039215686275, 'r1_f1': 0.5207547169811321, 'pegasus_entailment': 0.4013992818072438, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5543478260869565, 'r1_recall': 0.5, 'r1_f1': 0.5257731958762887, 'pegasus_entailment': 0.2391748187597841, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 12}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3717948717948718, 'r1_recall': 0.5087719298245614, 'r1_f1': 0.42962962962962964, 'pegasus_entailment': 0.452177157625556, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6346153846153846, 'r1_recall': 0.515625, 'r1_f1': 0.5689655172413792, 'pegasus_entailment': 0.37966363737359643, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23529411764705882, 'r1_recall': 0.05333333333333334, 'r1_f1': 0.08695652173913045, 'pegasus_entailment': 0.0653669461607933, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45714285714285713, 'r1_recall': 0.6037735849056604, 'r1_f1': 0.5203252032520325, 'pegasus_entailment': 0.48726753675873624, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6376811594202898, 'r1_recall': 0.4731182795698925, 'r1_f1': 0.5432098765432098, 'pegasus_entailment': 0.3764042258262634, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5245901639344263, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.5378151260504203, 'pegasus_entailment': 0.7160676121711731, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 23, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4927536231884058, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5666666666666667, 'pegasus_entailment': 0.40244885138235986, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5891472868217055, 'r1_recall': 0.4810126582278481, 'r1_f1': 0.529616724738676, 'pegasus_entailment': 0.5804440423846244, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31, 'r1_recall': 0.543859649122807, 'r1_f1': 0.39490445859872614, 'pegasus_entailment': 0.2815565150231123, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6233766233766234, 'r1_recall': 0.3221476510067114, 'r1_f1': 0.42477876106194684, 'pegasus_entailment': 0.5042420476675034, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 19}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6825396825396826, 'r1_recall': 0.31386861313868614, 'r1_f1': 0.43, 'pegasus_entailment': 0.5956462100148201, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5616438356164384, 'r1_recall': 0.6212121212121212, 'r1_f1': 0.5899280575539569, 'pegasus_entailment': 0.3873921619572987, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5268817204301075, 'r1_recall': 0.44144144144144143, 'r1_f1': 0.4803921568627451, 'pegasus_entailment': 0.19429100914276204, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4148936170212766, 'r1_recall': 0.4875, 'r1_f1': 0.4482758620689655, 'pegasus_entailment': 0.8285662333170573, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.711864406779661, 'r1_recall': 0.33070866141732286, 'r1_f1': 0.4516129032258065, 'pegasus_entailment': 0.4939652069782217, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7627118644067796, 'r1_recall': 0.45685279187817257, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.23233398026786745, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7079646017699115, 'r1_recall': 0.3292181069958848, 'r1_f1': 0.449438202247191, 'pegasus_entailment': 0.25708772204816344, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6883116883116883, 'r1_recall': 0.381294964028777, 'r1_f1': 0.4907407407407408, 'pegasus_entailment': 0.6478161892708159, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.21153846153846154, 'r1_recall': 0.3013698630136986, 'r1_f1': 0.2485875706214689, 'pegasus_entailment': 0.0010812453911057673, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29523809523809524, 'r1_recall': 0.5081967213114754, 'r1_f1': 0.3734939759036145, 'pegasus_entailment': 0.13693178130779415, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5662650602409639, 'r1_recall': 0.5465116279069767, 'r1_f1': 0.5562130177514794, 'pegasus_entailment': 0.36327083808525157, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39, 'r1_recall': 0.527027027027027, 'r1_f1': 0.4482758620689655, 'pegasus_entailment': 0.375768318772316, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7325581395348837, 'r1_recall': 0.3620689655172414, 'r1_f1': 0.48461538461538467, 'pegasus_entailment': 0.6982632676760355, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4659090909090909, 'r1_recall': 0.2847222222222222, 'r1_f1': 0.35344827586206895, 'pegasus_entailment': 0.49764816276729107, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7319587628865979, 'r1_recall': 0.3641025641025641, 'r1_f1': 0.48630136986301375, 'pegasus_entailment': 0.6763494983315468, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5932203389830508, 'r1_recall': 0.4794520547945205, 'r1_f1': 0.5303030303030303, 'pegasus_entailment': 0.29400688130408525, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44660194174757284, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.5168539325842697, 'pegasus_entailment': 0.19494265911635011, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5394736842105263, 'r1_recall': 0.35964912280701755, 'r1_f1': 0.43157894736842106, 'pegasus_entailment': 0.29116031744827825, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7111111111111111, 'r1_recall': 0.425531914893617, 'r1_f1': 0.5324459234608985, 'pegasus_entailment': 0.7590576112270355, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39655172413793105, 'r1_recall': 0.3898305084745763, 'r1_f1': 0.39316239316239315, 'pegasus_entailment': 0.22132568061351776, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.646551724137931, 'r1_recall': 0.44642857142857145, 'r1_f1': 0.5281690140845071, 'pegasus_entailment': 0.7117453664541245, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6538461538461539, 'r1_recall': 0.3953488372093023, 'r1_f1': 0.49275362318840576, 'pegasus_entailment': 0.6533933679262797, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.3221476510067114, 'r1_f1': 0.4192139737991266, 'pegasus_entailment': 0.31715003550052645, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5785714285714286, 'r1_recall': 0.47928994082840237, 'r1_f1': 0.5242718446601942, 'pegasus_entailment': 0.24808189421892166, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6224489795918368, 'r1_recall': 0.46564885496183206, 'r1_f1': 0.5327510917030569, 'pegasus_entailment': 0.23942258612563214, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5238095238095238, 'r1_recall': 0.532258064516129, 'r1_f1': 0.5280000000000001, 'pegasus_entailment': 0.49483666840630275, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40268456375838924, 'r1_recall': 0.7228915662650602, 'r1_f1': 0.5172413793103449, 'pegasus_entailment': 0.47315582586452365, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3088235294117647, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.3925233644859813, 'pegasus_entailment': 0.45464125578291714, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.46551724137931033, 'r1_f1': 0.5242718446601942, 'pegasus_entailment': 0.16487021125794854, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7159090909090909, 'r1_recall': 0.34054054054054056, 'r1_f1': 0.4615384615384616, 'pegasus_entailment': 0.5282547404058278, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.8851564228534698, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 23, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.672, 'r1_recall': 0.43636363636363634, 'r1_f1': 0.5291338582677165, 'pegasus_entailment': 0.5170786785227912, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4966887417218543, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.5084745762711865, 'pegasus_entailment': 0.8989964326222738, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.28368794326241137, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.38834951456310685, 'pegasus_entailment': 0.4467944564918677, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 16, 'pegasus_ari': 29, 'pegasus_smog': 20}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32038834951456313, 'r1_recall': 0.55, 'r1_f1': 0.4049079754601227, 'pegasus_entailment': 0.12850643179020457, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.345679012345679, 'r1_f1': 0.40875912408759124, 'pegasus_entailment': 0.018389595672488213, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 18, 'pegasus_ari': 35, 'pegasus_smog': 21}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7, 'r1_recall': 0.47115384615384615, 'r1_f1': 0.5632183908045978, 'pegasus_entailment': 0.1453975196927786, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4339622641509434, 'r1_recall': 0.5348837209302325, 'r1_f1': 0.47916666666666663, 'pegasus_entailment': 0.723859449227651, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4946808510638298, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.5406976744186046, 'pegasus_entailment': 0.39766652036147815, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7168141592920354, 'r1_recall': 0.4909090909090909, 'r1_f1': 0.5827338129496403, 'pegasus_entailment': 0.33335270881652834, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41379310344827586, 'r1_recall': 0.5901639344262295, 'r1_f1': 0.4864864864864865, 'pegasus_entailment': 0.2022070052975323, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5859375, 'r1_recall': 0.5, 'r1_f1': 0.539568345323741, 'pegasus_entailment': 0.6479035906493664, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48717948717948717, 'r1_recall': 0.4175824175824176, 'r1_f1': 0.44970414201183434, 'pegasus_entailment': 0.2641806455212645, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6818181818181818, 'r1_recall': 0.4580152671755725, 'r1_f1': 0.547945205479452, 'pegasus_entailment': 0.631058469414711, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4144736842105263, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.5185185185185185, 'pegasus_entailment': 0.3858222835032003, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.5245901639344263, 'pegasus_entailment': 0.5878540016710758, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4392523364485981, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.5222222222222223, 'pegasus_entailment': 0.30612644273787737, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5522388059701493, 'r1_recall': 0.296, 'r1_f1': 0.38541666666666663, 'pegasus_entailment': 0.07094790410095204, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 13}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.504424778761062, 'r1_recall': 0.5, 'r1_f1': 0.5022026431718061, 'pegasus_entailment': 0.20251757348305546, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5492957746478874, 'r1_recall': 0.43820224719101125, 'r1_f1': 0.48750000000000004, 'pegasus_entailment': 0.4297967453797658, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.28, 'r1_recall': 0.6511627906976745, 'r1_f1': 0.39160839160839167, 'pegasus_entailment': 0.3199242276799244, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6776315789473685, 'r1_recall': 0.4660633484162896, 'r1_f1': 0.5522788203753352, 'pegasus_entailment': 0.3553817222515742, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6571428571428571, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6330275229357798, 'pegasus_entailment': 0.4087427332997322, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 22}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2727272727272727, 'r1_recall': 0.6486486486486487, 'r1_f1': 0.38399999999999995, 'pegasus_entailment': 0.3264001646700005, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5588235294117647, 'r1_recall': 0.4634146341463415, 'r1_f1': 0.5066666666666667, 'pegasus_entailment': 0.6736915856599808, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.581081081081081, 'r1_recall': 0.40186915887850466, 'r1_f1': 0.4751381215469613, 'pegasus_entailment': 0.49501284258440137, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5056179775280899, 'r1_recall': 0.625, 'r1_f1': 0.5590062111801242, 'pegasus_entailment': 0.30183806860198575, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5106382978723404, 'pegasus_entailment': 0.7005455922335386, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6621621621621622, 'r1_recall': 0.550561797752809, 'r1_f1': 0.6012269938650308, 'pegasus_entailment': 0.4066946959355846, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4492753623188406, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.484375, 'pegasus_entailment': 0.9169673323631287, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6470588235294118, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.5269461077844311, 'pegasus_entailment': 0.684887225429217, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.4375, 'r1_f1': 0.4827586206896552, 'pegasus_entailment': 0.4835085906088352, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5975609756097561, 'r1_recall': 0.5212765957446809, 'r1_f1': 0.5568181818181819, 'pegasus_entailment': 0.7304622009396553, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8238341968911918, 'r1_recall': 0.3045977011494253, 'r1_f1': 0.4447552447552448, 'pegasus_entailment': 0.5423346150459515, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6637168141592921, 'r1_recall': 0.375, 'r1_f1': 0.47923322683706077, 'pegasus_entailment': 0.8337749481201172, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2631578947368421, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.33175355450236965, 'pegasus_entailment': 0.2057568357558921, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7358490566037735, 'r1_recall': 0.37142857142857144, 'r1_f1': 0.4936708860759493, 'pegasus_entailment': 0.4617142595234327, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7741935483870968, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.6288209606986899, 'pegasus_entailment': 0.89059017598629, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6213592233009708, 'r1_recall': 0.5663716814159292, 'r1_f1': 0.5925925925925926, 'pegasus_entailment': 0.49294085395667936, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.611764705882353, 'r1_f1': 0.5909090909090909, 'pegasus_entailment': 0.6145323514938354, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45121951219512196, 'r1_recall': 0.5606060606060606, 'r1_f1': 0.5, 'pegasus_entailment': 0.5913373579581579, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.59, 'r1_recall': 0.6413043478260869, 'r1_f1': 0.6145833333333333, 'pegasus_entailment': 0.34540564753115177, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4953271028037383, 'r1_recall': 0.6385542168674698, 'r1_f1': 0.5578947368421053, 'pegasus_entailment': 0.29065255483146757, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7538461538461538, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.5130890052356022, 'pegasus_entailment': 0.06029536621645093, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5168539325842697, 'r1_recall': 0.45098039215686275, 'r1_f1': 0.4816753926701571, 'pegasus_entailment': 0.3652747745315234, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7283950617283951, 'r1_recall': 0.36645962732919257, 'r1_f1': 0.48760330578512395, 'pegasus_entailment': 0.6860548456509908, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2571428571428571, 'r1_recall': 0.631578947368421, 'r1_f1': 0.36548223350253806, 'pegasus_entailment': 0.03588070108089596, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7419354838709677, 'r1_recall': 0.3053097345132743, 'r1_f1': 0.43260188087774293, 'pegasus_entailment': 0.4756706903378169, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46551724137931033, 'r1_recall': 0.45, 'r1_f1': 0.4576271186440678, 'pegasus_entailment': 0.29845850347192027, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 16}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5853658536585366, 'r1_recall': 0.4752475247524752, 'r1_f1': 0.5245901639344261, 'pegasus_entailment': 0.2533897231332958, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3522727272727273, 'r1_recall': 0.6326530612244898, 'r1_f1': 0.45255474452554745, 'pegasus_entailment': 0.23555034247692674, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3148148148148148, 'r1_recall': 0.3695652173913043, 'r1_f1': 0.34, 'pegasus_entailment': 0.005355368135496974, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6532258064516129, 'r1_recall': 0.5547945205479452, 'r1_f1': 0.6, 'pegasus_entailment': 0.7421259681383768, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6526946107784432, 'r1_recall': 0.5677083333333334, 'r1_f1': 0.6072423398328691, 'pegasus_entailment': 0.4340795502066612, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4888888888888889, 'r1_recall': 0.2972972972972973, 'r1_f1': 0.3697478991596639, 'pegasus_entailment': 0.0029938132114087543, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 12, 'pegasus_ari': 11, 'pegasus_smog': 13}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4875, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.43575418994413406, 'pegasus_entailment': 0.18622161977691576, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4810126582278481, 'r1_recall': 0.4578313253012048, 'r1_f1': 0.4691358024691358, 'pegasus_entailment': 0.2256873435107991, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3858267716535433, 'r1_recall': 0.6901408450704225, 'r1_f1': 0.4949494949494949, 'pegasus_entailment': 0.22747321869246662, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4701492537313433, 'r1_recall': 0.5478260869565217, 'r1_f1': 0.5060240963855422, 'pegasus_entailment': 0.5092088735837024, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5488721804511278, 'r1_recall': 0.43452380952380953, 'r1_f1': 0.4850498338870432, 'pegasus_entailment': 0.7731835424900055, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3918918918918919, 'r1_recall': 0.5471698113207547, 'r1_f1': 0.4566929133858268, 'pegasus_entailment': 0.5933437372247378, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5757575757575758, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.5507246376811594, 'pegasus_entailment': 0.42176832258701324, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5175438596491229, 'r1_recall': 0.5221238938053098, 'r1_f1': 0.5198237885462554, 'pegasus_entailment': 0.2577771311509423, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49333333333333335, 'r1_recall': 0.5211267605633803, 'r1_f1': 0.5068493150684932, 'pegasus_entailment': 0.694510648958385, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.68, 'r1_recall': 0.3105022831050228, 'r1_f1': 0.4263322884012539, 'pegasus_entailment': 0.7543691396713257, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 22, 'pegasus_ari': 35, 'pegasus_smog': 28}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19047619047619047, 'r1_recall': 0.34285714285714286, 'r1_f1': 0.24489795918367344, 'pegasus_entailment': 0.01146448760603865, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4727272727272727, 'r1_recall': 0.6265060240963856, 'r1_f1': 0.538860103626943, 'pegasus_entailment': 0.2698114917854712, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27350427350427353, 'r1_recall': 0.6530612244897959, 'r1_f1': 0.3855421686746988, 'pegasus_entailment': 0.23474489261085787, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8484848484848485, 'r1_recall': 0.49411764705882355, 'r1_f1': 0.6245353159851301, 'pegasus_entailment': 0.8357995351155599, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 14, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6637931034482759, 'r1_recall': 0.5968992248062015, 'r1_f1': 0.6285714285714284, 'pegasus_entailment': 0.6661639884114265, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43333333333333335, 'r1_recall': 0.5977011494252874, 'r1_f1': 0.5024154589371982, 'pegasus_entailment': 0.06539008691906929, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.625, 'r1_recall': 0.37593984962406013, 'r1_f1': 0.4694835680751173, 'pegasus_entailment': 0.6138516338542104, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5882352941176471, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.5633802816901409, 'pegasus_entailment': 0.25909999292343855, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4772727272727273, 'r1_recall': 0.4375, 'r1_f1': 0.45652173913043476, 'pegasus_entailment': 0.018625499680638313, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6696428571428571, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.5952380952380952, 'pegasus_entailment': 0.702000328223221, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7590361445783133, 'r1_recall': 0.4375, 'r1_f1': 0.5550660792951542, 'pegasus_entailment': 0.7652055263519287, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5492957746478874, 'r1_recall': 0.42391304347826086, 'r1_f1': 0.4785276073619632, 'pegasus_entailment': 0.4665947282628622, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7945205479452054, 'r1_recall': 0.5631067961165048, 'r1_f1': 0.6590909090909092, 'pegasus_entailment': 0.2585303795834382, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2818181818181818, 'r1_recall': 0.4626865671641791, 'r1_f1': 0.3502824858757062, 'pegasus_entailment': 0.5226254791021347, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.4835164835164835, 'r1_f1': 0.5238095238095237, 'pegasus_entailment': 0.9090200811624527, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5253164556962026, 'r1_recall': 0.5804195804195804, 'r1_f1': 0.5514950166112956, 'pegasus_entailment': 0.7720384015701711, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7209302325581395, 'r1_recall': 0.5081967213114754, 'r1_f1': 0.5961538461538461, 'pegasus_entailment': 0.21137877049235007, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6388888888888888, 'r1_recall': 0.41566265060240964, 'r1_f1': 0.5036496350364963, 'pegasus_entailment': 0.5220512747764587, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.603448275862069, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.6194690265486726, 'pegasus_entailment': 0.036868637427687645, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.390625, 'r1_recall': 0.33783783783783783, 'r1_f1': 0.36231884057971014, 'pegasus_entailment': 0.6827562749385834, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7280701754385965, 'r1_recall': 0.4068627450980392, 'r1_f1': 0.5220125786163522, 'pegasus_entailment': 0.23763460721820592, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6967741935483871, 'r1_recall': 0.5, 'r1_f1': 0.5822102425876011, 'pegasus_entailment': 0.5734842071930567, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5901639344262295, 'r1_recall': 0.2975206611570248, 'r1_f1': 0.3956043956043956, 'pegasus_entailment': 0.7795554473996162, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7032967032967034, 'r1_recall': 0.44755244755244755, 'r1_f1': 0.5470085470085471, 'pegasus_entailment': 0.21916713267564775, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.51, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.826888233423233, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45864661654135336, 'r1_recall': 0.6703296703296703, 'r1_f1': 0.5446428571428571, 'pegasus_entailment': 0.4504663408588385, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6545454545454545, 'r1_recall': 0.35294117647058826, 'r1_f1': 0.45859872611464964, 'pegasus_entailment': 0.17572769708931446, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5609756097560976, 'r1_recall': 0.40350877192982454, 'r1_f1': 0.46938775510204084, 'pegasus_entailment': 0.27834285655990243, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6721311475409836, 'r1_recall': 0.41414141414141414, 'r1_f1': 0.5125, 'pegasus_entailment': 0.07824645575601608, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3548387096774194, 'r1_recall': 0.3707865168539326, 'r1_f1': 0.3626373626373627, 'pegasus_entailment': 0.2102958217728883, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8163265306122449, 'r1_recall': 0.49079754601226994, 'r1_f1': 0.6130268199233716, 'pegasus_entailment': 0.46545881778001785, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5934065934065934, 'r1_recall': 0.2967032967032967, 'r1_f1': 0.39560439560439564, 'pegasus_entailment': 0.7938524335622787, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7093023255813954, 'r1_recall': 0.22181818181818183, 'r1_f1': 0.3379501385041551, 'pegasus_entailment': 0.4308655308559537, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5398230088495575, 'r1_recall': 0.5596330275229358, 'r1_f1': 0.5495495495495495, 'pegasus_entailment': 0.4997203334933147, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22826086956521738, 'r1_recall': 0.3620689655172414, 'r1_f1': 0.27999999999999997, 'pegasus_entailment': 0.01893338256923016, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5873015873015873, 'r1_recall': 0.20441988950276244, 'r1_f1': 0.30327868852459017, 'pegasus_entailment': 0.3344754916615784, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37755102040816324, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.4228571428571429, 'pegasus_entailment': 0.08950371143873781, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5882352941176471, 'r1_recall': 0.625, 'r1_f1': 0.6060606060606061, 'pegasus_entailment': 0.5023345947265625, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6236559139784946, 'r1_recall': 0.6236559139784946, 'r1_f1': 0.6236559139784946, 'pegasus_entailment': 0.6843661209568381, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2972972972972973, 'r1_recall': 0.13580246913580246, 'r1_f1': 0.1864406779661017, 'pegasus_entailment': 0.10854119807481766, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 23, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5652173913043478, 'r1_recall': 0.14444444444444443, 'r1_f1': 0.2300884955752212, 'pegasus_entailment': 0.4080766486003995, 'pegasus_flesch_kincaid': 7, 'pegasus_coleman_liau': 13, 'pegasus_ari': 9, 'pegasus_smog': 13}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4189189189189189, 'r1_recall': 0.4492753623188406, 'r1_f1': 0.4335664335664336, 'pegasus_entailment': 0.3632390555382396, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6041666666666666, 'r1_recall': 0.6041666666666666, 'r1_f1': 0.6041666666666666, 'pegasus_entailment': 0.5665489689563401, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40963855421686746, 'r1_recall': 0.53125, 'r1_f1': 0.4625850340136054, 'pegasus_entailment': 0.4310962548479438, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.28110599078341014, 'r1_recall': 0.6703296703296703, 'r1_f1': 0.39610389610389607, 'pegasus_entailment': 0.6520374058357751, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4330708661417323, 'r1_recall': 0.625, 'r1_f1': 0.5116279069767442, 'pegasus_entailment': 0.25369271845556796, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48148148148148145, 'r1_recall': 0.6290322580645161, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.26886735134758055, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.452991452991453, 'r1_recall': 0.4953271028037383, 'r1_f1': 0.47321428571428575, 'pegasus_entailment': 0.2616075202822685, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.345679012345679, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.3888888888888889, 'pegasus_entailment': 0.3568934366727869, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8389261744966443, 'r1_recall': 0.4716981132075472, 'r1_f1': 0.6038647342995169, 'pegasus_entailment': 0.6146889434506496, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34408602150537637, 'r1_recall': 0.5, 'r1_f1': 0.40764331210191085, 'pegasus_entailment': 0.4342047969500224, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5833333333333334, 'r1_recall': 0.45652173913043476, 'r1_f1': 0.5121951219512195, 'pegasus_entailment': 0.3857937181989352, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4621212121212121, 'r1_recall': 0.61, 'r1_f1': 0.5258620689655172, 'pegasus_entailment': 0.5128747057169676, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4888888888888889, 'r1_recall': 0.4714285714285714, 'r1_f1': 0.48000000000000004, 'pegasus_entailment': 0.5660718083381653, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5675675675675675, 'r1_recall': 0.44680851063829785, 'r1_f1': 0.5, 'pegasus_entailment': 0.2727746842429042, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5849056603773585, 'r1_recall': 0.2440944881889764, 'r1_f1': 0.34444444444444444, 'pegasus_entailment': 0.7440048257509867, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.31645569620253167, 'r1_recall': 0.704225352112676, 'r1_f1': 0.4366812227074236, 'pegasus_entailment': 0.17523739983638129, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 17, 'pegasus_ari': 33, 'pegasus_smog': 21}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46153846153846156, 'r1_recall': 0.6382978723404256, 'r1_f1': 0.5357142857142858, 'pegasus_entailment': 0.42867345510361093, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5769230769230769, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.421624193713069, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.425, 'r1_recall': 0.4594594594594595, 'r1_f1': 0.44155844155844154, 'pegasus_entailment': 0.021041283883581247, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4368932038834951, 'r1_recall': 0.6716417910447762, 'r1_f1': 0.5294117647058824, 'pegasus_entailment': 0.4455683398991823, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3627450980392157, 'r1_recall': 0.578125, 'r1_f1': 0.4457831325301205, 'pegasus_entailment': 0.5612352564930916, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5871559633027523, 'r1_recall': 0.3699421965317919, 'r1_f1': 0.4539007092198581, 'pegasus_entailment': 0.16655916082007544, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7391304347826086, 'r1_recall': 0.5151515151515151, 'r1_f1': 0.6071428571428571, 'pegasus_entailment': 0.18901790007948877, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.589041095890411, 'r1_recall': 0.4387755102040816, 'r1_f1': 0.5029239766081871, 'pegasus_entailment': 0.2902490955311805, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5773195876288659, 'r1_recall': 0.2994652406417112, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.03896785690449178, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5072463768115942, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.4268292682926829, 'pegasus_entailment': 0.18790753709618002, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48484848484848486, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5614035087719298, 'pegasus_entailment': 0.31654736475805595, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3695652173913043, 'r1_recall': 0.6181818181818182, 'r1_f1': 0.46258503401360546, 'pegasus_entailment': 0.7165430970489979, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21238938053097345, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.3096774193548387, 'pegasus_entailment': 0.11072736676032946, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4523809523809524, 'r1_recall': 0.5352112676056338, 'r1_f1': 0.4903225806451613, 'pegasus_entailment': 0.5438422407023609, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36764705882352944, 'r1_recall': 0.4807692307692308, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.003713229874847457, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7096774193548387, 'r1_recall': 0.18803418803418803, 'r1_f1': 0.2972972972972973, 'pegasus_entailment': 0.48671754263341427, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5864661654135338, 'r1_recall': 0.5954198473282443, 'r1_f1': 0.5909090909090908, 'pegasus_entailment': 0.6226864261552691, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46153846153846156, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.30153324007987975, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6219512195121951, 'r1_recall': 0.2833333333333333, 'r1_f1': 0.3893129770992366, 'pegasus_entailment': 0.8282308578491211, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37037037037037035, 'r1_recall': 0.43956043956043955, 'r1_f1': 0.4020100502512563, 'pegasus_entailment': 0.16681114553163448, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29473684210526313, 'r1_recall': 0.509090909090909, 'r1_f1': 0.3733333333333333, 'pegasus_entailment': 0.3116639871150255, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 32, 'pegasus_smog': 24}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.532608695652174, 'r1_f1': 0.5798816568047338, 'pegasus_entailment': 0.6674774661660194, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4731182795698925, 'r1_recall': 0.44, 'r1_f1': 0.455958549222798, 'pegasus_entailment': 0.4345028018578887, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2773109243697479, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.35106382978723405, 'pegasus_entailment': 0.6178764815752705, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45384615384615384, 'r1_recall': 0.6781609195402298, 'r1_f1': 0.543778801843318, 'pegasus_entailment': 0.3512584867887199, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5757575757575758, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.5671641791044776, 'pegasus_entailment': 0.2775772443274036, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6027397260273972, 'r1_recall': 0.5238095238095238, 'r1_f1': 0.5605095541401273, 'pegasus_entailment': 0.6694806814193726, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 19}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25842696629213485, 'r1_recall': 0.4423076923076923, 'r1_f1': 0.3262411347517731, 'pegasus_entailment': 0.2425217945710756, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3915094339622642, 'r1_recall': 0.5804195804195804, 'r1_f1': 0.46760563380281694, 'pegasus_entailment': 0.30365121056092903, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5238095238095238, 'r1_recall': 0.632183908045977, 'r1_f1': 0.5729166666666667, 'pegasus_entailment': 0.3250060162196557, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5094339622641509, 'r1_recall': 0.5, 'r1_f1': 0.5046728971962616, 'pegasus_entailment': 0.33642625242161256, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5545454545454546, 'r1_recall': 0.5041322314049587, 'r1_f1': 0.5281385281385281, 'pegasus_entailment': 0.4992438942193985, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.23076923076923078, 'r1_f1': 0.3243243243243243, 'pegasus_entailment': 0.8898718059062958, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 11, 'pegasus_smog': 15}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.6250000000000001, 'pegasus_entailment': 0.5121286114056905, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4473684210526316, 'r1_recall': 0.4722222222222222, 'r1_f1': 0.4594594594594595, 'pegasus_entailment': 0.46734356695378665, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42391304347826086, 'r1_recall': 0.43820224719101125, 'r1_f1': 0.430939226519337, 'pegasus_entailment': 0.5460474546998739, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2236842105263158, 'r1_recall': 0.37777777777777777, 'r1_f1': 0.2809917355371901, 'pegasus_entailment': 0.464003464517494, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6923076923076923, 'r1_recall': 0.4368932038834951, 'r1_f1': 0.5357142857142856, 'pegasus_entailment': 0.3937336727976799, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.12359550561797752, 'r1_recall': 0.3142857142857143, 'r1_f1': 0.17741935483870966, 'pegasus_entailment': 0.3343777679062138, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4576271186440678, 'r1_recall': 0.6, 'r1_f1': 0.5192307692307693, 'pegasus_entailment': 0.3207470726338215, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23140495867768596, 'r1_recall': 0.717948717948718, 'r1_f1': 0.35, 'pegasus_entailment': 0.35348644660552964, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6951219512195121, 'r1_recall': 0.38513513513513514, 'r1_f1': 0.4956521739130435, 'pegasus_entailment': 0.3755269180983305, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6016949152542372, 'r1_recall': 0.6173913043478261, 'r1_f1': 0.6094420600858369, 'pegasus_entailment': 0.4777877559303306, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6091954022988506, 'r1_recall': 0.5520833333333334, 'r1_f1': 0.5792349726775957, 'pegasus_entailment': 0.9002805948257446, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6526315789473685, 'r1_recall': 0.5688073394495413, 'r1_f1': 0.607843137254902, 'pegasus_entailment': 0.8430788176400321, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4375, 'r1_recall': 0.15217391304347827, 'r1_f1': 0.22580645161290325, 'pegasus_entailment': 0.1521342247724533, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8, 'r1_recall': 0.2840909090909091, 'r1_f1': 0.4192872117400419, 'pegasus_entailment': 0.29927765391767025, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5609756097560976, 'r1_recall': 0.4144144144144144, 'r1_f1': 0.4766839378238342, 'pegasus_entailment': 0.5770558267831802, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5619047619047619, 'r1_recall': 0.3959731543624161, 'r1_f1': 0.4645669291338582, 'pegasus_entailment': 0.48856014946553233, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.803030303030303, 'r1_recall': 0.35570469798657717, 'r1_f1': 0.49302325581395345, 'pegasus_entailment': 0.47053321699301404, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2972972972972973, 'r1_recall': 0.4489795918367347, 'r1_f1': 0.35772357723577236, 'pegasus_entailment': 0.7621709009011587, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47674418604651164, 'r1_recall': 0.5694444444444444, 'r1_f1': 0.5189873417721519, 'pegasus_entailment': 0.3312702588737011, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3706896551724138, 'r1_recall': 0.5308641975308642, 'r1_f1': 0.43654822335025384, 'pegasus_entailment': 0.5273428629152477, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7154471544715447, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.6446886446886446, 'pegasus_entailment': 0.27760346510913225, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.358695652173913, 'r1_recall': 0.4925373134328358, 'r1_f1': 0.4150943396226415, 'pegasus_entailment': 0.35641757895549137, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7428571428571429, 'r1_recall': 0.45348837209302323, 'r1_f1': 0.5631768953068592, 'pegasus_entailment': 0.6636869891663082, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3564356435643564, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.4114285714285714, 'pegasus_entailment': 0.5243946320842952, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5588235294117647, 'r1_recall': 0.4691358024691358, 'r1_f1': 0.5100671140939597, 'pegasus_entailment': 0.031310774463539325, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.3971631205673759, 'r1_f1': 0.4890829694323144, 'pegasus_entailment': 0.16784461997449399, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5504587155963303, 'r1_recall': 0.4580152671755725, 'r1_f1': 0.5, 'pegasus_entailment': 0.44064136892557143, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.593103448275862, 'r1_recall': 0.40375586854460094, 'r1_f1': 0.4804469273743017, 'pegasus_entailment': 0.44277930663277704, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 21}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7017543859649122, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.54421768707483, 'pegasus_entailment': 0.2624810232470433, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3918918918918919, 'r1_recall': 0.5087719298245614, 'r1_f1': 0.44274809160305345, 'pegasus_entailment': 0.05814546218607575, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6480446927374302, 'r1_recall': 0.6137566137566137, 'r1_f1': 0.6304347826086957, 'pegasus_entailment': 0.23546925311287245, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6612021857923497, 'r1_recall': 0.3980263157894737, 'r1_f1': 0.4969199178644764, 'pegasus_entailment': 0.8292464663585027, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2540983606557377, 'r1_recall': 0.49206349206349204, 'r1_f1': 0.3351351351351351, 'pegasus_entailment': 0.5160067807883024, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5339805825242718, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.5555555555555556, 'pegasus_entailment': 0.5508510674117133, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.78125, 'r1_recall': 0.31645569620253167, 'r1_f1': 0.4504504504504505, 'pegasus_entailment': 0.21257390826940536, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3157894736842105, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.39215686274509803, 'pegasus_entailment': 0.20564899980672635, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6979166666666666, 'r1_recall': 0.3701657458563536, 'r1_f1': 0.4837545126353791, 'pegasus_entailment': 0.7567678958177566, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5138888888888888, 'r1_recall': 0.2605633802816901, 'r1_f1': 0.34579439252336447, 'pegasus_entailment': 0.4780891826376319, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.5113636363636364, 'pegasus_entailment': 0.41813201690092683, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6160714285714286, 'r1_recall': 0.4011627906976744, 'r1_f1': 0.48591549295774644, 'pegasus_entailment': 0.6132536220053831, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48936170212765956, 'r1_recall': 0.647887323943662, 'r1_f1': 0.5575757575757576, 'pegasus_entailment': 0.5262786547342936, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.717948717948718, 'r1_recall': 0.40384615384615385, 'r1_f1': 0.5169230769230769, 'pegasus_entailment': 0.026653469152127702, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5632183908045977, 'r1_recall': 0.5268817204301075, 'r1_f1': 0.5444444444444445, 'pegasus_entailment': 0.5978093152400106, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.35714285714285715, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.480349344978166, 'pegasus_entailment': 0.48548137582838535, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4326923076923077, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.5142857142857142, 'pegasus_entailment': 0.1960699786664918, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4375, 'r1_recall': 0.13861386138613863, 'r1_f1': 0.2105263157894737, 'pegasus_entailment': 0.0867074728012085, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7738095238095238, 'r1_recall': 0.3140096618357488, 'r1_f1': 0.44673539518900346, 'pegasus_entailment': 0.4585116853316625, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41739130434782606, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.4423963133640553, 'pegasus_entailment': 0.48269470608793197, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28205128205128205, 'r1_recall': 0.36666666666666664, 'r1_f1': 0.31884057971014496, 'pegasus_entailment': 0.04873016124474816, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6333333333333333, 'r1_recall': 0.42696629213483145, 'r1_f1': 0.5100671140939598, 'pegasus_entailment': 0.42443630984053016, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5252525252525253, 'r1_recall': 0.7123287671232876, 'r1_f1': 0.6046511627906977, 'pegasus_entailment': 0.31885094195604324, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.358974358974359, 'r1_recall': 0.18421052631578946, 'r1_f1': 0.24347826086956523, 'pegasus_entailment': 0.17479929327964783, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4097222222222222, 'r1_recall': 0.6483516483516484, 'r1_f1': 0.502127659574468, 'pegasus_entailment': 0.2629004143178463, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7534246575342466, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.5699481865284973, 'pegasus_entailment': 0.2970141498371959, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8699551569506726, 'r1_recall': 0.275177304964539, 'r1_f1': 0.41810344827586204, 'pegasus_entailment': 0.405609199590981, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5952380952380952, 'r1_recall': 0.528169014084507, 'r1_f1': 0.5597014925373134, 'pegasus_entailment': 0.4642709232866764, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8617021276595744, 'r1_recall': 0.4426229508196721, 'r1_f1': 0.5848375451263538, 'pegasus_entailment': 0.5242636874318123, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5060240963855421, 'r1_recall': 0.45161290322580644, 'r1_f1': 0.47727272727272724, 'pegasus_entailment': 0.3742579681177934, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6160714285714286, 'r1_recall': 0.5948275862068966, 'r1_f1': 0.6052631578947368, 'pegasus_entailment': 0.5242529900278896, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6212121212121212, 'r1_recall': 0.6307692307692307, 'r1_f1': 0.6259541984732825, 'pegasus_entailment': 0.6417783402721398, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4782608695652174, 'r1_recall': 0.42038216560509556, 'r1_f1': 0.4474576271186441, 'pegasus_entailment': 0.6319357802470525, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31683168316831684, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.4295302013422819, 'pegasus_entailment': 0.4413568416275666, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.36082474226804123, 'r1_f1': 0.4375, 'pegasus_entailment': 0.9489929676055908, 'pegasus_flesch_kincaid': 34, 'pegasus_coleman_liau': 20, 'pegasus_ari': 40, 'pegasus_smog': 29}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.16666666666666666, 'r1_recall': 0.3142857142857143, 'r1_f1': 0.21782178217821782, 'pegasus_entailment': 0.6985078454017639, 'pegasus_flesch_kincaid': 32, 'pegasus_coleman_liau': 17, 'pegasus_ari': 39, 'pegasus_smog': 21}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5257731958762887, 'r1_recall': 0.5257731958762887, 'r1_f1': 0.5257731958762887, 'pegasus_entailment': 0.583312850445509, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6875, 'r1_recall': 0.3893805309734513, 'r1_f1': 0.4971751412429378, 'pegasus_entailment': 0.7490876019001007, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6330275229357798, 'r1_recall': 0.5111111111111111, 'r1_f1': 0.5655737704918032, 'pegasus_entailment': 0.5573974692961201, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45454545454545453, 'r1_recall': 0.09259259259259259, 'r1_f1': 0.15384615384615383, 'pegasus_entailment': 0.9548187851905823, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 16, 'pegasus_smog': 20}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5818181818181818, 'r1_recall': 0.32, 'r1_f1': 0.41290322580645156, 'pegasus_entailment': 0.23208325852950415, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
** Analysing column: malformed_chain



malformed_chain
Length after nones removed
616
MIN
0
MEAN
0
MAX
1
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.12359550561797752
MEAN
0.5382850000259155
MAX
0.9357798165137615
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.009569377990430622
MEAN
0.48503782864057127
MAX
0.8043478260869565
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.018779342723004692
MEAN
0.48712696647165604
MAX
0.6949152542372881
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.0008791161235421896
MEAN
0.44062150717725146
MAX
0.9743112126986185
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
7
MEAN
16
MAX
34
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
5
MEAN
17
MAX
24
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
4
MEAN
19
MAX
40
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
12
MEAN
18
MAX
29
{}
Entered file!
Imports done!
*** RUN *** 
eval_4cO
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 13:51:44.499175: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 13:51:45.046741: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/4cO_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4857142857142857, 'r1_recall': 0.4636363636363636, 'r1_f1': 0.47441860465116276, 'pegasus_entailment': 0.5386731922626495, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7403846153846154, 'r1_recall': 0.44508670520231214, 'r1_f1': 0.555956678700361, 'pegasus_entailment': 0.5587037851413091, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3082706766917293, 'r1_recall': 0.7068965517241379, 'r1_f1': 0.42931937172774864, 'pegasus_entailment': 0.5532244183123112, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6956521739130435, 'r1_recall': 0.49612403100775193, 'r1_f1': 0.5791855203619909, 'pegasus_entailment': 0.4147118031978607, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7285714285714285, 'r1_recall': 0.29310344827586204, 'r1_f1': 0.41803278688524587, 'pegasus_entailment': 0.7605021893978119, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5405405405405406, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5755395683453237, 'pegasus_entailment': 0.5881165366619825, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.17391304347826086, 'r1_recall': 0.625, 'r1_f1': 0.27210884353741494, 'pegasus_entailment': 0.2745407675392926, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2894736842105263, 'r1_recall': 0.7096774193548387, 'r1_f1': 0.4112149532710281, 'pegasus_entailment': 0.030658330768346786, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6979166666666666, 'r1_recall': 0.44966442953020136, 'r1_f1': 0.5469387755102041, 'pegasus_entailment': 0.7501286473125219, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6727272727272727, 'r1_recall': 0.5362318840579711, 'r1_f1': 0.5967741935483871, 'pegasus_entailment': 0.5780914593487978, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5625, 'r1_recall': 0.36, 'r1_f1': 0.43902439024390244, 'pegasus_entailment': 0.5267324939370155, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6206896551724138, 'r1_recall': 0.15126050420168066, 'r1_f1': 0.24324324324324323, 'pegasus_entailment': 0.19970690831542015, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 18, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7866666666666666, 'r1_recall': 0.5514018691588785, 'r1_f1': 0.6483516483516483, 'pegasus_entailment': 0.9532280564308167, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6144578313253012, 'r1_recall': 0.5795454545454546, 'r1_f1': 0.5964912280701754, 'pegasus_entailment': 0.46091824769973755, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8681318681318682, 'r1_recall': 0.4114583333333333, 'r1_f1': 0.5583038869257951, 'pegasus_entailment': 0.8062357803185781, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38461538461538464, 'r1_recall': 0.423728813559322, 'r1_f1': 0.40322580645161293, 'pegasus_entailment': 0.9360373914241791, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4915254237288136, 'r1_recall': 0.29292929292929293, 'r1_f1': 0.3670886075949367, 'pegasus_entailment': 0.38838009536266327, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.9242424242424242, 'r1_recall': 0.20469798657718122, 'r1_f1': 0.33516483516483514, 'pegasus_entailment': 0.5038566365838051, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6774193548387096, 'r1_recall': 0.391304347826087, 'r1_f1': 0.49606299212598426, 'pegasus_entailment': 0.5339887936909994, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5274725274725275, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.5393258426966292, 'pegasus_entailment': 0.7940096735954285, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6097560975609756, 'r1_recall': 0.27472527472527475, 'r1_f1': 0.3787878787878788, 'pegasus_entailment': 0.9370941321055094, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7362637362637363, 'r1_recall': 0.44666666666666666, 'r1_f1': 0.5560165975103735, 'pegasus_entailment': 0.8906015356381735, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5641025641025641, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.47311827956989244, 'pegasus_entailment': 0.5140941739082336, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6805555555555556, 'r1_recall': 0.3602941176470588, 'r1_f1': 0.47115384615384615, 'pegasus_entailment': 0.4279619213193655, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3372093023255814, 'r1_recall': 0.58, 'r1_f1': 0.4264705882352941, 'pegasus_entailment': 0.2043156255967915, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8440366972477065, 'r1_recall': 0.48677248677248675, 'r1_f1': 0.6174496644295302, 'pegasus_entailment': 0.9195415178934733, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6730769230769231, 'r1_recall': 0.5109489051094891, 'r1_f1': 0.5809128630705395, 'pegasus_entailment': 0.5406418889760971, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7857142857142857, 'r1_recall': 0.2462686567164179, 'r1_f1': 0.375, 'pegasus_entailment': 0.6711753830313683, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45098039215686275, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.5168539325842696, 'pegasus_entailment': 0.5852247388102114, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5048543689320388, 'r1_recall': 0.46017699115044247, 'r1_f1': 0.48148148148148145, 'pegasus_entailment': 0.5649097607820295, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45689655172413796, 'r1_recall': 0.6091954022988506, 'r1_f1': 0.5221674876847291, 'pegasus_entailment': 0.11385147162945941, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7948717948717948, 'r1_recall': 0.30845771144278605, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.9697926938533783, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.373015873015873, 'r1_recall': 0.4563106796116505, 'r1_f1': 0.4104803493449782, 'pegasus_entailment': 0.2913358547569563, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5909090909090909, 'r1_recall': 0.5360824742268041, 'r1_f1': 0.5621621621621622, 'pegasus_entailment': 0.6506626109282175, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32653061224489793, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.41558441558441556, 'pegasus_entailment': 0.07027949253097177, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5652173913043478, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.4999999999999999, 'pegasus_entailment': 0.490454139187932, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.49056603773584906, 'r1_recall': 0.7536231884057971, 'r1_f1': 0.5942857142857143, 'pegasus_entailment': 0.18637208418476803, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.37142857142857144, 'r1_recall': 0.5735294117647058, 'r1_f1': 0.4508670520231214, 'pegasus_entailment': 0.12428227439522743, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.35714285714285715, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.396039603960396, 'pegasus_entailment': 0.7154171665509542, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6474820143884892, 'r1_recall': 0.5421686746987951, 'r1_f1': 0.5901639344262294, 'pegasus_entailment': 0.7605056936542193, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6886792452830188, 'r1_recall': 0.45625, 'r1_f1': 0.5488721804511277, 'pegasus_entailment': 0.6147625672941407, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5119047619047619, 'r1_recall': 0.5584415584415584, 'r1_f1': 0.5341614906832297, 'pegasus_entailment': 0.582618544343859, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5172413793103449, 'r1_recall': 0.410958904109589, 'r1_f1': 0.4580152671755725, 'pegasus_entailment': 0.0031229858577717096, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6283185840707964, 'r1_recall': 0.5772357723577236, 'r1_f1': 0.6016949152542374, 'pegasus_entailment': 0.5666934074833989, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5783132530120482, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5962732919254657, 'pegasus_entailment': 0.3028559231509765, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5511363636363636, 'r1_recall': 0.6466666666666666, 'r1_f1': 0.5950920245398773, 'pegasus_entailment': 0.4416971281170845, 'pegasus_flesch_kincaid': 31, 'pegasus_coleman_liau': 19, 'pegasus_ari': 37, 'pegasus_smog': 25}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6203703703703703, 'r1_recall': 0.5677966101694916, 'r1_f1': 0.5929203539823009, 'pegasus_entailment': 0.5728331034886651, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5869565217391305, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.5320197044334976, 'pegasus_entailment': 0.9612356871366501, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6046511627906976, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.611764705882353, 'pegasus_entailment': 0.64121438190341, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39759036144578314, 'r1_recall': 0.3173076923076923, 'r1_f1': 0.35294117647058815, 'pegasus_entailment': 0.3862584133942922, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3051948051948052, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.4122807017543859, 'pegasus_entailment': 0.6218561589717865, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2549019607843137, 'r1_recall': 0.7647058823529411, 'r1_f1': 0.38235294117647056, 'pegasus_entailment': 0.32247371977427974, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.673469387755102, 'r1_recall': 0.44594594594594594, 'r1_f1': 0.5365853658536585, 'pegasus_entailment': 0.7640211284160614, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6818181818181818, 'r1_recall': 0.3389830508474576, 'r1_f1': 0.4528301886792453, 'pegasus_entailment': 0.07607040531001985, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6759259259259259, 'r1_recall': 0.4101123595505618, 'r1_f1': 0.5104895104895105, 'pegasus_entailment': 0.4496644362807274, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35668789808917195, 'r1_recall': 0.7777777777777778, 'r1_f1': 0.48908296943231433, 'pegasus_entailment': 0.39195842212066057, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.9, 'r1_recall': 0.32270916334661354, 'r1_f1': 0.47507331378299117, 'pegasus_entailment': 0.2679983004927635, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46236559139784944, 'r1_recall': 0.671875, 'r1_f1': 0.5477707006369426, 'pegasus_entailment': 0.42773888011773425, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 16, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.656, 'r1_recall': 0.6776859504132231, 'r1_f1': 0.6666666666666666, 'pegasus_entailment': 0.48594269319437444, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4778761061946903, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.49541284403669716, 'pegasus_entailment': 0.21737178042531013, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5238095238095238, 'r1_recall': 0.375, 'r1_f1': 0.43708609271523186, 'pegasus_entailment': 0.6282724160701036, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45454545454545453, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.4697986577181208, 'pegasus_entailment': 0.007874188246205449, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7215189873417721, 'r1_recall': 0.3392857142857143, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.80851944287618, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5894736842105263, 'r1_recall': 0.5773195876288659, 'r1_f1': 0.5833333333333334, 'pegasus_entailment': 0.8806429704030355, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 23, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24806201550387597, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.36158192090395475, 'pegasus_entailment': 0.26889867964200675, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.759493670886076, 'r1_recall': 0.47244094488188976, 'r1_f1': 0.5825242718446602, 'pegasus_entailment': 0.8579362034797668, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6172839506172839, 'r1_recall': 0.4716981132075472, 'r1_f1': 0.53475935828877, 'pegasus_entailment': 0.4519762160780374, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7272727272727273, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.6473988439306358, 'pegasus_entailment': 0.4258534187877861, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5116279069767442, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.5409836065573771, 'pegasus_entailment': 0.18899137081461959, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7258064516129032, 'r1_recall': 0.4411764705882353, 'r1_f1': 0.548780487804878, 'pegasus_entailment': 0.36915297230007127, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5849056603773585, 'r1_recall': 0.37349397590361444, 'r1_f1': 0.45588235294117646, 'pegasus_entailment': 0.4283239736687392, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4375, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.5121951219512195, 'pegasus_entailment': 0.2516980729997158, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4157303370786517, 'r1_recall': 0.5606060606060606, 'r1_f1': 0.4774193548387097, 'pegasus_entailment': 0.6167049606641134, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8296296296296296, 'r1_recall': 0.5894736842105263, 'r1_f1': 0.6892307692307691, 'pegasus_entailment': 0.7477040253579617, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34615384615384615, 'r1_recall': 0.375, 'r1_f1': 0.35999999999999993, 'pegasus_entailment': 0.36944014951586723, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 13, 'pegasus_ari': 12, 'pegasus_smog': 15}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7333333333333333, 'r1_recall': 0.5176470588235295, 'r1_f1': 0.6068965517241379, 'pegasus_entailment': 0.2508294953343769, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43209876543209874, 'r1_recall': 0.546875, 'r1_f1': 0.4827586206896552, 'pegasus_entailment': 0.4855247964384034, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4927536231884058, 'r1_recall': 0.6538461538461539, 'r1_f1': 0.5619834710743802, 'pegasus_entailment': 0.3683419327426236, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 14, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.703125, 'r1_recall': 0.5232558139534884, 'r1_f1': 0.6000000000000001, 'pegasus_entailment': 0.8647364675998688, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6617647058823529, 'r1_recall': 0.6716417910447762, 'r1_f1': 0.6666666666666667, 'pegasus_entailment': 0.5261392494042715, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.411214953271028, 'r1_recall': 0.5641025641025641, 'r1_f1': 0.47567567567567565, 'pegasus_entailment': 0.6988151291152462, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 23}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7073170731707317, 'r1_recall': 0.5631067961165048, 'r1_f1': 0.627027027027027, 'pegasus_entailment': 0.6449466635240242, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3977272727272727, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.45751633986928103, 'pegasus_entailment': 0.6239803807499508, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6071428571428571, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.5964912280701754, 'pegasus_entailment': 0.01935295102884993, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5241935483870968, 'r1_recall': 0.7065217391304348, 'r1_f1': 0.6018518518518519, 'pegasus_entailment': 0.4356710887514055, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3944954128440367, 'r1_recall': 0.4942528735632184, 'r1_f1': 0.4387755102040817, 'pegasus_entailment': 0.28240625322796403, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2604166666666667, 'r1_recall': 0.32051282051282054, 'r1_f1': 0.28735632183908044, 'pegasus_entailment': 0.24687064485624433, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.25833333333333336, 'r1_recall': 0.6888888888888889, 'r1_f1': 0.37575757575757585, 'pegasus_entailment': 0.4945505673531443, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7788461538461539, 'r1_recall': 0.3894230769230769, 'r1_f1': 0.5192307692307692, 'pegasus_entailment': 0.31801765188574793, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.4, 'r1_f1': 0.3636363636363636, 'pegasus_entailment': 0.5742998970672488, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6139240506329114, 'r1_recall': 0.5052083333333334, 'r1_f1': 0.5542857142857144, 'pegasus_entailment': 0.6812887489795685, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5858585858585859, 'r1_recall': 0.43283582089552236, 'r1_f1': 0.49785407725321884, 'pegasus_entailment': 0.38826189041137693, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5242718446601942, 'r1_recall': 0.7397260273972602, 'r1_f1': 0.6136363636363635, 'pegasus_entailment': 0.3687876310548745, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5607476635514018, 'r1_recall': 0.5128205128205128, 'r1_f1': 0.5357142857142856, 'pegasus_entailment': 0.12314004877892633, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.53125, 'r1_recall': 0.17525773195876287, 'r1_f1': 0.2635658914728682, 'pegasus_entailment': 0.8310293555259705, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 8}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6106194690265486, 'r1_recall': 0.3898305084745763, 'r1_f1': 0.47586206896551725, 'pegasus_entailment': 0.38648987049236894, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5445544554455446, 'r1_recall': 0.5670103092783505, 'r1_f1': 0.5555555555555556, 'pegasus_entailment': 0.6881622076034546, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5225225225225225, 'r1_recall': 0.4603174603174603, 'r1_f1': 0.4894514767932489, 'pegasus_entailment': 0.4814733627717942, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.325, 'r1_recall': 0.6, 'r1_f1': 0.4216216216216216, 'pegasus_entailment': 0.43919336050748825, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4838709677419355, 'r1_recall': 0.26785714285714285, 'r1_f1': 0.3448275862068966, 'pegasus_entailment': 0.24931865849066526, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.379746835443038, 'r1_recall': 0.4918032786885246, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.06025717779994011, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 13, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.56, 'r1_recall': 0.5957446808510638, 'r1_f1': 0.577319587628866, 'pegasus_entailment': 0.31538022914901376, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5338345864661654, 'r1_recall': 0.6173913043478261, 'r1_f1': 0.5725806451612903, 'pegasus_entailment': 0.8659707506497701, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 16, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5398230088495575, 'r1_recall': 0.5446428571428571, 'r1_f1': 0.5422222222222222, 'pegasus_entailment': 0.17253611733516058, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45454545454545453, 'r1_recall': 0.75, 'r1_f1': 0.5660377358490566, 'pegasus_entailment': 0.8090813606977463, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6219512195121951, 'r1_recall': 0.3953488372093023, 'r1_f1': 0.4834123222748815, 'pegasus_entailment': 0.7042722329497337, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5897435897435898, 'r1_recall': 0.44660194174757284, 'r1_f1': 0.5082872928176796, 'pegasus_entailment': 0.42296322556212546, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.583941605839416, 'r1_recall': 0.5, 'r1_f1': 0.5387205387205387, 'pegasus_entailment': 0.9157374501228333, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.4251207729468599, 'pegasus_entailment': 0.2479945648170542, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38823529411764707, 'r1_recall': 0.55, 'r1_f1': 0.4551724137931035, 'pegasus_entailment': 0.3558443208457902, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6282051282051282, 'r1_recall': 0.7101449275362319, 'r1_f1': 0.6666666666666667, 'pegasus_entailment': 0.4728699253561596, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6132075471698113, 'r1_recall': 0.48872180451127817, 'r1_f1': 0.5439330543933053, 'pegasus_entailment': 0.6967566814273596, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.53, 'r1_recall': 0.6708860759493671, 'r1_f1': 0.5921787709497207, 'pegasus_entailment': 0.22982135249185376, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5393258426966292, 'r1_recall': 0.5393258426966292, 'r1_f1': 0.5393258426966292, 'pegasus_entailment': 0.5937358470012745, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5094339622641509, 'r1_recall': 0.4153846153846154, 'r1_f1': 0.45762711864406785, 'pegasus_entailment': 0.530707836151123, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7407407407407407, 'r1_recall': 0.449438202247191, 'r1_f1': 0.5594405594405595, 'pegasus_entailment': 0.27808120403278735, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8823529411764706, 'r1_recall': 0.5113636363636364, 'r1_f1': 0.6474820143884893, 'pegasus_entailment': 0.6568011440336704, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6224489795918368, 'r1_recall': 0.4552238805970149, 'r1_f1': 0.5258620689655172, 'pegasus_entailment': 0.3287266935221851, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5040650406504065, 'r1_recall': 0.6595744680851063, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.4177573059666126, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5982142857142857, 'r1_recall': 0.5275590551181102, 'r1_f1': 0.5606694560669456, 'pegasus_entailment': 0.6594261241145432, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5566037735849056, 'r1_recall': 0.6704545454545454, 'r1_f1': 0.6082474226804124, 'pegasus_entailment': 0.4873217456188286, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47619047619047616, 'r1_recall': 0.6086956521739131, 'r1_f1': 0.5343511450381679, 'pegasus_entailment': 0.279126186738722, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.392, 'r1_recall': 0.6447368421052632, 'r1_f1': 0.4875621890547263, 'pegasus_entailment': 0.29177384545619134, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2916666666666667, 'r1_recall': 0.4883720930232558, 'r1_f1': 0.3652173913043478, 'pegasus_entailment': 0.5336591955274343, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5857142857142857, 'r1_recall': 0.7321428571428571, 'r1_f1': 0.6507936507936508, 'pegasus_entailment': 0.5123849130468443, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6446280991735537, 'r1_recall': 0.5954198473282443, 'r1_f1': 0.6190476190476191, 'pegasus_entailment': 0.5596605609171093, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.58, 'r1_recall': 0.3625, 'r1_f1': 0.4461538461538462, 'pegasus_entailment': 0.179645087569952, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5539568345323741, 'r1_recall': 0.6581196581196581, 'r1_f1': 0.6015625, 'pegasus_entailment': 0.5956547856330872, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5284552845528455, 'r1_recall': 0.5603448275862069, 'r1_f1': 0.5439330543933054, 'pegasus_entailment': 0.6485964772291481, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38317757009345793, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.4939759036144578, 'pegasus_entailment': 0.3497798866825178, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7692307692307693, 'r1_recall': 0.31746031746031744, 'r1_f1': 0.44943820224719094, 'pegasus_entailment': 0.43018729084481794, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7368421052631579, 'r1_recall': 0.4628099173553719, 'r1_f1': 0.568527918781726, 'pegasus_entailment': 0.4910557468732198, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7888888888888889, 'r1_recall': 0.45806451612903226, 'r1_f1': 0.5795918367346938, 'pegasus_entailment': 0.35654197237454355, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6890756302521008, 'r1_recall': 0.5030674846625767, 'r1_f1': 0.5815602836879432, 'pegasus_entailment': 0.5462899832054973, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.66, 'r1_recall': 0.32673267326732675, 'r1_f1': 0.43708609271523186, 'pegasus_entailment': 0.8643788894017538, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.660377358490566, 'r1_recall': 0.5785123966942148, 'r1_f1': 0.6167400881057269, 'pegasus_entailment': 0.5644716173410416, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.425531914893617, 'r1_recall': 0.6451612903225806, 'r1_f1': 0.5128205128205128, 'pegasus_entailment': 0.1849118138391835, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6212121212121212, 'r1_recall': 0.6165413533834586, 'r1_f1': 0.6188679245283019, 'pegasus_entailment': 0.9357427656650543, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.723404255319149, 'r1_recall': 0.5513513513513514, 'r1_f1': 0.6257668711656442, 'pegasus_entailment': 0.689685528477033, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42105263157894735, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.47761194029850745, 'pegasus_entailment': 0.041565095617746316, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43103448275862066, 'r1_recall': 0.5681818181818182, 'r1_f1': 0.4901960784313726, 'pegasus_entailment': 0.3053005784749985, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5287356321839081, 'r1_recall': 0.4946236559139785, 'r1_f1': 0.5111111111111112, 'pegasus_entailment': 0.030017956742085516, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4915254237288136, 'r1_recall': 0.5132743362831859, 'r1_f1': 0.5021645021645023, 'pegasus_entailment': 0.446700356900692, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7349397590361446, 'r1_recall': 0.7625, 'r1_f1': 0.7484662576687117, 'pegasus_entailment': 0.7826871673266093, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5089285714285714, 'r1_recall': 0.5643564356435643, 'r1_f1': 0.5352112676056338, 'pegasus_entailment': 0.34720031602773815, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7142857142857143, 'r1_recall': 0.31100478468899523, 'r1_f1': 0.4333333333333333, 'pegasus_entailment': 0.9437304139137268, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.736, 'r1_recall': 0.5082872928176796, 'r1_f1': 0.6013071895424837, 'pegasus_entailment': 0.7424098721572331, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.39436619718309857, 'r1_recall': 0.4745762711864407, 'r1_f1': 0.4307692307692308, 'pegasus_entailment': 0.6536577691634496, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8157894736842105, 'r1_recall': 0.38271604938271603, 'r1_f1': 0.5210084033613445, 'pegasus_entailment': 0.3904603570699692, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4028776978417266, 'r1_recall': 0.6829268292682927, 'r1_f1': 0.5067873303167421, 'pegasus_entailment': 0.6604241393506527, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48333333333333334, 'r1_recall': 0.3020833333333333, 'r1_f1': 0.37179487179487175, 'pegasus_entailment': 0.548448363939921, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6043956043956044, 'r1_recall': 0.5978260869565217, 'r1_f1': 0.6010928961748634, 'pegasus_entailment': 0.2745849722996354, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.75, 'r1_recall': 0.4329896907216495, 'r1_f1': 0.5490196078431373, 'pegasus_entailment': 0.596211314201355, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6814159292035398, 'r1_recall': 0.463855421686747, 'r1_f1': 0.5519713261648745, 'pegasus_entailment': 0.3101230651140213, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44565217391304346, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.543046357615894, 'pegasus_entailment': 0.10773287146973114, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7410714285714286, 'r1_recall': 0.4797687861271676, 'r1_f1': 0.5824561403508772, 'pegasus_entailment': 0.4956665118224919, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4044943820224719, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4235294117647059, 'pegasus_entailment': 0.5095729753375053, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5981308411214953, 'r1_recall': 0.42953020134228187, 'r1_f1': 0.5, 'pegasus_entailment': 0.6403452698141336, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4146341463414634, 'r1_recall': 0.7311827956989247, 'r1_f1': 0.5291828793774319, 'pegasus_entailment': 0.25009144430514424, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6404494382022472, 'r1_recall': 0.35403726708074534, 'r1_f1': 0.456, 'pegasus_entailment': 0.17037003518392643, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.20930232558139536, 'r1_recall': 0.23684210526315788, 'r1_f1': 0.2222222222222222, 'pegasus_entailment': 0.8509160876274109, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 31, 'pegasus_smog': 25}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6129032258064516, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.5671641791044777, 'pegasus_entailment': 0.5053998887306079, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5882352941176471, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.5853658536585367, 'pegasus_entailment': 0.35545037873089314, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5961538461538461, 'r1_recall': 0.3803680981595092, 'r1_f1': 0.46441947565543074, 'pegasus_entailment': 0.38403200200991705, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6732673267326733, 'r1_recall': 0.6238532110091743, 'r1_f1': 0.6476190476190478, 'pegasus_entailment': 0.52153574898839, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5983606557377049, 'r1_recall': 0.4147727272727273, 'r1_f1': 0.48993288590604034, 'pegasus_entailment': 0.7526381611824036, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5473684210526316, 'r1_recall': 0.3466666666666667, 'r1_f1': 0.42448979591836733, 'pegasus_entailment': 0.7179651707410812, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5338345864661654, 'r1_recall': 0.5071428571428571, 'r1_f1': 0.5201465201465201, 'pegasus_entailment': 0.37108289962634444, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5379310344827586, 'r1_recall': 0.5234899328859061, 'r1_f1': 0.5306122448979591, 'pegasus_entailment': 0.5737296625971794, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5416666666666666, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.4785276073619632, 'pegasus_entailment': 0.6764635294675827, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4603174603174603, 'r1_recall': 0.7532467532467533, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.6750161200761795, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46078431372549017, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.5371428571428571, 'pegasus_entailment': 0.23339406354352832, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7981651376146789, 'r1_recall': 0.23641304347826086, 'r1_f1': 0.36477987421383645, 'pegasus_entailment': 0.8674067258834839, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3803680981595092, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.45421245421245426, 'pegasus_entailment': 0.5120722243562341, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4873417721518987, 'r1_recall': 0.6209677419354839, 'r1_f1': 0.5460992907801419, 'pegasus_entailment': 0.5636437479406595, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6601941747572816, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.6098654708520179, 'pegasus_entailment': 0.5628354052702585, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7966101694915254, 'r1_recall': 0.4, 'r1_f1': 0.5325779036827196, 'pegasus_entailment': 0.5454090461134911, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5474452554744526, 'r1_recall': 0.4934210526315789, 'r1_f1': 0.5190311418685121, 'pegasus_entailment': 0.319192205555737, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5376344086021505, 'r1_recall': 0.5813953488372093, 'r1_f1': 0.5586592178770949, 'pegasus_entailment': 0.5851937929789225, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5223880597014925, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.4929577464788732, 'pegasus_entailment': 0.423816142603755, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5473684210526316, 'r1_recall': 0.5777777777777777, 'r1_f1': 0.5621621621621621, 'pegasus_entailment': 0.5281524494290352, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8076923076923077, 'r1_recall': 0.38414634146341464, 'r1_f1': 0.5206611570247934, 'pegasus_entailment': 0.8661005049943924, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.768, 'r1_recall': 0.3344947735191638, 'r1_f1': 0.4660194174757281, 'pegasus_entailment': 0.46107130497694016, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7733333333333333, 'r1_recall': 0.3240223463687151, 'r1_f1': 0.45669291338582685, 'pegasus_entailment': 0.6250564348883927, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7833333333333333, 'r1_recall': 0.41228070175438597, 'r1_f1': 0.5402298850574713, 'pegasus_entailment': 0.881163626909256, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6770833333333334, 'r1_recall': 0.5, 'r1_f1': 0.5752212389380531, 'pegasus_entailment': 0.6621916526928544, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.49038461538461536, 'r1_f1': 0.4951456310679611, 'pegasus_entailment': 0.8074436187744141, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4369747899159664, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.5123152709359606, 'pegasus_entailment': 0.9247127920389175, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7339449541284404, 'r1_recall': 0.49382716049382713, 'r1_f1': 0.5904059040590406, 'pegasus_entailment': 0.7714919969439507, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5978260869565217, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.6508875739644971, 'pegasus_entailment': 0.3546212749060942, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7387387387387387, 'r1_recall': 0.5694444444444444, 'r1_f1': 0.6431372549019607, 'pegasus_entailment': 0.6088003364857286, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5252525252525253, 'r1_recall': 0.6933333333333334, 'r1_f1': 0.5977011494252874, 'pegasus_entailment': 0.719058922783006, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4537037037037037, 'r1_recall': 0.4049586776859504, 'r1_f1': 0.4279475982532751, 'pegasus_entailment': 0.4047343786805868, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7058823529411765, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.6122448979591837, 'pegasus_entailment': 0.46517804940231144, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 31, 'pegasus_smog': 25}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.56, 'r1_recall': 0.4294478527607362, 'r1_f1': 0.48611111111111116, 'pegasus_entailment': 0.08833710814360529, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.4090909090909091, 'r1_f1': 0.49146757679180886, 'pegasus_entailment': 0.5404894147068262, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5252525252525253, 'r1_recall': 0.65, 'r1_f1': 0.5810055865921787, 'pegasus_entailment': 0.6528947475599125, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5409836065573771, 'r1_recall': 0.55, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.49956856295466423, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3584905660377358, 'r1_recall': 0.6333333333333333, 'r1_f1': 0.45783132530120485, 'pegasus_entailment': 0.5336849745828658, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3959731543624161, 'r1_recall': 0.6020408163265306, 'r1_f1': 0.47773279352226716, 'pegasus_entailment': 0.25682089030742644, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7037037037037037, 'r1_recall': 0.5846153846153846, 'r1_f1': 0.638655462184874, 'pegasus_entailment': 0.3874310354391734, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2743362831858407, 'r1_recall': 0.6739130434782609, 'r1_f1': 0.389937106918239, 'pegasus_entailment': 0.2420041361474432, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.5617021276595744, 'pegasus_entailment': 0.41209939832333475, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5607476635514018, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.5504587155963303, 'pegasus_entailment': 0.2975324789683024, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7022900763358778, 'r1_recall': 0.4200913242009132, 'r1_f1': 0.5257142857142856, 'pegasus_entailment': 0.6375362525383631, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 25}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7121212121212122, 'r1_recall': 0.573170731707317, 'r1_f1': 0.6351351351351352, 'pegasus_entailment': 0.377943804487586, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5057471264367817, 'r1_recall': 0.5, 'r1_f1': 0.5028571428571429, 'pegasus_entailment': 0.24977545393630862, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6511627906976745, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.5989304812834225, 'pegasus_entailment': 0.44205021609862644, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6105263157894737, 'r1_recall': 0.5370370370370371, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.8568801134824753, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2988505747126437, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.38518518518518524, 'pegasus_entailment': 0.22042128955945373, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7272727272727273, 'r1_recall': 0.40404040404040403, 'r1_f1': 0.5194805194805194, 'pegasus_entailment': 0.7890618965029716, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4775510204081633, 'r1_recall': 0.740506329113924, 'r1_f1': 0.5806451612903225, 'pegasus_entailment': 0.8132644941409429, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5647058823529412, 'r1_recall': 0.6075949367088608, 'r1_f1': 0.5853658536585367, 'pegasus_entailment': 0.2544080658893411, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6130952380952381, 'r1_recall': 0.533678756476684, 'r1_f1': 0.5706371191135734, 'pegasus_entailment': 0.6876302560170492, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7065217391304348, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.6598984771573604, 'pegasus_entailment': 0.4964259103871882, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 22, 'pegasus_ari': 33, 'pegasus_smog': 25}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5188679245283019, 'r1_recall': 0.44, 'r1_f1': 0.4761904761904762, 'pegasus_entailment': 0.39375958032906055, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.325, 'r1_recall': 0.25, 'r1_f1': 0.28260869565217395, 'pegasus_entailment': 0.638924370209376, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4065934065934066, 'r1_recall': 0.6065573770491803, 'r1_f1': 0.4868421052631579, 'pegasus_entailment': 0.3819402605295181, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3516483516483517, 'r1_recall': 0.5161290322580645, 'r1_f1': 0.4183006535947712, 'pegasus_entailment': 0.12055269720440265, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37142857142857144, 'r1_recall': 0.4406779661016949, 'r1_f1': 0.40310077519379844, 'pegasus_entailment': 0.2268264968879521, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4778761061946903, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.4757709251101322, 'pegasus_entailment': 0.884339764714241, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.52, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.44827586206896547, 'pegasus_entailment': 0.07995263475459069, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.25510204081632654, 'r1_recall': 0.625, 'r1_f1': 0.36231884057971014, 'pegasus_entailment': 0.29539934650529176, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7008547008547008, 'r1_recall': 0.47398843930635837, 'r1_f1': 0.5655172413793103, 'pegasus_entailment': 0.7423489019274712, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6179775280898876, 'r1_recall': 0.6875, 'r1_f1': 0.6508875739644969, 'pegasus_entailment': 0.09409874929406215, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6210526315789474, 'r1_recall': 0.33146067415730335, 'r1_f1': 0.43223443223443225, 'pegasus_entailment': 0.11879946192493662, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7702702702702703, 'r1_recall': 0.35403726708074534, 'r1_f1': 0.4851063829787234, 'pegasus_entailment': 0.5246679609020551, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6329113924050633, 'r1_recall': 0.373134328358209, 'r1_f1': 0.46948356807511743, 'pegasus_entailment': 0.6462346970414122, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7850467289719626, 'r1_recall': 0.345679012345679, 'r1_f1': 0.48000000000000004, 'pegasus_entailment': 0.4146229128042857, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41379310344827586, 'r1_recall': 0.5853658536585366, 'r1_f1': 0.48484848484848475, 'pegasus_entailment': 0.6154974069446325, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7352941176470589, 'r1_recall': 0.4934210526315789, 'r1_f1': 0.5905511811023622, 'pegasus_entailment': 0.590349406003952, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39080459770114945, 'r1_recall': 0.4722222222222222, 'r1_f1': 0.42767295597484273, 'pegasus_entailment': 0.5095678903162479, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8617021276595744, 'r1_recall': 0.3632286995515695, 'r1_f1': 0.5110410094637223, 'pegasus_entailment': 0.2320128732244484, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38144329896907214, 'r1_recall': 0.3274336283185841, 'r1_f1': 0.35238095238095235, 'pegasus_entailment': 0.21614754448334375, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.35714285714285715, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.43103448275862066, 'pegasus_entailment': 0.8656584322452545, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5704697986577181, 'r1_recall': 0.4696132596685083, 'r1_f1': 0.5151515151515151, 'pegasus_entailment': 0.30170405879616735, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6283783783783784, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.5723076923076923, 'pegasus_entailment': 0.5030978237045929, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5894736842105263, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.5863874345549739, 'pegasus_entailment': 0.4903913440357428, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.525, 'r1_recall': 0.43448275862068964, 'r1_f1': 0.47547169811320755, 'pegasus_entailment': 0.743214076757431, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.17894736842105263, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.2764227642276423, 'pegasus_entailment': 0.01583547971677035, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24087591240875914, 'r1_recall': 0.5689655172413793, 'r1_f1': 0.3384615384615384, 'pegasus_entailment': 0.2688622587360442, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6597938144329897, 'r1_recall': 0.5378151260504201, 'r1_f1': 0.5925925925925926, 'pegasus_entailment': 0.2636572755436646, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5921052631578947, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.6122448979591837, 'pegasus_entailment': 0.9607909768819809, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3522727272727273, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.4335664335664336, 'pegasus_entailment': 0.1578108087182045, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34579439252336447, 'r1_recall': 0.4567901234567901, 'r1_f1': 0.3936170212765957, 'pegasus_entailment': 0.3185675007601579, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 34, 'pegasus_smog': 26}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7213114754098361, 'r1_recall': 0.5432098765432098, 'r1_f1': 0.6197183098591549, 'pegasus_entailment': 0.9296085834503174, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5116279069767442, 'r1_recall': 0.5301204819277109, 'r1_f1': 0.5207100591715977, 'pegasus_entailment': 0.9470702012379965, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5666666666666667, 'r1_recall': 0.6126126126126126, 'r1_f1': 0.5887445887445887, 'pegasus_entailment': 0.32481815793435087, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7583333333333333, 'r1_recall': 0.2708333333333333, 'r1_f1': 0.3991228070175438, 'pegasus_entailment': 0.6135059595108032, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6494845360824743, 'r1_recall': 0.28378378378378377, 'r1_f1': 0.3949843260188088, 'pegasus_entailment': 0.5918774232268333, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6842105263157895, 'r1_recall': 0.5, 'r1_f1': 0.5777777777777778, 'pegasus_entailment': 0.5363876720269521, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 13}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.6346153846153846, 'r1_f1': 0.6502463054187192, 'pegasus_entailment': 0.6529100914485753, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3069306930693069, 'r1_recall': 0.4246575342465753, 'r1_f1': 0.3563218390804598, 'pegasus_entailment': 0.42173531899849576, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46987951807228917, 'r1_recall': 0.6, 'r1_f1': 0.5270270270270271, 'pegasus_entailment': 0.005866532097570598, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4180327868852459, 'r1_recall': 0.7083333333333334, 'r1_f1': 0.5257731958762887, 'pegasus_entailment': 0.7007169215939939, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6891891891891891, 'r1_recall': 0.6296296296296297, 'r1_f1': 0.6580645161290323, 'pegasus_entailment': 0.5722353203843037, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5694444444444444, 'r1_recall': 0.5394736842105263, 'r1_f1': 0.5540540540540541, 'pegasus_entailment': 0.5343949496746063, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 16}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5757575757575758, 'r1_recall': 0.4523809523809524, 'r1_f1': 0.5066666666666667, 'pegasus_entailment': 0.36819351848680526, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7215189873417721, 'r1_recall': 0.3630573248407643, 'r1_f1': 0.48305084745762705, 'pegasus_entailment': 0.8723911841710409, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7154471544715447, 'r1_recall': 0.6111111111111112, 'r1_f1': 0.6591760299625469, 'pegasus_entailment': 0.4644877513249715, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5172413793103449, 'r1_recall': 0.4787234042553192, 'r1_f1': 0.49723756906077354, 'pegasus_entailment': 0.5047380141913891, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7058823529411765, 'r1_recall': 0.5654450261780105, 'r1_f1': 0.627906976744186, 'pegasus_entailment': 0.3394870632328093, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.24806201550387597, 'r1_recall': 0.6530612244897959, 'r1_f1': 0.3595505617977528, 'pegasus_entailment': 0.5855702102649957, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4810126582278481, 'r1_recall': 0.4578313253012048, 'r1_f1': 0.4691358024691358, 'pegasus_entailment': 0.5265114828944206, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 12, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48695652173913045, 'r1_recall': 0.717948717948718, 'r1_f1': 0.5803108808290156, 'pegasus_entailment': 0.0211791209934745, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6585365853658537, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6625766871165645, 'pegasus_entailment': 0.2738832759205252, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6857142857142857, 'r1_recall': 0.5255474452554745, 'r1_f1': 0.5950413223140496, 'pegasus_entailment': 0.5211914759129286, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29310344827586204, 'r1_recall': 0.38636363636363635, 'r1_f1': 0.33333333333333337, 'pegasus_entailment': 0.3502412562568982, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46938775510204084, 'r1_recall': 0.3898305084745763, 'r1_f1': 0.42592592592592593, 'pegasus_entailment': 0.23324302459756532, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6037735849056604, 'r1_recall': 0.47761194029850745, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.8396524041891098, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6097560975609756, 'r1_recall': 0.4807692307692308, 'r1_f1': 0.5376344086021505, 'pegasus_entailment': 0.6259816437959671, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4537037037037037, 'r1_recall': 0.7538461538461538, 'r1_f1': 0.5664739884393063, 'pegasus_entailment': 0.6526416763663292, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49, 'r1_recall': 0.5568181818181818, 'r1_f1': 0.5212765957446808, 'pegasus_entailment': 0.7340193558484316, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5, 'r1_f1': 0.5, 'pegasus_entailment': 0.4111659284681082, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3592233009708738, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.4111111111111111, 'pegasus_entailment': 0.022963359525116783, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35833333333333334, 'r1_recall': 0.5375, 'r1_f1': 0.43, 'pegasus_entailment': 0.7003122274957908, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6946564885496184, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.6341463414634146, 'pegasus_entailment': 0.5387315712869167, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4725274725274725, 'r1_recall': 0.5657894736842105, 'r1_f1': 0.5149700598802395, 'pegasus_entailment': 0.6305468181769053, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4152542372881356, 'r1_recall': 0.5764705882352941, 'r1_f1': 0.48275862068965514, 'pegasus_entailment': 0.41532119433395565, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6847826086956522, 'r1_recall': 0.48091603053435117, 'r1_f1': 0.5650224215246636, 'pegasus_entailment': 0.25282993882137816, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.527027027027027, 'r1_recall': 0.36792452830188677, 'r1_f1': 0.43333333333333324, 'pegasus_entailment': 0.38094073576212395, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.76, 'r1_recall': 0.41530054644808745, 'r1_f1': 0.5371024734982333, 'pegasus_entailment': 0.3388150831063588, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5238095238095238, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.5500000000000002, 'pegasus_entailment': 0.2733832908173402, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5585585585585585, 'r1_recall': 0.6739130434782609, 'r1_f1': 0.6108374384236452, 'pegasus_entailment': 0.4368555801920593, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7591240875912408, 'r1_recall': 0.48148148148148145, 'r1_f1': 0.5892351274787536, 'pegasus_entailment': 0.5243314180523158, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.49122807017543857, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.5209302325581396, 'pegasus_entailment': 0.07819020543247461, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.515625, 'r1_recall': 0.673469387755102, 'r1_f1': 0.5840707964601769, 'pegasus_entailment': 0.15979439672082663, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5230769230769231, 'r1_recall': 0.4857142857142857, 'r1_f1': 0.5037037037037038, 'pegasus_entailment': 0.025879634369630367, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6133333333333333, 'r1_recall': 0.6917293233082706, 'r1_f1': 0.6501766784452296, 'pegasus_entailment': 0.41303714116414386, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 21, 'pegasus_ari': 34, 'pegasus_smog': 26}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6710526315789473, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.6144578313253012, 'pegasus_entailment': 0.6633808389306068, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6714285714285714, 'r1_recall': 0.40869565217391307, 'r1_f1': 0.5081081081081081, 'pegasus_entailment': 0.7650447487831116, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 24}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5096153846153846, 'r1_recall': 0.4774774774774775, 'r1_f1': 0.49302325581395345, 'pegasus_entailment': 0.33537151105701923, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 17, 'pegasus_ari': 32, 'pegasus_smog': 25}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7818181818181819, 'r1_recall': 0.6231884057971014, 'r1_f1': 0.6935483870967741, 'pegasus_entailment': 0.8193046301603317, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.25, 'r1_recall': 0.52, 'r1_f1': 0.33766233766233766, 'pegasus_entailment': 0.007531404805680116, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34234234234234234, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.4550898203592814, 'pegasus_entailment': 0.008975539356470108, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2608695652173913, 'r1_recall': 0.3829787234042553, 'r1_f1': 0.3103448275862069, 'pegasus_entailment': 0.6482600743571917, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4576271186440678, 'r1_recall': 0.38028169014084506, 'r1_f1': 0.41538461538461535, 'pegasus_entailment': 0.4810643481711547, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.672566371681416, 'r1_recall': 0.41530054644808745, 'r1_f1': 0.5135135135135135, 'pegasus_entailment': 0.7208999246358871, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 13, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4321608040201005, 'r1_recall': 0.6277372262773723, 'r1_f1': 0.5119047619047619, 'pegasus_entailment': 0.2331510116928257, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.663157894736842, 'pegasus_entailment': 0.6994193381287914, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.539568345323741, 'r1_recall': 0.5639097744360902, 'r1_f1': 0.551470588235294, 'pegasus_entailment': 0.3812336171045899, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7731958762886598, 'r1_recall': 0.4573170731707317, 'r1_f1': 0.5747126436781609, 'pegasus_entailment': 0.34158644638955593, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7105263157894737, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.6118980169971671, 'pegasus_entailment': 0.7309864871203899, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35833333333333334, 'r1_recall': 0.43, 'r1_f1': 0.3909090909090909, 'pegasus_entailment': 0.42596350237727165, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.580208033323288, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.5121951219512195, 'r1_f1': 0.525, 'pegasus_entailment': 0.3067730264738202, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20408163265306123, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.273972602739726, 'pegasus_entailment': 0.25118690612725914, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37735849056603776, 'r1_recall': 0.6349206349206349, 'r1_f1': 0.47337278106508884, 'pegasus_entailment': 0.28098699714367587, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20833333333333334, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.3076923076923077, 'pegasus_entailment': 0.42588669853284955, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45569620253164556, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.4645161290322581, 'pegasus_entailment': 0.2935250042937696, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6785714285714286, 'r1_recall': 0.41304347826086957, 'r1_f1': 0.5135135135135135, 'pegasus_entailment': 0.8125672303140163, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.375, 'r1_recall': 0.44776119402985076, 'r1_f1': 0.4081632653061225, 'pegasus_entailment': 0.5407034961972386, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6923076923076923, 'r1_recall': 0.375, 'r1_f1': 0.48648648648648646, 'pegasus_entailment': 0.6719222863515218, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5570469798657718, 'r1_recall': 0.6287878787878788, 'r1_f1': 0.590747330960854, 'pegasus_entailment': 0.9162841439247131, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8170731707317073, 'r1_recall': 0.4240506329113924, 'r1_f1': 0.5583333333333333, 'pegasus_entailment': 0.528026724855105, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 22}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.782608695652174, 'r1_recall': 0.30405405405405406, 'r1_f1': 0.43795620437956206, 'pegasus_entailment': 0.809465155005455, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3584905660377358, 'r1_recall': 0.6909090909090909, 'r1_f1': 0.4720496894409938, 'pegasus_entailment': 0.6194477424025535, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.3553299492385787, 'r1_f1': 0.4560260586319218, 'pegasus_entailment': 0.639728327592214, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 23, 'pegasus_ari': 30, 'pegasus_smog': 25}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.23333333333333334, 'r1_f1': 0.3181818181818182, 'pegasus_entailment': 0.7030017375946045, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 22, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6282051282051282, 'r1_recall': 0.3983739837398374, 'r1_f1': 0.4875621890547263, 'pegasus_entailment': 0.703146626551946, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6351351351351351, 'r1_recall': 0.44761904761904764, 'r1_f1': 0.5251396648044693, 'pegasus_entailment': 0.9451293547948202, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8152173913043478, 'r1_recall': 0.5725190839694656, 'r1_f1': 0.6726457399103138, 'pegasus_entailment': 0.6874455859263738, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4418604651162791, 'r1_recall': 0.5671641791044776, 'r1_f1': 0.4967320261437908, 'pegasus_entailment': 0.24250974389724433, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40625, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.4297520661157025, 'pegasus_entailment': 0.6612735539674759, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 23, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2932330827067669, 'r1_recall': 0.6842105263157895, 'r1_f1': 0.4105263157894737, 'pegasus_entailment': 0.301195350359194, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6790123456790124, 'r1_recall': 0.4296875, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.7677584141492844, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7183098591549296, 'r1_recall': 0.5730337078651685, 'r1_f1': 0.6375, 'pegasus_entailment': 0.498198722799619, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 32, 'pegasus_smog': 25}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6929824561403509, 'r1_recall': 0.48466257668711654, 'r1_f1': 0.5703971119133574, 'pegasus_entailment': 0.6289108792940775, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6240601503759399, 'r1_recall': 0.43005181347150256, 'r1_f1': 0.50920245398773, 'pegasus_entailment': 0.7016647010110318, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6290322580645161, 'r1_recall': 0.38613861386138615, 'r1_f1': 0.4785276073619632, 'pegasus_entailment': 0.05020290364821752, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4897959183673469, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5274725274725275, 'pegasus_entailment': 0.5346299987286329, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7142857142857143, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.5479452054794521, 'pegasus_entailment': 0.974156528711319, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4666666666666667, 'r1_recall': 0.5490196078431373, 'r1_f1': 0.5045045045045046, 'pegasus_entailment': 0.29655300406739116, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7555555555555555, 'r1_recall': 0.4594594594594595, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.3733849488198757, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6627906976744186, 'r1_recall': 0.4351145038167939, 'r1_f1': 0.5253456221198156, 'pegasus_entailment': 0.30510936472564937, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6292134831460674, 'r1_recall': 0.4745762711864407, 'r1_f1': 0.5410628019323671, 'pegasus_entailment': 0.6126461209108433, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7380952380952381, 'r1_recall': 0.47692307692307695, 'r1_f1': 0.5794392523364486, 'pegasus_entailment': 0.5169866923242807, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45323741007194246, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.48837209302325585, 'pegasus_entailment': 0.38479008595459163, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7395833333333334, 'r1_recall': 0.4930555555555556, 'r1_f1': 0.5916666666666668, 'pegasus_entailment': 0.25454112724401057, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 21}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.675, 'r1_recall': 0.6, 'r1_f1': 0.6352941176470589, 'pegasus_entailment': 0.5755258748928705, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.3609022556390977, 'r1_f1': 0.4192139737991266, 'pegasus_entailment': 0.06295357400085777, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.36792452830188677, 'r1_f1': 0.47416413373860183, 'pegasus_entailment': 0.50906982421875, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.379746835443038, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.44117647058823534, 'pegasus_entailment': 0.3366001870017499, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.75, 'r1_recall': 0.3515625, 'r1_f1': 0.4787234042553192, 'pegasus_entailment': 0.7569457292556763, 'pegasus_flesch_kincaid': 31, 'pegasus_coleman_liau': 19, 'pegasus_ari': 38, 'pegasus_smog': 25}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.35294117647058826, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.4225352112676057, 'pegasus_entailment': 0.7304647965356708, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6551724137931034, 'r1_recall': 0.4973821989528796, 'r1_f1': 0.5654761904761905, 'pegasus_entailment': 0.44734674133360386, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6404494382022472, 'r1_recall': 0.3877551020408163, 'r1_f1': 0.4830508474576271, 'pegasus_entailment': 0.8068372756242752, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6416666666666667, 'r1_recall': 0.5, 'r1_f1': 0.562043795620438, 'pegasus_entailment': 0.43179995511309244, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47107438016528924, 'r1_recall': 0.76, 'r1_f1': 0.5816326530612245, 'pegasus_entailment': 0.7993030369281768, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5365853658536586, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.5546218487394958, 'pegasus_entailment': 0.6030842959880829, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7128712871287128, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.5669291338582678, 'pegasus_entailment': 0.48322822464009124, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4830508474576271, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.5181818181818181, 'pegasus_entailment': 0.1342559375189012, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 13}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3135593220338983, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.4228571428571428, 'pegasus_entailment': 0.44151710271835326, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6086956521739131, 'r1_recall': 0.4375, 'r1_f1': 0.5090909090909091, 'pegasus_entailment': 0.5492575913667679, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 23, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5333333333333333, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.7418962319691976, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5915492957746479, 'r1_recall': 0.7924528301886793, 'r1_f1': 0.6774193548387097, 'pegasus_entailment': 0.936962366104126, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6122448979591837, 'r1_recall': 0.6451612903225806, 'r1_f1': 0.6282722513089005, 'pegasus_entailment': 0.689201109111309, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6025641025641025, 'r1_recall': 0.8103448275862069, 'r1_f1': 0.6911764705882352, 'pegasus_entailment': 0.41079063015058637, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6826923076923077, 'r1_recall': 0.696078431372549, 'r1_f1': 0.6893203883495146, 'pegasus_entailment': 0.7342901136726141, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6526315789473685, 'r1_recall': 0.3924050632911392, 'r1_f1': 0.49011857707509876, 'pegasus_entailment': 0.7182375118136406, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2653061224489796, 'r1_recall': 0.6842105263157895, 'r1_f1': 0.3823529411764706, 'pegasus_entailment': 0.22817643824964762, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5933333333333334, 'r1_recall': 0.5973154362416108, 'r1_f1': 0.5953177257525084, 'pegasus_entailment': 0.48457507682698114, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 19}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7023809523809523, 'r1_recall': 0.4306569343065693, 'r1_f1': 0.5339366515837103, 'pegasus_entailment': 0.5720223970711231, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.6511627906976744, 'pegasus_entailment': 0.6216221316717565, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.4144144144144144, 'r1_f1': 0.5111111111111111, 'pegasus_entailment': 0.031102170546849568, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.40425531914893614, 'r1_recall': 0.475, 'r1_f1': 0.4367816091954023, 'pegasus_entailment': 0.8263799945513407, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5979381443298969, 'r1_recall': 0.4566929133858268, 'r1_f1': 0.5178571428571429, 'pegasus_entailment': 0.7058928459882736, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6012658227848101, 'r1_recall': 0.48223350253807107, 'r1_f1': 0.5352112676056338, 'pegasus_entailment': 0.3149314023903571, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6854838709677419, 'r1_recall': 0.3497942386831276, 'r1_f1': 0.46321525885558584, 'pegasus_entailment': 0.4159137727692723, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7083333333333334, 'r1_recall': 0.3669064748201439, 'r1_f1': 0.48341232227488146, 'pegasus_entailment': 0.6019874115784963, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.20353982300884957, 'r1_recall': 0.3150684931506849, 'r1_f1': 0.24731182795698922, 'pegasus_entailment': 0.0009797130514925811, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3402061855670103, 'r1_recall': 0.5409836065573771, 'r1_f1': 0.4177215189873418, 'pegasus_entailment': 0.04368852451443672, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5862068965517241, 'r1_recall': 0.3953488372093023, 'r1_f1': 0.4722222222222222, 'pegasus_entailment': 0.5430960655212402, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 24, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4772727272727273, 'r1_recall': 0.5675675675675675, 'r1_f1': 0.5185185185185185, 'pegasus_entailment': 0.41792620725755114, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7547169811320755, 'r1_recall': 0.45977011494252873, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.4360298936565717, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5465116279069767, 'r1_recall': 0.3263888888888889, 'r1_f1': 0.408695652173913, 'pegasus_entailment': 0.37296416983008385, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 18}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6722689075630253, 'r1_recall': 0.41025641025641024, 'r1_f1': 0.5095541401273885, 'pegasus_entailment': 0.6951983347535133, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46808510638297873, 'r1_recall': 0.6027397260273972, 'r1_f1': 0.5269461077844312, 'pegasus_entailment': 0.13136220102508864, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3953488372093023, 'r1_recall': 0.68, 'r1_f1': 0.5, 'pegasus_entailment': 0.2726284360833233, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5188679245283019, 'r1_recall': 0.4824561403508772, 'r1_f1': 0.5, 'pegasus_entailment': 0.32398311933502555, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7368421052631579, 'r1_recall': 0.5212765957446809, 'r1_f1': 0.6105919003115264, 'pegasus_entailment': 0.5316855367273092, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6590909090909091, 'r1_recall': 0.4915254237288136, 'r1_f1': 0.5631067961165048, 'pegasus_entailment': 0.5965647399425507, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.375, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.7380540956343923, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4496124031007752, 'r1_f1': 0.47346938775510206, 'pegasus_entailment': 0.4509031918365508, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6385542168674698, 'r1_recall': 0.35570469798657717, 'r1_f1': 0.4568965517241379, 'pegasus_entailment': 0.9062450230121613, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.625, 'r1_recall': 0.4437869822485207, 'r1_f1': 0.5190311418685121, 'pegasus_entailment': 0.3534269866067916, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6346153846153846, 'r1_recall': 0.5038167938931297, 'r1_f1': 0.5617021276595745, 'pegasus_entailment': 0.30829523876309395, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5688073394495413, 'r1_recall': 0.5, 'r1_f1': 0.5321888412017167, 'pegasus_entailment': 0.435407480597496, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47115384615384615, 'r1_recall': 0.5903614457831325, 'r1_f1': 0.5240641711229947, 'pegasus_entailment': 0.7280815094709396, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 32, 'pegasus_smog': 21}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23529411764705882, 'r1_recall': 0.5128205128205128, 'r1_f1': 0.3225806451612903, 'pegasus_entailment': 0.3110573083977215, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6447368421052632, 'r1_recall': 0.4224137931034483, 'r1_f1': 0.5104166666666667, 'pegasus_entailment': 0.225012594088912, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8271604938271605, 'r1_recall': 0.3621621621621622, 'r1_f1': 0.5037593984962406, 'pegasus_entailment': 0.5138658471405506, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7755102040816326, 'r1_recall': 0.3958333333333333, 'r1_f1': 0.5241379310344828, 'pegasus_entailment': 0.8818435668945312, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6693877551020408, 'r1_recall': 0.42597402597402595, 'r1_f1': 0.5206349206349206, 'pegasus_entailment': 0.6473641736166817, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.660377358490566, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.56, 'pegasus_entailment': 0.826188713312149, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3723404255319149, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.44025157232704404, 'pegasus_entailment': 0.45115775366624195, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43157894736842106, 'r1_recall': 0.6833333333333333, 'r1_f1': 0.5290322580645161, 'pegasus_entailment': 0.24114019502303563, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5135135135135135, 'r1_recall': 0.2345679012345679, 'r1_f1': 0.3220338983050847, 'pegasus_entailment': 0.0038369831163436174, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6097560975609756, 'r1_recall': 0.4807692307692308, 'r1_f1': 0.5376344086021505, 'pegasus_entailment': 0.6024879862864813, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4520547945205479, 'r1_recall': 0.38372093023255816, 'r1_f1': 0.41509433962264153, 'pegasus_entailment': 0.5947982420523962, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 23}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5853658536585366, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.5161290322580645, 'pegasus_entailment': 0.6980070397257805, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5825242718446602, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.4477611940298507, 'pegasus_entailment': 0.32213637481133145, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47191011235955055, 'r1_recall': 0.6885245901639344, 'r1_f1': 0.5599999999999999, 'pegasus_entailment': 0.5655423700809479, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6037735849056604, 'r1_recall': 0.4266666666666667, 'r1_f1': 0.5, 'pegasus_entailment': 0.562807347625494, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5047619047619047, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.5408163265306122, 'pegasus_entailment': 0.4842569960746914, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7073170731707317, 'r1_recall': 0.44274809160305345, 'r1_f1': 0.5446009389671361, 'pegasus_entailment': 0.5883258881221991, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5463917525773195, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.5638297872340425, 'pegasus_entailment': 0.6006406784057617, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6057692307692307, 'r1_recall': 0.6, 'r1_f1': 0.6028708133971292, 'pegasus_entailment': 0.665514598786831, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4126984126984127, 'r1_recall': 0.7123287671232876, 'r1_f1': 0.5226130653266331, 'pegasus_entailment': 0.41128520702477545, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4810126582278481, 'r1_recall': 0.304, 'r1_f1': 0.37254901960784315, 'pegasus_entailment': 0.14849316544132307, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6756756756756757, 'r1_recall': 0.43859649122807015, 'r1_f1': 0.5319148936170213, 'pegasus_entailment': 0.6912057865411043, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45544554455445546, 'r1_recall': 0.5168539325842697, 'r1_f1': 0.4842105263157895, 'pegasus_entailment': 0.2620711348718032, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39622641509433965, 'r1_recall': 0.4883720930232558, 'r1_f1': 0.4375, 'pegasus_entailment': 0.31817012549436186, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 21, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6722689075630253, 'r1_recall': 0.36199095022624433, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.38779549673199654, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6538461538461539, 'r1_recall': 0.6017699115044248, 'r1_f1': 0.6267281105990784, 'pegasus_entailment': 0.6008991599082947, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 34, 'pegasus_smog': 22}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2376237623762376, 'r1_recall': 0.6486486486486487, 'r1_f1': 0.34782608695652173, 'pegasus_entailment': 0.23593706208339427, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5833333333333334, 'r1_recall': 0.5121951219512195, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.756098784506321, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6805555555555556, 'r1_recall': 0.45794392523364486, 'r1_f1': 0.5474860335195532, 'pegasus_entailment': 0.6608500762959011, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4166666666666667, 'r1_recall': 0.6944444444444444, 'r1_f1': 0.5208333333333334, 'pegasus_entailment': 0.09417724329978228, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.75, 'r1_recall': 0.375, 'r1_f1': 0.5, 'pegasus_entailment': 0.6320036053657532, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5797101449275363, 'r1_recall': 0.449438202247191, 'r1_f1': 0.5063291139240506, 'pegasus_entailment': 0.42890890245325863, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.33663366336633666, 'r1_recall': 0.576271186440678, 'r1_f1': 0.425, 'pegasus_entailment': 0.3244402241107309, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6375, 'r1_recall': 0.5151515151515151, 'r1_f1': 0.5698324022346368, 'pegasus_entailment': 0.6579134166240692, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.625, 'r1_f1': 0.5194805194805195, 'pegasus_entailment': 0.7236576976254583, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5955056179775281, 'r1_recall': 0.5638297872340425, 'r1_f1': 0.5792349726775957, 'pegasus_entailment': 0.394684540728728, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8472222222222222, 'r1_recall': 0.23371647509578544, 'r1_f1': 0.3663663663663663, 'pegasus_entailment': 0.8048006296157837, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7, 'r1_recall': 0.525, 'r1_f1': 0.6, 'pegasus_entailment': 0.7226494295256478, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29927007299270075, 'r1_recall': 0.5256410256410257, 'r1_f1': 0.38139534883720927, 'pegasus_entailment': 0.11161823485357066, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7065217391304348, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.6598984771573604, 'pegasus_entailment': 0.6518382082382838, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.797752808988764, 'r1_recall': 0.5220588235294118, 'r1_f1': 0.6311111111111112, 'pegasus_entailment': 0.8736783266067505, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.696969696969697, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6509433962264151, 'pegasus_entailment': 0.8716341654459635, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5862068965517241, 'r1_recall': 0.6, 'r1_f1': 0.5930232558139535, 'pegasus_entailment': 0.6358925799528757, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5217391304347826, 'pegasus_entailment': 0.6282533953587214, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5684210526315789, 'r1_recall': 0.5869565217391305, 'r1_f1': 0.5775401069518717, 'pegasus_entailment': 0.45091199583839625, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5425531914893617, 'r1_recall': 0.6144578313253012, 'r1_f1': 0.576271186440678, 'pegasus_entailment': 0.38228214035431546, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7538461538461538, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.5130890052356022, 'pegasus_entailment': 0.06029536621645093, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.6274509803921569, 'r1_f1': 0.6213592233009709, 'pegasus_entailment': 0.38479975052177906, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7558139534883721, 'r1_recall': 0.40372670807453415, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.669269194205602, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2786885245901639, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.37988826815642457, 'pegasus_entailment': 0.1412342593364883, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7739130434782608, 'r1_recall': 0.3938053097345133, 'r1_f1': 0.5219941348973607, 'pegasus_entailment': 0.3706295856585105, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.484375, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.5000000000000001, 'pegasus_entailment': 0.3921894115046598, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 17}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5344827586206896, 'r1_recall': 0.6138613861386139, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.42032560938969254, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30973451327433627, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.43209876543209874, 'pegasus_entailment': 0.7733643501996994, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2602739726027397, 'r1_recall': 0.41304347826086957, 'r1_f1': 0.31932773109243695, 'pegasus_entailment': 0.2544440357014537, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6470588235294118, 'r1_recall': 0.6027397260273972, 'r1_f1': 0.6241134751773049, 'pegasus_entailment': 0.7340955336888632, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 22}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6408839779005525, 'r1_recall': 0.6041666666666666, 'r1_f1': 0.6219839142091153, 'pegasus_entailment': 0.5891011536121369, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6046511627906976, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.46870342642068863, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5180722891566265, 'r1_recall': 0.43434343434343436, 'r1_f1': 0.4725274725274725, 'pegasus_entailment': 0.0791447170486208, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41732283464566927, 'r1_recall': 0.6385542168674698, 'r1_f1': 0.5047619047619049, 'pegasus_entailment': 0.2645831329806242, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.5113636363636364, 'pegasus_entailment': 0.9385031461715698, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6413043478260869, 'r1_recall': 0.5130434782608696, 'r1_f1': 0.5700483091787439, 'pegasus_entailment': 0.2431898858437004, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.576271186440678, 'r1_recall': 0.40476190476190477, 'r1_f1': 0.4755244755244756, 'pegasus_entailment': 0.8722059726715088, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 19}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34615384615384615, 'r1_recall': 0.5094339622641509, 'r1_f1': 0.4122137404580153, 'pegasus_entailment': 0.3774367126170546, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5764705882352941, 'r1_recall': 0.4537037037037037, 'r1_f1': 0.5077720207253886, 'pegasus_entailment': 0.3474792130291462, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7611940298507462, 'r1_recall': 0.45132743362831856, 'r1_f1': 0.5666666666666667, 'pegasus_entailment': 0.36956122593255714, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4731182795698925, 'r1_recall': 0.6197183098591549, 'r1_f1': 0.5365853658536585, 'pegasus_entailment': 0.3836066474439576, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6989247311827957, 'r1_recall': 0.2968036529680365, 'r1_f1': 0.4166666666666667, 'pegasus_entailment': 0.545773446559906, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 31, 'pegasus_smog': 26}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3142857142857143, 'r1_recall': 0.3142857142857143, 'r1_f1': 0.3142857142857143, 'pegasus_entailment': 0.9527797102928162, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 19}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5980392156862745, 'r1_recall': 0.7349397590361446, 'r1_f1': 0.6594594594594596, 'pegasus_entailment': 0.3318661932135001, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33766233766233766, 'r1_recall': 0.5306122448979592, 'r1_f1': 0.4126984126984127, 'pegasus_entailment': 0.2445310114417225, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8648648648648649, 'r1_recall': 0.3764705882352941, 'r1_f1': 0.5245901639344263, 'pegasus_entailment': 0.480934189632535, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 14, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7228915662650602, 'r1_recall': 0.46511627906976744, 'r1_f1': 0.5660377358490566, 'pegasus_entailment': 0.7397405703862509, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4076923076923077, 'r1_recall': 0.6091954022988506, 'r1_f1': 0.488479262672811, 'pegasus_entailment': 0.29562088526048075, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6818181818181818, 'r1_recall': 0.45112781954887216, 'r1_f1': 0.5429864253393664, 'pegasus_entailment': 0.17294072763373455, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5611510791366906, 'r1_recall': 0.7027027027027027, 'r1_f1': 0.624, 'pegasus_entailment': 0.09037331631407142, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46601941747572817, 'r1_recall': 0.5, 'r1_f1': 0.4824120603015076, 'pegasus_entailment': 0.01374647110545387, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6410256410256411, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.5836575875486382, 'pegasus_entailment': 0.8392471869786581, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 26}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6785714285714286, 'r1_recall': 0.2638888888888889, 'r1_f1': 0.38, 'pegasus_entailment': 0.6016486287117004, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.569620253164557, 'r1_recall': 0.4891304347826087, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.4893290083273314, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6172839506172839, 'r1_recall': 0.4854368932038835, 'r1_f1': 0.5434782608695653, 'pegasus_entailment': 0.44833963612715405, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29133858267716534, 'r1_recall': 0.5522388059701493, 'r1_f1': 0.3814432989690722, 'pegasus_entailment': 0.4384570375084877, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5777777777777777, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.574585635359116, 'pegasus_entailment': 0.9530182083447775, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48366013071895425, 'r1_recall': 0.5174825174825175, 'r1_f1': 0.5, 'pegasus_entailment': 0.5925259746611118, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.725, 'r1_recall': 0.47540983606557374, 'r1_f1': 0.5742574257425742, 'pegasus_entailment': 0.30356103455414996, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6296296296296297, 'r1_recall': 0.5120481927710844, 'r1_f1': 0.5647840531561462, 'pegasus_entailment': 0.2957903079688549, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5689655172413793, 'r1_recall': 0.6, 'r1_f1': 0.584070796460177, 'pegasus_entailment': 0.024477798491716385, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5483870967741935, 'r1_recall': 0.4594594594594595, 'r1_f1': 0.5, 'pegasus_entailment': 0.804145336151123, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7397260273972602, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.6171428571428571, 'pegasus_entailment': 0.668599526087443, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6296296296296297, 'r1_recall': 0.4722222222222222, 'r1_f1': 0.5396825396825397, 'pegasus_entailment': 0.5384667172717551, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6056338028169014, 'r1_recall': 0.35537190082644626, 'r1_f1': 0.44791666666666663, 'pegasus_entailment': 0.15776231279596686, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7142857142857143, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.5, 'pegasus_entailment': 0.2643346773693338, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45714285714285713, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.5, 'pegasus_entailment': 0.2474722086917609, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5533980582524272, 'r1_recall': 0.6263736263736264, 'r1_f1': 0.5876288659793815, 'pegasus_entailment': 0.6001048039955398, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6266666666666667, 'r1_recall': 0.46078431372549017, 'r1_f1': 0.5310734463276837, 'pegasus_entailment': 0.27455772645771503, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 13, 'pegasus_ari': 11, 'pegasus_smog': 16}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5632183908045977, 'r1_recall': 0.4298245614035088, 'r1_f1': 0.48756218905472637, 'pegasus_entailment': 0.39027057494968176, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5591397849462365, 'r1_recall': 0.5252525252525253, 'r1_f1': 0.5416666666666666, 'pegasus_entailment': 0.2895403727889061, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3877551020408163, 'r1_recall': 0.42696629213483145, 'r1_f1': 0.40641711229946526, 'pegasus_entailment': 0.07333515852224082, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8913043478260869, 'r1_recall': 0.5030674846625767, 'r1_f1': 0.6431372549019607, 'pegasus_entailment': 0.4657302275300026, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5825242718446602, 'r1_recall': 0.32967032967032966, 'r1_f1': 0.42105263157894735, 'pegasus_entailment': 0.6743720650672913, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.75, 'r1_recall': 0.18545454545454546, 'r1_f1': 0.2973760932944607, 'pegasus_entailment': 0.6229693442583084, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 19}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5234375, 'r1_recall': 0.6146788990825688, 'r1_f1': 0.5654008438818565, 'pegasus_entailment': 0.6346258404664695, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3253012048192771, 'r1_recall': 0.46551724137931033, 'r1_f1': 0.38297872340425526, 'pegasus_entailment': 0.4883445667073829, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6190476190476191, 'r1_recall': 0.287292817679558, 'r1_f1': 0.3924528301886792, 'pegasus_entailment': 0.21929532061330975, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43529411764705883, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.4567901234567901, 'pegasus_entailment': 0.3026811781649788, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6935483870967742, 'r1_recall': 0.5375, 'r1_f1': 0.6056338028169015, 'pegasus_entailment': 0.60991903146108, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7307692307692307, 'r1_recall': 0.6129032258064516, 'r1_f1': 0.6666666666666667, 'pegasus_entailment': 0.6888184873387218, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4411764705882353, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.49180327868852464, 'pegasus_entailment': 0.42317373730475083, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5168539325842697, 'r1_recall': 0.5111111111111111, 'r1_f1': 0.5139664804469274, 'pegasus_entailment': 0.2878431126009673, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27927927927927926, 'r1_recall': 0.4492753623188406, 'r1_f1': 0.3444444444444444, 'pegasus_entailment': 0.46534459555793245, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5595238095238095, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.5222222222222223, 'pegasus_entailment': 0.4036517061293125, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4861111111111111, 'r1_recall': 0.546875, 'r1_f1': 0.5147058823529411, 'pegasus_entailment': 0.8426908850669861, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2980769230769231, 'r1_recall': 0.6813186813186813, 'r1_f1': 0.41471571906354515, 'pegasus_entailment': 0.6424526761984453, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6021505376344086, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.6187845303867403, 'pegasus_entailment': 0.723336935043335, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.6935483870967742, 'r1_f1': 0.5810810810810811, 'pegasus_entailment': 0.20719996358578405, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 23}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4146341463414634, 'r1_recall': 0.6355140186915887, 'r1_f1': 0.5018450184501845, 'pegasus_entailment': 0.39242072887718676, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5625, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.4864864864864864, 'pegasus_entailment': 0.3877964572360118, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7469879518072289, 'r1_recall': 0.4679245283018868, 'r1_f1': 0.5754060324825986, 'pegasus_entailment': 0.47542234929278493, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4, 'r1_recall': 0.53125, 'r1_f1': 0.45637583892617456, 'pegasus_entailment': 0.17221104446798563, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 16, 'pegasus_ari': 27, 'pegasus_smog': 19}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4489795918367347, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.46315789473684216, 'pegasus_entailment': 0.4780100516974926, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6385542168674698, 'r1_recall': 0.53, 'r1_f1': 0.5792349726775956, 'pegasus_entailment': 0.7155208190282186, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5416666666666666, 'r1_recall': 0.5571428571428572, 'r1_f1': 0.5492957746478873, 'pegasus_entailment': 0.6098360270261765, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.691358024691358, 'r1_recall': 0.5957446808510638, 'r1_f1': 0.64, 'pegasus_entailment': 0.26851136088371275, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.58, 'r1_recall': 0.2283464566929134, 'r1_f1': 0.327683615819209, 'pegasus_entailment': 0.8597428599993387, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 23, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3381294964028777, 'r1_recall': 0.6619718309859155, 'r1_f1': 0.4476190476190476, 'pegasus_entailment': 0.5832446962594986, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47183098591549294, 'r1_recall': 0.7127659574468085, 'r1_f1': 0.5677966101694916, 'pegasus_entailment': 0.42149994485080244, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47560975609756095, 'r1_recall': 0.4642857142857143, 'r1_f1': 0.4698795180722891, 'pegasus_entailment': 0.381483922402064, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45045045045045046, 'r1_recall': 0.6756756756756757, 'r1_f1': 0.5405405405405405, 'pegasus_entailment': 0.29597114748321474, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3669064748201439, 'r1_recall': 0.7611940298507462, 'r1_f1': 0.49514563106796117, 'pegasus_entailment': 0.6084662079811096, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 31, 'pegasus_smog': 22}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.312, 'r1_recall': 0.609375, 'r1_f1': 0.4126984126984127, 'pegasus_entailment': 0.3435855984687805, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5934065934065934, 'r1_recall': 0.31213872832369943, 'r1_f1': 0.40909090909090906, 'pegasus_entailment': 0.7173126220703125, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8365384615384616, 'r1_recall': 0.5272727272727272, 'r1_f1': 0.6468401486988847, 'pegasus_entailment': 0.3802299678325653, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7435897435897436, 'r1_recall': 0.5918367346938775, 'r1_f1': 0.6590909090909091, 'pegasus_entailment': 0.31663723243400455, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7073170731707317, 'r1_recall': 0.31016042780748665, 'r1_f1': 0.4312267657992565, 'pegasus_entailment': 0.3623160235583782, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5529411764705883, 'r1_recall': 0.49473684210526314, 'r1_f1': 0.5222222222222223, 'pegasus_entailment': 0.09927467608940788, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45, 'r1_recall': 0.625, 'r1_f1': 0.5232558139534884, 'pegasus_entailment': 0.4031892465427518, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3709677419354839, 'r1_recall': 0.41818181818181815, 'r1_f1': 0.39316239316239315, 'pegasus_entailment': 0.7504100104173025, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31958762886597936, 'r1_recall': 0.7380952380952381, 'r1_f1': 0.4460431654676259, 'pegasus_entailment': 0.2569907233895113, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5368421052631579, 'r1_recall': 0.7183098591549296, 'r1_f1': 0.6144578313253012, 'pegasus_entailment': 0.7679864168167114, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3875, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.46969696969696967, 'pegasus_entailment': 0.17098598601296544, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47115384615384615, 'r1_recall': 0.4188034188034188, 'r1_f1': 0.44343891402714936, 'pegasus_entailment': 0.2529902651440352, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6788990825688074, 'r1_recall': 0.5648854961832062, 'r1_f1': 0.6166666666666667, 'pegasus_entailment': 0.7023168504238129, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46938775510204084, 'r1_recall': 0.5476190476190477, 'r1_f1': 0.5054945054945055, 'pegasus_entailment': 0.5014954973012209, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.36666666666666664, 'r1_f1': 0.4551724137931034, 'pegasus_entailment': 0.6799797723069787, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38666666666666666, 'r1_recall': 0.6373626373626373, 'r1_f1': 0.4813278008298755, 'pegasus_entailment': 0.16212726160883903, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34285714285714286, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.42105263157894735, 'pegasus_entailment': 0.5017980833072215, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5083333333333333, 'r1_recall': 0.6630434782608695, 'r1_f1': 0.5754716981132074, 'pegasus_entailment': 0.26568822492845356, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7241379310344828, 'r1_recall': 0.42, 'r1_f1': 0.5316455696202531, 'pegasus_entailment': 0.658155565460523, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45161290322580644, 'r1_recall': 0.4057971014492754, 'r1_f1': 0.42748091603053434, 'pegasus_entailment': 0.4444344718940556, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6590909090909091, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6628571428571428, 'pegasus_entailment': 0.5457254368811846, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6352941176470588, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.5775401069518717, 'pegasus_entailment': 0.8490336139996847, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5783132530120482, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5748502994011976, 'pegasus_entailment': 0.9160239994525909, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 17}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24347826086956523, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.33532934131736525, 'pegasus_entailment': 0.4397152030918126, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6330275229357798, 'r1_recall': 0.4825174825174825, 'r1_f1': 0.5476190476190476, 'pegasus_entailment': 0.34532110920796794, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.514018691588785, 'r1_recall': 0.632183908045977, 'r1_f1': 0.5670103092783505, 'pegasus_entailment': 0.5462395921349525, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45714285714285713, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.5161290322580645, 'pegasus_entailment': 0.6101346015930176, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6097560975609756, 'r1_recall': 0.4132231404958678, 'r1_f1': 0.49261083743842365, 'pegasus_entailment': 0.47821498569101095, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.23076923076923078, 'r1_f1': 0.3243243243243243, 'pegasus_entailment': 0.8898718059062958, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 11, 'pegasus_smog': 15}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47706422018348627, 'r1_recall': 0.7428571428571429, 'r1_f1': 0.5810055865921788, 'pegasus_entailment': 0.39430809766054153, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.380952380952381, 'pegasus_entailment': 0.633194329837958, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46601941747572817, 'r1_recall': 0.5393258426966292, 'r1_f1': 0.5, 'pegasus_entailment': 0.5382579462602735, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1891891891891892, 'r1_recall': 0.3111111111111111, 'r1_f1': 0.23529411764705882, 'pegasus_entailment': 0.26649900743116933, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5858585858585859, 'r1_recall': 0.5631067961165048, 'r1_f1': 0.5742574257425742, 'pegasus_entailment': 0.16702541802078485, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.13043478260869565, 'r1_recall': 0.34285714285714286, 'r1_f1': 0.1889763779527559, 'pegasus_entailment': 0.33528886139780906, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4406779661016949, 'r1_recall': 0.5777777777777777, 'r1_f1': 0.5, 'pegasus_entailment': 0.23831663621240295, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32653061224489793, 'r1_recall': 0.8205128205128205, 'r1_f1': 0.46715328467153283, 'pegasus_entailment': 0.8259178102016449, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 25}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6956521739130435, 'r1_recall': 0.6486486486486487, 'r1_f1': 0.6713286713286714, 'pegasus_entailment': 0.5340379796301326, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5871559633027523, 'r1_recall': 0.5565217391304348, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.6615029037930071, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5203252032520326, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5844748858447488, 'pegasus_entailment': 0.759085456530253, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.5504587155963303, 'r1_f1': 0.6030150753768844, 'pegasus_entailment': 0.5975206188857556, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7777777777777778, 'r1_recall': 0.35507246376811596, 'r1_f1': 0.4875621890547263, 'pegasus_entailment': 0.3495127068211635, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8440366972477065, 'r1_recall': 0.26136363636363635, 'r1_f1': 0.3991323210412147, 'pegasus_entailment': 0.8646760582923889, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38596491228070173, 'r1_recall': 0.5945945945945946, 'r1_f1': 0.4680851063829787, 'pegasus_entailment': 0.7785562515258789, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6296296296296297, 'r1_recall': 0.3422818791946309, 'r1_f1': 0.4434782608695652, 'pegasus_entailment': 0.6747756568598561, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7837837837837838, 'r1_recall': 0.38926174496644295, 'r1_f1': 0.5201793721973094, 'pegasus_entailment': 0.4803390900293986, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2972972972972973, 'r1_recall': 0.4489795918367347, 'r1_f1': 0.35772357723577236, 'pegasus_entailment': 0.7621709009011587, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.411214953271028, 'r1_recall': 0.6111111111111112, 'r1_f1': 0.49162011173184356, 'pegasus_entailment': 0.5091306157410145, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36065573770491804, 'r1_recall': 0.5432098765432098, 'r1_f1': 0.43349753694581283, 'pegasus_entailment': 0.5812654793844558, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7518796992481203, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.7067137809187278, 'pegasus_entailment': 0.4729217223066371, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3465346534653465, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.17324429424479604, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6946564885496184, 'r1_recall': 0.5290697674418605, 'r1_f1': 0.6006600660066007, 'pegasus_entailment': 0.8201907475789388, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 19}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41935483870967744, 'r1_recall': 0.7027027027027027, 'r1_f1': 0.5252525252525253, 'pegasus_entailment': 0.7269778624176979, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4180327868852459, 'r1_recall': 0.6296296296296297, 'r1_f1': 0.5024630541871922, 'pegasus_entailment': 0.5496799894608557, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.616822429906542, 'r1_recall': 0.46808510638297873, 'r1_f1': 0.532258064516129, 'pegasus_entailment': 0.0639453565934673, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47058823529411764, 'r1_recall': 0.549618320610687, 'r1_f1': 0.5070422535211268, 'pegasus_entailment': 0.2849316731095314, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.39436619718309857, 'r1_f1': 0.495575221238938, 'pegasus_entailment': 0.30518401072671014, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 26}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5728155339805825, 'r1_recall': 0.6555555555555556, 'r1_f1': 0.6113989637305699, 'pegasus_entailment': 0.52633021119982, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45977011494252873, 'r1_recall': 0.7017543859649122, 'r1_f1': 0.5555555555555556, 'pegasus_entailment': 0.015388617292046547, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7264150943396226, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.5220338983050847, 'pegasus_entailment': 0.41122795194387435, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7085714285714285, 'r1_recall': 0.40789473684210525, 'r1_f1': 0.5177453027139874, 'pegasus_entailment': 0.6302314193121025, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28888888888888886, 'r1_recall': 0.4126984126984127, 'r1_f1': 0.3398692810457516, 'pegasus_entailment': 0.5339284986257553, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5428571428571428, 'r1_recall': 0.6, 'r1_f1': 0.57, 'pegasus_entailment': 0.48761877475772053, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7191011235955056, 'r1_recall': 0.4050632911392405, 'r1_f1': 0.5182186234817814, 'pegasus_entailment': 0.4012993773794733, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2976190476190476, 'r1_recall': 0.43103448275862066, 'r1_f1': 0.35211267605633806, 'pegasus_entailment': 0.2571674588834867, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7582417582417582, 'r1_recall': 0.3812154696132597, 'r1_f1': 0.5073529411764707, 'pegasus_entailment': 0.7299708753824234, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.65, 'r1_recall': 0.2746478873239437, 'r1_f1': 0.38613861386138615, 'pegasus_entailment': 0.3208341083178918, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 13, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42727272727272725, 'r1_recall': 0.49473684210526314, 'r1_f1': 0.4585365853658537, 'pegasus_entailment': 0.27412521801888945, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5963302752293578, 'r1_recall': 0.37790697674418605, 'r1_f1': 0.4626334519572954, 'pegasus_entailment': 0.6487397775053978, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5421686746987951, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.5844155844155844, 'pegasus_entailment': 0.677254993468523, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7922077922077922, 'r1_recall': 0.2932692307692308, 'r1_f1': 0.42807017543859655, 'pegasus_entailment': 0.04508242600907882, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5684210526315789, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.5744680851063831, 'pegasus_entailment': 0.6767893660580739, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3795180722891566, 'r1_recall': 0.84, 'r1_f1': 0.5228215767634855, 'pegasus_entailment': 0.613037247210741, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6862745098039216, 'r1_recall': 0.49295774647887325, 'r1_f1': 0.5737704918032787, 'pegasus_entailment': 0.923418253660202, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5851063829787234, 'r1_recall': 0.5445544554455446, 'r1_f1': 0.5641025641025641, 'pegasus_entailment': 0.360297550757726, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7898550724637681, 'r1_recall': 0.5265700483091788, 'r1_f1': 0.6318840579710144, 'pegasus_entailment': 0.730494940537028, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48091603053435117, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.5407725321888412, 'pegasus_entailment': 0.6188696641474962, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3047619047619048, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.3878787878787879, 'pegasus_entailment': 0.31330004237437, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8230088495575221, 'r1_recall': 0.5224719101123596, 'r1_f1': 0.6391752577319588, 'pegasus_entailment': 0.30148603953421116, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4752475247524752, 'r1_recall': 0.6575342465753424, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.3451885223388672, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5128205128205128, 'r1_recall': 0.7894736842105263, 'r1_f1': 0.6217616580310881, 'pegasus_entailment': 0.5572363952174783, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 14}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5148514851485149, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5416666666666666, 'pegasus_entailment': 0.4179484276100993, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7209302325581395, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.6019417475728156, 'pegasus_entailment': 0.4201848767697811, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8518518518518519, 'r1_recall': 0.16312056737588654, 'r1_f1': 0.27380952380952384, 'pegasus_entailment': 0.5323627803474664, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5441176470588235, 'r1_recall': 0.5211267605633803, 'r1_f1': 0.5323741007194244, 'pegasus_entailment': 0.4613384291529655, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.9390243902439024, 'r1_recall': 0.4207650273224044, 'r1_f1': 0.5811320754716981, 'pegasus_entailment': 0.4538766145706177, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5142857142857142, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.7663617531458536, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6396396396396397, 'r1_recall': 0.6120689655172413, 'r1_f1': 0.6255506607929516, 'pegasus_entailment': 0.5171209685504436, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5915492957746479, 'r1_recall': 0.6461538461538462, 'r1_f1': 0.6176470588235294, 'pegasus_entailment': 0.007687581198600431, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6052631578947368, 'r1_recall': 0.4394904458598726, 'r1_f1': 0.5092250922509225, 'pegasus_entailment': 0.6922828654448191, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2782608695652174, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.39263803680981596, 'pegasus_entailment': 0.6153541346313431, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6388888888888888, 'r1_recall': 0.4742268041237113, 'r1_f1': 0.544378698224852, 'pegasus_entailment': 0.9019886553287506, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2413793103448276, 'r1_recall': 0.6, 'r1_f1': 0.34426229508196726, 'pegasus_entailment': 0.6214545418818792, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.525, 'r1_recall': 0.4329896907216495, 'r1_f1': 0.4745762711864407, 'pegasus_entailment': 0.9324716627597809, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5948275862068966, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6026200873362445, 'pegasus_entailment': 0.6677283097989857, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5948275862068966, 'r1_recall': 0.5111111111111111, 'r1_f1': 0.549800796812749, 'pegasus_entailment': 0.46482395904604346, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.37777777777777777, 'r1_recall': 0.3148148148148148, 'r1_f1': 0.34343434343434337, 'pegasus_entailment': 0.8325608472029368, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 12, 'pegasus_ari': 8, 'pegasus_smog': 14}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.28, 'r1_f1': 0.3888888888888889, 'pegasus_entailment': 0.37830590456724167, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
** Analysing column: malformed_chain



malformed_chain
Length after nones removed
616
MIN
0
MEAN
0
MAX
1
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.13043478260869565
MEAN
0.5555916720221356
MAX
0.9390243902439024
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.15126050420168066
MEAN
0.5116395934604099
MAX
0.84
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.1889763779527559
MEAN
0.5092476544880534
MAX
0.7484662576687117
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.0009797130514925811
MEAN
0.4919953870697068
MAX
0.974156528711319
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
17
MAX
31
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
12
MEAN
17
MAX
24
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
8
MEAN
20
MAX
38
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
8
MEAN
18
MAX
26
{}
Entered file!
Imports done!
*** RUN *** 
eval_5cO
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 13:53:10.696301: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 13:53:11.243117: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/5cO_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5192307692307693, 'r1_recall': 0.4909090909090909, 'r1_f1': 0.5046728971962617, 'pegasus_entailment': 0.4547572173178196, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7204301075268817, 'r1_recall': 0.3872832369942196, 'r1_f1': 0.5037593984962405, 'pegasus_entailment': 0.7008093237876892, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3490566037735849, 'r1_recall': 0.6379310344827587, 'r1_f1': 0.4512195121951219, 'pegasus_entailment': 0.49421179946511984, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.65, 'r1_recall': 0.40310077519379844, 'r1_f1': 0.4976076555023924, 'pegasus_entailment': 0.1941155143082142, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7285714285714285, 'r1_recall': 0.29310344827586204, 'r1_f1': 0.41803278688524587, 'pegasus_entailment': 0.7605021893978119, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5772357723577236, 'r1_recall': 0.5461538461538461, 'r1_f1': 0.5612648221343873, 'pegasus_entailment': 0.4846452582627535, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1574074074074074, 'r1_recall': 0.53125, 'r1_f1': 0.24285714285714285, 'pegasus_entailment': 0.3842166581501563, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 14, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24561403508771928, 'r1_recall': 0.9032258064516129, 'r1_f1': 0.38620689655172413, 'pegasus_entailment': 0.46028713633616763, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6728971962616822, 'r1_recall': 0.48322147651006714, 'r1_f1': 0.5625, 'pegasus_entailment': 0.7336321976035833, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7009345794392523, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.6122448979591837, 'pegasus_entailment': 0.7325082942843437, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6702127659574468, 'r1_recall': 0.42, 'r1_f1': 0.5163934426229508, 'pegasus_entailment': 0.28197044879198074, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6133333333333333, 'r1_recall': 0.3865546218487395, 'r1_f1': 0.4742268041237114, 'pegasus_entailment': 0.5286122094839811, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7125, 'r1_recall': 0.5327102803738317, 'r1_f1': 0.6096256684491977, 'pegasus_entailment': 0.7330564437434077, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5373134328358209, 'r1_recall': 0.4090909090909091, 'r1_f1': 0.46451612903225803, 'pegasus_entailment': 0.2470002267509699, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8444444444444444, 'r1_recall': 0.3958333333333333, 'r1_f1': 0.5390070921985816, 'pegasus_entailment': 0.6828110466400782, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.24561403508771928, 'r1_recall': 0.4745762711864407, 'r1_f1': 0.3236994219653179, 'pegasus_entailment': 0.6556905681888262, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.52, 'r1_recall': 0.26262626262626265, 'r1_f1': 0.3489932885906041, 'pegasus_entailment': 0.18881801998941228, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 15}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7246376811594203, 'r1_recall': 0.33557046979865773, 'r1_f1': 0.4587155963302752, 'pegasus_entailment': 0.5010517537593842, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8095238095238095, 'r1_recall': 0.3167701863354037, 'r1_f1': 0.4553571428571428, 'pegasus_entailment': 0.6092554032802582, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5185185185185185, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.5, 'pegasus_entailment': 0.7640366852283478, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6290322580645161, 'r1_recall': 0.21428571428571427, 'r1_f1': 0.31967213114754095, 'pegasus_entailment': 0.958128347992897, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6739130434782609, 'r1_recall': 0.41333333333333333, 'r1_f1': 0.512396694214876, 'pegasus_entailment': 0.4735186950614055, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6794871794871795, 'r1_recall': 0.49074074074074076, 'r1_f1': 0.5698924731182796, 'pegasus_entailment': 0.5965227286020914, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6739130434782609, 'r1_recall': 0.45588235294117646, 'r1_f1': 0.543859649122807, 'pegasus_entailment': 0.3781549703329802, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4318181818181818, 'r1_recall': 0.38, 'r1_f1': 0.4042553191489362, 'pegasus_entailment': 0.43648873766263324, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.754601226993865, 'r1_recall': 0.6507936507936508, 'r1_f1': 0.6988636363636364, 'pegasus_entailment': 0.8902220487594604, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6140350877192983, 'r1_recall': 0.5109489051094891, 'r1_f1': 0.5577689243027888, 'pegasus_entailment': 0.7787386924028397, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7410071942446043, 'r1_recall': 0.3843283582089552, 'r1_f1': 0.5061425061425061, 'pegasus_entailment': 0.5357062295079231, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4918032786885246, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.43795620437956206, 'pegasus_entailment': 0.4284621886909008, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 12, 'pegasus_ari': 11, 'pegasus_smog': 13}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5882352941176471, 'r1_recall': 0.4424778761061947, 'r1_f1': 0.5050505050505051, 'pegasus_entailment': 0.6329844667576253, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4098360655737705, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.4784688995215311, 'pegasus_entailment': 0.1184430387802422, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7355371900826446, 'r1_recall': 0.4427860696517413, 'r1_f1': 0.5527950310559007, 'pegasus_entailment': 0.7940247108538946, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45161290322580644, 'r1_recall': 0.4077669902912621, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.4023602865636349, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5402298850574713, 'r1_recall': 0.4845360824742268, 'r1_f1': 0.5108695652173914, 'pegasus_entailment': 0.19770891095201173, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38016528925619836, 'r1_recall': 0.5476190476190477, 'r1_f1': 0.44878048780487806, 'pegasus_entailment': 0.19887015093117952, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5851063829787234, 'r1_recall': 0.47413793103448276, 'r1_f1': 0.5238095238095238, 'pegasus_entailment': 0.0971195346986254, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5824175824175825, 'r1_recall': 0.7681159420289855, 'r1_f1': 0.6625, 'pegasus_entailment': 0.5295602480570475, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32038834951456313, 'r1_recall': 0.4852941176470588, 'r1_f1': 0.3859649122807018, 'pegasus_entailment': 0.2541389241348952, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3258426966292135, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.4328358208955224, 'pegasus_entailment': 0.463817598298192, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6183206106870229, 'r1_recall': 0.4879518072289157, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.6112852751809571, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6909090909090909, 'r1_recall': 0.475, 'r1_f1': 0.5629629629629629, 'pegasus_entailment': 0.5889354938020309, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5194805194805194, 'r1_recall': 0.5194805194805194, 'r1_f1': 0.5194805194805194, 'pegasus_entailment': 0.9069710671901703, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3669724770642202, 'r1_recall': 0.547945205479452, 'r1_f1': 0.43956043956043955, 'pegasus_entailment': 0.19416909117426256, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4962962962962963, 'r1_recall': 0.5447154471544715, 'r1_f1': 0.5193798449612403, 'pegasus_entailment': 0.5773926949477755, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4861111111111111, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.5211630165576935, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48404255319148937, 'r1_recall': 0.6066666666666667, 'r1_f1': 0.5384615384615385, 'pegasus_entailment': 0.5221125176176429, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 31, 'pegasus_smog': 22}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5508474576271186, 'r1_f1': 0.5241935483870969, 'pegasus_entailment': 0.31413047675741834, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.5066666666666666, 'pegasus_entailment': 0.6697952263057232, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4636363636363636, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.5257731958762887, 'pegasus_entailment': 0.5047082498669624, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41836734693877553, 'r1_recall': 0.3942307692307692, 'r1_f1': 0.4059405940594059, 'pegasus_entailment': 0.10903806425631046, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3150684931506849, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.41818181818181815, 'pegasus_entailment': 0.43380062431097033, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23076923076923078, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.33149171270718236, 'pegasus_entailment': 0.5702637958650788, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45977011494252873, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.49689440993788814, 'pegasus_entailment': 0.6573883160948754, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.711340206185567, 'r1_recall': 0.3898305084745763, 'r1_f1': 0.5036496350364964, 'pegasus_entailment': 0.2893517462653108, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6982758620689655, 'r1_recall': 0.4550561797752809, 'r1_f1': 0.5510204081632653, 'pegasus_entailment': 0.6461948985233903, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.424, 'r1_recall': 0.7361111111111112, 'r1_f1': 0.5380710659898478, 'pegasus_entailment': 0.37694393404360327, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8125, 'r1_recall': 0.3107569721115538, 'r1_f1': 0.4495677233429395, 'pegasus_entailment': 0.5598669022321701, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 22, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5507246376811594, 'r1_recall': 0.59375, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.4419704709822933, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6517857142857143, 'r1_recall': 0.6033057851239669, 'r1_f1': 0.6266094420600858, 'pegasus_entailment': 0.6921478522199322, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43137254901960786, 'r1_recall': 0.6285714285714286, 'r1_f1': 0.5116279069767442, 'pegasus_entailment': 0.21758349953840175, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4605263157894737, 'r1_recall': 0.3977272727272727, 'r1_f1': 0.4268292682926829, 'pegasus_entailment': 0.33316514268517494, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.40404040404040403, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.46783625730994155, 'pegasus_entailment': 0.02211554371751845, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7375, 'r1_recall': 0.35119047619047616, 'r1_f1': 0.47580645161290325, 'pegasus_entailment': 0.7061285972595215, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5425531914893617, 'r1_recall': 0.5257731958762887, 'r1_f1': 0.5340314136125655, 'pegasus_entailment': 0.3889732248305033, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2601626016260163, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.37426900584795325, 'pegasus_entailment': 0.2971218394523021, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.6456692913385826, 'r1_f1': 0.6559999999999999, 'pegasus_entailment': 0.8228334337472916, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.559322033898305, 'r1_recall': 0.3113207547169811, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.45876808173488826, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 18}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.375, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.35532980039715767, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.5344129554655871, 'pegasus_entailment': 0.19349438982317224, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6046511627906976, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.553191489361702, 'pegasus_entailment': 0.27025873967795633, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5298507462686567, 'r1_recall': 0.42771084337349397, 'r1_f1': 0.47333333333333333, 'pegasus_entailment': 0.6133209695108235, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43478260869565216, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.5, 'pegasus_entailment': 0.6521885395050049, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4146341463414634, 'r1_recall': 0.5151515151515151, 'r1_f1': 0.4594594594594595, 'pegasus_entailment': 0.4804653407384952, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8189655172413793, 'r1_recall': 0.5, 'r1_f1': 0.6209150326797385, 'pegasus_entailment': 0.766584038734436, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32954545454545453, 'r1_recall': 0.4027777777777778, 'r1_f1': 0.36250000000000004, 'pegasus_entailment': 0.39548415690660477, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.575, 'r1_recall': 0.5411764705882353, 'r1_f1': 0.5575757575757575, 'pegasus_entailment': 0.577065709233284, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.475, 'r1_recall': 0.59375, 'r1_f1': 0.5277777777777778, 'pegasus_entailment': 0.476458779850509, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32926829268292684, 'r1_recall': 0.5192307692307693, 'r1_f1': 0.4029850746268657, 'pegasus_entailment': 0.5386059939861297, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5494505494505495, 'r1_recall': 0.5813953488372093, 'r1_f1': 0.5649717514124295, 'pegasus_entailment': 0.6016268385574222, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.575, 'r1_recall': 0.6865671641791045, 'r1_f1': 0.6258503401360543, 'pegasus_entailment': 0.32271190942265093, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4260869565217391, 'r1_recall': 0.6282051282051282, 'r1_f1': 0.5077720207253885, 'pegasus_entailment': 0.4923415002413094, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8518518518518519, 'r1_recall': 0.44660194174757284, 'r1_f1': 0.5859872611464969, 'pegasus_entailment': 0.9749370217323303, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3548387096774194, 'r1_recall': 0.676923076923077, 'r1_f1': 0.4656084656084657, 'pegasus_entailment': 0.9795190890630087, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6515151515151515, 'r1_recall': 0.4942528735632184, 'r1_f1': 0.5620915032679737, 'pegasus_entailment': 0.45281492348294705, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6310679611650486, 'r1_recall': 0.7065217391304348, 'r1_f1': 0.6666666666666667, 'pegasus_entailment': 0.6800751984119415, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.422680412371134, 'r1_recall': 0.47126436781609193, 'r1_f1': 0.44565217391304346, 'pegasus_entailment': 0.1975090615451336, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30666666666666664, 'r1_recall': 0.2948717948717949, 'r1_f1': 0.3006535947712418, 'pegasus_entailment': 0.4619447461639841, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.26785714285714285, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.38216560509554137, 'pegasus_entailment': 0.6199810199439526, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7151898734177216, 'r1_recall': 0.5432692307692307, 'r1_f1': 0.6174863387978142, 'pegasus_entailment': 0.443035173540314, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32978723404255317, 'r1_recall': 0.44285714285714284, 'r1_f1': 0.3780487804878049, 'pegasus_entailment': 0.6057835717995962, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6438356164383562, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.5562130177514792, 'pegasus_entailment': 0.4045475119103988, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49038461538461536, 'r1_recall': 0.3805970149253731, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.4286592299118638, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4807692307692308, 'r1_recall': 0.684931506849315, 'r1_f1': 0.5649717514124294, 'pegasus_entailment': 0.44445357006043196, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.611764705882353, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.5148514851485149, 'pegasus_entailment': 0.43021868099458516, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.40816326530612246, 'r1_recall': 0.20618556701030927, 'r1_f1': 0.273972602739726, 'pegasus_entailment': 0.004111862857826054, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6730769230769231, 'r1_recall': 0.3954802259887006, 'r1_f1': 0.4982206405693951, 'pegasus_entailment': 0.4838306292891502, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4842105263157895, 'r1_recall': 0.4742268041237113, 'r1_f1': 0.47916666666666663, 'pegasus_entailment': 0.19605597341433167, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5403225806451613, 'r1_recall': 0.5317460317460317, 'r1_f1': 0.5359999999999999, 'pegasus_entailment': 0.9257842501004537, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3023255813953488, 'r1_recall': 0.6, 'r1_f1': 0.40206185567010305, 'pegasus_entailment': 0.6147606326267123, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49514563106796117, 'r1_recall': 0.45535714285714285, 'r1_f1': 0.47441860465116287, 'pegasus_entailment': 0.2744912341237068, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.45901639344262296, 'r1_f1': 0.4516129032258064, 'pegasus_entailment': 0.44930511247366667, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.5957446808510638, 'r1_f1': 0.5833333333333334, 'pegasus_entailment': 0.19489420702060065, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5488721804511278, 'r1_recall': 0.6347826086956522, 'r1_f1': 0.5887096774193548, 'pegasus_entailment': 0.5684690728783608, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4714285714285714, 'r1_recall': 0.5892857142857143, 'r1_f1': 0.5238095238095238, 'pegasus_entailment': 0.6970765665173531, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5779816513761468, 'r1_recall': 0.7875, 'r1_f1': 0.6666666666666666, 'pegasus_entailment': 0.8547473400831223, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7076923076923077, 'r1_recall': 0.35658914728682173, 'r1_f1': 0.4742268041237113, 'pegasus_entailment': 0.8825129717588425, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6, 'r1_recall': 0.6116504854368932, 'r1_f1': 0.6057692307692308, 'pegasus_entailment': 0.6255697443460425, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5321637426900585, 'r1_recall': 0.56875, 'r1_f1': 0.5498489425981873, 'pegasus_entailment': 0.8646834095319113, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4329896907216495, 'r1_recall': 0.56, 'r1_f1': 0.48837209302325585, 'pegasus_entailment': 0.26207928979420103, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 15, 'pegasus_ari': 12, 'pegasus_smog': 15}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3548387096774194, 'r1_recall': 0.55, 'r1_f1': 0.43137254901960786, 'pegasus_entailment': 0.5676052389899269, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5151515151515151, 'r1_recall': 0.7391304347826086, 'r1_f1': 0.6071428571428571, 'pegasus_entailment': 0.3418939361072262, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5932203389830508, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5577689243027888, 'pegasus_entailment': 0.4832079929765314, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4943820224719101, 'r1_recall': 0.5569620253164557, 'r1_f1': 0.5238095238095238, 'pegasus_entailment': 0.3879296483588405, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4523809523809524, 'r1_recall': 0.6404494382022472, 'r1_f1': 0.530232558139535, 'pegasus_entailment': 0.9242216149965922, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5483870967741935, 'r1_recall': 0.3923076923076923, 'r1_f1': 0.45739910313901344, 'pegasus_entailment': 0.5468306317925453, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.711864406779661, 'r1_recall': 0.47191011235955055, 'r1_f1': 0.5675675675675675, 'pegasus_entailment': 0.28122262075921756, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8269230769230769, 'r1_recall': 0.48863636363636365, 'r1_f1': 0.6142857142857143, 'pegasus_entailment': 0.559128218020002, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4308510638297872, 'r1_recall': 0.6044776119402985, 'r1_f1': 0.5031055900621118, 'pegasus_entailment': 0.4712789462237197, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49, 'r1_recall': 0.5212765957446809, 'r1_f1': 0.5051546391752578, 'pegasus_entailment': 0.35631937843572814, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6226415094339622, 'r1_recall': 0.5196850393700787, 'r1_f1': 0.5665236051502145, 'pegasus_entailment': 0.7125053922645748, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.504424778761062, 'r1_recall': 0.6477272727272727, 'r1_f1': 0.5671641791044776, 'pegasus_entailment': 0.6349826342891902, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49242424242424243, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.8419744670391083, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4392523364485981, 'r1_recall': 0.618421052631579, 'r1_f1': 0.5136612021857924, 'pegasus_entailment': 0.0011409258974405627, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2345679012345679, 'r1_recall': 0.4418604651162791, 'r1_f1': 0.30645161290322576, 'pegasus_entailment': 0.748577605932951, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5294117647058824, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.5806451612903226, 'pegasus_entailment': 0.4110640204356362, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.635036496350365, 'r1_recall': 0.6641221374045801, 'r1_f1': 0.6492537313432836, 'pegasus_entailment': 0.841702863574028, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45454545454545453, 'r1_recall': 0.5625, 'r1_f1': 0.5027932960893855, 'pegasus_entailment': 0.06291316201289494, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.59375, 'r1_recall': 0.6495726495726496, 'r1_f1': 0.6204081632653062, 'pegasus_entailment': 0.596148622687906, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5535714285714286, 'r1_recall': 0.5344827586206896, 'r1_f1': 0.5438596491228069, 'pegasus_entailment': 0.5899448469281197, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43157894736842106, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.5324675324675325, 'pegasus_entailment': 0.4678065405227244, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6808510638297872, 'r1_recall': 0.3386243386243386, 'r1_f1': 0.4522968197879858, 'pegasus_entailment': 0.3986293874680996, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7411764705882353, 'r1_recall': 0.5206611570247934, 'r1_f1': 0.6116504854368933, 'pegasus_entailment': 0.5998997446149588, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7096774193548387, 'r1_recall': 0.2838709677419355, 'r1_f1': 0.40552995391705066, 'pegasus_entailment': 0.12083935341797769, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5828220858895705, 'r1_recall': 0.5828220858895705, 'r1_f1': 0.5828220858895705, 'pegasus_entailment': 0.6390466990415007, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.62, 'r1_recall': 0.3069306930693069, 'r1_f1': 0.41059602649006627, 'pegasus_entailment': 0.665187656879425, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6052631578947368, 'r1_recall': 0.38016528925619836, 'r1_f1': 0.46700507614213205, 'pegasus_entailment': 0.5739999214808146, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5309734513274337, 'r1_recall': 0.6451612903225806, 'r1_f1': 0.5825242718446603, 'pegasus_entailment': 0.22030727243400178, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6190476190476191, 'r1_recall': 0.5864661654135338, 'r1_f1': 0.6023166023166024, 'pegasus_entailment': 0.7234416287392378, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.608, 'r1_recall': 0.41081081081081083, 'r1_f1': 0.4903225806451614, 'pegasus_entailment': 0.357766469674451, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2980769230769231, 'r1_recall': 0.5344827586206896, 'r1_f1': 0.38271604938271603, 'pegasus_entailment': 0.26610930760701496, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5106382978723404, 'pegasus_entailment': 0.17723499925341457, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4878048780487805, 'r1_recall': 0.43010752688172044, 'r1_f1': 0.45714285714285713, 'pegasus_entailment': 0.06271394404272239, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49074074074074076, 'r1_recall': 0.4690265486725664, 'r1_f1': 0.4796380090497738, 'pegasus_entailment': 0.20085427798330785, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6049382716049383, 'r1_recall': 0.6125, 'r1_f1': 0.6086956521739131, 'pegasus_entailment': 0.49882117472589016, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4807692307692308, 'r1_recall': 0.49504950495049505, 'r1_f1': 0.4878048780487805, 'pegasus_entailment': 0.1348678264184855, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7524752475247525, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.4903225806451614, 'pegasus_entailment': 0.9474332928657532, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6791044776119403, 'r1_recall': 0.5027624309392266, 'r1_f1': 0.5777777777777777, 'pegasus_entailment': 0.8251610497633616, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36507936507936506, 'r1_recall': 0.3898305084745763, 'r1_f1': 0.3770491803278688, 'pegasus_entailment': 0.9485523998737335, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8648648648648649, 'r1_recall': 0.3950617283950617, 'r1_f1': 0.5423728813559322, 'pegasus_entailment': 0.7021280825138092, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.39285714285714285, 'r1_recall': 0.6707317073170732, 'r1_f1': 0.4954954954954955, 'pegasus_entailment': 0.6584364734590054, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5294117647058824, 'r1_recall': 0.375, 'r1_f1': 0.4390243902439025, 'pegasus_entailment': 0.47663890360854566, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6351351351351351, 'r1_recall': 0.5108695652173914, 'r1_f1': 0.5662650602409639, 'pegasus_entailment': 0.49426236127813655, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.75, 'r1_recall': 0.3711340206185567, 'r1_f1': 0.496551724137931, 'pegasus_entailment': 0.5806096270680428, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6064516129032258, 'r1_recall': 0.5662650602409639, 'r1_f1': 0.5856697819314642, 'pegasus_entailment': 0.45859258497754735, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27, 'r1_recall': 0.4576271186440678, 'r1_f1': 0.339622641509434, 'pegasus_entailment': 0.035832382360240445, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6198347107438017, 'r1_recall': 0.43352601156069365, 'r1_f1': 0.5102040816326531, 'pegasus_entailment': 0.7119067509969076, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.43209876543209874, 'r1_f1': 0.47945205479452047, 'pegasus_entailment': 0.36304479589064914, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.62, 'r1_recall': 0.4161073825503356, 'r1_f1': 0.497991967871486, 'pegasus_entailment': 0.5002250652760267, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6091954022988506, 'r1_recall': 0.5698924731182796, 'r1_f1': 0.5888888888888889, 'pegasus_entailment': 0.18951129913330078, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6739130434782609, 'r1_recall': 0.38509316770186336, 'r1_f1': 0.4901185770750988, 'pegasus_entailment': 0.21629436562458673, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2835820895522388, 'r1_recall': 0.5, 'r1_f1': 0.3619047619047619, 'pegasus_entailment': 0.9100295603275299, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6601941747572816, 'r1_recall': 0.6296296296296297, 'r1_f1': 0.6445497630331755, 'pegasus_entailment': 0.40277292020618916, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5263157894736842, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.5529953917050691, 'pegasus_entailment': 0.7129992935922929, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5116279069767442, 'r1_recall': 0.4049079754601227, 'r1_f1': 0.4520547945205479, 'pegasus_entailment': 0.3922724693082273, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5698924731182796, 'r1_recall': 0.48623853211009177, 'r1_f1': 0.5247524752475248, 'pegasus_entailment': 0.3236485600937158, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6081081081081081, 'r1_recall': 0.5113636363636364, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.7037510275840759, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 13, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.525, 'r1_recall': 0.42, 'r1_f1': 0.4666666666666666, 'pegasus_entailment': 0.46294979963983807, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5833333333333334, 'r1_recall': 0.4, 'r1_f1': 0.4745762711864407, 'pegasus_entailment': 0.6697496175765991, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6559139784946236, 'r1_recall': 0.40939597315436244, 'r1_f1': 0.5041322314049587, 'pegasus_entailment': 0.5982153536751866, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5443037974683544, 'r1_recall': 0.4725274725274725, 'r1_f1': 0.5058823529411766, 'pegasus_entailment': 0.6768862307071686, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 19}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3986013986013986, 'r1_recall': 0.7402597402597403, 'r1_f1': 0.5181818181818181, 'pegasus_entailment': 0.7066376606623331, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47191011235955055, 'r1_recall': 0.5753424657534246, 'r1_f1': 0.5185185185185185, 'pegasus_entailment': 0.0982921466541787, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8018867924528302, 'r1_recall': 0.23097826086956522, 'r1_f1': 0.35864978902953587, 'pegasus_entailment': 0.8698795199394226, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4338235294117647, 'r1_recall': 0.5363636363636364, 'r1_f1': 0.4796747967479675, 'pegasus_entailment': 0.5283188069239259, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4339622641509434, 'r1_recall': 0.5564516129032258, 'r1_f1': 0.48763250883392223, 'pegasus_entailment': 0.32779139205813407, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.559322033898305, 'r1_recall': 0.55, 'r1_f1': 0.5546218487394957, 'pegasus_entailment': 0.6729408383369446, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7371794871794872, 'r1_recall': 0.48936170212765956, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.28325343281030657, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4695121951219512, 'r1_recall': 0.506578947368421, 'r1_f1': 0.4873417721518987, 'pegasus_entailment': 0.3028441972897521, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5046728971962616, 'r1_recall': 0.627906976744186, 'r1_f1': 0.5595854922279792, 'pegasus_entailment': 0.5537518858909607, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43478260869565216, 'r1_recall': 0.4, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.2765284045599401, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47959183673469385, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.5, 'pegasus_entailment': 0.5331524014472961, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7419354838709677, 'r1_recall': 0.42073170731707316, 'r1_f1': 0.5369649805447471, 'pegasus_entailment': 0.7168566465377808, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.87, 'r1_recall': 0.30313588850174217, 'r1_f1': 0.44961240310077516, 'pegasus_entailment': 0.2946237747867902, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8266666666666667, 'r1_recall': 0.3463687150837989, 'r1_f1': 0.48818897637795283, 'pegasus_entailment': 0.6473060535887877, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7647058823529411, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.5714285714285713, 'pegasus_entailment': 0.9016415675481161, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.578125, 'r1_recall': 0.2846153846153846, 'r1_f1': 0.38144329896907214, 'pegasus_entailment': 0.24386749090626836, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5058823529411764, 'r1_recall': 0.41346153846153844, 'r1_f1': 0.455026455026455, 'pegasus_entailment': 0.7971100211143494, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4015748031496063, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.4834123222748815, 'pegasus_entailment': 0.7171830747808728, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7410714285714286, 'r1_recall': 0.5123456790123457, 'r1_f1': 0.6058394160583942, 'pegasus_entailment': 0.49450457021594046, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.675, 'r1_recall': 0.7012987012987013, 'r1_f1': 0.6878980891719745, 'pegasus_entailment': 0.33780517828805995, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6620689655172414, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6643598615916956, 'pegasus_entailment': 0.6475498674437403, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5684210526315789, 'r1_recall': 0.72, 'r1_f1': 0.6352941176470588, 'pegasus_entailment': 0.5592343928292394, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4539877300613497, 'r1_recall': 0.6115702479338843, 'r1_f1': 0.5211267605633803, 'pegasus_entailment': 0.5532936393283308, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8, 'r1_recall': 0.5765765765765766, 'r1_f1': 0.6701570680628272, 'pegasus_entailment': 0.5793205636049, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5869565217391305, 'r1_recall': 0.3312883435582822, 'r1_f1': 0.4235294117647059, 'pegasus_entailment': 0.213460274040699, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 21}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5229357798165137, 'r1_recall': 0.32386363636363635, 'r1_f1': 0.4, 'pegasus_entailment': 0.5196586704502503, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5360824742268041, 'r1_recall': 0.65, 'r1_f1': 0.5875706214689265, 'pegasus_entailment': 0.23356399961630814, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4782608695652174, 'r1_recall': 0.55, 'r1_f1': 0.5116279069767442, 'pegasus_entailment': 0.385879202435414, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2692307692307692, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.3414634146341463, 'pegasus_entailment': 0.024302729092596564, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5522388059701493, 'r1_recall': 0.37755102040816324, 'r1_f1': 0.4484848484848485, 'pegasus_entailment': 0.42422353972991306, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5625, 'r1_recall': 0.4153846153846154, 'r1_f1': 0.47787610619469023, 'pegasus_entailment': 0.2226736331358552, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2767857142857143, 'r1_recall': 0.6739130434782609, 'r1_f1': 0.3924050632911393, 'pegasus_entailment': 0.21533116246573628, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5096153846153846, 'r1_recall': 0.4649122807017544, 'r1_f1': 0.4862385321100917, 'pegasus_entailment': 0.4541822373867035, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5578947368421052, 'r1_recall': 0.4774774774774775, 'r1_f1': 0.5145631067961165, 'pegasus_entailment': 0.2709395280107856, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7480314960629921, 'r1_recall': 0.4337899543378995, 'r1_f1': 0.5491329479768786, 'pegasus_entailment': 0.6770729422569275, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5294117647058824, 'r1_recall': 0.6585365853658537, 'r1_f1': 0.5869565217391304, 'pegasus_entailment': 0.07083196880315275, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.41353383458646614, 'r1_recall': 0.625, 'r1_f1': 0.497737556561086, 'pegasus_entailment': 0.23221328123472632, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7297297297297297, 'r1_recall': 0.5346534653465347, 'r1_f1': 0.6171428571428571, 'pegasus_entailment': 0.8029910524686178, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 19}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5978260869565217, 'r1_recall': 0.5092592592592593, 'r1_f1': 0.55, 'pegasus_entailment': 0.39526257663965225, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.21428571428571427, 'r1_recall': 0.5625, 'r1_f1': 0.31034482758620685, 'pegasus_entailment': 0.39165846960774314, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7380952380952381, 'r1_recall': 0.31313131313131315, 'r1_f1': 0.4397163120567376, 'pegasus_entailment': 0.5531285628676414, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 18, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5583756345177665, 'r1_recall': 0.6962025316455697, 'r1_f1': 0.6197183098591549, 'pegasus_entailment': 0.6559483545521895, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.582089552238806, 'r1_recall': 0.4936708860759494, 'r1_f1': 0.5342465753424658, 'pegasus_entailment': 0.3595076301523174, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5590551181102362, 'r1_recall': 0.36787564766839376, 'r1_f1': 0.44375, 'pegasus_entailment': 0.5588219791650773, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5957446808510638, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5628140703517588, 'pegasus_entailment': 0.3733616390575965, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4954954954954955, 'r1_recall': 0.44, 'r1_f1': 0.4661016949152542, 'pegasus_entailment': 0.21770504784459868, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.25, 'r1_f1': 0.28571428571428575, 'pegasus_entailment': 0.8619402945041656, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4714285714285714, 'r1_recall': 0.5409836065573771, 'r1_f1': 0.5038167938931298, 'pegasus_entailment': 0.39102548733353615, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3917525773195876, 'r1_recall': 0.6129032258064516, 'r1_f1': 0.4779874213836478, 'pegasus_entailment': 0.601025757069389, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42592592592592593, 'r1_recall': 0.3898305084745763, 'r1_f1': 0.40707964601769914, 'pegasus_entailment': 0.7281122406323751, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45774647887323944, 'r1_recall': 0.5701754385964912, 'r1_f1': 0.5078125, 'pegasus_entailment': 0.6176237821578979, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4875, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.43575418994413406, 'pegasus_entailment': 0.016594387707300484, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.27710843373493976, 'r1_recall': 0.575, 'r1_f1': 0.37398373983739835, 'pegasus_entailment': 0.6519792278607687, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.704, 'r1_recall': 0.5086705202312138, 'r1_f1': 0.5906040268456375, 'pegasus_entailment': 0.6557723641395569, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6162790697674418, 'r1_recall': 0.6625, 'r1_f1': 0.6385542168674699, 'pegasus_entailment': 0.0075607405306072906, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7916666666666666, 'r1_recall': 0.3202247191011236, 'r1_f1': 0.456, 'pegasus_entailment': 0.37660567089915276, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6372549019607843, 'r1_recall': 0.40372670807453415, 'r1_f1': 0.49429657794676807, 'pegasus_entailment': 0.7364901751279831, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.616822429906542, 'r1_recall': 0.4925373134328358, 'r1_f1': 0.5477178423236515, 'pegasus_entailment': 0.36714198417030275, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7422680412371134, 'r1_recall': 0.2962962962962963, 'r1_f1': 0.4235294117647059, 'pegasus_entailment': 0.475004555284977, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43902439024390244, 'r1_recall': 0.43902439024390244, 'r1_f1': 0.43902439024390244, 'pegasus_entailment': 0.5763420343399048, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7164179104477612, 'r1_recall': 0.3157894736842105, 'r1_f1': 0.4383561643835616, 'pegasus_entailment': 0.48948652017861605, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4, 'r1_recall': 0.4722222222222222, 'r1_f1': 0.4331210191082802, 'pegasus_entailment': 0.5240987502038479, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7583333333333333, 'r1_recall': 0.4080717488789238, 'r1_f1': 0.5306122448979592, 'pegasus_entailment': 0.25785954655730164, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2833333333333333, 'r1_recall': 0.3008849557522124, 'r1_f1': 0.2918454935622318, 'pegasus_entailment': 0.2627763142809272, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.782608695652174, 'r1_f1': 0.5669291338582676, 'pegasus_entailment': 0.8294623891512553, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7280701754385965, 'r1_recall': 0.4585635359116022, 'r1_f1': 0.5627118644067797, 'pegasus_entailment': 0.29814673122018576, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6118421052631579, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.5653495440729484, 'pegasus_entailment': 0.48639863764401525, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5816326530612245, 'r1_recall': 0.59375, 'r1_f1': 0.5876288659793814, 'pegasus_entailment': 0.6284084244689438, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6511627906976745, 'r1_recall': 0.5793103448275863, 'r1_f1': 0.6131386861313869, 'pegasus_entailment': 0.4993723721127026, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1717171717171717, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.26771653543307083, 'pegasus_entailment': 0.0625382122816518, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20915032679738563, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.3033175355450237, 'pegasus_entailment': 0.5702443250588008, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5354330708661418, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5528455284552845, 'pegasus_entailment': 0.1951143310579937, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48936170212765956, 'r1_recall': 0.647887323943662, 'r1_f1': 0.5575757575757576, 'pegasus_entailment': 0.7381358542479575, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37037037037037035, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.4411764705882353, 'pegasus_entailment': 0.20936792963184417, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3490566037735849, 'r1_recall': 0.4567901234567901, 'r1_f1': 0.3957219251336898, 'pegasus_entailment': 0.333054824732244, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5428571428571428, 'r1_recall': 0.4691358024691358, 'r1_f1': 0.5033112582781456, 'pegasus_entailment': 0.0032663787327085934, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5679012345679012, 'r1_recall': 0.5542168674698795, 'r1_f1': 0.5609756097560975, 'pegasus_entailment': 0.6620810084665815, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46621621621621623, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.5328185328185329, 'pegasus_entailment': 0.4339442280761432, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7699115044247787, 'r1_recall': 0.25892857142857145, 'r1_f1': 0.38752783964365256, 'pegasus_entailment': 0.5354285597801208, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6559139784946236, 'r1_recall': 0.2747747747747748, 'r1_f1': 0.38730158730158737, 'pegasus_entailment': 0.5986442193388939, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6470588235294118, 'r1_recall': 0.4230769230769231, 'r1_f1': 0.5116279069767442, 'pegasus_entailment': 0.6887405663728714, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 11}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5775862068965517, 'r1_recall': 0.6442307692307693, 'r1_f1': 0.6090909090909091, 'pegasus_entailment': 0.40865663066506386, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23770491803278687, 'r1_recall': 0.3972602739726027, 'r1_f1': 0.29743589743589743, 'pegasus_entailment': 0.6420263281712929, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.3384615384615385, 'r1_f1': 0.33587786259541985, 'pegasus_entailment': 0.04938065969326999, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38235294117647056, 'r1_recall': 0.7222222222222222, 'r1_f1': 0.4999999999999999, 'pegasus_entailment': 0.5500594340264797, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5925925925925926, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.5925925925925926, 'pegasus_entailment': 0.3552734577291024, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5423728813559322, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.47407407407407404, 'pegasus_entailment': 0.250574616715312, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5396825396825397, 'r1_recall': 0.40476190476190477, 'r1_f1': 0.46258503401360546, 'pegasus_entailment': 0.8795398771762848, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7244897959183674, 'r1_recall': 0.45222929936305734, 'r1_f1': 0.5568627450980391, 'pegasus_entailment': 0.6104395650327206, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7217391304347827, 'r1_recall': 0.5763888888888888, 'r1_f1': 0.6409266409266409, 'pegasus_entailment': 0.43142700878282386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36666666666666664, 'r1_recall': 0.5851063829787234, 'r1_f1': 0.45081967213114754, 'pegasus_entailment': 0.4239083569962531, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6193181818181818, 'r1_recall': 0.5706806282722513, 'r1_f1': 0.5940054495912807, 'pegasus_entailment': 0.2679169778046863, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2727272727272727, 'r1_recall': 0.673469387755102, 'r1_f1': 0.38823529411764707, 'pegasus_entailment': 0.392447573132813, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4948453608247423, 'r1_recall': 0.5783132530120482, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.8402112275362015, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5274725274725275, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5680473372781065, 'pegasus_entailment': 0.24389910011086613, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 13}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5697674418604651, 'r1_recall': 0.6049382716049383, 'r1_f1': 0.5868263473053892, 'pegasus_entailment': 0.07020216435194016, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6608695652173913, 'r1_recall': 0.5547445255474452, 'r1_f1': 0.6031746031746031, 'pegasus_entailment': 0.7558043599128723, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23529411764705882, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.31007751937984496, 'pegasus_entailment': 0.29977261989067, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5277777777777778, 'r1_recall': 0.3220338983050847, 'r1_f1': 0.4, 'pegasus_entailment': 0.3734480291604996, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7222222222222222, 'r1_recall': 0.48507462686567165, 'r1_f1': 0.5803571428571428, 'pegasus_entailment': 0.7177227661013603, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4431818181818182, 'r1_recall': 0.5, 'r1_f1': 0.46987951807228917, 'pegasus_entailment': 0.40589067021695274, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.373134328358209, 'r1_recall': 0.7692307692307693, 'r1_f1': 0.5025125628140703, 'pegasus_entailment': 0.5002178270369768, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37398373983739835, 'r1_recall': 0.5227272727272727, 'r1_f1': 0.4360189573459715, 'pegasus_entailment': 0.19809399312362075, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6140350877192983, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.49645390070921985, 'pegasus_entailment': 0.10929484106600285, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4111111111111111, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.4431137724550898, 'pegasus_entailment': 0.03531395168101881, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3235294117647059, 'r1_recall': 0.55, 'r1_f1': 0.4074074074074075, 'pegasus_entailment': 0.6598337377820697, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6474358974358975, 'r1_recall': 0.6474358974358975, 'r1_f1': 0.6474358974358975, 'pegasus_entailment': 0.6346629142761231, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4157303370786517, 'r1_recall': 0.4868421052631579, 'r1_f1': 0.44848484848484854, 'pegasus_entailment': 0.24011984653770924, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43564356435643564, 'r1_recall': 0.5176470588235295, 'r1_f1': 0.47311827956989244, 'pegasus_entailment': 0.7834135442972183, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6310679611650486, 'r1_recall': 0.4961832061068702, 'r1_f1': 0.5555555555555556, 'pegasus_entailment': 0.32075001345947385, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46534653465346537, 'r1_recall': 0.44339622641509435, 'r1_f1': 0.45410628019323673, 'pegasus_entailment': 0.2880712253972888, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7391304347826086, 'r1_recall': 0.4644808743169399, 'r1_f1': 0.5704697986577182, 'pegasus_entailment': 0.48181906528770924, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45348837209302323, 'r1_recall': 0.5131578947368421, 'r1_f1': 0.48148148148148145, 'pegasus_entailment': 0.5691981371492147, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5875, 'r1_recall': 0.5108695652173914, 'r1_f1': 0.5465116279069767, 'pegasus_entailment': 0.4369298204158743, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6942148760330579, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.49851632047477745, 'pegasus_entailment': 0.5320611267040173, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4097222222222222, 'r1_recall': 0.5841584158415841, 'r1_f1': 0.48163265306122444, 'pegasus_entailment': 0.26125772200092406, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5081967213114754, 'r1_recall': 0.6326530612244898, 'r1_f1': 0.5636363636363637, 'pegasus_entailment': 0.4053996046539396, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.49333333333333335, 'r1_recall': 0.5285714285714286, 'r1_f1': 0.5103448275862069, 'pegasus_entailment': 0.40382167561134946, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6097560975609756, 'r1_recall': 0.7518796992481203, 'r1_f1': 0.6734006734006734, 'pegasus_entailment': 0.4275754204718396, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 22, 'pegasus_ari': 31, 'pegasus_smog': 25}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7066666666666667, 'r1_recall': 0.5888888888888889, 'r1_f1': 0.6424242424242425, 'pegasus_entailment': 0.40082798649867374, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 13}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6881720430107527, 'r1_recall': 0.5565217391304348, 'r1_f1': 0.6153846153846153, 'pegasus_entailment': 0.7722006241480509, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4041095890410959, 'r1_recall': 0.5315315315315315, 'r1_f1': 0.45914396887159536, 'pegasus_entailment': 0.43468702662115294, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7592592592592593, 'r1_recall': 0.5942028985507246, 'r1_f1': 0.6666666666666666, 'pegasus_entailment': 0.8035492032766343, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.25773195876288657, 'r1_recall': 0.5, 'r1_f1': 0.3401360544217687, 'pegasus_entailment': 0.19001415597449522, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.30303030303030304, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.42553191489361697, 'pegasus_entailment': 0.2135480500292033, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.14285714285714285, 'r1_recall': 0.3191489361702128, 'r1_f1': 0.19736842105263158, 'pegasus_entailment': 0.39300735054227215, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4155844155844156, 'r1_recall': 0.4507042253521127, 'r1_f1': 0.4324324324324325, 'pegasus_entailment': 0.014564724328617254, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7272727272727273, 'r1_recall': 0.39344262295081966, 'r1_f1': 0.5106382978723404, 'pegasus_entailment': 0.6057766303420067, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45098039215686275, 'r1_recall': 0.5036496350364964, 'r1_f1': 0.47586206896551725, 'pegasus_entailment': 0.512576501483896, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6236559139784946, 'r1_recall': 0.6373626373626373, 'r1_f1': 0.6304347826086957, 'pegasus_entailment': 0.4257651387597434, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5111111111111111, 'r1_recall': 0.6917293233082706, 'r1_f1': 0.5878594249201278, 'pegasus_entailment': 0.7327527129091322, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7339449541284404, 'r1_recall': 0.4878048780487805, 'r1_f1': 0.5860805860805861, 'pegasus_entailment': 0.29505858570337296, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7720588235294118, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.6231454005934718, 'pegasus_entailment': 0.502057274337858, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3870967741935484, 'r1_recall': 0.36, 'r1_f1': 0.37305699481865284, 'pegasus_entailment': 0.46509729884564877, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4268292682926829, 'r1_recall': 0.4375, 'r1_f1': 0.4320987654320988, 'pegasus_entailment': 0.3010230482323095, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.65, 'r1_recall': 0.47560975609756095, 'r1_f1': 0.5492957746478874, 'pegasus_entailment': 0.010006933473050594, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2033898305084746, 'r1_recall': 0.5, 'r1_f1': 0.2891566265060241, 'pegasus_entailment': 0.15227797999978065, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31932773109243695, 'r1_recall': 0.6031746031746031, 'r1_f1': 0.4175824175824176, 'pegasus_entailment': 0.20316458297893406, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20408163265306123, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.30303030303030304, 'pegasus_entailment': 0.6102116188655297, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4819277108433735, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5031446540880502, 'pegasus_entailment': 0.051521819084882736, 'pegasus_flesch_kincaid': 41, 'pegasus_coleman_liau': 21, 'pegasus_ari': 50, 'pegasus_smog': 30}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.71, 'r1_recall': 0.3858695652173913, 'r1_f1': 0.5, 'pegasus_entailment': 0.5363905699923635, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3595505617977528, 'r1_recall': 0.47761194029850745, 'r1_f1': 0.4102564102564102, 'pegasus_entailment': 0.328000371887659, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7272727272727273, 'r1_recall': 0.2857142857142857, 'r1_f1': 0.4102564102564102, 'pegasus_entailment': 0.7314561108748118, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6517857142857143, 'r1_recall': 0.553030303030303, 'r1_f1': 0.598360655737705, 'pegasus_entailment': 0.7460322566330433, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.535031847133758, 'r1_recall': 0.5316455696202531, 'r1_f1': 0.5333333333333332, 'pegasus_entailment': 0.40857540927827357, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7910447761194029, 'r1_recall': 0.3581081081081081, 'r1_f1': 0.49302325581395345, 'pegasus_entailment': 0.8228646069765091, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32, 'r1_recall': 0.7272727272727273, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.6220452174544334, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.603448275862069, 'r1_recall': 0.3553299492385787, 'r1_f1': 0.4472843450479233, 'pegasus_entailment': 0.530978205303351, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 23, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5952380952380952, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.4901960784313726, 'pegasus_entailment': 0.4989727586507797, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 22, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5909090909090909, 'r1_recall': 0.5284552845528455, 'r1_f1': 0.5579399141630901, 'pegasus_entailment': 0.8094228208065033, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6470588235294118, 'r1_recall': 0.5238095238095238, 'r1_f1': 0.5789473684210527, 'pegasus_entailment': 0.49772836912112933, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6590909090909091, 'r1_recall': 0.44274809160305345, 'r1_f1': 0.5296803652968037, 'pegasus_entailment': 0.8914786577224731, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41304347826086957, 'r1_recall': 0.5671641791044776, 'r1_f1': 0.47798742138364786, 'pegasus_entailment': 0.3254151791334152, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34065934065934067, 'r1_recall': 0.543859649122807, 'r1_f1': 0.41891891891891897, 'pegasus_entailment': 0.29436961313088733, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3870967741935484, 'r1_recall': 0.631578947368421, 'r1_f1': 0.48000000000000004, 'pegasus_entailment': 0.3195296215514342, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7093023255813954, 'r1_recall': 0.4765625, 'r1_f1': 0.5700934579439253, 'pegasus_entailment': 0.7092751450836658, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7063492063492064, 'r1_recall': 0.5, 'r1_f1': 0.5855263157894737, 'pegasus_entailment': 0.4261347505574425, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6692913385826772, 'r1_recall': 0.5214723926380368, 'r1_f1': 0.5862068965517242, 'pegasus_entailment': 0.49549029879271983, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6379310344827587, 'r1_recall': 0.38341968911917096, 'r1_f1': 0.47896440129449835, 'pegasus_entailment': 0.6325454991019797, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.569620253164557, 'r1_recall': 0.44554455445544555, 'r1_f1': 0.5, 'pegasus_entailment': 0.48367298347875476, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5257731958762887, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.56353591160221, 'pegasus_entailment': 0.585495688021183, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6857142857142857, 'r1_recall': 0.26666666666666666, 'r1_f1': 0.384, 'pegasus_entailment': 0.9530735909938812, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 26, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4117647058823529, 'r1_recall': 0.4117647058823529, 'r1_f1': 0.4117647058823529, 'pegasus_entailment': 0.8123230040073395, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6339285714285714, 'r1_recall': 0.4797297297297297, 'r1_f1': 0.5461538461538461, 'pegasus_entailment': 0.5172383611400923, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6379310344827587, 'r1_recall': 0.5648854961832062, 'r1_f1': 0.5991902834008098, 'pegasus_entailment': 0.20675576331892184, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6212121212121212, 'r1_recall': 0.3474576271186441, 'r1_f1': 0.44565217391304346, 'pegasus_entailment': 0.32666817400604486, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7325581395348837, 'r1_recall': 0.4846153846153846, 'r1_f1': 0.5833333333333333, 'pegasus_entailment': 0.676494716356198, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45081967213114754, 'r1_recall': 0.46218487394957986, 'r1_f1': 0.45643153526970953, 'pegasus_entailment': 0.3384932402521372, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.625, 'r1_recall': 0.3472222222222222, 'r1_f1': 0.44642857142857145, 'pegasus_entailment': 0.6317010534306368, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.5828571428571429, 'pegasus_entailment': 0.5879462584853172, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5280898876404494, 'r1_recall': 0.3533834586466165, 'r1_f1': 0.42342342342342343, 'pegasus_entailment': 0.0025774883882453046, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.635593220338983, 'r1_recall': 0.35377358490566035, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.41566953547298907, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38461538461538464, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.646497929096222, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6354166666666666, 'r1_recall': 0.4765625, 'r1_f1': 0.5446428571428572, 'pegasus_entailment': 0.5680866488837637, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.33070866141732286, 'pegasus_entailment': 0.2500395694223698, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6956521739130435, 'r1_recall': 0.5026178010471204, 'r1_f1': 0.5835866261398175, 'pegasus_entailment': 0.3321160776540637, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6857142857142857, 'r1_recall': 0.32653061224489793, 'r1_f1': 0.4423963133640553, 'pegasus_entailment': 0.7420151631037394, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5285714285714286, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.5034013605442177, 'pegasus_entailment': 0.7522405862808228, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5333333333333333, 'r1_recall': 0.64, 'r1_f1': 0.5818181818181818, 'pegasus_entailment': 0.45801215960333747, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.584, 'r1_recall': 0.6347826086956522, 'r1_f1': 0.6083333333333333, 'pegasus_entailment': 0.692538358271122, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.72, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.6474820143884893, 'pegasus_entailment': 0.1940935842692852, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4782608695652174, 'r1_recall': 0.43137254901960786, 'r1_f1': 0.4536082474226804, 'pegasus_entailment': 0.09190720992046408, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5357142857142857, 'r1_recall': 0.2631578947368421, 'r1_f1': 0.35294117647058815, 'pegasus_entailment': 0.7075561881065369, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.34375, 'r1_f1': 0.45360824742268047, 'pegasus_entailment': 0.4197937324643135, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5616438356164384, 'r1_recall': 0.5466666666666666, 'r1_f1': 0.5540540540540541, 'pegasus_entailment': 0.7639863888422648, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4883720930232558, 'r1_recall': 0.7924528301886793, 'r1_f1': 0.60431654676259, 'pegasus_entailment': 0.7491995791594187, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6282051282051282, 'r1_recall': 0.5268817204301075, 'r1_f1': 0.5730994152046783, 'pegasus_entailment': 0.5221591149456799, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5205479452054794, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.580152671755725, 'pegasus_entailment': 0.7422394752502441, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.717391304347826, 'r1_recall': 0.6470588235294118, 'r1_f1': 0.6804123711340206, 'pegasus_entailment': 0.9412103742361069, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5362318840579711, 'r1_recall': 0.46835443037974683, 'r1_f1': 0.5, 'pegasus_entailment': 0.5808589312558373, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2807017543859649, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.3742690058479532, 'pegasus_entailment': 0.2900243643671274, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6216216216216216, 'r1_recall': 0.46308724832214765, 'r1_f1': 0.5307692307692308, 'pegasus_entailment': 0.446823600679636, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7439024390243902, 'r1_recall': 0.44525547445255476, 'r1_f1': 0.5570776255707762, 'pegasus_entailment': 0.6443813413381576, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.639344262295082, 'r1_recall': 0.5909090909090909, 'r1_f1': 0.6141732283464568, 'pegasus_entailment': 0.643150786558787, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6132075471698113, 'r1_recall': 0.5855855855855856, 'r1_f1': 0.5990783410138248, 'pegasus_entailment': 0.27598599053453654, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.40425531914893614, 'r1_recall': 0.475, 'r1_f1': 0.4367816091954023, 'pegasus_entailment': 0.8263799945513407, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6533333333333333, 'r1_recall': 0.3858267716535433, 'r1_f1': 0.48514851485148514, 'pegasus_entailment': 0.38170908734900877, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6956521739130435, 'r1_recall': 0.3248730964467005, 'r1_f1': 0.4429065743944636, 'pegasus_entailment': 0.4012066231475079, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6545454545454545, 'r1_recall': 0.2962962962962963, 'r1_f1': 0.40793201133144474, 'pegasus_entailment': 0.21232818253338337, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6372549019607843, 'r1_recall': 0.4676258992805755, 'r1_f1': 0.5394190871369294, 'pegasus_entailment': 0.16793697368120775, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.21153846153846154, 'r1_recall': 0.3013698630136986, 'r1_f1': 0.2485875706214689, 'pegasus_entailment': 0.0010812453911057673, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.24, 'r1_recall': 0.4918032786885246, 'r1_f1': 0.3225806451612903, 'pegasus_entailment': 0.0768964735713477, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5567010309278351, 'r1_recall': 0.627906976744186, 'r1_f1': 0.5901639344262295, 'pegasus_entailment': 0.3833241023676237, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38461538461538464, 'r1_recall': 0.6081081081081081, 'r1_f1': 0.47120418848167545, 'pegasus_entailment': 0.10878023706027307, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7241379310344828, 'r1_recall': 0.3620689655172414, 'r1_f1': 0.4827586206896552, 'pegasus_entailment': 0.7471591681241989, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5816326530612245, 'r1_recall': 0.3958333333333333, 'r1_f1': 0.4710743801652892, 'pegasus_entailment': 0.36977174784988165, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.4, 'r1_f1': 0.5, 'pegasus_entailment': 0.7142753899097443, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6164383561643836, 'r1_recall': 0.6164383561643836, 'r1_f1': 0.6164383561643836, 'pegasus_entailment': 0.4211526648141444, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4854368932038835, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5617977528089887, 'pegasus_entailment': 0.6441357457078993, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.453781512605042, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.463519313304721, 'pegasus_entailment': 0.09111783874686807, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7446808510638298, 'r1_recall': 0.4654255319148936, 'r1_f1': 0.5728314238952538, 'pegasus_entailment': 0.4984442684799433, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45454545454545453, 'r1_recall': 0.3389830508474576, 'r1_f1': 0.38834951456310673, 'pegasus_entailment': 0.3689693436026573, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 19}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6857142857142857, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.5274725274725274, 'pegasus_entailment': 0.6184069955100616, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.627906976744186, 'r1_recall': 0.4186046511627907, 'r1_f1': 0.5023255813953488, 'pegasus_entailment': 0.7623661607503891, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 21}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6090909090909091, 'r1_recall': 0.44966442953020136, 'r1_f1': 0.5173745173745175, 'pegasus_entailment': 0.5839814320206642, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5325443786982249, 'r1_f1': 0.515759312320917, 'pegasus_entailment': 0.2459812385754453, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6140350877192983, 'r1_recall': 0.5343511450381679, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.15597456988568106, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5444444444444444, 'r1_recall': 0.3951612903225806, 'r1_f1': 0.4579439252336448, 'pegasus_entailment': 0.4735266998759471, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42276422764227645, 'r1_recall': 0.6265060240963856, 'r1_f1': 0.5048543689320388, 'pegasus_entailment': 0.3824509486556053, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.33093525179856115, 'pegasus_entailment': 0.46548168594017625, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.686046511627907, 'r1_recall': 0.5086206896551724, 'r1_f1': 0.584158415841584, 'pegasus_entailment': 0.31061054550809786, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8152173913043478, 'r1_recall': 0.40540540540540543, 'r1_f1': 0.5415162454873647, 'pegasus_entailment': 0.2800406254827976, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7142857142857143, 'r1_recall': 0.3645833333333333, 'r1_f1': 0.4827586206896552, 'pegasus_entailment': 0.9955117106437683, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 23, 'pegasus_ari': 35, 'pegasus_smog': 27}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.694300518134715, 'r1_recall': 0.34805194805194806, 'r1_f1': 0.46366782006920415, 'pegasus_entailment': 0.49682725753102985, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6585365853658537, 'r1_recall': 0.375, 'r1_f1': 0.4778761061946902, 'pegasus_entailment': 0.8411269982655843, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3592233009708738, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.44047619047619047, 'pegasus_entailment': 0.47667217378815013, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3211009174311927, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4142011834319527, 'pegasus_entailment': 0.007169990474358201, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5135135135135135, 'r1_recall': 0.2345679012345679, 'r1_f1': 0.3220338983050847, 'pegasus_entailment': 0.0038369831163436174, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6521739130434783, 'r1_recall': 0.4326923076923077, 'r1_f1': 0.5202312138728323, 'pegasus_entailment': 0.3828133942248921, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.39603960396039606, 'r1_recall': 0.46511627906976744, 'r1_f1': 0.427807486631016, 'pegasus_entailment': 0.37635400231617194, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5819672131147541, 'r1_recall': 0.4551282051282051, 'r1_f1': 0.5107913669064748, 'pegasus_entailment': 0.6623215675354004, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.648854961832061, 'r1_recall': 0.5151515151515151, 'r1_f1': 0.5743243243243242, 'pegasus_entailment': 0.5912671387195587, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5161290322580645, 'r1_recall': 0.5245901639344263, 'r1_f1': 0.5203252032520325, 'pegasus_entailment': 0.494627823587507, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5934959349593496, 'r1_recall': 0.4866666666666667, 'r1_f1': 0.5347985347985349, 'pegasus_entailment': 0.6285577151924372, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.52, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5445026178010471, 'pegasus_entailment': 0.40332768205553293, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6785714285714286, 'r1_recall': 0.4351145038167939, 'r1_f1': 0.530232558139535, 'pegasus_entailment': 0.8561534682909647, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.40559440559440557, 'r1_recall': 0.6373626373626373, 'r1_f1': 0.4957264957264957, 'pegasus_entailment': 0.5173082828521729, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6625, 'r1_recall': 0.5047619047619047, 'r1_f1': 0.5729729729729729, 'pegasus_entailment': 0.8532549887895584, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.8082191780821918, 'r1_f1': 0.472, 'pegasus_entailment': 0.37287464216351507, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.368, 'r1_f1': 0.423963133640553, 'pegasus_entailment': 0.21661549573764205, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 13}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6404494382022472, 'r1_recall': 0.5, 'r1_f1': 0.5615763546798029, 'pegasus_entailment': 0.7149555059149861, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47413793103448276, 'r1_recall': 0.6179775280898876, 'r1_f1': 0.5365853658536586, 'pegasus_entailment': 0.323000104771927, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3902439024390244, 'r1_recall': 0.7441860465116279, 'r1_f1': 0.5120000000000001, 'pegasus_entailment': 0.20059307431802154, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 21}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7247706422018348, 'r1_recall': 0.3574660633484163, 'r1_f1': 0.4787878787878789, 'pegasus_entailment': 0.38857753823200863, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6571428571428571, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6330275229357798, 'pegasus_entailment': 0.4087427332997322, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 22}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26136363636363635, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.368, 'pegasus_entailment': 0.24770333024207503, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5942028985507246, 'r1_recall': 0.5, 'r1_f1': 0.543046357615894, 'pegasus_entailment': 0.7662728205323219, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6739130434782609, 'r1_recall': 0.2897196261682243, 'r1_f1': 0.4052287581699346, 'pegasus_entailment': 0.6367264650762081, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4, 'r1_recall': 0.7222222222222222, 'r1_f1': 0.5148514851485149, 'pegasus_entailment': 0.15060965956321784, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4380952380952381, 'r1_recall': 0.5227272727272727, 'r1_f1': 0.47668393782383417, 'pegasus_entailment': 0.5699800997972488, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6951219512195121, 'r1_recall': 0.6404494382022472, 'r1_f1': 0.6666666666666666, 'pegasus_entailment': 0.5045966774225235, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43661971830985913, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.4769230769230769, 'pegasus_entailment': 0.6409266777336597, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.620253164556962, 'r1_recall': 0.494949494949495, 'r1_f1': 0.550561797752809, 'pegasus_entailment': 0.5115587413311005, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4126984126984127, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.46846846846846846, 'pegasus_entailment': 0.5450708956341259, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6021505376344086, 'r1_recall': 0.5957446808510638, 'r1_f1': 0.5989304812834225, 'pegasus_entailment': 0.37988119339570403, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.85, 'r1_recall': 0.22796934865900384, 'r1_f1': 0.3595166163141994, 'pegasus_entailment': 0.753331184387207, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6495726495726496, 'r1_recall': 0.38, 'r1_f1': 0.4794952681388013, 'pegasus_entailment': 0.7090113580226898, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23417721518987342, 'r1_recall': 0.47435897435897434, 'r1_f1': 0.31355932203389825, 'pegasus_entailment': 0.029104504082351924, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6976744186046512, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.6282722513089005, 'pegasus_entailment': 0.6029020771384239, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6825396825396826, 'r1_recall': 0.6323529411764706, 'r1_f1': 0.6564885496183206, 'pegasus_entailment': 0.8215160965919495, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.536, 'r1_recall': 0.5929203539823009, 'r1_f1': 0.5630252100840336, 'pegasus_entailment': 0.7573079355061054, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5617977528089888, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.5747126436781609, 'pegasus_entailment': 0.4484330415725708, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45454545454545453, 'r1_recall': 0.6060606060606061, 'r1_f1': 0.5194805194805195, 'pegasus_entailment': 0.4694901518523693, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.532608695652174, 'r1_f1': 0.5798816568047338, 'pegasus_entailment': 0.2961356195931633, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44144144144144143, 'r1_recall': 0.5903614457831325, 'r1_f1': 0.5051546391752577, 'pegasus_entailment': 0.3518718353783091, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7377049180327869, 'r1_recall': 0.35714285714285715, 'r1_f1': 0.4812834224598931, 'pegasus_entailment': 0.06432850379496813, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5333333333333333, 'r1_recall': 0.6274509803921569, 'r1_f1': 0.5765765765765766, 'pegasus_entailment': 0.44998678416013715, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6972477064220184, 'r1_recall': 0.4720496894409938, 'r1_f1': 0.5629629629629629, 'pegasus_entailment': 0.6678470075130463, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.631578947368421, 'r1_f1': 0.5106382978723404, 'pegasus_entailment': 0.6267653879379699, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7333333333333333, 'r1_recall': 0.43805309734513276, 'r1_f1': 0.5484764542936288, 'pegasus_entailment': 0.3313679300248623, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.484375, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.5000000000000001, 'pegasus_entailment': 0.3186903278401587, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5047619047619047, 'r1_recall': 0.5247524752475248, 'r1_f1': 0.5145631067961165, 'pegasus_entailment': 0.4747712993994355, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35106382978723405, 'r1_recall': 0.673469387755102, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.03576089930720627, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3225806451612903, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.37037037037037035, 'pegasus_entailment': 0.006824601616244763, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.4246575342465753, 'r1_f1': 0.5188284518828452, 'pegasus_entailment': 0.6217616746822993, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6560509554140127, 'r1_recall': 0.5364583333333334, 'r1_f1': 0.5902578796561605, 'pegasus_entailment': 0.3353851778166635, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35714285714285715, 'r1_recall': 0.2702702702702703, 'r1_f1': 0.3076923076923077, 'pegasus_entailment': 0.15596746385563165, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4631578947368421, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4536082474226804, 'pegasus_entailment': 0.12766573985572904, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5888888888888889, 'r1_recall': 0.6385542168674698, 'r1_f1': 0.6127167630057803, 'pegasus_entailment': 0.8260471026102701, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4017094017094017, 'r1_recall': 0.6619718309859155, 'r1_f1': 0.5000000000000001, 'pegasus_entailment': 0.38740522786974907, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4925373134328358, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.5301204819277108, 'pegasus_entailment': 0.3728818662154178, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5939849624060151, 'r1_recall': 0.47023809523809523, 'r1_f1': 0.5249169435215947, 'pegasus_entailment': 0.7690991163253784, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.39436619718309857, 'r1_recall': 0.5283018867924528, 'r1_f1': 0.4516129032258064, 'pegasus_entailment': 0.26666153836413287, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6885245901639344, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.49704142011834324, 'pegasus_entailment': 0.4623813293874264, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5818181818181818, 'r1_recall': 0.5663716814159292, 'r1_f1': 0.5739910313901345, 'pegasus_entailment': 0.15153165840699026, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3953488372093023, 'r1_recall': 0.4788732394366197, 'r1_f1': 0.43312101910828027, 'pegasus_entailment': 0.41605374752543867, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6299212598425197, 'r1_recall': 0.365296803652968, 'r1_f1': 0.4624277456647399, 'pegasus_entailment': 0.421481857697169, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 26}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3076923076923077, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.36781609195402304, 'pegasus_entailment': 0.9543628692626953, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.8192771084337349, 'r1_f1': 0.576271186440678, 'pegasus_entailment': 0.35847569406032564, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3717948717948718, 'r1_recall': 0.5918367346938775, 'r1_f1': 0.4566929133858268, 'pegasus_entailment': 0.3485365842158596, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.84, 'r1_recall': 0.49411764705882355, 'r1_f1': 0.6222222222222222, 'pegasus_entailment': 0.6645702943205833, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6095238095238096, 'r1_recall': 0.49612403100775193, 'r1_f1': 0.547008547008547, 'pegasus_entailment': 0.5034935544943437, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4842105263157895, 'r1_recall': 0.5287356321839081, 'r1_f1': 0.5054945054945056, 'pegasus_entailment': 0.14104087558807804, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6829268292682927, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.5209302325581395, 'pegasus_entailment': 0.24779932433739305, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.44505494505494503, 'r1_recall': 0.7297297297297297, 'r1_f1': 0.552901023890785, 'pegasus_entailment': 0.1157068731651331, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5050505050505051, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.5128205128205129, 'pegasus_entailment': 0.167428829241544, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6692913385826772, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.6367041198501873, 'pegasus_entailment': 0.5899536989163607, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7901234567901234, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.5688888888888889, 'pegasus_entailment': 0.8366526663303375, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5256410256410257, 'r1_recall': 0.44565217391304346, 'r1_f1': 0.4823529411764706, 'pegasus_entailment': 0.5959897181019187, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5742574257425742, 'r1_recall': 0.5631067961165048, 'r1_f1': 0.5686274509803921, 'pegasus_entailment': 0.4635230290393035, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 24}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46835443037974683, 'r1_recall': 0.5522388059701493, 'r1_f1': 0.5068493150684932, 'pegasus_entailment': 0.2558885266383489, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5569620253164557, 'r1_recall': 0.4835164835164835, 'r1_f1': 0.5176470588235295, 'pegasus_entailment': 0.9378021558125814, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5142857142857142, 'r1_recall': 0.5034965034965035, 'r1_f1': 0.5088339222614842, 'pegasus_entailment': 0.6435557759832591, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6847826086956522, 'r1_recall': 0.5163934426229508, 'r1_f1': 0.588785046728972, 'pegasus_entailment': 0.3005060118623078, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6239316239316239, 'r1_recall': 0.4397590361445783, 'r1_f1': 0.5159010600706714, 'pegasus_entailment': 0.3114685605590542, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.6545454545454545, 'r1_f1': 0.6101694915254237, 'pegasus_entailment': 0.05285581139226755, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4411764705882353, 'r1_recall': 0.40540540540540543, 'r1_f1': 0.4225352112676056, 'pegasus_entailment': 0.7809248864650726, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6853146853146853, 'r1_recall': 0.4803921568627451, 'r1_f1': 0.5648414985590778, 'pegasus_entailment': 0.5656060576438904, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.5483765549336871, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6056338028169014, 'r1_recall': 0.35537190082644626, 'r1_f1': 0.44791666666666663, 'pegasus_entailment': 0.3496397817507386, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7108433734939759, 'r1_recall': 0.4125874125874126, 'r1_f1': 0.5221238938053098, 'pegasus_entailment': 0.2659141831099987, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.454054054054054, 'pegasus_entailment': 0.24337471481412648, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.6483516483516484, 'r1_f1': 0.5645933014354068, 'pegasus_entailment': 0.6021042016509455, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5614035087719298, 'r1_recall': 0.3137254901960784, 'r1_f1': 0.4025157232704403, 'pegasus_entailment': 0.3607928728063901, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4835164835164835, 'r1_recall': 0.38596491228070173, 'r1_f1': 0.4292682926829269, 'pegasus_entailment': 0.5447477400302887, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4076923076923077, 'r1_recall': 0.5353535353535354, 'r1_f1': 0.46288209606986896, 'pegasus_entailment': 0.396281698346138, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40594059405940597, 'r1_recall': 0.4606741573033708, 'r1_f1': 0.43157894736842106, 'pegasus_entailment': 0.15178178722271696, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8041237113402062, 'r1_recall': 0.4785276073619632, 'r1_f1': 0.6, 'pegasus_entailment': 0.3814313933253288, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.2967032967032967, 'r1_f1': 0.3970588235294118, 'pegasus_entailment': 0.8125646313031515, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6829268292682927, 'r1_recall': 0.20363636363636364, 'r1_f1': 0.3137254901960785, 'pegasus_entailment': 0.3428415581583977, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 20}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47863247863247865, 'r1_recall': 0.5137614678899083, 'r1_f1': 0.49557522123893805, 'pegasus_entailment': 0.5503402009606362, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2857142857142857, 'r1_recall': 0.3448275862068966, 'r1_f1': 0.3125, 'pegasus_entailment': 0.3705165015223126, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5882352941176471, 'r1_recall': 0.22099447513812154, 'r1_f1': 0.321285140562249, 'pegasus_entailment': 0.3338600257411599, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4342105263157895, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.43137254901960786, 'pegasus_entailment': 0.2334568911464885, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.6375, 'r1_f1': 0.6181818181818182, 'pegasus_entailment': 0.41197715525049716, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.6236559139784946, 'r1_f1': 0.6444444444444445, 'pegasus_entailment': 0.7074971627444029, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6417910447761194, 'r1_recall': 0.5308641975308642, 'r1_f1': 0.5810810810810811, 'pegasus_entailment': 0.5364517221460119, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5348837209302325, 'r1_recall': 0.5111111111111111, 'r1_f1': 0.5227272727272726, 'pegasus_entailment': 0.19490767526440322, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32222222222222224, 'r1_recall': 0.42028985507246375, 'r1_f1': 0.36477987421383645, 'pegasus_entailment': 0.20765850271952027, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49122807017543857, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.4590872285189107, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.5625, 'r1_f1': 0.496551724137931, 'pegasus_entailment': 0.8407394687334696, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3937007874015748, 'r1_recall': 0.5494505494505495, 'r1_f1': 0.45871559633027525, 'pegasus_entailment': 0.48918431500593823, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5789473684210527, 'r1_recall': 0.625, 'r1_f1': 0.6010928961748634, 'pegasus_entailment': 0.7121124416589737, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4636363636363636, 'r1_recall': 0.8225806451612904, 'r1_f1': 0.5930232558139535, 'pegasus_entailment': 0.21535198837518693, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4827586206896552, 'r1_recall': 0.6542056074766355, 'r1_f1': 0.5555555555555556, 'pegasus_entailment': 0.7085834126919508, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3411764705882353, 'r1_recall': 0.4603174603174603, 'r1_f1': 0.3918918918918919, 'pegasus_entailment': 0.3563250995551546, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7530864197530864, 'r1_recall': 0.46037735849056605, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.5542622171342373, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4225352112676056, 'r1_recall': 0.46875, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.4790181467930476, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.4878048780487805, 'pegasus_entailment': 0.3057500645518303, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4740740740740741, 'r1_recall': 0.64, 'r1_f1': 0.5446808510638298, 'pegasus_entailment': 0.5302391856908798, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6475409836065574, 'r1_recall': 0.5642857142857143, 'r1_f1': 0.6030534351145037, 'pegasus_entailment': 0.672253531217575, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6341463414634146, 'r1_recall': 0.5531914893617021, 'r1_f1': 0.5909090909090909, 'pegasus_entailment': 0.23976329248398542, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5853658536585366, 'r1_recall': 0.3779527559055118, 'r1_f1': 0.4593301435406698, 'pegasus_entailment': 0.4896363732405007, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.7183098591549296, 'r1_f1': 0.45535714285714285, 'pegasus_entailment': 0.14294281539817652, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 17, 'pegasus_ari': 32, 'pegasus_smog': 23}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4496124031007752, 'r1_recall': 0.6170212765957447, 'r1_f1': 0.5201793721973094, 'pegasus_entailment': 0.3458154585212469, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4935064935064935, 'r1_recall': 0.4523809523809524, 'r1_f1': 0.4720496894409938, 'pegasus_entailment': 0.3527494982117787, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4318181818181818, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.46913580246913583, 'pegasus_entailment': 0.03191599925048649, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5050505050505051, 'r1_recall': 0.746268656716418, 'r1_f1': 0.6024096385542169, 'pegasus_entailment': 0.5920894667506218, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.453125, 'r1_f1': 0.3841059602649007, 'pegasus_entailment': 0.3427408644929528, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6464646464646465, 'r1_recall': 0.3699421965317919, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.4955295454710722, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7285714285714285, 'r1_recall': 0.3090909090909091, 'r1_f1': 0.43404255319148927, 'pegasus_entailment': 0.31443946436047554, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5974025974025974, 'r1_recall': 0.46938775510204084, 'r1_f1': 0.5257142857142857, 'pegasus_entailment': 0.4689618246241783, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.42780748663101603, 'r1_f1': 0.4892966360856269, 'pegasus_entailment': 0.40829460322856903, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5737704918032787, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.4487179487179487, 'pegasus_entailment': 0.10683411321952008, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4479166666666667, 'r1_recall': 0.5972222222222222, 'r1_f1': 0.511904761904762, 'pegasus_entailment': 0.5447785817086697, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3611111111111111, 'r1_recall': 0.4727272727272727, 'r1_f1': 0.4094488188976378, 'pegasus_entailment': 0.6964867934584618, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3076923076923077, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.42105263157894735, 'pegasus_entailment': 0.38684752250555904, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4431818181818182, 'r1_recall': 0.5492957746478874, 'r1_f1': 0.490566037735849, 'pegasus_entailment': 0.7495021522045135, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.4848484848484849, 'pegasus_entailment': 0.16492857318371534, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5542168674698795, 'r1_recall': 0.39316239316239315, 'r1_f1': 0.46, 'pegasus_entailment': 0.7677229046821594, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6481481481481481, 'r1_recall': 0.5343511450381679, 'r1_f1': 0.5857740585774058, 'pegasus_entailment': 0.8285982012748718, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.44761904761904764, 'r1_recall': 0.5595238095238095, 'r1_f1': 0.49735449735449744, 'pegasus_entailment': 0.6022118553519249, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 15}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5625, 'r1_recall': 0.3, 'r1_f1': 0.3913043478260869, 'pegasus_entailment': 0.8399109443028768, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32142857142857145, 'r1_recall': 0.5934065934065934, 'r1_f1': 0.416988416988417, 'pegasus_entailment': 0.23881301722888434, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3851851851851852, 'r1_recall': 0.4727272727272727, 'r1_f1': 0.4244897959183673, 'pegasus_entailment': 0.5552951242774725, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5042016806722689, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.5687203791469194, 'pegasus_entailment': 0.4651691700331867, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7291666666666666, 'r1_recall': 0.35, 'r1_f1': 0.47297297297297297, 'pegasus_entailment': 0.8775761127471924, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36, 'r1_recall': 0.391304347826087, 'r1_f1': 0.37499999999999994, 'pegasus_entailment': 0.4555963333696127, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7023809523809523, 'r1_recall': 0.6781609195402298, 'r1_f1': 0.6900584795321637, 'pegasus_entailment': 0.40686717303469777, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5769230769230769, 'r1_recall': 0.4411764705882353, 'r1_f1': 0.5, 'pegasus_entailment': 0.9033390581607819, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5679012345679012, 'r1_recall': 0.5476190476190477, 'r1_f1': 0.5575757575757575, 'pegasus_entailment': 0.5534253617127737, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2543859649122807, 'r1_recall': 0.5576923076923077, 'r1_f1': 0.3493975903614458, 'pegasus_entailment': 0.3034357830765657, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6701030927835051, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.5416666666666666, 'pegasus_entailment': 0.39420387769738835, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48717948717948717, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.5588235294117647, 'pegasus_entailment': 0.7092081264127046, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46153846153846156, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.504201680672269, 'pegasus_entailment': 0.4417166101047769, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 18}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.47619047619047616, 'pegasus_entailment': 0.7875414043664932, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.23076923076923078, 'r1_f1': 0.3243243243243243, 'pegasus_entailment': 0.8898718059062958, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 11, 'pegasus_smog': 15}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.6, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.25740155251696706, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 14}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.44295302013422816, 'pegasus_entailment': 0.6566747037383417, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3728813559322034, 'r1_recall': 0.4943820224719101, 'r1_f1': 0.4251207729468599, 'pegasus_entailment': 0.2825247263535857, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.28169014084507044, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.3448275862068965, 'pegasus_entailment': 0.7156878461440405, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5656565656565656, 'r1_recall': 0.5436893203883495, 'r1_f1': 0.5544554455445545, 'pegasus_entailment': 0.4135845866985619, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.13636363636363635, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.20689655172413793, 'pegasus_entailment': 0.24711426698195282, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3670886075949367, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.46774193548387094, 'pegasus_entailment': 0.2497283387419884, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34615384615384615, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.34128375072032213, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6076923076923076, 'r1_recall': 0.5337837837837838, 'r1_f1': 0.5683453237410071, 'pegasus_entailment': 0.571494962487902, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5847457627118644, 'r1_recall': 0.6, 'r1_f1': 0.592274678111588, 'pegasus_entailment': 0.45352883140246075, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 17, 'pegasus_ari': 35, 'pegasus_smog': 25}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4818181818181818, 'r1_recall': 0.5520833333333334, 'r1_f1': 0.5145631067961165, 'pegasus_entailment': 0.9695355296134949, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5163934426229508, 'r1_recall': 0.5779816513761468, 'r1_f1': 0.5454545454545453, 'pegasus_entailment': 0.8330058753490448, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.625, 'r1_recall': 0.5072463768115942, 'r1_f1': 0.56, 'pegasus_entailment': 0.3674211611971259, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8439716312056738, 'r1_recall': 0.3380681818181818, 'r1_f1': 0.48275862068965514, 'pegasus_entailment': 0.5178969517350197, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.4878048780487805, 'pegasus_entailment': 0.8412090167403221, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6036036036036037, 'r1_recall': 0.44966442953020136, 'r1_f1': 0.5153846153846153, 'pegasus_entailment': 0.4264629807190171, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7840909090909091, 'r1_recall': 0.46308724832214765, 'r1_f1': 0.5822784810126582, 'pegasus_entailment': 0.4739781888201833, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2972972972972973, 'r1_recall': 0.4489795918367347, 'r1_f1': 0.35772357723577236, 'pegasus_entailment': 0.7621709009011587, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4470588235294118, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.4840764331210191, 'pegasus_entailment': 0.3687402871437371, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.37962962962962965, 'r1_recall': 0.5061728395061729, 'r1_f1': 0.4338624338624339, 'pegasus_entailment': 0.5391341038048267, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7714285714285715, 'r1_recall': 0.54, 'r1_f1': 0.6352941176470589, 'pegasus_entailment': 0.6850778169173282, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43902439024390244, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.48322147651006714, 'pegasus_entailment': 0.5058476477861404, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6540880503144654, 'r1_recall': 0.6046511627906976, 'r1_f1': 0.6283987915407854, 'pegasus_entailment': 0.7064967884798534, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42105263157894735, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.4733727810650888, 'pegasus_entailment': 0.26778208382893354, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4954128440366973, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5684210526315789, 'pegasus_entailment': 0.5329109467566013, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6190476190476191, 'r1_recall': 0.36879432624113473, 'r1_f1': 0.4622222222222222, 'pegasus_entailment': 0.09555321303196251, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.4122137404580153, 'r1_f1': 0.45188284518828453, 'pegasus_entailment': 0.20558193349279463, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.593103448275862, 'r1_recall': 0.40375586854460094, 'r1_f1': 0.4804469273743017, 'pegasus_entailment': 0.44277930663277704, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 21}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.627906976744186, 'r1_recall': 0.6, 'r1_f1': 0.6136363636363636, 'pegasus_entailment': 0.26776587155958015, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4470588235294118, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5352112676056338, 'pegasus_entailment': 0.013588044792413712, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7054794520547946, 'r1_recall': 0.544973544973545, 'r1_f1': 0.6149253731343284, 'pegasus_entailment': 0.2676427932456136, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 25}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6758241758241759, 'r1_recall': 0.40460526315789475, 'r1_f1': 0.506172839506173, 'pegasus_entailment': 0.7348699818054835, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35443037974683544, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.14917663438245654, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5268817204301075, 'r1_recall': 0.5157894736842106, 'r1_f1': 0.5212765957446808, 'pegasus_entailment': 0.4903262574443943, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.4177215189873418, 'r1_f1': 0.5136186770428016, 'pegasus_entailment': 0.6114744329825044, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.39215686274509803, 'r1_recall': 0.3448275862068966, 'r1_f1': 0.3669724770642202, 'pegasus_entailment': 0.2063844450749457, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7472527472527473, 'r1_recall': 0.3756906077348066, 'r1_f1': 0.5, 'pegasus_entailment': 0.695135059952736, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5657894736842105, 'r1_recall': 0.3028169014084507, 'r1_f1': 0.3944954128440367, 'pegasus_entailment': 0.4781536761438474, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4298245614035088, 'r1_recall': 0.5157894736842106, 'r1_f1': 0.4688995215311005, 'pegasus_entailment': 0.09278845228254795, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6705882352941176, 'r1_recall': 0.3313953488372093, 'r1_f1': 0.4435797665369649, 'pegasus_entailment': 0.5352424122393131, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4205607476635514, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.5056179775280899, 'pegasus_entailment': 0.5834330411744304, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8125, 'r1_recall': 0.3125, 'r1_f1': 0.4513888888888889, 'pegasus_entailment': 0.01103096983085076, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5072463768115942, 'r1_recall': 0.3763440860215054, 'r1_f1': 0.43209876543209874, 'pegasus_entailment': 0.9700732111930848, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3395061728395062, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.46413502109704635, 'pegasus_entailment': 0.3723879288882017, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5675675675675675, 'r1_recall': 0.5915492957746479, 'r1_f1': 0.5793103448275861, 'pegasus_entailment': 0.49653375521302223, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5825242718446602, 'r1_recall': 0.594059405940594, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.49910893791820854, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7739130434782608, 'r1_recall': 0.42995169082125606, 'r1_f1': 0.5527950310559006, 'pegasus_entailment': 0.8467006385326385, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42727272727272725, 'r1_recall': 0.46078431372549017, 'r1_f1': 0.44339622641509435, 'pegasus_entailment': 0.5505682299844921, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32323232323232326, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.4025157232704403, 'pegasus_entailment': 0.5298038050532341, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6842105263157895, 'r1_recall': 0.5842696629213483, 'r1_f1': 0.6303030303030304, 'pegasus_entailment': 0.3976615988843453, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44329896907216493, 'r1_recall': 0.589041095890411, 'r1_f1': 0.5058823529411766, 'pegasus_entailment': 0.1174050010740757, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.509090909090909, 'r1_recall': 0.7368421052631579, 'r1_f1': 0.6021505376344085, 'pegasus_entailment': 0.4070443567179609, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43410852713178294, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5090909090909091, 'pegasus_entailment': 0.18181057833135128, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7625, 'r1_recall': 0.5083333333333333, 'r1_f1': 0.61, 'pegasus_entailment': 0.3153360513970256, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8731707317073171, 'r1_recall': 0.25390070921985813, 'r1_f1': 0.3934065934065934, 'pegasus_entailment': 0.5460614093712398, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5531914893617021, 'r1_recall': 0.5492957746478874, 'r1_f1': 0.5512367491166078, 'pegasus_entailment': 0.4397847458720207, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8762886597938144, 'r1_recall': 0.4644808743169399, 'r1_f1': 0.6071428571428571, 'pegasus_entailment': 0.7260619004567465, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5308641975308642, 'r1_recall': 0.46236559139784944, 'r1_f1': 0.4942528735632184, 'pegasus_entailment': 0.689808984597524, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6346153846153846, 'r1_recall': 0.5689655172413793, 'r1_f1': 0.6, 'pegasus_entailment': 0.38395133139565585, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6133333333333333, 'r1_recall': 0.7076923076923077, 'r1_f1': 0.657142857142857, 'pegasus_entailment': 0.416796456076554, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5700934579439252, 'r1_recall': 0.3885350318471338, 'r1_f1': 0.4621212121212121, 'pegasus_entailment': 0.8344499667485555, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30612244897959184, 'r1_recall': 0.625, 'r1_f1': 0.4109589041095891, 'pegasus_entailment': 0.6895756777375937, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6166666666666667, 'r1_recall': 0.38144329896907214, 'r1_f1': 0.4713375796178344, 'pegasus_entailment': 0.894415408372879, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34146341463414637, 'r1_recall': 0.4, 'r1_f1': 0.368421052631579, 'pegasus_entailment': 0.8285192847251892, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 20}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49504950495049505, 'r1_recall': 0.5154639175257731, 'r1_f1': 0.5050505050505051, 'pegasus_entailment': 0.7718284964561463, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6538461538461539, 'r1_recall': 0.6017699115044248, 'r1_f1': 0.6267281105990784, 'pegasus_entailment': 0.613120224326849, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5725190839694656, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.5639097744360902, 'pegasus_entailment': 0.5034143881639466, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3048780487804878, 'r1_recall': 0.46296296296296297, 'r1_f1': 0.36764705882352944, 'pegasus_entailment': 0.11769566001991431, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.671875, 'r1_recall': 0.43, 'r1_f1': 0.524390243902439, 'pegasus_entailment': 0.5316696148365736, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 16}
** Analysing column: malformed_chain



malformed_chain
Length after nones removed
616
MIN
0
MEAN
0
MAX
1
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.13636363636363635
MEAN
0.5393430743885008
MAX
0.8762886597938144
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.20363636363636364
MEAN
0.5033660203091695
MAX
0.9032258064516129
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.19736842105263158
MEAN
0.49910072381965176
MAX
0.6988636363636364
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.0010812453911057673
MEAN
0.4758762207903313
MAX
0.9955117106437683
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
17
MAX
41
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
12
MEAN
17
MAX
26
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
11
MEAN
20
MAX
50
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
11
MEAN
18
MAX
30
{}
Entered file!
Imports done!
*** RUN *** 
eval_1d
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 13:54:42.538651: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 13:54:43.394736: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/1d_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.547945205479452, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.4371584699453552, 'pegasus_entailment': 0.7116689880688986, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5826086956521739, 'r1_recall': 0.3872832369942196, 'r1_f1': 0.46527777777777773, 'pegasus_entailment': 0.666071243584156, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24468085106382978, 'r1_recall': 0.39655172413793105, 'r1_f1': 0.3026315789473684, 'pegasus_entailment': 0.4764786183834076, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6428571428571429, 'r1_recall': 0.4883720930232558, 'r1_f1': 0.5550660792951543, 'pegasus_entailment': 0.51149782538414, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7555555555555555, 'r1_recall': 0.39080459770114945, 'r1_f1': 0.5151515151515151, 'pegasus_entailment': 0.7247506678104401, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.36923076923076925, 'r1_f1': 0.384, 'pegasus_entailment': 0.7439693570137024, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16279069767441862, 'r1_recall': 0.4375, 'r1_f1': 0.23728813559322032, 'pegasus_entailment': 0.571635864675045, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.12871287128712872, 'r1_recall': 0.41935483870967744, 'r1_f1': 0.196969696969697, 'pegasus_entailment': 0.8996748725573221, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.524822695035461, 'r1_recall': 0.4966442953020134, 'r1_f1': 0.5103448275862068, 'pegasus_entailment': 0.3353196941316128, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5144927536231884, 'r1_recall': 0.5144927536231884, 'r1_f1': 0.5144927536231884, 'pegasus_entailment': 0.5298699789680541, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.504424778761062, 'r1_recall': 0.38, 'r1_f1': 0.43346007604562736, 'pegasus_entailment': 0.6447652479012808, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3939393939393939, 'r1_recall': 0.5462184873949579, 'r1_f1': 0.45774647887323944, 'pegasus_entailment': 0.621767240886887, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 18, 'pegasus_ari': 35, 'pegasus_smog': 25}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.504950495049505, 'r1_recall': 0.4766355140186916, 'r1_f1': 0.4903846153846154, 'pegasus_entailment': 0.6183358356356621, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4845360824742268, 'r1_recall': 0.5340909090909091, 'r1_f1': 0.5081081081081081, 'pegasus_entailment': 0.6060794070363045, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6301369863013698, 'r1_recall': 0.23958333333333334, 'r1_f1': 0.3471698113207547, 'pegasus_entailment': 0.4267313228920102, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23333333333333334, 'r1_recall': 0.3559322033898305, 'r1_f1': 0.28187919463087246, 'pegasus_entailment': 0.5041147880256176, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39325842696629215, 'r1_recall': 0.35353535353535354, 'r1_f1': 0.3723404255319149, 'pegasus_entailment': 0.7420316338539124, 'pegasus_flesch_kincaid': 44, 'pegasus_coleman_liau': 20, 'pegasus_ari': 53, 'pegasus_smog': 31}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.648936170212766, 'r1_recall': 0.20469798657718122, 'r1_f1': 0.31122448979591844, 'pegasus_entailment': 0.5728464722633362, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.2981366459627329, 'r1_f1': 0.401673640167364, 'pegasus_entailment': 0.18747738655656576, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.582089552238806, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.5064935064935066, 'pegasus_entailment': 0.59804967045784, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 13}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6818181818181818, 'r1_recall': 0.41208791208791207, 'r1_f1': 0.5136986301369862, 'pegasus_entailment': 0.6312385499477386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6511627906976745, 'r1_recall': 0.37333333333333335, 'r1_f1': 0.4745762711864407, 'pegasus_entailment': 0.38488870300352573, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5714285714285714, 'r1_recall': 0.48148148148148145, 'r1_f1': 0.5226130653266332, 'pegasus_entailment': 0.7772088348865509, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5073529411764706, 'r1_recall': 0.5073529411764706, 'r1_f1': 0.5073529411764706, 'pegasus_entailment': 0.3849626541137695, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3, 'r1_recall': 0.54, 'r1_f1': 0.3857142857142857, 'pegasus_entailment': 0.4759623795747757, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7446808510638298, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.6363636363636364, 'pegasus_entailment': 0.8032576590776443, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5036496350364964, 'r1_f1': 0.5018181818181818, 'pegasus_entailment': 0.42681920528411865, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6258992805755396, 'r1_recall': 0.3246268656716418, 'r1_f1': 0.4275184275184275, 'pegasus_entailment': 0.4240839838981628, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49382716049382713, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5095541401273886, 'pegasus_entailment': 0.4725390076637268, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37606837606837606, 'r1_recall': 0.3893805309734513, 'r1_f1': 0.382608695652174, 'pegasus_entailment': 0.8215039968490601, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2824858757062147, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.37878787878787873, 'pegasus_entailment': 0.5716495301042285, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5470085470085471, 'r1_recall': 0.31840796019900497, 'r1_f1': 0.4025157232704403, 'pegasus_entailment': 0.2915831238031387, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3387096774193548, 'r1_recall': 0.4077669902912621, 'r1_f1': 0.3700440528634361, 'pegasus_entailment': 0.8711265126864115, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5157894736842106, 'r1_recall': 0.5051546391752577, 'r1_f1': 0.5104166666666667, 'pegasus_entailment': 0.5728132635354996, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2945205479452055, 'r1_recall': 0.5119047619047619, 'r1_f1': 0.3739130434782609, 'pegasus_entailment': 0.5717255190014839, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47, 'r1_recall': 0.4051724137931034, 'r1_f1': 0.4351851851851852, 'pegasus_entailment': 0.5426786661148071, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.408, 'r1_recall': 0.7391304347826086, 'r1_f1': 0.5257731958762887, 'pegasus_entailment': 0.7366785705089569, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2866666666666667, 'r1_recall': 0.6323529411764706, 'r1_f1': 0.3944954128440367, 'pegasus_entailment': 0.5626005977392197, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2222222222222222, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.3137254901960784, 'pegasus_entailment': 0.3798774816095829, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5246913580246914, 'r1_recall': 0.5120481927710844, 'r1_f1': 0.5182926829268293, 'pegasus_entailment': 0.5699965804815292, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7375, 'r1_recall': 0.36875, 'r1_f1': 0.49166666666666664, 'pegasus_entailment': 0.4684705436229706, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.5384615384615385, 'pegasus_entailment': 0.25387746962951496, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3793103448275862, 'r1_recall': 0.4520547945205479, 'r1_f1': 0.4125, 'pegasus_entailment': 0.3860382284813871, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.5121951219512195, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.39695369228720667, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26153846153846155, 'r1_recall': 0.6538461538461539, 'r1_f1': 0.37362637362637363, 'pegasus_entailment': 0.7383989521435329, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5540540540540541, 'r1_recall': 0.2733333333333333, 'r1_f1': 0.36607142857142855, 'pegasus_entailment': 0.6690704226493835, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6530612244897959, 'r1_recall': 0.5423728813559322, 'r1_f1': 0.5925925925925926, 'pegasus_entailment': 0.6957162618637085, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.512396694214876, 'r1_recall': 0.5585585585585585, 'r1_f1': 0.5344827586206896, 'pegasus_entailment': 0.7408182203769684, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4857142857142857, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.5396825396825397, 'pegasus_entailment': 0.42992558777332307, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36879432624113473, 'r1_recall': 0.5, 'r1_f1': 0.42448979591836733, 'pegasus_entailment': 0.4041567100211978, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.325, 'r1_recall': 0.7027027027027027, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.5174738485366106, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24087591240875914, 'r1_recall': 0.6470588235294118, 'r1_f1': 0.35106382978723405, 'pegasus_entailment': 0.8186076964650836, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.5675675675675675, 'r1_f1': 0.42, 'pegasus_entailment': 0.7381453216075897, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 23, 'pegasus_ari': 33, 'pegasus_smog': 25}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.22598870056497175, 'r1_f1': 0.31746031746031744, 'pegasus_entailment': 0.3293006320794423, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.631578947368421, 'r1_recall': 0.47191011235955055, 'r1_f1': 0.540192926045016, 'pegasus_entailment': 0.4900782306989034, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2922077922077922, 'r1_recall': 0.625, 'r1_f1': 0.39823008849557523, 'pegasus_entailment': 0.4595879022963345, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4766355140186916, 'r1_recall': 0.20318725099601595, 'r1_f1': 0.28491620111731847, 'pegasus_entailment': 0.7187477648258209, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45121951219512196, 'r1_recall': 0.578125, 'r1_f1': 0.5068493150684932, 'pegasus_entailment': 0.4532991424202919, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5460526315789473, 'r1_recall': 0.6859504132231405, 'r1_f1': 0.608058608058608, 'pegasus_entailment': 0.7617147922515869, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5, 'pegasus_entailment': 0.7668958008289337, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 15}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.4659090909090909, 'r1_f1': 0.4823529411764706, 'pegasus_entailment': 0.7171827554702759, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34545454545454546, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.4175824175824176, 'pegasus_entailment': 0.3744451515376568, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4639175257731959, 'r1_recall': 0.26785714285714285, 'r1_f1': 0.33962264150943394, 'pegasus_entailment': 0.2699683606624603, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41836734693877553, 'r1_recall': 0.422680412371134, 'r1_f1': 0.4205128205128206, 'pegasus_entailment': 0.5383849591016769, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29245283018867924, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.4025974025974026, 'pegasus_entailment': 0.6155667205651602, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6071428571428571, 'r1_recall': 0.5354330708661418, 'r1_f1': 0.5690376569037657, 'pegasus_entailment': 0.8335050940513611, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5631067961165048, 'r1_recall': 0.5471698113207547, 'r1_f1': 0.5550239234449761, 'pegasus_entailment': 0.6384412571787834, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34615384615384615, 'r1_recall': 0.5625, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.5504471898078919, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4407894736842105, 'r1_recall': 0.5826086956521739, 'r1_f1': 0.50187265917603, 'pegasus_entailment': 0.5584174456695715, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7228915662650602, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.6486486486486487, 'pegasus_entailment': 0.5038634190956751, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6166666666666667, 'r1_recall': 0.4457831325301205, 'r1_f1': 0.5174825174825175, 'pegasus_entailment': 0.8910328596830368, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45977011494252873, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.5161290322580645, 'pegasus_entailment': 0.6448667496442795, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.5151515151515151, 'r1_f1': 0.45033112582781454, 'pegasus_entailment': 0.5673547200858593, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.515, 'r1_recall': 0.5421052631578948, 'r1_f1': 0.5282051282051282, 'pegasus_entailment': 0.6603145844170025, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21739130434782608, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.3004291845493562, 'pegasus_entailment': 0.6813492700457573, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35664335664335667, 'r1_recall': 0.6, 'r1_f1': 0.4473684210526316, 'pegasus_entailment': 0.4239334613084793, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3007518796992481, 'r1_recall': 0.625, 'r1_f1': 0.40609137055837563, 'pegasus_entailment': 0.272820907831192, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 13, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38144329896907214, 'r1_recall': 0.7115384615384616, 'r1_f1': 0.4966442953020133, 'pegasus_entailment': 0.34353720024228096, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3051948051948052, 'r1_recall': 0.5465116279069767, 'r1_f1': 0.3916666666666667, 'pegasus_entailment': 0.7291710178057352, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 25}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41379310344827586, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.4675324675324676, 'pegasus_entailment': 0.8551362603902817, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47191011235955055, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5029940119760479, 'pegasus_entailment': 0.5483718290925026, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6605504587155964, 'r1_recall': 0.6990291262135923, 'r1_f1': 0.6792452830188679, 'pegasus_entailment': 0.5104497194290161, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3111111111111111, 'r1_recall': 0.4307692307692308, 'r1_f1': 0.36129032258064514, 'pegasus_entailment': 0.7541700601577759, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3630573248407643, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.4672131147540984, 'pegasus_entailment': 0.6105150945484639, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5869565217391305, 'r1_f1': 0.54, 'pegasus_entailment': 0.5398991480469704, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25443786982248523, 'r1_recall': 0.4942528735632184, 'r1_f1': 0.3359375, 'pegasus_entailment': 0.4090337668146406, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1732283464566929, 'r1_recall': 0.28205128205128205, 'r1_f1': 0.21463414634146338, 'pegasus_entailment': 0.7124988079071045, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.256, 'r1_recall': 0.7111111111111111, 'r1_f1': 0.3764705882352941, 'pegasus_entailment': 0.7860204219818115, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5307692307692308, 'r1_recall': 0.3317307692307692, 'r1_f1': 0.40828402366863903, 'pegasus_entailment': 0.6264692395925522, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.32323232323232326, 'pegasus_entailment': 0.5654619783163071, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5975609756097561, 'r1_recall': 0.5104166666666666, 'r1_f1': 0.550561797752809, 'pegasus_entailment': 0.5928005456924439, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 26}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.514018691588785, 'r1_recall': 0.41044776119402987, 'r1_f1': 0.4564315352697096, 'pegasus_entailment': 0.51454296708107, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34782608695652173, 'r1_recall': 0.6575342465753424, 'r1_f1': 0.4549763033175355, 'pegasus_entailment': 0.5931411623954773, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5072463768115942, 'r1_recall': 0.5982905982905983, 'r1_f1': 0.5490196078431372, 'pegasus_entailment': 0.467057262857755, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3203125, 'r1_recall': 0.422680412371134, 'r1_f1': 0.3644444444444444, 'pegasus_entailment': 0.6108669877052307, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5096153846153846, 'r1_recall': 0.2994350282485876, 'r1_f1': 0.37722419928825623, 'pegasus_entailment': 0.5003048330545425, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4028776978417266, 'r1_recall': 0.5773195876288659, 'r1_f1': 0.4745762711864407, 'pegasus_entailment': 0.5175752103328705, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45925925925925926, 'r1_recall': 0.49206349206349204, 'r1_f1': 0.475095785440613, 'pegasus_entailment': 0.7741196274757385, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3025210084033613, 'r1_recall': 0.5538461538461539, 'r1_f1': 0.3913043478260869, 'pegasus_entailment': 0.6673876762390136, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47959183673469385, 'r1_recall': 0.41964285714285715, 'r1_f1': 0.4476190476190476, 'pegasus_entailment': 0.9206894189119339, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.20454545454545456, 'r1_recall': 0.4426229508196721, 'r1_f1': 0.2797927461139897, 'pegasus_entailment': 0.6652069061994552, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3879310344827586, 'r1_recall': 0.4787234042553192, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.7159821510314941, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.576271186440678, 'r1_recall': 0.591304347826087, 'r1_f1': 0.5836909871244637, 'pegasus_entailment': 0.7748668670654297, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5225225225225225, 'r1_recall': 0.5178571428571429, 'r1_f1': 0.5201793721973095, 'pegasus_entailment': 0.7319629490375519, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43243243243243246, 'r1_recall': 0.6, 'r1_f1': 0.5026178010471204, 'pegasus_entailment': 0.5530060082674026, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.6201550387596899, 'r1_f1': 0.5536332179930796, 'pegasus_entailment': 0.7374778240919113, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.296, 'r1_recall': 0.7184466019417476, 'r1_f1': 0.4192634560906516, 'pegasus_entailment': 0.6184001167615255, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5151515151515151, 'r1_recall': 0.425, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.3683085411787033, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4878048780487805, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5095541401273885, 'pegasus_entailment': 0.39486534893512726, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2956521739130435, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.38857142857142857, 'pegasus_entailment': 0.7879900097846985, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3063583815028902, 'r1_recall': 0.7681159420289855, 'r1_f1': 0.4380165289256198, 'pegasus_entailment': 0.5035060733556748, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5748031496062992, 'r1_recall': 0.5488721804511278, 'r1_f1': 0.5615384615384615, 'pegasus_entailment': 0.6030261609703302, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3445378151260504, 'r1_recall': 0.5189873417721519, 'r1_f1': 0.4141414141414141, 'pegasus_entailment': 0.7616279006004334, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5633802816901409, 'r1_recall': 0.449438202247191, 'r1_f1': 0.5000000000000001, 'pegasus_entailment': 0.3193804733455181, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45977011494252873, 'r1_recall': 0.3076923076923077, 'r1_f1': 0.3686635944700461, 'pegasus_entailment': 0.5721726516882578, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5869565217391305, 'r1_recall': 0.4550561797752809, 'r1_f1': 0.5126582278481013, 'pegasus_entailment': 0.7395468279719353, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7674418604651163, 'r1_recall': 0.375, 'r1_f1': 0.5038167938931298, 'pegasus_entailment': 0.4442046098411083, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6311475409836066, 'r1_recall': 0.5746268656716418, 'r1_f1': 0.6015625, 'pegasus_entailment': 0.6936100125312805, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5392156862745098, 'r1_recall': 0.5851063829787234, 'r1_f1': 0.5612244897959183, 'pegasus_entailment': 0.2846868534882863, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6868686868686869, 'r1_recall': 0.5354330708661418, 'r1_f1': 0.6017699115044248, 'pegasus_entailment': 0.4224584013223648, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5436893203883495, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.5863874345549738, 'pegasus_entailment': 0.6371643468737602, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5370370370370371, 'r1_recall': 0.5043478260869565, 'r1_f1': 0.5201793721973095, 'pegasus_entailment': 0.41023630897204083, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2677165354330709, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.3349753694581281, 'pegasus_entailment': 0.6029059052467346, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2054794520547945, 'r1_recall': 0.6976744186046512, 'r1_f1': 0.31746031746031744, 'pegasus_entailment': 0.64065982401371, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425531914893617, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.6639387965202331, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.576271186440678, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.5461847389558233, 'pegasus_entailment': 0.6153720915317535, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37209302325581395, 'r1_recall': 0.6, 'r1_f1': 0.45933014354066987, 'pegasus_entailment': 0.4895836357027292, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5714285714285714, 'r1_recall': 0.6495726495726496, 'r1_f1': 0.608, 'pegasus_entailment': 0.5050405144691468, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5181818181818182, 'r1_recall': 0.49137931034482757, 'r1_f1': 0.504424778761062, 'pegasus_entailment': 0.786547964811325, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2672413793103448, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.35428571428571426, 'pegasus_entailment': 0.5242541998624801, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5579710144927537, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.4709480122324159, 'pegasus_entailment': 0.7234940230846405, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44666666666666666, 'r1_recall': 0.5537190082644629, 'r1_f1': 0.49446494464944646, 'pegasus_entailment': 0.800745141506195, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6697247706422018, 'r1_recall': 0.47096774193548385, 'r1_f1': 0.553030303030303, 'pegasus_entailment': 0.8924667090177536, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4519774011299435, 'r1_recall': 0.49079754601226994, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.45416309460997584, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.373134328358209, 'r1_recall': 0.49504950495049505, 'r1_f1': 0.4255319148936171, 'pegasus_entailment': 0.7406548062960306, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4925373134328358, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5176470588235293, 'pegasus_entailment': 0.3950080027182897, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4305555555555556, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5232067510548523, 'pegasus_entailment': 0.5263183359056711, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6145833333333334, 'r1_recall': 0.44360902255639095, 'r1_f1': 0.5152838427947598, 'pegasus_entailment': 0.8071256875991821, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 23}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.34054054054054056, 'r1_f1': 0.4144736842105263, 'pegasus_entailment': 0.3922102339565754, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3625, 'r1_recall': 0.5, 'r1_f1': 0.42028985507246375, 'pegasus_entailment': 0.5195363561312357, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33884297520661155, 'r1_recall': 0.4659090909090909, 'r1_f1': 0.3923444976076555, 'pegasus_entailment': 0.5300447146097819, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 25}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.43010752688172044, 'r1_f1': 0.48484848484848486, 'pegasus_entailment': 0.6176441311836243, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4752475247524752, 'r1_recall': 0.4247787610619469, 'r1_f1': 0.4485981308411215, 'pegasus_entailment': 0.6222943812608719, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5571428571428572, 'r1_recall': 0.4875, 'r1_f1': 0.52, 'pegasus_entailment': 0.7359208265940348, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4482758620689655, 'r1_recall': 0.38613861386138615, 'r1_f1': 0.4148936170212766, 'pegasus_entailment': 0.26649039797484875, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6349206349206349, 'r1_recall': 0.3827751196172249, 'r1_f1': 0.47761194029850745, 'pegasus_entailment': 0.6817525699734688, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.3314917127071823, 'r1_f1': 0.4428044280442805, 'pegasus_entailment': 0.5896317005157471, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2727272727272727, 'r1_recall': 0.2033898305084746, 'r1_f1': 0.23300970873786409, 'pegasus_entailment': 0.812537670135498, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 23, 'pegasus_ari': 33, 'pegasus_smog': 22}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6526315789473685, 'r1_recall': 0.38271604938271603, 'r1_f1': 0.48249027237354086, 'pegasus_entailment': 0.49986863136291504, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4787234042553192, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.5113636363636364, 'pegasus_entailment': 0.32467150191466015, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36363636363636365, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.40552995391705066, 'pegasus_entailment': 0.43069726377725603, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5054945054945055, 'r1_recall': 0.5, 'r1_f1': 0.5027322404371585, 'pegasus_entailment': 0.5946051403880119, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6287878787878788, 'r1_recall': 0.42783505154639173, 'r1_f1': 0.50920245398773, 'pegasus_entailment': 0.40941788218915465, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.3313253012048193, 'r1_f1': 0.43307086614173235, 'pegasus_entailment': 0.4317089281976223, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.52, 'r1_recall': 0.6610169491525424, 'r1_f1': 0.582089552238806, 'pegasus_entailment': 0.4522808815042178, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.54, 'r1_recall': 0.4682080924855491, 'r1_f1': 0.5015479876160991, 'pegasus_entailment': 0.4464271391431491, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46987951807228917, 'r1_recall': 0.48148148148148145, 'r1_f1': 0.47560975609756095, 'pegasus_entailment': 0.42506975928942364, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5034965034965035, 'r1_recall': 0.48322147651006714, 'r1_f1': 0.49315068493150693, 'pegasus_entailment': 0.725921368598938, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5128205128205128, 'r1_recall': 0.6451612903225806, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.7128672748804092, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48695652173913045, 'r1_recall': 0.34782608695652173, 'r1_f1': 0.4057971014492754, 'pegasus_entailment': 0.6822736660639445, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.20535714285714285, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.30666666666666664, 'pegasus_entailment': 0.8111149370670319, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46601941747572817, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4549763033175355, 'pegasus_entailment': 0.7061222493648529, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46153846153846156, 'r1_recall': 0.4077669902912621, 'r1_f1': 0.4329896907216495, 'pegasus_entailment': 0.7908738702535629, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46511627906976744, 'r1_recall': 0.36809815950920244, 'r1_f1': 0.410958904109589, 'pegasus_entailment': 0.6973916962742805, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49514563106796117, 'r1_recall': 0.46788990825688076, 'r1_f1': 0.4811320754716981, 'pegasus_entailment': 0.6036132524410883, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5306122448979592, 'r1_recall': 0.4431818181818182, 'r1_f1': 0.4829721362229102, 'pegasus_entailment': 0.6931322485208511, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48514851485148514, 'r1_recall': 0.32666666666666666, 'r1_f1': 0.3904382470119522, 'pegasus_entailment': 0.503323882818222, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4818181818181818, 'r1_recall': 0.37857142857142856, 'r1_f1': 0.424, 'pegasus_entailment': 0.660187341272831, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5432098765432098, 'r1_recall': 0.2953020134228188, 'r1_f1': 0.3826086956521739, 'pegasus_entailment': 0.5758454352617264, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3027027027027027, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.4057971014492754, 'pegasus_entailment': 0.5372047856450081, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26436781609195403, 'r1_recall': 0.2987012987012987, 'r1_f1': 0.28048780487804875, 'pegasus_entailment': 0.754843125740687, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31125827814569534, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.41964285714285715, 'pegasus_entailment': 0.5616520285606384, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6774193548387096, 'r1_recall': 0.3423913043478261, 'r1_f1': 0.4548736462093863, 'pegasus_entailment': 0.6584490736325582, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45614035087719296, 'r1_recall': 0.4727272727272727, 'r1_f1': 0.46428571428571425, 'pegasus_entailment': 0.7437730828921, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2808219178082192, 'r1_recall': 0.33064516129032256, 'r1_f1': 0.30370370370370375, 'pegasus_entailment': 0.5543145500123501, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5739130434782609, 'r1_recall': 0.55, 'r1_f1': 0.5617021276595745, 'pegasus_entailment': 0.7211165428161621, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6091954022988506, 'r1_recall': 0.225531914893617, 'r1_f1': 0.32919254658385094, 'pegasus_entailment': 0.5291611790657044, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4338235294117647, 'r1_recall': 0.3881578947368421, 'r1_f1': 0.4097222222222222, 'pegasus_entailment': 0.4824587322771549, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.423728813559322, 'r1_recall': 0.5813953488372093, 'r1_f1': 0.4901960784313726, 'pegasus_entailment': 0.6929145753383636, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2830188679245283, 'r1_recall': 0.6, 'r1_f1': 0.3846153846153846, 'pegasus_entailment': 0.6125464833208493, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2971014492753623, 'r1_recall': 0.45555555555555555, 'r1_f1': 0.35964912280701755, 'pegasus_entailment': 0.4804466813802719, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6125, 'r1_recall': 0.29878048780487804, 'r1_f1': 0.4016393442622951, 'pegasus_entailment': 0.6480180323123932, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.524822695035461, 'r1_recall': 0.2578397212543554, 'r1_f1': 0.34579439252336447, 'pegasus_entailment': 0.8908912539482117, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6951219512195121, 'r1_recall': 0.31843575418994413, 'r1_f1': 0.4367816091954023, 'pegasus_entailment': 0.608722448348999, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.5470085470085471, 'pegasus_entailment': 0.6600356213748455, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5581395348837209, 'r1_recall': 0.36923076923076925, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.3789946486552556, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3422818791946309, 'r1_recall': 0.49038461538461536, 'r1_f1': 0.4031620553359684, 'pegasus_entailment': 0.6602086573839188, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3904109589041096, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.4956521739130435, 'pegasus_entailment': 0.672099158167839, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7375, 'r1_recall': 0.36419753086419754, 'r1_f1': 0.48760330578512395, 'pegasus_entailment': 0.5452903553843498, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4742268041237113, 'r1_recall': 0.5974025974025974, 'r1_f1': 0.5287356321839081, 'pegasus_entailment': 0.4157569818198681, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 21, 'pegasus_ari': 34, 'pegasus_smog': 25}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6842105263157895, 'r1_recall': 0.4513888888888889, 'r1_f1': 0.5439330543933054, 'pegasus_entailment': 0.42085585941094905, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4485981308411215, 'r1_recall': 0.64, 'r1_f1': 0.5274725274725275, 'pegasus_entailment': 0.545948455731074, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.49586776859504134, 'r1_f1': 0.5529953917050691, 'pegasus_entailment': 0.7921659052371979, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5714285714285714, 'r1_recall': 0.6126126126126126, 'r1_f1': 0.591304347826087, 'pegasus_entailment': 0.7504397034645081, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49640287769784175, 'r1_recall': 0.4233128834355828, 'r1_f1': 0.45695364238410596, 'pegasus_entailment': 0.7153758406639099, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5877192982456141, 'r1_recall': 0.3806818181818182, 'r1_f1': 0.4620689655172414, 'pegasus_entailment': 0.3903159573674202, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39344262295081966, 'r1_recall': 0.6, 'r1_f1': 0.4752475247524752, 'pegasus_entailment': 0.28559451308101413, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2698412698412698, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.3655913978494623, 'pegasus_entailment': 0.3103298656642437, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3425925925925926, 'r1_recall': 0.6166666666666667, 'r1_f1': 0.4404761904761905, 'pegasus_entailment': 0.4848189353942871, 'pegasus_flesch_kincaid': 50, 'pegasus_coleman_liau': 18, 'pegasus_ari': 61, 'pegasus_smog': 32}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4774774774774775, 'r1_recall': 0.5408163265306123, 'r1_f1': 0.5071770334928231, 'pegasus_entailment': 0.7443739771842957, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.574468085106383, 'r1_recall': 0.6230769230769231, 'r1_f1': 0.5977859778597786, 'pegasus_entailment': 0.6611455952127775, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.203125, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.2988505747126437, 'pegasus_entailment': 0.5538761019706726, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5227272727272727, 'r1_recall': 0.40350877192982454, 'r1_f1': 0.4554455445544554, 'pegasus_entailment': 0.36638781676689786, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29518072289156627, 'r1_recall': 0.44144144144144143, 'r1_f1': 0.3537906137184115, 'pegasus_entailment': 0.4632329111918807, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5982142857142857, 'r1_recall': 0.3059360730593607, 'r1_f1': 0.40483383685800606, 'pegasus_entailment': 0.2933636959642172, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4016393442622951, 'r1_recall': 0.5975609756097561, 'r1_f1': 0.4803921568627451, 'pegasus_entailment': 0.5571486130356789, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3983739837398374, 'r1_recall': 0.5568181818181818, 'r1_f1': 0.46445497630331756, 'pegasus_entailment': 0.8623994588851929, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46308724832214765, 'r1_recall': 0.6831683168316832, 'r1_f1': 0.552, 'pegasus_entailment': 0.5113308224827051, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43609022556390975, 'r1_recall': 0.5370370370370371, 'r1_f1': 0.48132780082987553, 'pegasus_entailment': 0.5684201642870903, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1875, 'r1_recall': 0.4375, 'r1_f1': 0.2625, 'pegasus_entailment': 0.6938558034598827, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4392523364485981, 'r1_recall': 0.47474747474747475, 'r1_f1': 0.4563106796116505, 'pegasus_entailment': 0.5661094225943089, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44886363636363635, 'r1_recall': 0.5, 'r1_f1': 0.47305389221556887, 'pegasus_entailment': 0.7008199453353882, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4452054794520548, 'r1_recall': 0.41139240506329117, 'r1_f1': 0.4276315789473685, 'pegasus_entailment': 0.6863609671592712, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6559139784946236, 'r1_recall': 0.3160621761658031, 'r1_f1': 0.42657342657342656, 'pegasus_entailment': 0.42242670655250547, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5544554455445545, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5436893203883496, 'pegasus_entailment': 0.7149469455083212, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.475, 'r1_recall': 0.456, 'r1_f1': 0.46530612244897956, 'pegasus_entailment': 0.4130570888519287, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.216, 'r1_recall': 0.5192307692307693, 'r1_f1': 0.3050847457627119, 'pegasus_entailment': 0.31399669237434863, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25384615384615383, 'r1_recall': 0.5409836065573771, 'r1_f1': 0.3455497382198953, 'pegasus_entailment': 0.4061473372081916, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3425925925925926, 'r1_recall': 0.5967741935483871, 'r1_f1': 0.43529411764705883, 'pegasus_entailment': 0.42968251183629036, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23529411764705882, 'r1_recall': 0.4067796610169492, 'r1_f1': 0.2981366459627329, 'pegasus_entailment': 0.16883782390505075, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.41025641025641024, 'pegasus_entailment': 0.5562919874986013, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3305084745762712, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.3594470046082949, 'pegasus_entailment': 0.5275392060478529, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.17272727272727273, 'r1_recall': 0.475, 'r1_f1': 0.25333333333333335, 'pegasus_entailment': 0.5863654613494873, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4330357142857143, 'r1_recall': 0.5606936416184971, 'r1_f1': 0.48866498740554154, 'pegasus_entailment': 0.8049858212471008, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53125, 'r1_recall': 0.6375, 'r1_f1': 0.5795454545454545, 'pegasus_entailment': 0.397839680314064, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5886524822695035, 'r1_recall': 0.46629213483146065, 'r1_f1': 0.5203761755485893, 'pegasus_entailment': 0.4493711863954862, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6697247706422018, 'r1_recall': 0.453416149068323, 'r1_f1': 0.5407407407407407, 'pegasus_entailment': 0.6970231980085373, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5648148148148148, 'r1_recall': 0.4552238805970149, 'r1_f1': 0.5041322314049587, 'pegasus_entailment': 0.5876177151997884, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6697247706422018, 'r1_recall': 0.3004115226337449, 'r1_f1': 0.41477272727272724, 'pegasus_entailment': 0.3861895650625229, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3048780487804878, 'r1_recall': 0.3048780487804878, 'r1_f1': 0.3048780487804878, 'pegasus_entailment': 0.7048590257763863, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.580952380952381, 'r1_recall': 0.40131578947368424, 'r1_f1': 0.47470817120622577, 'pegasus_entailment': 0.8373359888792038, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35051546391752575, 'r1_recall': 0.4722222222222222, 'r1_f1': 0.40236686390532544, 'pegasus_entailment': 0.4483148315921426, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6857142857142857, 'r1_recall': 0.21524663677130046, 'r1_f1': 0.3276450511945393, 'pegasus_entailment': 0.4516259394586086, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2375, 'r1_recall': 0.168141592920354, 'r1_f1': 0.1968911917098446, 'pegasus_entailment': 0.3563977329370876, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2909090909090909, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.41025641025641024, 'pegasus_entailment': 0.6249985750764608, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5238095238095238, 'r1_recall': 0.30386740331491713, 'r1_f1': 0.38461538461538464, 'pegasus_entailment': 0.8131734132766724, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6363636363636364, 'r1_recall': 0.3163841807909605, 'r1_f1': 0.4226415094339622, 'pegasus_entailment': 0.43622495234012604, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4409448818897638, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.5022421524663677, 'pegasus_entailment': 0.7008512347936631, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6436781609195402, 'r1_recall': 0.38620689655172413, 'r1_f1': 0.48275862068965514, 'pegasus_entailment': 0.33684495091438293, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.10526315789473684, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.17777777777777778, 'pegasus_entailment': 0.5961997985839844, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24242424242424243, 'r1_recall': 0.41379310344827586, 'r1_f1': 0.3057324840764331, 'pegasus_entailment': 0.6260488331317902, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6309523809523809, 'r1_recall': 0.44537815126050423, 'r1_f1': 0.5221674876847291, 'pegasus_entailment': 0.29404733267923194, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21428571428571427, 'r1_recall': 0.5070422535211268, 'r1_f1': 0.30125523012552297, 'pegasus_entailment': 0.4928355866244861, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3218390804597701, 'r1_recall': 0.509090909090909, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.25126622058451176, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24675324675324675, 'r1_recall': 0.4691358024691358, 'r1_f1': 0.3234042553191489, 'pegasus_entailment': 0.703338885307312, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5700934579439252, 'r1_recall': 0.7530864197530864, 'r1_f1': 0.648936170212766, 'pegasus_entailment': 0.3494804981164634, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5058823529411764, 'r1_recall': 0.5180722891566265, 'r1_f1': 0.511904761904762, 'pegasus_entailment': 0.6397628635168076, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5869565217391305, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.5320197044334976, 'pegasus_entailment': 0.3808538168668747, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7209302325581395, 'r1_recall': 0.18452380952380953, 'r1_f1': 0.29383886255924174, 'pegasus_entailment': 0.4750573579221964, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5772357723577236, 'r1_recall': 0.31981981981981983, 'r1_f1': 0.41159420289855075, 'pegasus_entailment': 0.681549894809723, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2727272727272727, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.3620689655172414, 'pegasus_entailment': 0.6950721542040507, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5773195876288659, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5572139303482586, 'pegasus_entailment': 0.29879713207483294, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 12}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3047619047619048, 'r1_recall': 0.4383561643835616, 'r1_f1': 0.3595505617977528, 'pegasus_entailment': 0.4709047647193074, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4583333333333333, 'r1_recall': 0.5076923076923077, 'r1_f1': 0.48175182481751827, 'pegasus_entailment': 0.4379807114601135, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5584415584415584, 'r1_recall': 0.5972222222222222, 'r1_f1': 0.5771812080536912, 'pegasus_entailment': 0.44652173947542906, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4153846153846154, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5118483412322276, 'pegasus_entailment': 0.5173580825328827, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2857142857142857, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.38260869565217387, 'pegasus_entailment': 0.6125749170780181, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.4891304347826087, 'pegasus_entailment': 0.6169806718826294, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6097560975609756, 'r1_recall': 0.47770700636942676, 'r1_f1': 0.5357142857142857, 'pegasus_entailment': 0.4588583083823323, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.725, 'r1_recall': 0.4027777777777778, 'r1_f1': 0.5178571428571429, 'pegasus_entailment': 0.2857955666258931, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3898305084745763, 'r1_recall': 0.48936170212765956, 'r1_f1': 0.4339622641509434, 'pegasus_entailment': 0.6756517201662063, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6326530612244898, 'r1_recall': 0.32460732984293195, 'r1_f1': 0.4290657439446367, 'pegasus_entailment': 0.41943716009457904, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.304, 'r1_recall': 0.7755102040816326, 'r1_f1': 0.43678160919540227, 'pegasus_entailment': 0.7031233504414558, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37755102040816324, 'r1_recall': 0.4457831325301205, 'r1_f1': 0.4088397790055249, 'pegasus_entailment': 0.8282516151666641, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5599999999999999, 'pegasus_entailment': 0.3364373904963334, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 14}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39, 'r1_recall': 0.48148148148148145, 'r1_f1': 0.43093922651933697, 'pegasus_entailment': 0.5574856884777546, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.39416058394160586, 'r1_f1': 0.47577092511013214, 'pegasus_entailment': 0.6311478540301323, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1958762886597938, 'r1_recall': 0.4318181818181818, 'r1_f1': 0.2695035460992908, 'pegasus_entailment': 0.6988627115885416, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2524271844660194, 'r1_recall': 0.4406779661016949, 'r1_f1': 0.3209876543209876, 'pegasus_entailment': 0.6130781273047129, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45588235294117646, 'r1_recall': 0.4626865671641791, 'r1_f1': 0.45925925925925926, 'pegasus_entailment': 0.7218033224344254, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6756756756756757, 'r1_recall': 0.32051282051282054, 'r1_f1': 0.4347826086956522, 'pegasus_entailment': 0.4399121527870496, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.384, 'r1_recall': 0.7384615384615385, 'r1_f1': 0.505263157894737, 'pegasus_entailment': 0.5392576642334461, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3888888888888889, 'r1_recall': 0.3181818181818182, 'r1_f1': 0.35000000000000003, 'pegasus_entailment': 0.8124988675117493, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37362637362637363, 'r1_recall': 0.40476190476190477, 'r1_f1': 0.38857142857142857, 'pegasus_entailment': 0.6156468316912651, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38372093023255816, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.40490797546012264, 'pegasus_entailment': 0.5343942095836004, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31756756756756754, 'r1_recall': 0.5875, 'r1_f1': 0.41228070175438597, 'pegasus_entailment': 0.4919295385479927, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5096774193548387, 'r1_recall': 0.5064102564102564, 'r1_f1': 0.5080385852090031, 'pegasus_entailment': 0.4051272187914167, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31451612903225806, 'r1_recall': 0.5131578947368421, 'r1_f1': 0.39, 'pegasus_entailment': 0.30577885508537295, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40476190476190477, 'r1_recall': 0.6, 'r1_f1': 0.4834123222748815, 'pegasus_entailment': 0.49239592254161835, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48091603053435117, 'r1_recall': 0.48091603053435117, 'r1_f1': 0.48091603053435117, 'pegasus_entailment': 0.6837172359228134, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.336, 'r1_recall': 0.39622641509433965, 'r1_f1': 0.3636363636363637, 'pegasus_entailment': 0.3431853324174881, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5345911949685535, 'r1_recall': 0.4644808743169399, 'r1_f1': 0.4970760233918129, 'pegasus_entailment': 0.4944487636288007, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5176470588235295, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.5465838509316772, 'pegasus_entailment': 0.6787532195448875, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3586206896551724, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.43881856540084385, 'pegasus_entailment': 0.4574415609240532, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7216494845360825, 'r1_recall': 0.32407407407407407, 'r1_f1': 0.4472843450479233, 'pegasus_entailment': 0.6681190431118011, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4891304347826087, 'r1_recall': 0.44554455445544555, 'r1_f1': 0.46632124352331605, 'pegasus_entailment': 0.5070118783041835, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6029411764705882, 'r1_recall': 0.41836734693877553, 'r1_f1': 0.49397590361445787, 'pegasus_entailment': 0.3384382873773575, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.573170731707317, 'r1_recall': 0.6714285714285714, 'r1_f1': 0.6184210526315789, 'pegasus_entailment': 0.5352461735407511, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4520547945205479, 'r1_recall': 0.49624060150375937, 'r1_f1': 0.4731182795698925, 'pegasus_entailment': 0.5840541243553161, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4251968503937008, 'r1_recall': 0.6, 'r1_f1': 0.4976958525345623, 'pegasus_entailment': 0.6737633407115936, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45098039215686275, 'r1_recall': 0.4, 'r1_f1': 0.423963133640553, 'pegasus_entailment': 0.6542875568072001, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3007518796992481, 'r1_recall': 0.36036036036036034, 'r1_f1': 0.32786885245901637, 'pegasus_entailment': 0.5377448126673698, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.65, 'r1_recall': 0.37681159420289856, 'r1_f1': 0.47706422018348627, 'pegasus_entailment': 0.6357953250408173, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16748768472906403, 'r1_recall': 0.68, 'r1_f1': 0.26877470355731226, 'pegasus_entailment': 0.48896451741456987, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2727272727272727, 'r1_recall': 0.6964285714285714, 'r1_f1': 0.39195979899497485, 'pegasus_entailment': 0.4615897759795189, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16161616161616163, 'r1_recall': 0.3404255319148936, 'r1_f1': 0.21917808219178087, 'pegasus_entailment': 0.4808129258453846, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 16, 'pegasus_ari': 30, 'pegasus_smog': 19}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4235294117647059, 'r1_recall': 0.5070422535211268, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.7542008757591248, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6637168141592921, 'r1_recall': 0.4098360655737705, 'r1_f1': 0.5067567567567567, 'pegasus_entailment': 0.71630380153656, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5684210526315789, 'r1_recall': 0.39416058394160586, 'r1_f1': 0.4655172413793104, 'pegasus_entailment': 0.49078149497509005, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5142857142857142, 'r1_recall': 0.3956043956043956, 'r1_f1': 0.4472049689440994, 'pegasus_entailment': 0.6528112689654032, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4878048780487805, 'r1_recall': 0.45112781954887216, 'r1_f1': 0.46874999999999994, 'pegasus_entailment': 0.3158726617693901, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5915492957746479, 'r1_recall': 0.5121951219512195, 'r1_f1': 0.5490196078431372, 'pegasus_entailment': 0.5081589102745057, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8207547169811321, 'r1_recall': 0.43283582089552236, 'r1_f1': 0.5667752442996743, 'pegasus_entailment': 0.7945481836795807, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 24}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4067796610169492, 'r1_recall': 0.48, 'r1_f1': 0.44036697247706424, 'pegasus_entailment': 0.49912766367197037, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5212765957446809, 'r1_recall': 0.6125, 'r1_f1': 0.5632183908045978, 'pegasus_entailment': 0.6049029141664505, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40476190476190477, 'r1_recall': 0.4146341463414634, 'r1_f1': 0.4096385542168674, 'pegasus_entailment': 0.22438185413678488, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2, 'r1_recall': 0.5, 'r1_f1': 0.28571428571428575, 'pegasus_entailment': 0.766668975353241, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24285714285714285, 'r1_recall': 0.5396825396825397, 'r1_f1': 0.33497536945812806, 'pegasus_entailment': 0.7683663964271545, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18627450980392157, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.27941176470588236, 'pegasus_entailment': 0.5201807200908661, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25757575757575757, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.32692307692307687, 'pegasus_entailment': 0.4407361877150834, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.635036496350365, 'r1_recall': 0.47282608695652173, 'r1_f1': 0.5420560747663552, 'pegasus_entailment': 0.6604075481494268, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3368421052631579, 'r1_recall': 0.47761194029850745, 'r1_f1': 0.3950617283950617, 'pegasus_entailment': 0.7328931868076325, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5594405594405595, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5144694533762059, 'pegasus_entailment': 0.4193584465732177, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5221238938053098, 'r1_recall': 0.44696969696969696, 'r1_f1': 0.48163265306122455, 'pegasus_entailment': 0.7172692894935608, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.627906976744186, 'r1_recall': 0.34177215189873417, 'r1_f1': 0.4426229508196721, 'pegasus_entailment': 0.6216167435050011, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6538461538461539, 'r1_recall': 0.34459459459459457, 'r1_f1': 0.45132743362831856, 'pegasus_entailment': 0.707441379626592, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3225806451612903, 'r1_recall': 0.7272727272727273, 'r1_f1': 0.446927374301676, 'pegasus_entailment': 0.293211130425334, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.36548223350253806, 'r1_f1': 0.4324324324324324, 'pegasus_entailment': 0.4395460090599954, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.375, 'r1_recall': 0.7, 'r1_f1': 0.48837209302325574, 'pegasus_entailment': 0.5344156235456466, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5102040816326531, 'r1_recall': 0.4065040650406504, 'r1_f1': 0.45248868778280543, 'pegasus_entailment': 0.6704647898674011, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5596330275229358, 'r1_recall': 0.580952380952381, 'r1_f1': 0.5700934579439252, 'pegasus_entailment': 0.6977772315343221, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6027397260273972, 'r1_recall': 0.33587786259541985, 'r1_f1': 0.43137254901960786, 'pegasus_entailment': 0.47894929721951485, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2807017543859649, 'r1_recall': 0.47761194029850745, 'r1_f1': 0.3535911602209944, 'pegasus_entailment': 0.5192745253443718, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21875, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.32258064516129037, 'pegasus_entailment': 0.685415044426918, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29245283018867924, 'r1_recall': 0.543859649122807, 'r1_f1': 0.3803680981595092, 'pegasus_entailment': 0.6760816693305969, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5595238095238095, 'r1_recall': 0.3671875, 'r1_f1': 0.44339622641509435, 'pegasus_entailment': 0.3888249769806862, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5258620689655172, 'r1_recall': 0.34269662921348315, 'r1_f1': 0.41496598639455784, 'pegasus_entailment': 0.48170930785792215, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5871559633027523, 'r1_recall': 0.39263803680981596, 'r1_f1': 0.4705882352941177, 'pegasus_entailment': 0.5319487094879151, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6052631578947368, 'r1_recall': 0.35751295336787564, 'r1_f1': 0.4495114006514658, 'pegasus_entailment': 0.6319346725940704, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4166666666666667, 'r1_recall': 0.594059405940594, 'r1_f1': 0.489795918367347, 'pegasus_entailment': 0.47162246108055117, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30864197530864196, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.4065040650406504, 'pegasus_entailment': 0.40167891383171084, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24675324675324675, 'r1_recall': 0.4222222222222222, 'r1_f1': 0.3114754098360656, 'pegasus_entailment': 0.7202855587005615, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2653061224489796, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.348993288590604, 'pegasus_entailment': 0.6181944496929646, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5463917525773195, 'r1_recall': 0.3581081081081081, 'r1_f1': 0.43265306122448977, 'pegasus_entailment': 0.3857880290597677, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5384615384615384, 'r1_recall': 0.42748091603053434, 'r1_f1': 0.4765957446808511, 'pegasus_entailment': 0.32279550035794574, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.488, 'r1_recall': 0.5169491525423728, 'r1_f1': 0.5020576131687242, 'pegasus_entailment': 0.5819950153430303, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5511811023622047, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5447470817120622, 'pegasus_entailment': 0.5098807513713837, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46788990825688076, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.4473684210526315, 'pegasus_entailment': 0.28940185136161745, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7604166666666666, 'r1_recall': 0.5069444444444444, 'r1_f1': 0.6083333333333333, 'pegasus_entailment': 0.739960769812266, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43157894736842106, 'r1_recall': 0.45555555555555555, 'r1_f1': 0.44324324324324327, 'pegasus_entailment': 0.6064335763454437, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41739130434782606, 'r1_recall': 0.3609022556390977, 'r1_f1': 0.3870967741935483, 'pegasus_entailment': 0.2101848628371954, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.65, 'r1_recall': 0.36792452830188677, 'r1_f1': 0.46987951807228917, 'pegasus_entailment': 0.6918951719999313, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2534246575342466, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.36453201970443355, 'pegasus_entailment': 0.6658226698637009, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4146341463414634, 'r1_recall': 0.3984375, 'r1_f1': 0.4063745019920319, 'pegasus_entailment': 0.6162566343943278, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36363636363636365, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.4413793103448276, 'pegasus_entailment': 0.35630643367767334, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5272727272727272, 'r1_recall': 0.3036649214659686, 'r1_f1': 0.3853820598006644, 'pegasus_entailment': 0.6042539402842522, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5533980582524272, 'r1_recall': 0.3877551020408163, 'r1_f1': 0.456, 'pegasus_entailment': 0.43803736101835966, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.512, 'r1_recall': 0.4155844155844156, 'r1_f1': 0.45878136200716846, 'pegasus_entailment': 0.5577546606461207, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3089887640449438, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.4347826086956522, 'pegasus_entailment': 0.6603837410608927, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5775862068965517, 'r1_recall': 0.5826086956521739, 'r1_f1': 0.58008658008658, 'pegasus_entailment': 0.6201486065983772, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6344086021505376, 'r1_recall': 0.38562091503267976, 'r1_f1': 0.4796747967479675, 'pegasus_entailment': 0.5493087247014046, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3816793893129771, 'r1_recall': 0.49019607843137253, 'r1_f1': 0.4291845493562232, 'pegasus_entailment': 0.5180387228727341, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3409090909090909, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.4137931034482758, 'pegasus_entailment': 0.7145083174109459, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4606741573033708, 'r1_recall': 0.640625, 'r1_f1': 0.5359477124183006, 'pegasus_entailment': 0.670559361577034, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23857868020304568, 'r1_recall': 0.6266666666666667, 'r1_f1': 0.34558823529411764, 'pegasus_entailment': 0.6280752662569284, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28368794326241137, 'r1_recall': 0.7547169811320755, 'r1_f1': 0.4123711340206186, 'pegasus_entailment': 0.534083272020022, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5666666666666667, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.5573770491803278, 'pegasus_entailment': 0.8108065724372864, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5822784810126582, 'r1_recall': 0.7931034482758621, 'r1_f1': 0.6715328467153284, 'pegasus_entailment': 0.44513995945453644, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6265060240963856, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.5621621621621622, 'pegasus_entailment': 0.2821234464645386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48, 'r1_recall': 0.45569620253164556, 'r1_f1': 0.4675324675324675, 'pegasus_entailment': 0.44530246903498966, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2740740740740741, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.3854166666666667, 'pegasus_entailment': 0.6374925002455711, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5959595959595959, 'r1_recall': 0.3959731543624161, 'r1_f1': 0.4758064516129032, 'pegasus_entailment': 0.4386082887649536, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5161290322580645, 'r1_recall': 0.23357664233576642, 'r1_f1': 0.32160804020100503, 'pegasus_entailment': 0.5920418679714203, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 14, 'pegasus_ari': 11, 'pegasus_smog': 14}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28104575163398693, 'r1_recall': 0.6515151515151515, 'r1_f1': 0.3926940639269406, 'pegasus_entailment': 0.5055662453174591, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5813953488372093, 'r1_recall': 0.45045045045045046, 'r1_f1': 0.5076142131979695, 'pegasus_entailment': 0.45006218925118446, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33540372670807456, 'r1_recall': 0.675, 'r1_f1': 0.4481327800829876, 'pegasus_entailment': 0.7553877085447311, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6195652173913043, 'r1_recall': 0.44881889763779526, 'r1_f1': 0.5205479452054794, 'pegasus_entailment': 0.46628549706656486, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6615384615384615, 'r1_recall': 0.4365482233502538, 'r1_f1': 0.5259938837920489, 'pegasus_entailment': 0.6508480608463287, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6627218934911243, 'r1_recall': 0.4609053497942387, 'r1_f1': 0.5436893203883496, 'pegasus_entailment': 0.6355108966430029, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7247706422018348, 'r1_recall': 0.5683453237410072, 'r1_f1': 0.6370967741935485, 'pegasus_entailment': 0.3063703626394272, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1724137931034483, 'r1_recall': 0.0684931506849315, 'r1_f1': 0.09803921568627451, 'pegasus_entailment': 0.08133979141712189, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 11, 'pegasus_ari': 16, 'pegasus_smog': 8}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19852941176470587, 'r1_recall': 0.4426229508196721, 'r1_f1': 0.27411167512690354, 'pegasus_entailment': 0.5723375957459211, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4830508474576271, 'r1_recall': 0.6627906976744186, 'r1_f1': 0.5588235294117647, 'pegasus_entailment': 0.6243046298623085, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43023255813953487, 'r1_recall': 0.5, 'r1_f1': 0.46249999999999997, 'pegasus_entailment': 0.7014586329460144, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5548387096774193, 'r1_recall': 0.4942528735632184, 'r1_f1': 0.5227963525835866, 'pegasus_entailment': 0.5570059610264642, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4864864864864865, 'r1_recall': 0.375, 'r1_f1': 0.42352941176470593, 'pegasus_entailment': 0.44925788044929504, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5982905982905983, 'r1_recall': 0.358974358974359, 'r1_f1': 0.44871794871794873, 'pegasus_entailment': 0.44696809649467467, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47115384615384615, 'r1_recall': 0.6712328767123288, 'r1_f1': 0.5536723163841807, 'pegasus_entailment': 0.1730489529669285, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3700787401574803, 'r1_recall': 0.6266666666666667, 'r1_f1': 0.46534653465346537, 'pegasus_entailment': 0.8026982545852661, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42748091603053434, 'r1_recall': 0.49122807017543857, 'r1_f1': 0.4571428571428571, 'pegasus_entailment': 0.5805051997303963, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.78, 'r1_recall': 0.2074468085106383, 'r1_f1': 0.3277310924369748, 'pegasus_entailment': 0.5183591842651367, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3488372093023256, 'r1_recall': 0.5084745762711864, 'r1_f1': 0.41379310344827586, 'pegasus_entailment': 0.4261971712112427, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5957446808510638, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.42748091603053434, 'pegasus_entailment': 0.5643905594944953, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4240506329113924, 'r1_recall': 0.5193798449612403, 'r1_f1': 0.46689895470383275, 'pegasus_entailment': 0.4299915835261345, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5259259259259259, 'r1_recall': 0.47651006711409394, 'r1_f1': 0.5, 'pegasus_entailment': 0.6951553851366044, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5462184873949579, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.4513888888888889, 'pegasus_entailment': 0.4005549311637878, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44, 'r1_recall': 0.5038167938931297, 'r1_f1': 0.4697508896797153, 'pegasus_entailment': 0.4290229491889477, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3821138211382114, 'r1_recall': 0.3790322580645161, 'r1_f1': 0.3805668016194332, 'pegasus_entailment': 0.6183282807469368, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37254901960784315, 'r1_recall': 0.4578313253012048, 'r1_f1': 0.41081081081081083, 'pegasus_entailment': 0.3118539661169052, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26666666666666666, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.37209302325581395, 'pegasus_entailment': 0.3601117208600044, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 22}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5393258426966292, 'r1_recall': 0.41379310344827586, 'r1_f1': 0.4682926829268293, 'pegasus_entailment': 0.5379602372646332, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5688073394495413, 'r1_recall': 0.33513513513513515, 'r1_f1': 0.4217687074829932, 'pegasus_entailment': 0.47055692970752716, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5638297872340425, 'r1_recall': 0.5520833333333334, 'r1_f1': 0.5578947368421052, 'pegasus_entailment': 0.6123773604631424, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6353591160220995, 'r1_recall': 0.2987012987012987, 'r1_f1': 0.40636042402826855, 'pegasus_entailment': 0.5042361037598716, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5773195876288659, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.46473029045643155, 'pegasus_entailment': 0.502325713634491, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24113475177304963, 'r1_recall': 0.5230769230769231, 'r1_f1': 0.3300970873786408, 'pegasus_entailment': 0.5170303791761398, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28421052631578947, 'r1_recall': 0.45, 'r1_f1': 0.34838709677419355, 'pegasus_entailment': 0.78828364610672, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25, 'r1_recall': 0.4567901234567901, 'r1_f1': 0.3231441048034934, 'pegasus_entailment': 0.49398232872287434, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.3076923076923077, 'r1_f1': 0.380952380952381, 'pegasus_entailment': 0.5669788718223572, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2727272727272727, 'r1_recall': 0.313953488372093, 'r1_f1': 0.2918918918918919, 'pegasus_entailment': 0.5214952670037747, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5169491525423728, 'r1_recall': 0.391025641025641, 'r1_f1': 0.44525547445255476, 'pegasus_entailment': 0.6584614098072052, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5648854961832062, 'r1_recall': 0.4484848484848485, 'r1_f1': 0.5, 'pegasus_entailment': 0.6986455321311951, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24812030075187969, 'r1_recall': 0.5409836065573771, 'r1_f1': 0.3402061855670103, 'pegasus_entailment': 0.7827723026275635, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6239316239316239, 'r1_recall': 0.4866666666666667, 'r1_f1': 0.5468164794007491, 'pegasus_entailment': 0.5591140190760294, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3416666666666667, 'r1_recall': 0.45054945054945056, 'r1_f1': 0.38862559241706157, 'pegasus_entailment': 0.22658791323192418, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4140127388535032, 'r1_recall': 0.4961832061068702, 'r1_f1': 0.45138888888888895, 'pegasus_entailment': 0.3161278005157198, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3888888888888889, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.4765957446808511, 'pegasus_entailment': 0.5501415090901511, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53, 'r1_recall': 0.5047619047619047, 'r1_f1': 0.5170731707317073, 'pegasus_entailment': 0.5645731464028358, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45555555555555555, 'r1_recall': 0.5616438356164384, 'r1_f1': 0.5030674846625767, 'pegasus_entailment': 0.5850240443833172, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46875, 'r1_recall': 0.36, 'r1_f1': 0.40723981900452483, 'pegasus_entailment': 0.2724561234936118, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7341772151898734, 'r1_recall': 0.5087719298245614, 'r1_f1': 0.6010362694300517, 'pegasus_entailment': 0.24136992155884704, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40298507462686567, 'r1_recall': 0.6067415730337079, 'r1_f1': 0.4843049327354261, 'pegasus_entailment': 0.5236648801714182, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18269230769230768, 'r1_recall': 0.4418604651162791, 'r1_f1': 0.2585034013605442, 'pegasus_entailment': 0.3015216131461784, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5666666666666667, 'r1_recall': 0.3076923076923077, 'r1_f1': 0.3988269794721408, 'pegasus_entailment': 0.23440367628687195, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4631578947368421, 'r1_recall': 0.3893805309734513, 'r1_f1': 0.4230769230769231, 'pegasus_entailment': 0.3314610403031111, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.09502262443438914, 'r1_recall': 0.5675675675675675, 'r1_f1': 0.1627906976744186, 'pegasus_entailment': 0.6604368627071381, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 25}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36666666666666664, 'r1_recall': 0.5365853658536586, 'r1_f1': 0.4356435643564356, 'pegasus_entailment': 0.522095238789916, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33879781420765026, 'r1_recall': 0.5794392523364486, 'r1_f1': 0.4275862068965517, 'pegasus_entailment': 0.5271476097404957, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3291139240506329, 'r1_recall': 0.7222222222222222, 'r1_f1': 0.4521739130434782, 'pegasus_entailment': 0.9195612788200378, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5098039215686274, 'r1_recall': 0.5909090909090909, 'r1_f1': 0.5473684210526317, 'pegasus_entailment': 0.7777872085571289, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35507246376811596, 'r1_recall': 0.550561797752809, 'r1_f1': 0.43171806167400884, 'pegasus_entailment': 0.29178259428590536, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23118279569892472, 'r1_recall': 0.7288135593220338, 'r1_f1': 0.3510204081632653, 'pegasus_entailment': 0.5840718746185303, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5588235294117647, 'r1_recall': 0.5757575757575758, 'r1_f1': 0.5671641791044776, 'pegasus_entailment': 0.5058976233005523, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45714285714285713, 'r1_recall': 0.5, 'r1_f1': 0.4776119402985075, 'pegasus_entailment': 0.6712418496608734, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49557522123893805, 'r1_recall': 0.5957446808510638, 'r1_f1': 0.5410628019323672, 'pegasus_entailment': 0.5382455835739771, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8623853211009175, 'r1_recall': 0.18007662835249041, 'r1_f1': 0.2979397781299524, 'pegasus_entailment': 0.7702000141143799, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5648148148148148, 'r1_recall': 0.305, 'r1_f1': 0.396103896103896, 'pegasus_entailment': 0.5489356338977813, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32075471698113206, 'r1_recall': 0.4358974358974359, 'r1_f1': 0.3695652173913044, 'pegasus_entailment': 0.20209923386573792, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.594059405940594, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5825242718446602, 'pegasus_entailment': 0.6056196987628937, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 15, 'pegasus_ari': 30, 'pegasus_smog': 18}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.68, 'r1_recall': 0.375, 'r1_f1': 0.48341232227488146, 'pegasus_entailment': 0.6298333555459976, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5523809523809524, 'r1_recall': 0.5132743362831859, 'r1_f1': 0.5321100917431192, 'pegasus_entailment': 0.37211183831095695, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3253968253968254, 'r1_recall': 0.4823529411764706, 'r1_f1': 0.38862559241706157, 'pegasus_entailment': 0.8184705575307211, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 17}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49206349206349204, 'r1_recall': 0.4696969696969697, 'r1_f1': 0.48062015503875966, 'pegasus_entailment': 0.8625607093175253, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3983050847457627, 'r1_recall': 0.5108695652173914, 'r1_f1': 0.44761904761904764, 'pegasus_entailment': 0.3551782116293907, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4305555555555556, 'r1_recall': 0.37349397590361444, 'r1_f1': 0.4, 'pegasus_entailment': 0.512772424146533, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5783132530120482, 'r1_recall': 0.38095238095238093, 'r1_f1': 0.4593301435406698, 'pegasus_entailment': 0.4366057999432087, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5373134328358209, 'r1_recall': 0.35294117647058826, 'r1_f1': 0.4260355029585799, 'pegasus_entailment': 0.32485433916250867, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6022727272727273, 'r1_recall': 0.32919254658385094, 'r1_f1': 0.42570281124497994, 'pegasus_entailment': 0.6036211550235748, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 13}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2716049382716049, 'r1_recall': 0.38596491228070173, 'r1_f1': 0.3188405797101449, 'pegasus_entailment': 0.3073163108589749, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5238095238095238, 'r1_recall': 0.24336283185840707, 'r1_f1': 0.33232628398791547, 'pegasus_entailment': 0.36981090903282166, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25757575757575757, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.3541666666666667, 'pegasus_entailment': 0.515577665397099, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5161290322580645, 'r1_recall': 0.4752475247524752, 'r1_f1': 0.4948453608247423, 'pegasus_entailment': 0.778304323554039, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21333333333333335, 'r1_recall': 0.6530612244897959, 'r1_f1': 0.32160804020100503, 'pegasus_entailment': 0.5626005977392197, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.17307692307692307, 'r1_recall': 0.391304347826087, 'r1_f1': 0.24, 'pegasus_entailment': 0.635090458393097, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5503875968992248, 'r1_recall': 0.4863013698630137, 'r1_f1': 0.5163636363636362, 'pegasus_entailment': 0.6277516335248947, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4896907216494845, 'r1_recall': 0.4947916666666667, 'r1_f1': 0.49222797927461137, 'pegasus_entailment': 0.5997907902513232, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35772357723577236, 'r1_recall': 0.5945945945945946, 'r1_f1': 0.44670050761421315, 'pegasus_entailment': 0.7011303380131721, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5342465753424658, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.4534883720930233, 'pegasus_entailment': 0.4836561568081379, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4132231404958678, 'r1_recall': 0.6024096385542169, 'r1_f1': 0.49019607843137253, 'pegasus_entailment': 0.713262935479482, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36885245901639346, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.46632124352331605, 'pegasus_entailment': 0.3511446602642536, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38461538461538464, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.4577464788732394, 'pegasus_entailment': 0.43072380423545836, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6055045871559633, 'r1_recall': 0.39285714285714285, 'r1_f1': 0.4765342960288808, 'pegasus_entailment': 0.35578487114980817, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.211864406779661, 'r1_recall': 0.4716981132075472, 'r1_f1': 0.29239766081871343, 'pegasus_entailment': 0.6503561623394489, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5241935483870968, 'r1_recall': 0.6018518518518519, 'r1_f1': 0.560344827586207, 'pegasus_entailment': 0.4592871852219105, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4883720930232558, 'r1_recall': 0.18584070796460178, 'r1_f1': 0.2692307692307692, 'pegasus_entailment': 0.9004939595858256, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 23, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2808219178082192, 'r1_recall': 0.5774647887323944, 'r1_f1': 0.3778801843317972, 'pegasus_entailment': 0.6243804216384887, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5798319327731093, 'r1_recall': 0.3150684931506849, 'r1_f1': 0.40828402366863903, 'pegasus_entailment': 0.6257137656211853, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.08333333333333333, 'r1_recall': 0.3142857142857143, 'r1_f1': 0.13173652694610777, 'pegasus_entailment': 0.4705091789364815, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5486725663716814, 'r1_recall': 0.7469879518072289, 'r1_f1': 0.6326530612244897, 'pegasus_entailment': 0.5454468727111816, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1793103448275862, 'r1_recall': 0.5306122448979592, 'r1_f1': 0.26804123711340205, 'pegasus_entailment': 0.4943750949576497, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7181818181818181, 'r1_recall': 0.4647058823529412, 'r1_f1': 0.5642857142857143, 'pegasus_entailment': 0.5297838164493441, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5158730158730159, 'r1_recall': 0.5038759689922481, 'r1_f1': 0.5098039215686275, 'pegasus_entailment': 0.833868658542633, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3885350318471338, 'r1_recall': 0.7011494252873564, 'r1_f1': 0.5, 'pegasus_entailment': 0.7619022093713284, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45081967213114754, 'r1_recall': 0.41353383458646614, 'r1_f1': 0.4313725490196078, 'pegasus_entailment': 0.5617232844233513, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40310077519379844, 'r1_recall': 0.46846846846846846, 'r1_f1': 0.43333333333333335, 'pegasus_entailment': 0.4036387659609318, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28484848484848485, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.36015325670498083, 'pegasus_entailment': 0.4838643968105316, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5104895104895105, 'r1_recall': 0.5214285714285715, 'r1_f1': 0.5159010600706714, 'pegasus_entailment': 0.45109667629003525, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4491525423728814, 'r1_recall': 0.3680555555555556, 'r1_f1': 0.4045801526717558, 'pegasus_entailment': 0.40409862250089645, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.569620253164557, 'r1_recall': 0.4891304347826087, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.7325196489691734, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3893129770992366, 'r1_recall': 0.49514563106796117, 'r1_f1': 0.4358974358974359, 'pegasus_entailment': 0.766289214293162, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3493975903614458, 'r1_recall': 0.43283582089552236, 'r1_f1': 0.38666666666666666, 'pegasus_entailment': 0.4960238039493561, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38461538461538464, 'r1_recall': 0.6043956043956044, 'r1_f1': 0.47008547008547, 'pegasus_entailment': 0.467092901468277, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6923076923076923, 'r1_recall': 0.4405594405594406, 'r1_f1': 0.5384615384615384, 'pegasus_entailment': 0.38784564062953, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5959595959595959, 'r1_recall': 0.48360655737704916, 'r1_f1': 0.5339366515837105, 'pegasus_entailment': 0.3378147780895233, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5952380952380952, 'r1_recall': 0.45180722891566266, 'r1_f1': 0.5136986301369864, 'pegasus_entailment': 0.48454082012176514, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37, 'r1_recall': 0.6727272727272727, 'r1_f1': 0.4774193548387097, 'pegasus_entailment': 0.2868343472480774, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3541666666666667, 'r1_recall': 0.4594594594594595, 'r1_f1': 0.4000000000000001, 'pegasus_entailment': 0.3542625233530998, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5730994152046783, 'r1_recall': 0.4803921568627451, 'r1_f1': 0.5226666666666667, 'pegasus_entailment': 0.6547221839427948, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.25925925925925924, 'r1_f1': 0.37333333333333335, 'pegasus_entailment': 0.15764727319280306, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5196850393700787, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.532258064516129, 'pegasus_entailment': 0.6101354598999024, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4090909090909091, 'r1_recall': 0.4405594405594406, 'r1_f1': 0.42424242424242425, 'pegasus_entailment': 0.23069642271314347, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34459459459459457, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.43404255319148927, 'pegasus_entailment': 0.48367043149967986, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49107142857142855, 'r1_recall': 0.6043956043956044, 'r1_f1': 0.541871921182266, 'pegasus_entailment': 0.5939199229081472, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5698924731182796, 'r1_recall': 0.5196078431372549, 'r1_f1': 0.5435897435897437, 'pegasus_entailment': 0.443744283169508, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4049586776859504, 'r1_recall': 0.4298245614035088, 'r1_f1': 0.41702127659574467, 'pegasus_entailment': 0.47696413695812223, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5054945054945055, 'r1_recall': 0.46464646464646464, 'r1_f1': 0.4842105263157894, 'pegasus_entailment': 0.47815547604113817, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2708333333333333, 'r1_recall': 0.43820224719101125, 'r1_f1': 0.33476394849785407, 'pegasus_entailment': 0.43160770693793893, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6853932584269663, 'r1_recall': 0.37423312883435583, 'r1_f1': 0.48412698412698413, 'pegasus_entailment': 0.2894093990325928, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5737704918032787, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.46052631578947373, 'pegasus_entailment': 0.3677360676229, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.64, 'r1_recall': 0.23272727272727273, 'r1_f1': 0.3413333333333333, 'pegasus_entailment': 0.5252489211658636, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5324675324675324, 'r1_recall': 0.3761467889908257, 'r1_f1': 0.4408602150537634, 'pegasus_entailment': 0.8363401492436727, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16071428571428573, 'r1_recall': 0.3103448275862069, 'r1_f1': 0.21176470588235297, 'pegasus_entailment': 0.3457467663101852, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5130434782608696, 'r1_recall': 0.3259668508287293, 'r1_f1': 0.39864864864864863, 'pegasus_entailment': 0.5790630280971527, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2891566265060241, 'r1_recall': 0.6233766233766234, 'r1_f1': 0.3950617283950617, 'pegasus_entailment': 0.4495223253965378, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.366412213740458, 'r1_recall': 0.6, 'r1_f1': 0.4549763033175355, 'pegasus_entailment': 0.5585023403167725, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5465116279069767, 'r1_recall': 0.5053763440860215, 'r1_f1': 0.5251396648044693, 'pegasus_entailment': 0.4892889693379402, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3216374269005848, 'r1_recall': 0.6790123456790124, 'r1_f1': 0.4365079365079365, 'pegasus_entailment': 0.6020141541957855, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47474747474747475, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.4973544973544973, 'pegasus_entailment': 0.5774325355887413, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24705882352941178, 'r1_recall': 0.30434782608695654, 'r1_f1': 0.27272727272727276, 'pegasus_entailment': 0.5491951256990433, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3979591836734694, 'r1_recall': 0.40625, 'r1_f1': 0.40206185567010305, 'pegasus_entailment': 0.3117429297417402, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22435897435897437, 'r1_recall': 0.546875, 'r1_f1': 0.31818181818181823, 'pegasus_entailment': 0.642843212400164, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41025641025641024, 'r1_recall': 0.5274725274725275, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.7249060869216919, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 20, 'pegasus_ari': 38, 'pegasus_smog': 25}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47115384615384615, 'r1_recall': 0.5568181818181818, 'r1_f1': 0.5104166666666667, 'pegasus_entailment': 0.5920843213796616, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37168141592920356, 'r1_recall': 0.6774193548387096, 'r1_f1': 0.48, 'pegasus_entailment': 0.3228264699379603, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53125, 'r1_recall': 0.6355140186915887, 'r1_f1': 0.5787234042553191, 'pegasus_entailment': 0.7505555152893066, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2727272727272727, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.3468208092485549, 'pegasus_entailment': 0.35186103731393814, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.78125, 'r1_recall': 0.2830188679245283, 'r1_f1': 0.41551246537396125, 'pegasus_entailment': 0.7326204776763916, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3008130081300813, 'r1_recall': 0.578125, 'r1_f1': 0.39572192513368987, 'pegasus_entailment': 0.3624199390411377, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45161290322580644, 'r1_recall': 0.45652173913043476, 'r1_f1': 0.4540540540540541, 'pegasus_entailment': 0.6767552196979523, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6176470588235294, 'r1_recall': 0.42, 'r1_f1': 0.5, 'pegasus_entailment': 0.7729672193527222, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4652777777777778, 'r1_recall': 0.4785714285714286, 'r1_f1': 0.471830985915493, 'pegasus_entailment': 0.5225115306675434, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5581395348837209, 'r1_recall': 0.5106382978723404, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.5854346267879009, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5277777777777778, 'r1_recall': 0.5984251968503937, 'r1_f1': 0.5608856088560885, 'pegasus_entailment': 0.576496496796608, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31496062992125984, 'r1_recall': 0.5633802816901409, 'r1_f1': 0.40404040404040403, 'pegasus_entailment': 0.5607479453086853, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3893129770992366, 'r1_recall': 0.5425531914893617, 'r1_f1': 0.4533333333333333, 'pegasus_entailment': 0.5509363561868668, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35294117647058826, 'r1_recall': 0.5, 'r1_f1': 0.41379310344827586, 'pegasus_entailment': 0.6331271901726723, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3697478991596639, 'r1_recall': 0.5945945945945946, 'r1_f1': 0.45595854922279794, 'pegasus_entailment': 0.5842207372188568, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 23}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36082474226804123, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.42682926829268286, 'pegasus_entailment': 0.3910604566335678, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28888888888888886, 'r1_recall': 0.40625, 'r1_f1': 0.3376623376623376, 'pegasus_entailment': 0.2925424873828888, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44, 'r1_recall': 0.3179190751445087, 'r1_f1': 0.36912751677852357, 'pegasus_entailment': 0.38132974079677034, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5357142857142857, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.43321299638989175, 'pegasus_entailment': 0.6007225438952446, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49557522123893805, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5308056872037914, 'pegasus_entailment': 0.39308541143933934, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6103896103896104, 'r1_recall': 0.25133689839572193, 'r1_f1': 0.3560606060606061, 'pegasus_entailment': 0.6237019201119741, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4375, 'r1_recall': 0.5157894736842106, 'r1_f1': 0.47342995169082125, 'pegasus_entailment': 0.15538834314793348, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3548387096774194, 'r1_recall': 0.6111111111111112, 'r1_f1': 0.4489795918367347, 'pegasus_entailment': 0.3531760280020535, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36470588235294116, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.44285714285714284, 'pegasus_entailment': 0.6270374283194542, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16847826086956522, 'r1_recall': 0.7380952380952381, 'r1_f1': 0.2743362831858407, 'pegasus_entailment': 0.5591985821723938, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3474576271186441, 'r1_recall': 0.5774647887323944, 'r1_f1': 0.43386243386243384, 'pegasus_entailment': 0.6284926608204842, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2682926829268293, 'r1_recall': 0.6346153846153846, 'r1_f1': 0.37714285714285717, 'pegasus_entailment': 0.5059975783030192, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3893805309734513, 'r1_recall': 0.37606837606837606, 'r1_f1': 0.382608695652174, 'pegasus_entailment': 0.544543232768774, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5565217391304348, 'r1_recall': 0.48854961832061067, 'r1_f1': 0.5203252032520325, 'pegasus_entailment': 0.676344707608223, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32679738562091504, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.4219409282700422, 'pegasus_entailment': 0.3517763428390026, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4883720930232558, 'r1_recall': 0.35, 'r1_f1': 0.4077669902912621, 'pegasus_entailment': 0.49714462757110595, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4019607843137255, 'r1_recall': 0.45054945054945056, 'r1_f1': 0.42487046632124353, 'pegasus_entailment': 0.6447470684846243, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37681159420289856, 'r1_recall': 0.4727272727272727, 'r1_f1': 0.41935483870967744, 'pegasus_entailment': 0.7809694111347198, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5053763440860215, 'r1_recall': 0.5108695652173914, 'r1_f1': 0.508108108108108, 'pegasus_entailment': 0.5922582944234213, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46153846153846156, 'r1_recall': 0.42, 'r1_f1': 0.4397905759162304, 'pegasus_entailment': 0.7536548872788748, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.358695652173913, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.4099378881987578, 'pegasus_entailment': 0.7042716344197592, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5376344086021505, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.5570486970245838, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3617021276595745, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.3469387755102041, 'pegasus_entailment': 0.7273746579885483, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4205607476635514, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.47120418848167533, 'pegasus_entailment': 0.8186355630556742, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1744186046511628, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.26785714285714285, 'pegasus_entailment': 0.6965209186077118, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6883116883116883, 'r1_recall': 0.3706293706293706, 'r1_f1': 0.48181818181818176, 'pegasus_entailment': 0.6517106592655182, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45535714285714285, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.5125628140703518, 'pegasus_entailment': 0.7101704776287079, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3153153153153153, 'r1_recall': 0.6481481481481481, 'r1_f1': 0.42424242424242425, 'pegasus_entailment': 0.4265016441543897, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5638297872340425, 'r1_recall': 0.4380165289256198, 'r1_f1': 0.4930232558139534, 'pegasus_entailment': 0.5597939218084017, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33695652173913043, 'r1_recall': 0.2980769230769231, 'r1_f1': 0.31632653061224486, 'pegasus_entailment': 0.28346450813114643, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24855491329479767, 'r1_recall': 0.6142857142857143, 'r1_f1': 0.35390946502057613, 'pegasus_entailment': 0.7210965553919474, 'pegasus_flesch_kincaid': 31, 'pegasus_coleman_liau': 19, 'pegasus_ari': 36, 'pegasus_smog': 26}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38461538461538464, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.4, 'pegasus_entailment': 0.3473808616399765, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3900709219858156, 'r1_recall': 0.6179775280898876, 'r1_f1': 0.4782608695652174, 'pegasus_entailment': 0.5744590684771538, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.17777777777777778, 'r1_recall': 0.35555555555555557, 'r1_f1': 0.23703703703703705, 'pegasus_entailment': 0.5580895096063614, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5213675213675214, 'r1_recall': 0.5922330097087378, 'r1_f1': 0.5545454545454545, 'pegasus_entailment': 0.5001824796199799, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.10084033613445378, 'r1_recall': 0.34285714285714286, 'r1_f1': 0.15584415584415587, 'pegasus_entailment': 0.6785400450229645, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3118279569892473, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.42028985507246375, 'pegasus_entailment': 0.6629041910171509, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30303030303030304, 'r1_recall': 0.7692307692307693, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.37704103253781796, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45098039215686275, 'r1_recall': 0.3108108108108108, 'r1_f1': 0.368, 'pegasus_entailment': 0.3386633090674877, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6447368421052632, 'r1_recall': 0.4260869565217391, 'r1_f1': 0.5130890052356022, 'pegasus_entailment': 0.39899813880523044, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.589041095890411, 'r1_recall': 0.4479166666666667, 'r1_f1': 0.5088757396449705, 'pegasus_entailment': 0.5281783975660801, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.6422018348623854, 'r1_f1': 0.5622489959839357, 'pegasus_entailment': 0.5147545430809259, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6551724137931034, 'r1_recall': 0.41304347826086957, 'r1_f1': 0.5066666666666666, 'pegasus_entailment': 0.4817139506340027, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8555555555555555, 'r1_recall': 0.21875, 'r1_f1': 0.34841628959276016, 'pegasus_entailment': 0.8089087903499603, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3225806451612903, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.4040404040404041, 'pegasus_entailment': 0.6430126011371613, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5975609756097561, 'r1_recall': 0.3288590604026846, 'r1_f1': 0.4242424242424243, 'pegasus_entailment': 0.7270730286836624, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.37583892617449666, 'r1_f1': 0.4571428571428572, 'pegasus_entailment': 0.6248853951692581, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2235294117647059, 'r1_recall': 0.3877551020408163, 'r1_f1': 0.28358208955223885, 'pegasus_entailment': 0.5479617317517599, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27325581395348836, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.38524590163934425, 'pegasus_entailment': 0.5382859706878662, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 22}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.4368932038834952, 'pegasus_entailment': 0.7412221307555834, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6821705426356589, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.6308243727598566, 'pegasus_entailment': 0.697112786769867, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.411214953271028, 'r1_recall': 0.6567164179104478, 'r1_f1': 0.5057471264367815, 'pegasus_entailment': 0.4630494648590684, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7227722772277227, 'r1_recall': 0.42441860465116277, 'r1_f1': 0.5347985347985347, 'pegasus_entailment': 0.49379144608974457, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32323232323232326, 'r1_recall': 0.43243243243243246, 'r1_f1': 0.3699421965317919, 'pegasus_entailment': 0.488835205634435, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.4691358024691358, 'r1_f1': 0.3897435897435897, 'pegasus_entailment': 0.793456494808197, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5363636363636364, 'r1_recall': 0.41843971631205673, 'r1_f1': 0.47011952191235057, 'pegasus_entailment': 0.8380859891573588, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4444444444444444, 'r1_recall': 0.42748091603053434, 'r1_f1': 0.43579766536964976, 'pegasus_entailment': 0.6536489129066467, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6213592233009708, 'r1_recall': 0.3004694835680751, 'r1_f1': 0.4050632911392405, 'pegasus_entailment': 0.6893047317862511, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 21}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3717948717948718, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.47154471544715454, 'pegasus_entailment': 0.5126483082771301, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5588235294117647, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.608, 'pegasus_entailment': 0.21815470606088638, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5032679738562091, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.4502923976608187, 'pegasus_entailment': 0.44607687890529635, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.61, 'r1_recall': 0.20065789473684212, 'r1_f1': 0.30198019801980197, 'pegasus_entailment': 0.41280115619301794, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30666666666666664, 'r1_recall': 0.36507936507936506, 'r1_f1': 0.33333333333333326, 'pegasus_entailment': 0.37576694786548615, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.427536231884058, 'r1_recall': 0.6210526315789474, 'r1_f1': 0.5064377682403434, 'pegasus_entailment': 0.47248690128326415, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5961538461538461, 'r1_recall': 0.3924050632911392, 'r1_f1': 0.47328244274809156, 'pegasus_entailment': 0.3918276329835256, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30434782608695654, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.3733333333333333, 'pegasus_entailment': 0.7349880337715149, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6619718309859155, 'r1_recall': 0.2596685082872928, 'r1_f1': 0.373015873015873, 'pegasus_entailment': 0.6812121629714966, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 13}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4953271028037383, 'r1_recall': 0.3732394366197183, 'r1_f1': 0.42570281124497994, 'pegasus_entailment': 0.4854816819541156, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4946236559139785, 'r1_recall': 0.4842105263157895, 'r1_f1': 0.4893617021276596, 'pegasus_entailment': 0.49585745483636856, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5409836065573771, 'r1_recall': 0.38372093023255816, 'r1_f1': 0.44897959183673475, 'pegasus_entailment': 0.6189742162823677, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2348993288590604, 'r1_recall': 0.49295774647887325, 'r1_f1': 0.3181818181818182, 'pegasus_entailment': 0.7055622488260269, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7741935483870968, 'r1_recall': 0.34615384615384615, 'r1_f1': 0.47840531561461797, 'pegasus_entailment': 0.5573438704013824, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4632352941176471, 'r1_recall': 0.6774193548387096, 'r1_f1': 0.5502183406113537, 'pegasus_entailment': 0.8109116355578104, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 19}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.308411214953271, 'r1_recall': 0.44, 'r1_f1': 0.3626373626373626, 'pegasus_entailment': 0.7793782353401184, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5494505494505495, 'r1_recall': 0.704225352112676, 'r1_f1': 0.6172839506172839, 'pegasus_entailment': 0.40902961492538453, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49333333333333335, 'r1_recall': 0.36633663366336633, 'r1_f1': 0.42045454545454547, 'pegasus_entailment': 0.42507406510412693, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.684931506849315, 'r1_recall': 0.4830917874396135, 'r1_f1': 0.56657223796034, 'pegasus_entailment': 0.7533052325248718, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36363636363636365, 'r1_recall': 0.5490196078431373, 'r1_f1': 0.43750000000000006, 'pegasus_entailment': 0.517834797501564, 'pegasus_flesch_kincaid': 36, 'pegasus_coleman_liau': 17, 'pegasus_ari': 45, 'pegasus_smog': 24}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2857142857142857, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.37209302325581395, 'pegasus_entailment': 0.7366804281870524, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.5112359550561798, 'r1_f1': 0.5449101796407186, 'pegasus_entailment': 0.5300587763388952, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4358974358974359, 'r1_recall': 0.4657534246575342, 'r1_f1': 0.45033112582781454, 'pegasus_entailment': 0.3838203027844429, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2891566265060241, 'r1_recall': 0.631578947368421, 'r1_f1': 0.396694214876033, 'pegasus_entailment': 0.6430477897326151, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5526315789473685, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.6146341463414634, 'pegasus_entailment': 0.5911403894424438, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49056603773584906, 'r1_recall': 0.43333333333333335, 'r1_f1': 0.46017699115044247, 'pegasus_entailment': 0.6605715692043305, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7967479674796748, 'r1_recall': 0.13900709219858157, 'r1_f1': 0.23671497584541065, 'pegasus_entailment': 0.6277537435526028, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5764705882352941, 'r1_recall': 0.34507042253521125, 'r1_f1': 0.4317180616740088, 'pegasus_entailment': 0.6852381378412247, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6019417475728155, 'r1_recall': 0.33879781420765026, 'r1_f1': 0.4335664335664336, 'pegasus_entailment': 0.5498359426856041, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4528301886792453, 'r1_recall': 0.5161290322580645, 'r1_f1': 0.4824120603015076, 'pegasus_entailment': 0.5069712121039629, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43023255813953487, 'r1_recall': 0.6379310344827587, 'r1_f1': 0.5138888888888888, 'pegasus_entailment': 0.44695581775158644, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43564356435643564, 'r1_recall': 0.676923076923077, 'r1_f1': 0.5301204819277109, 'pegasus_entailment': 0.43928880989551544, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.532258064516129, 'r1_recall': 0.42038216560509556, 'r1_f1': 0.4697508896797153, 'pegasus_entailment': 0.6035769134759903, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23469387755102042, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.31506849315068497, 'pegasus_entailment': 0.552516108751297, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4157303370786517, 'r1_recall': 0.38144329896907214, 'r1_f1': 0.3978494623655914, 'pegasus_entailment': 0.5251320004463196, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.2782608695652174, 'pegasus_entailment': 0.2869273377582431, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5257731958762887, 'r1_f1': 0.5125628140703519, 'pegasus_entailment': 0.9068611413240433, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42592592592592593, 'r1_recall': 0.40707964601769914, 'r1_f1': 0.416289592760181, 'pegasus_entailment': 0.4760657008155249, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6629213483146067, 'r1_recall': 0.43703703703703706, 'r1_f1': 0.5267857142857143, 'pegasus_entailment': 0.19977375073358417, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2535211267605634, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.288, 'pegasus_entailment': 0.3666082337498665, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.368, 'r1_recall': 0.46, 'r1_f1': 0.4088888888888889, 'pegasus_entailment': 0.7696442246437073, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.08333333333333333
MEAN
0.45368173308715803
MAX
0.8623853211009175
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.0684931506849315
MEAN
0.4819224673736361
MAX
0.7931034482758621
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.09803921568627451
MEAN
0.4417281715412319
MAX
0.6792452830188679
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.08133979141712189
MEAN
0.5551492355504287
MAX
0.9206894189119339
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
17
MAX
50
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
11
MEAN
17
MAX
23
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
11
MEAN
20
MAX
61
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
8
MEAN
18
MAX
32
{}
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4084507042253521, 'r1_recall': 0.5272727272727272, 'r1_f1': 0.46031746031746035, 'pegasus_entailment': 0.7724915146827698, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6593406593406593, 'r1_recall': 0.3468208092485549, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.6576289087533951, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.4724409448818897, 'pegasus_entailment': 0.5390811171382666, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7349397590361446, 'r1_recall': 0.4728682170542636, 'r1_f1': 0.5754716981132076, 'pegasus_entailment': 0.4870912486997743, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7029702970297029, 'r1_recall': 0.40804597701149425, 'r1_f1': 0.5163636363636364, 'pegasus_entailment': 0.4424409940838814, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4178082191780822, 'r1_recall': 0.46923076923076923, 'r1_f1': 0.4420289855072464, 'pegasus_entailment': 0.3408838614821434, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16666666666666666, 'r1_recall': 0.375, 'r1_f1': 0.23076923076923078, 'pegasus_entailment': 0.28631126740947366, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22772277227722773, 'r1_recall': 0.7419354838709677, 'r1_f1': 0.3484848484848485, 'pegasus_entailment': 0.5533858048729599, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7415730337078652, 'r1_recall': 0.4429530201342282, 'r1_f1': 0.5546218487394958, 'pegasus_entailment': 0.47559825237840414, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6428571428571429, 'r1_recall': 0.5869565217391305, 'r1_f1': 0.6136363636363638, 'pegasus_entailment': 0.6252761855721474, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7027027027027027, 'r1_recall': 0.3466666666666667, 'r1_f1': 0.46428571428571436, 'pegasus_entailment': 0.516546007245779, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5892857142857143, 'r1_recall': 0.5546218487394958, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.889235277970632, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7887323943661971, 'r1_recall': 0.5233644859813084, 'r1_f1': 0.6292134831460674, 'pegasus_entailment': 0.7453572247177362, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5873015873015873, 'r1_recall': 0.42045454545454547, 'r1_f1': 0.4900662251655629, 'pegasus_entailment': 0.7580639521280924, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8701298701298701, 'r1_recall': 0.3489583333333333, 'r1_f1': 0.4981412639405205, 'pegasus_entailment': 0.655083179473877, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21052631578947367, 'r1_recall': 0.2033898305084746, 'r1_f1': 0.20689655172413796, 'pegasus_entailment': 0.6182583371798197, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4722222222222222, 'r1_recall': 0.3434343434343434, 'r1_f1': 0.39766081871345027, 'pegasus_entailment': 0.6825147171815237, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7951807228915663, 'r1_recall': 0.2214765100671141, 'r1_f1': 0.3464566929133859, 'pegasus_entailment': 0.38432972878217697, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6639344262295082, 'r1_recall': 0.5031055900621118, 'r1_f1': 0.5724381625441696, 'pegasus_entailment': 0.42666998878121376, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5494505494505495, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.5617977528089888, 'pegasus_entailment': 0.5804827511310577, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6194690265486725, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.47457627118644063, 'pegasus_entailment': 0.4292094074189663, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5693430656934306, 'r1_recall': 0.52, 'r1_f1': 0.5435540069686411, 'pegasus_entailment': 0.6179236595829328, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3963963963963964, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.4018264840182648, 'pegasus_entailment': 0.69203253587087, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 26}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6810344827586207, 'r1_recall': 0.5808823529411765, 'r1_f1': 0.626984126984127, 'pegasus_entailment': 0.5345117092132569, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3723404255319149, 'r1_recall': 0.7, 'r1_f1': 0.48611111111111105, 'pegasus_entailment': 0.6895427651082476, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6201117318435754, 'r1_recall': 0.5873015873015873, 'r1_f1': 0.6032608695652174, 'pegasus_entailment': 0.482532124966383, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5811965811965812, 'r1_recall': 0.49635036496350365, 'r1_f1': 0.5354330708661418, 'pegasus_entailment': 0.5321875838562846, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8620689655172413, 'r1_recall': 0.2798507462686567, 'r1_f1': 0.4225352112676056, 'pegasus_entailment': 0.6074931671222051, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42592592592592593, 'r1_recall': 0.3026315789473684, 'r1_f1': 0.3538461538461538, 'pegasus_entailment': 0.8554395437240601, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 12, 'pegasus_ari': 12, 'pegasus_smog': 11}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40404040404040403, 'r1_recall': 0.35398230088495575, 'r1_f1': 0.3773584905660377, 'pegasus_entailment': 0.5586630403995514, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 15, 'pegasus_ari': 30, 'pegasus_smog': 19}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4818181818181818, 'r1_recall': 0.6091954022988506, 'r1_f1': 0.5380710659898478, 'pegasus_entailment': 0.7331172972917557, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5688073394495413, 'r1_recall': 0.30845771144278605, 'r1_f1': 0.4, 'pegasus_entailment': 0.5389385223388672, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2708333333333333, 'r1_recall': 0.3786407766990291, 'r1_f1': 0.3157894736842105, 'pegasus_entailment': 0.6817261576652527, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6268656716417911, 'r1_recall': 0.4329896907216495, 'r1_f1': 0.5121951219512195, 'pegasus_entailment': 0.4571133553981781, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42016806722689076, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.49261083743842365, 'pegasus_entailment': 0.24310313016176224, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44, 'r1_recall': 0.5689655172413793, 'r1_f1': 0.49624060150375937, 'pegasus_entailment': 0.5995419124762217, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 16, 'pegasus_ari': 31, 'pegasus_smog': 22}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4824561403508772, 'r1_recall': 0.7971014492753623, 'r1_f1': 0.6010928961748634, 'pegasus_entailment': 0.3558418992906809, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3392857142857143, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.4222222222222223, 'pegasus_entailment': 0.7086844330769964, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2158273381294964, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.32608695652173914, 'pegasus_entailment': 0.5585499167442322, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5027027027027027, 'r1_recall': 0.5602409638554217, 'r1_f1': 0.5299145299145298, 'pegasus_entailment': 0.5907276675105095, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7029702970297029, 'r1_recall': 0.44375, 'r1_f1': 0.5440613026819924, 'pegasus_entailment': 0.6363784652203321, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5967741935483871, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.5323741007194245, 'pegasus_entailment': 0.6368355502684911, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5733333333333334, 'r1_recall': 0.589041095890411, 'r1_f1': 0.5810810810810811, 'pegasus_entailment': 0.4572935209920009, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8, 'r1_recall': 0.5203252032520326, 'r1_f1': 0.6305418719211824, 'pegasus_entailment': 0.8583741585413615, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3684210526315789, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.4046242774566474, 'pegasus_entailment': 0.6639065742492676, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4692737430167598, 'r1_recall': 0.56, 'r1_f1': 0.5106382978723405, 'pegasus_entailment': 0.47598588466644287, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.61, 'r1_recall': 0.5169491525423728, 'r1_f1': 0.5596330275229358, 'pegasus_entailment': 0.5543049506377429, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.7027027027027027, 'r1_f1': 0.5098039215686274, 'pegasus_entailment': 0.7242395494665418, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3708609271523179, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.47659574468085103, 'pegasus_entailment': 0.554472331268092, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3983739837398374, 'r1_recall': 0.47115384615384615, 'r1_f1': 0.4317180616740089, 'pegasus_entailment': 0.49961447566747663, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3082706766917293, 'r1_recall': 0.5540540540540541, 'r1_f1': 0.3961352657004831, 'pegasus_entailment': 0.5740776658058167, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24427480916030533, 'r1_recall': 0.6274509803921569, 'r1_f1': 0.3516483516483516, 'pegasus_entailment': 0.6189645236978928, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35537190082644626, 'r1_recall': 0.581081081081081, 'r1_f1': 0.441025641025641, 'pegasus_entailment': 0.4952914547175169, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.3107344632768362, 'r1_f1': 0.4119850187265918, 'pegasus_entailment': 0.2732164611419042, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6642857142857143, 'r1_recall': 0.5224719101123596, 'r1_f1': 0.5849056603773586, 'pegasus_entailment': 0.3126731589436531, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42727272727272725, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.5164835164835165, 'pegasus_entailment': 0.5515370219945908, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6196319018404908, 'r1_recall': 0.40239043824701193, 'r1_f1': 0.48792270531400955, 'pegasus_entailment': 0.5853856280446053, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39090909090909093, 'r1_recall': 0.671875, 'r1_f1': 0.4942528735632184, 'pegasus_entailment': 0.5879095159471035, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.6115702479338843, 'r1_f1': 0.6379310344827586, 'pegasus_entailment': 0.44853512570261955, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5918367346938775, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.30873304853836697, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42391304347826086, 'r1_recall': 0.4431818181818182, 'r1_f1': 0.4333333333333333, 'pegasus_entailment': 0.8287956515947977, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4358974358974359, 'r1_recall': 0.4722222222222222, 'r1_f1': 0.45333333333333337, 'pegasus_entailment': 0.3628084361553192, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5268817204301075, 'r1_recall': 0.2916666666666667, 'r1_f1': 0.3754789272030651, 'pegasus_entailment': 0.6636510118842125, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3894736842105263, 'r1_recall': 0.38144329896907214, 'r1_f1': 0.38541666666666663, 'pegasus_entailment': 0.6726335237423579, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30526315789473685, 'r1_recall': 0.6041666666666666, 'r1_f1': 0.4055944055944056, 'pegasus_entailment': 0.26413025458653766, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7254901960784313, 'r1_recall': 0.5826771653543307, 'r1_f1': 0.6462882096069869, 'pegasus_entailment': 0.5024576857686043, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31794871794871793, 'r1_recall': 0.5849056603773585, 'r1_f1': 0.4119601328903654, 'pegasus_entailment': 0.9247671961784363, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 24}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4097222222222222, 'r1_recall': 0.6145833333333334, 'r1_f1': 0.49166666666666664, 'pegasus_entailment': 0.3526182036846876, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6082474226804123, 'r1_recall': 0.5130434782608696, 'r1_f1': 0.5566037735849056, 'pegasus_entailment': 0.2738933617947623, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7230769230769231, 'r1_recall': 0.46078431372549017, 'r1_f1': 0.562874251497006, 'pegasus_entailment': 0.6452730645736059, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4327485380116959, 'r1_recall': 0.4457831325301205, 'r1_f1': 0.4391691394658754, 'pegasus_entailment': 0.6009947001934052, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2971014492753623, 'r1_recall': 0.6029411764705882, 'r1_f1': 0.3980582524271844, 'pegasus_entailment': 0.4221682965755463, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2972972972972973, 'r1_recall': 0.5, 'r1_f1': 0.3728813559322034, 'pegasus_entailment': 0.2889961926266551, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6638655462184874, 'r1_recall': 0.41578947368421054, 'r1_f1': 0.511326860841424, 'pegasus_entailment': 0.6325911656022072, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25280898876404495, 'r1_recall': 0.625, 'r1_f1': 0.36, 'pegasus_entailment': 0.24065336678177118, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.379746835443038, 'r1_recall': 0.7058823529411765, 'r1_f1': 0.49382716049382724, 'pegasus_entailment': 0.3533804578972714, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29357798165137616, 'r1_recall': 0.5, 'r1_f1': 0.36994219653179194, 'pegasus_entailment': 0.9561551511287689, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5818181818181818, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5981308411214953, 'pegasus_entailment': 0.49981139476100606, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5181818181818182, 'r1_recall': 0.6627906976744186, 'r1_f1': 0.5816326530612245, 'pegasus_entailment': 0.5459788478910923, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5223880597014925, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.5223880597014925, 'pegasus_entailment': 0.8432019501924515, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5180722891566265, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.5341614906832298, 'pegasus_entailment': 0.29760339111089706, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.71, 'r1_recall': 0.6893203883495146, 'r1_f1': 0.6995073891625615, 'pegasus_entailment': 0.3805353989203771, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.43243243243243246, 'pegasus_entailment': 0.44439053535461426, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.527027027027027, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.48447204968944096, 'pegasus_entailment': 0.9556332528591156, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5309734513274337, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.5853658536585366, 'pegasus_entailment': 0.4753687207897504, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3619047619047619, 'r1_recall': 0.4367816091954023, 'r1_f1': 0.39583333333333337, 'pegasus_entailment': 0.7331586927175522, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2716049382716049, 'r1_recall': 0.28205128205128205, 'r1_f1': 0.27672955974842767, 'pegasus_entailment': 0.42119892438252765, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2719298245614035, 'r1_recall': 0.6888888888888889, 'r1_f1': 0.389937106918239, 'pegasus_entailment': 0.8661567717790604, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7634408602150538, 'r1_recall': 0.34134615384615385, 'r1_f1': 0.4717607973421926, 'pegasus_entailment': 0.4846502721309662, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47191011235955055, 'r1_recall': 0.6, 'r1_f1': 0.5283018867924529, 'pegasus_entailment': 0.22750169615028426, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.5729166666666666, 'r1_f1': 0.5641025641025641, 'pegasus_entailment': 0.8042283654212952, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 33, 'pegasus_smog': 27}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425, 'r1_recall': 0.3805970149253731, 'r1_f1': 0.4015748031496063, 'pegasus_entailment': 0.42347376700490713, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 13}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31343283582089554, 'r1_recall': 0.5753424657534246, 'r1_f1': 0.4057971014492754, 'pegasus_entailment': 0.4569806487299502, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5094339622641509, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.484304932735426, 'pegasus_entailment': 0.44477460446069017, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.15463917525773196, 'r1_f1': 0.2307692307692308, 'pegasus_entailment': 0.9775312542915344, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4424778761061947, 'r1_recall': 0.5649717514124294, 'r1_f1': 0.4962779156327544, 'pegasus_entailment': 0.6841746978461742, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47572815533980584, 'r1_recall': 0.5051546391752577, 'r1_f1': 0.49, 'pegasus_entailment': 0.4672451963027318, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5306122448979592, 'r1_recall': 0.4126984126984127, 'r1_f1': 0.4642857142857143, 'pegasus_entailment': 0.7804876963297526, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3490566037735849, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.4327485380116959, 'pegasus_entailment': 0.6252047084271908, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3867924528301887, 'r1_recall': 0.36607142857142855, 'r1_f1': 0.37614678899082565, 'pegasus_entailment': 0.5853602214095494, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37681159420289856, 'r1_recall': 0.4262295081967213, 'r1_f1': 0.4, 'pegasus_entailment': 0.22727882644782463, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4639175257731959, 'r1_recall': 0.4787234042553192, 'r1_f1': 0.47120418848167545, 'pegasus_entailment': 0.7710384353995323, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5233644859813084, 'r1_recall': 0.48695652173913045, 'r1_f1': 0.5045045045045046, 'pegasus_entailment': 0.8629238605499268, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.547945205479452, 'r1_recall': 0.35714285714285715, 'r1_f1': 0.4324324324324324, 'pegasus_entailment': 0.7307569682598114, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3505747126436782, 'r1_recall': 0.7625, 'r1_f1': 0.4803149606299212, 'pegasus_entailment': 0.6758878976106644, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6710526315789473, 'r1_recall': 0.3953488372093023, 'r1_f1': 0.49756097560975604, 'pegasus_entailment': 0.44810023307800295, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49166666666666664, 'r1_recall': 0.5728155339805825, 'r1_f1': 0.5291479820627802, 'pegasus_entailment': 0.7231589108705521, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6979166666666666, 'r1_recall': 0.41875, 'r1_f1': 0.5234375, 'pegasus_entailment': 0.45678095519542694, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3790322580645161, 'r1_recall': 0.6266666666666667, 'r1_f1': 0.4723618090452261, 'pegasus_entailment': 0.6298145682667382, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34375, 'r1_recall': 0.55, 'r1_f1': 0.42307692307692313, 'pegasus_entailment': 0.6714966495831808, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.6040268456375839, 'pegasus_entailment': 0.927316352725029, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6020408163265306, 'r1_recall': 0.44360902255639095, 'r1_f1': 0.5108225108225107, 'pegasus_entailment': 0.22826587967574596, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7213114754098361, 'r1_recall': 0.5569620253164557, 'r1_f1': 0.6285714285714286, 'pegasus_entailment': 0.4885687637142837, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46956521739130436, 'r1_recall': 0.6067415730337079, 'r1_f1': 0.5294117647058824, 'pegasus_entailment': 0.6052300110459328, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.46923076923076923, 'r1_f1': 0.48412698412698413, 'pegasus_entailment': 0.6423696019919589, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851851851851851, 'r1_recall': 0.4438202247191011, 'r1_f1': 0.5047923322683706, 'pegasus_entailment': 0.6357724666595459, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7575757575757576, 'r1_recall': 0.42613636363636365, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.7660873532295227, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 19, 'pegasus_ari': 33, 'pegasus_smog': 23}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5841584158415841, 'r1_recall': 0.44029850746268656, 'r1_f1': 0.502127659574468, 'pegasus_entailment': 0.4436695694923401, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5092592592592593, 'r1_recall': 0.5851063829787234, 'r1_f1': 0.5445544554455446, 'pegasus_entailment': 0.5841448467690498, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6923076923076923, 'r1_recall': 0.3543307086614173, 'r1_f1': 0.46874999999999994, 'pegasus_entailment': 0.8002045949300131, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4766355140186916, 'r1_recall': 0.5795454545454546, 'r1_f1': 0.5230769230769231, 'pegasus_entailment': 0.7382049262523651, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5365853658536586, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.5546218487394958, 'pegasus_entailment': 0.7433254917462667, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 19}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39814814814814814, 'r1_recall': 0.5657894736842105, 'r1_f1': 0.46739130434782605, 'pegasus_entailment': 0.6243456929922104, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23232323232323232, 'r1_recall': 0.5348837209302325, 'r1_f1': 0.32394366197183094, 'pegasus_entailment': 0.45122377946972847, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7555555555555555, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.6732673267326731, 'pegasus_entailment': 0.9478484193483988, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5419847328244275, 'r1_recall': 0.5419847328244275, 'r1_f1': 0.5419847328244275, 'pegasus_entailment': 0.4712727442383766, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26, 'r1_recall': 0.65, 'r1_f1': 0.37142857142857144, 'pegasus_entailment': 0.47108266362920403, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.552, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.5702479338842975, 'pegasus_entailment': 0.9169735511144003, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 15, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5035460992907801, 'r1_recall': 0.6120689655172413, 'r1_f1': 0.5525291828793774, 'pegasus_entailment': 0.5796971842646599, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5256410256410257, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.5985401459854015, 'pegasus_entailment': 0.5310210337241491, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6834532374100719, 'r1_recall': 0.5026455026455027, 'r1_f1': 0.5792682926829269, 'pegasus_entailment': 0.1277024628361687, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.5950413223140496, 'r1_f1': 0.5255474452554746, 'pegasus_entailment': 0.9823962251345316, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 25}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.578125, 'r1_recall': 0.4774193548387097, 'r1_f1': 0.5229681978798586, 'pegasus_entailment': 0.8744952082633972, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6583333333333333, 'r1_recall': 0.48466257668711654, 'r1_f1': 0.5583038869257951, 'pegasus_entailment': 0.6053387373685837, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.475, 'r1_recall': 0.5643564356435643, 'r1_f1': 0.5158371040723981, 'pegasus_entailment': 0.5533628523349762, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4198895027624309, 'r1_recall': 0.628099173553719, 'r1_f1': 0.5033112582781457, 'pegasus_entailment': 0.7204168289899826, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5510204081632653, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.5654450261780105, 'pegasus_entailment': 0.6203324645757675, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6530612244897959, 'r1_recall': 0.48120300751879697, 'r1_f1': 0.5541125541125541, 'pegasus_entailment': 0.7693269610404968, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7019230769230769, 'r1_recall': 0.3945945945945946, 'r1_f1': 0.5051903114186851, 'pegasus_entailment': 0.6054031848907471, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3644859813084112, 'r1_recall': 0.6724137931034483, 'r1_f1': 0.4727272727272727, 'pegasus_entailment': 0.5255739882588386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39473684210526316, 'r1_recall': 0.5113636363636364, 'r1_f1': 0.44554455445544555, 'pegasus_entailment': 0.46424571610987186, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4782608695652174, 'r1_recall': 0.4731182795698925, 'r1_f1': 0.4756756756756757, 'pegasus_entailment': 0.3810370812813441, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53, 'r1_recall': 0.4690265486725664, 'r1_f1': 0.4976525821596244, 'pegasus_entailment': 0.7582129836082458, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5098039215686274, 'r1_recall': 0.65, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.6757595837116241, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.5436893203883496, 'pegasus_entailment': 0.5713955760002136, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6201550387596899, 'r1_recall': 0.3827751196172249, 'r1_f1': 0.47337278106508873, 'pegasus_entailment': 0.6067440658807755, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.660377358490566, 'r1_recall': 0.3867403314917127, 'r1_f1': 0.48780487804878053, 'pegasus_entailment': 0.44900578757127124, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3717948717948718, 'r1_recall': 0.4915254237288136, 'r1_f1': 0.4233576642335766, 'pegasus_entailment': 0.813797652721405, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7981651376146789, 'r1_recall': 0.5370370370370371, 'r1_f1': 0.6420664206642067, 'pegasus_entailment': 0.4584514629095793, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3923076923076923, 'r1_recall': 0.6219512195121951, 'r1_f1': 0.48113207547169806, 'pegasus_entailment': 0.37593673914670944, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43037974683544306, 'r1_recall': 0.3541666666666667, 'r1_f1': 0.3885714285714286, 'pegasus_entailment': 0.5583342090249062, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44881889763779526, 'r1_recall': 0.6195652173913043, 'r1_f1': 0.5205479452054794, 'pegasus_entailment': 0.4178726593963802, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7766990291262136, 'r1_recall': 0.41237113402061853, 'r1_f1': 0.5387205387205387, 'pegasus_entailment': 0.45479800179600716, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5370370370370371, 'r1_recall': 0.3493975903614458, 'r1_f1': 0.4233576642335767, 'pegasus_entailment': 0.41829054057598114, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33064516129032256, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.44808743169398907, 'pegasus_entailment': 0.7514328161875407, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6271186440677966, 'r1_recall': 0.4277456647398844, 'r1_f1': 0.5085910652920962, 'pegasus_entailment': 0.4022599846124649, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4626865671641791, 'r1_recall': 0.38271604938271603, 'r1_f1': 0.41891891891891897, 'pegasus_entailment': 0.6580566229919592, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5034965034965035, 'r1_recall': 0.48322147651006714, 'r1_f1': 0.49315068493150693, 'pegasus_entailment': 0.8055967092514038, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5747126436781609, 'r1_recall': 0.5376344086021505, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.27868172415765, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.33540372670807456, 'r1_f1': 0.4202334630350195, 'pegasus_entailment': 0.2320029828697443, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21739130434782608, 'r1_recall': 0.2631578947368421, 'r1_f1': 0.23809523809523808, 'pegasus_entailment': 0.9635570049285889, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 24, 'pegasus_ari': 35, 'pegasus_smog': 28}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5728155339805825, 'r1_recall': 0.5462962962962963, 'r1_f1': 0.5592417061611374, 'pegasus_entailment': 0.7289799526333809, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37572254335260113, 'r1_recall': 0.6310679611650486, 'r1_f1': 0.47101449275362317, 'pegasus_entailment': 0.869426429271698, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.654320987654321, 'r1_recall': 0.32515337423312884, 'r1_f1': 0.43442622950819676, 'pegasus_entailment': 0.6885570958256721, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5742574257425742, 'r1_recall': 0.5321100917431193, 'r1_f1': 0.5523809523809524, 'pegasus_entailment': 0.5509080678224564, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48863636363636365, 'r1_recall': 0.48863636363636365, 'r1_f1': 0.48863636363636365, 'pegasus_entailment': 0.4277232617139816, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43010752688172044, 'r1_recall': 0.26666666666666666, 'r1_f1': 0.3292181069958848, 'pegasus_entailment': 0.8380877176920573, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5089820359281437, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.5537459283387622, 'pegasus_entailment': 0.5460172792275747, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5080645161290323, 'r1_recall': 0.4228187919463087, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.6134821996092796, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48598130841121495, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5252525252525252, 'pegasus_entailment': 0.5923701326052347, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3805970149253731, 'r1_recall': 0.6623376623376623, 'r1_f1': 0.4834123222748815, 'pegasus_entailment': 0.5072733014822006, 'pegasus_flesch_kincaid': 33, 'pegasus_coleman_liau': 19, 'pegasus_ari': 41, 'pegasus_smog': 25}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39166666666666666, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.48704663212435234, 'pegasus_entailment': 0.620512424968183, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6896551724137931, 'r1_recall': 0.16304347826086957, 'r1_f1': 0.26373626373626374, 'pegasus_entailment': 0.5534291565418243, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.4909090909090909, 'r1_f1': 0.5167464114832535, 'pegasus_entailment': 0.6389245775838693, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5402298850574713, 'r1_recall': 0.3790322580645161, 'r1_f1': 0.44549763033175355, 'pegasus_entailment': 0.6536457240581512, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47468354430379744, 'r1_recall': 0.625, 'r1_f1': 0.539568345323741, 'pegasus_entailment': 0.5750852167606354, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7865168539325843, 'r1_recall': 0.2978723404255319, 'r1_f1': 0.4320987654320988, 'pegasus_entailment': 0.6572804339230061, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5100671140939598, 'r1_recall': 0.5, 'r1_f1': 0.5049833887043189, 'pegasus_entailment': 0.27998129092156887, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3089887640449438, 'r1_recall': 0.6395348837209303, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.528675944233934, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34408602150537637, 'r1_recall': 0.4266666666666667, 'r1_f1': 0.38095238095238104, 'pegasus_entailment': 0.6376828327775002, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41904761904761906, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.4512820512820513, 'pegasus_entailment': 0.9024880528450012, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6708860759493671, 'r1_recall': 0.3231707317073171, 'r1_f1': 0.43621399176954734, 'pegasus_entailment': 0.7083357274532318, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7829457364341085, 'r1_recall': 0.3519163763066202, 'r1_f1': 0.4855769230769231, 'pegasus_entailment': 0.41632277199200224, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6847826086956522, 'r1_recall': 0.35195530726256985, 'r1_f1': 0.46494464944649444, 'pegasus_entailment': 0.49718244187533855, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5752212389380531, 'r1_recall': 0.5701754385964912, 'r1_f1': 0.5726872246696035, 'pegasus_entailment': 0.6546744108200073, 'pegasus_flesch_kincaid': 52, 'pegasus_coleman_liau': 19, 'pegasus_ari': 64, 'pegasus_smog': 34}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6707317073170732, 'r1_recall': 0.4230769230769231, 'r1_f1': 0.5188679245283019, 'pegasus_entailment': 0.6752978463967642, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4661016949152542, 'r1_recall': 0.5288461538461539, 'r1_f1': 0.4954954954954955, 'pegasus_entailment': 0.3866795152425766, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3221476510067114, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.41201716738197425, 'pegasus_entailment': 0.9566343665122986, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6759259259259259, 'r1_recall': 0.4506172839506173, 'r1_f1': 0.5407407407407409, 'pegasus_entailment': 0.7148935596148173, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5897435897435898, 'r1_recall': 0.5974025974025974, 'r1_f1': 0.5935483870967742, 'pegasus_entailment': 0.4566979742376134, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.552, 'pegasus_entailment': 0.42761924816295505, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6133333333333333, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.6133333333333333, 'pegasus_entailment': 0.4594133794307709, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5688073394495413, 'r1_recall': 0.512396694214876, 'r1_f1': 0.5391304347826087, 'pegasus_entailment': 0.7448178589344024, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8082191780821918, 'r1_recall': 0.5315315315315315, 'r1_f1': 0.641304347826087, 'pegasus_entailment': 0.5455225699891647, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851063829787234, 'r1_recall': 0.3374233128834356, 'r1_f1': 0.42801556420233466, 'pegasus_entailment': 0.18151729305585226, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5779816513761468, 'r1_recall': 0.35795454545454547, 'r1_f1': 0.4421052631578947, 'pegasus_entailment': 0.3454425409436226, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5588235294117647, 'r1_recall': 0.7125, 'r1_f1': 0.6263736263736264, 'pegasus_entailment': 0.7891814609368643, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2636363636363636, 'r1_recall': 0.48333333333333334, 'r1_f1': 0.34117647058823525, 'pegasus_entailment': 0.6165966217716535, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 26}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4375, 'pegasus_entailment': 0.4352775923907757, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4426229508196721, 'r1_recall': 0.5510204081632653, 'r1_f1': 0.49090909090909085, 'pegasus_entailment': 0.33541417121887207, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5531914893617021, 'r1_recall': 0.6, 'r1_f1': 0.5756457564575646, 'pegasus_entailment': 0.617013406008482, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3047619047619048, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.42384105960264906, 'pegasus_entailment': 0.9890740911165873, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.675, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.5567010309278351, 'pegasus_entailment': 0.8306477467219034, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4672131147540984, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.4892703862660944, 'pegasus_entailment': 0.5148066524416208, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6938775510204082, 'r1_recall': 0.4657534246575342, 'r1_f1': 0.5573770491803278, 'pegasus_entailment': 0.4899275004863739, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.611764705882353, 'r1_recall': 0.6341463414634146, 'r1_f1': 0.6227544910179641, 'pegasus_entailment': 0.6797349055608114, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4621212121212121, 'r1_recall': 0.6931818181818182, 'r1_f1': 0.5545454545454546, 'pegasus_entailment': 0.7526635527610779, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5446428571428571, 'r1_recall': 0.6039603960396039, 'r1_f1': 0.5727699530516431, 'pegasus_entailment': 0.17453824058175088, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.472, 'r1_recall': 0.5462962962962963, 'r1_f1': 0.5064377682403434, 'pegasus_entailment': 0.2525451338539521, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2840909090909091, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.36764705882352944, 'pegasus_entailment': 0.27770412736572325, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5280898876404494, 'r1_recall': 0.47474747474747475, 'r1_f1': 0.5, 'pegasus_entailment': 0.584257165590922, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.56, 'r1_recall': 0.35443037974683544, 'r1_f1': 0.434108527131783, 'pegasus_entailment': 0.47310803333918255, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5140845070422535, 'r1_recall': 0.4620253164556962, 'r1_f1': 0.4866666666666667, 'pegasus_entailment': 0.48535676300525665, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5680473372781065, 'r1_recall': 0.49740932642487046, 'r1_f1': 0.5303867403314917, 'pegasus_entailment': 0.31199143330256146, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6885245901639344, 'r1_recall': 0.4, 'r1_f1': 0.5060240963855422, 'pegasus_entailment': 0.6027634143829346, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45569620253164556, 'r1_recall': 0.576, 'r1_f1': 0.5088339222614842, 'pegasus_entailment': 0.6013013064861298, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3409090909090909, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.3208227555733174, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3153153153153153, 'r1_recall': 0.5737704918032787, 'r1_f1': 0.40697674418604646, 'pegasus_entailment': 0.2494944843929261, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4657534246575342, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.5037037037037037, 'pegasus_entailment': 0.9451161424318949, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2702702702702703, 'r1_recall': 0.5084745762711864, 'r1_f1': 0.3529411764705882, 'pegasus_entailment': 0.2992536723613739, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4358974358974359, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.44155844155844154, 'pegasus_entailment': 0.3517903983592987, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4431818181818182, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.41711229946524064, 'pegasus_entailment': 0.6101228147745132, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2815533980582524, 'r1_recall': 0.725, 'r1_f1': 0.40559440559440557, 'pegasus_entailment': 0.6760659019152323, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4371584699453552, 'r1_recall': 0.4624277456647399, 'r1_f1': 0.44943820224719094, 'pegasus_entailment': 0.5536630700031916, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 25}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4351851851851852, 'r1_recall': 0.5875, 'r1_f1': 0.5, 'pegasus_entailment': 0.5107136726379394, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6224489795918368, 'r1_recall': 0.34269662921348315, 'r1_f1': 0.44202898550724645, 'pegasus_entailment': 0.5645067654550076, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7228915662650602, 'r1_recall': 0.37267080745341613, 'r1_f1': 0.49180327868852464, 'pegasus_entailment': 0.28952719643712044, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6076923076923076, 'r1_recall': 0.5895522388059702, 'r1_f1': 0.5984848484848485, 'pegasus_entailment': 0.20588585610191026, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 31, 'pegasus_smog': 26}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6875, 'r1_recall': 0.22633744855967078, 'r1_f1': 0.3405572755417957, 'pegasus_entailment': 0.5585938592751821, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4326923076923077, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.4838709677419355, 'pegasus_entailment': 0.6324315816164017, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 16, 'pegasus_ari': 31, 'pegasus_smog': 20}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49523809523809526, 'r1_recall': 0.34210526315789475, 'r1_f1': 0.4046692607003891, 'pegasus_entailment': 0.48075965978205204, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3211009174311927, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.3867403314917127, 'pegasus_entailment': 0.666877289613088, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5877862595419847, 'r1_recall': 0.3452914798206278, 'r1_f1': 0.4350282485875706, 'pegasus_entailment': 0.5783930346369743, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35714285714285715, 'r1_recall': 0.30973451327433627, 'r1_f1': 0.33175355450236965, 'pegasus_entailment': 0.316874402264754, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3402061855670103, 'r1_recall': 0.717391304347826, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.40247253281995654, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7555555555555555, 'r1_recall': 0.3756906077348066, 'r1_f1': 0.5018450184501846, 'pegasus_entailment': 0.330894747748971, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.686046511627907, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.4486692015209125, 'pegasus_entailment': 0.3104033973067999, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4236111111111111, 'r1_recall': 0.6354166666666666, 'r1_f1': 0.5083333333333334, 'pegasus_entailment': 0.6399297515551249, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6176470588235294, 'r1_recall': 0.43448275862068964, 'r1_f1': 0.5101214574898786, 'pegasus_entailment': 0.8030675768852233, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1450381679389313, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.23899371069182387, 'pegasus_entailment': 0.17203863114118575, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19310344827586207, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.27586206896551724, 'pegasus_entailment': 0.6303148925304413, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.68, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.6210045662100457, 'pegasus_entailment': 0.39496460537581396, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30952380952380953, 'r1_recall': 0.5492957746478874, 'r1_f1': 0.39593908629441626, 'pegasus_entailment': 0.3894849956035614, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.248, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.34444444444444444, 'pegasus_entailment': 0.7146193504333496, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3617021276595745, 'r1_recall': 0.41975308641975306, 'r1_f1': 0.38857142857142857, 'pegasus_entailment': 0.3070040214806795, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.611764705882353, 'r1_recall': 0.6419753086419753, 'r1_f1': 0.6265060240963856, 'pegasus_entailment': 0.8770049413045248, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5063291139240507, 'r1_recall': 0.4819277108433735, 'r1_f1': 0.49382716049382713, 'pegasus_entailment': 0.259297750541009, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5652173913043478, 'r1_recall': 0.46846846846846846, 'r1_f1': 0.5123152709359605, 'pegasus_entailment': 0.3363981540314853, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7961165048543689, 'r1_recall': 0.24404761904761904, 'r1_f1': 0.3735763097949886, 'pegasus_entailment': 0.5112008690834046, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.3108108108108108, 'r1_f1': 0.4207317073170732, 'pegasus_entailment': 0.4609153997153044, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47674418604651164, 'r1_recall': 0.5256410256410257, 'r1_f1': 0.5, 'pegasus_entailment': 0.5324264243245125, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5523809523809524, 'r1_recall': 0.5576923076923077, 'r1_f1': 0.5550239234449761, 'pegasus_entailment': 0.43314006303747493, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21965317919075145, 'r1_recall': 0.5205479452054794, 'r1_f1': 0.30894308943089427, 'pegasus_entailment': 0.5216895192861557, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3228346456692913, 'r1_recall': 0.6307692307692307, 'r1_f1': 0.4270833333333333, 'pegasus_entailment': 0.2945159201820691, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5921052631578947, 'r1_recall': 0.625, 'r1_f1': 0.6081081081081081, 'pegasus_entailment': 0.5674796203772227, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5487804878048781, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.5521472392638037, 'pegasus_entailment': 0.8695265799760818, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4375, 'r1_recall': 0.5526315789473685, 'r1_f1': 0.4883720930232558, 'pegasus_entailment': 0.8834349115689596, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42718446601941745, 'r1_recall': 0.5238095238095238, 'r1_f1': 0.4705882352941177, 'pegasus_entailment': 0.2228782958118245, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7254901960784313, 'r1_recall': 0.4713375796178344, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.7784717231988907, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6886792452830188, 'r1_recall': 0.5069444444444444, 'r1_f1': 0.584, 'pegasus_entailment': 0.5282692015171051, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3411764705882353, 'r1_recall': 0.30851063829787234, 'r1_f1': 0.32402234636871513, 'pegasus_entailment': 0.6005418747663498, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6483516483516484, 'r1_recall': 0.6178010471204188, 'r1_f1': 0.6327077747989276, 'pegasus_entailment': 0.4432292928298314, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3465346534653465, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.9816618164380392, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4492753623188406, 'r1_recall': 0.37349397590361444, 'r1_f1': 0.40789473684210525, 'pegasus_entailment': 0.9005027562379837, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7166666666666667, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.6231884057971016, 'pegasus_entailment': 0.6865303814411163, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 8}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44696969696969696, 'r1_recall': 0.7283950617283951, 'r1_f1': 0.5539906103286385, 'pegasus_entailment': 0.4352083284407854, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5310344827586206, 'r1_recall': 0.5620437956204379, 'r1_f1': 0.5460992907801417, 'pegasus_entailment': 0.7303782254457474, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3076923076923077, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.33333333333333337, 'pegasus_entailment': 0.6575305623312792, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32051282051282054, 'r1_recall': 0.423728813559322, 'r1_f1': 0.3649635036496351, 'pegasus_entailment': 0.46847159415483475, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.4701492537313433, 'r1_f1': 0.4980237154150198, 'pegasus_entailment': 0.5008024135604501, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.358974358974359, 'r1_f1': 0.4534412955465587, 'pegasus_entailment': 0.2949881562963128, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43119266055045874, 'r1_recall': 0.7230769230769231, 'r1_f1': 0.5402298850574713, 'pegasus_entailment': 0.7357929050922394, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4326923076923077, 'r1_recall': 0.5113636363636364, 'r1_f1': 0.46875, 'pegasus_entailment': 0.5529967024922371, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4946236559139785, 'r1_recall': 0.5476190476190477, 'r1_f1': 0.5197740112994351, 'pegasus_entailment': 0.6758133098483086, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3977272727272727, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.4242424242424242, 'pegasus_entailment': 0.5415948955342174, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33858267716535434, 'r1_recall': 0.5375, 'r1_f1': 0.41545893719806765, 'pegasus_entailment': 0.4993847645819187, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5035971223021583, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.4745762711864407, 'pegasus_entailment': 0.45366304895530146, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5063291139240507, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5161290322580646, 'pegasus_entailment': 0.25480619817972183, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3708609271523179, 'r1_recall': 0.6588235294117647, 'r1_f1': 0.47457627118644063, 'pegasus_entailment': 0.46662308648228645, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6730769230769231, 'r1_recall': 0.5343511450381679, 'r1_f1': 0.5957446808510639, 'pegasus_entailment': 0.45500591211020947, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4642857142857143, 'r1_recall': 0.36792452830188677, 'r1_f1': 0.4105263157894737, 'pegasus_entailment': 0.2987853630911559, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5939849624060151, 'r1_recall': 0.43169398907103823, 'r1_f1': 0.5, 'pegasus_entailment': 0.8131778538227081, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4880952380952381, 'r1_recall': 0.5394736842105263, 'r1_f1': 0.5125, 'pegasus_entailment': 0.34397818757376325, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5121951219512195, 'r1_recall': 0.45652173913043476, 'r1_f1': 0.48275862068965514, 'pegasus_entailment': 0.4509930331259966, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7520661157024794, 'r1_recall': 0.4212962962962963, 'r1_f1': 0.5400593471810089, 'pegasus_entailment': 0.2496687311679125, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5949367088607594, 'r1_recall': 0.46534653465346537, 'r1_f1': 0.5222222222222221, 'pegasus_entailment': 0.06338276776174705, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5119047619047619, 'r1_recall': 0.4387755102040816, 'r1_f1': 0.4725274725274725, 'pegasus_entailment': 0.18773385975509882, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5161290322580646, 'pegasus_entailment': 0.6153527131925026, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6990291262135923, 'r1_recall': 0.5413533834586466, 'r1_f1': 0.6101694915254237, 'pegasus_entailment': 0.2906938042433467, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.4, 'r1_f1': 0.4675324675324675, 'pegasus_entailment': 0.2651624729235967, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.3652173913043478, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.49146442785859107, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44329896907216493, 'r1_recall': 0.38738738738738737, 'r1_f1': 0.41346153846153844, 'pegasus_entailment': 0.696148137251536, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7528089887640449, 'r1_recall': 0.4855072463768116, 'r1_f1': 0.5903083700440528, 'pegasus_entailment': 0.6719439923763275, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21782178217821782, 'r1_recall': 0.44, 'r1_f1': 0.2913907284768212, 'pegasus_entailment': 0.32551082223653793, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26573426573426573, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.38190954773869346, 'pegasus_entailment': 0.25152797531336546, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22580645161290322, 'r1_recall': 0.2978723404255319, 'r1_f1': 0.2568807339449541, 'pegasus_entailment': 0.284672349691391, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4411764705882353, 'r1_recall': 0.4225352112676056, 'r1_f1': 0.43165467625899284, 'pegasus_entailment': 0.5144440829753876, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.3005464480874317, 'r1_f1': 0.40293040293040294, 'pegasus_entailment': 0.2458620723336935, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.514018691588785, 'r1_recall': 0.40145985401459855, 'r1_f1': 0.4508196721311475, 'pegasus_entailment': 0.8132250209649404, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 17}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6022727272727273, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.5921787709497207, 'pegasus_entailment': 0.7983407527208328, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5210084033613446, 'r1_recall': 0.46616541353383456, 'r1_f1': 0.49206349206349204, 'pegasus_entailment': 0.3848346810787916, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48333333333333334, 'r1_recall': 0.5304878048780488, 'r1_f1': 0.5058139534883721, 'pegasus_entailment': 0.2958300940692425, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6846153846153846, 'r1_recall': 0.4427860696517413, 'r1_f1': 0.5377643504531721, 'pegasus_entailment': 0.4883404541760683, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.3, 'r1_f1': 0.34285714285714286, 'pegasus_entailment': 0.5599430501461029, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.5625, 'r1_f1': 0.5590062111801242, 'pegasus_entailment': 0.5671789787709713, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33663366336633666, 'r1_recall': 0.4146341463414634, 'r1_f1': 0.37158469945355194, 'pegasus_entailment': 0.8419028123219808, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26666666666666666, 'r1_recall': 0.5, 'r1_f1': 0.3478260869565218, 'pegasus_entailment': 0.28081218898296356, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2857142857142857, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.3571428571428571, 'pegasus_entailment': 0.6898664496839046, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19607843137254902, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.29411764705882354, 'pegasus_entailment': 0.43534406144171955, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.375, 'r1_recall': 0.4342105263157895, 'r1_f1': 0.4024390243902439, 'pegasus_entailment': 0.5767182894051075, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6451612903225806, 'r1_recall': 0.32608695652173914, 'r1_f1': 0.4332129963898917, 'pegasus_entailment': 0.8045540452003479, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3402061855670103, 'r1_recall': 0.4925373134328358, 'r1_f1': 0.4024390243902439, 'pegasus_entailment': 0.34251442179083824, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6888888888888889, 'r1_recall': 0.36904761904761907, 'r1_f1': 0.4806201550387597, 'pegasus_entailment': 0.4161246486008167, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6320754716981132, 'r1_recall': 0.5075757575757576, 'r1_f1': 0.5630252100840336, 'pegasus_entailment': 0.32203347608447075, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7844827586206896, 'r1_recall': 0.5759493670886076, 'r1_f1': 0.6642335766423357, 'pegasus_entailment': 0.5782024264335632, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7647058823529411, 'r1_recall': 0.2195945945945946, 'r1_f1': 0.3412073490813648, 'pegasus_entailment': 0.43408970534801483, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.7272727272727273, 'r1_f1': 0.54421768707483, 'pegasus_entailment': 0.4875956103205681, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6481481481481481, 'r1_recall': 0.3553299492385787, 'r1_f1': 0.459016393442623, 'pegasus_entailment': 0.1930928498506546, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45588235294117646, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.484375, 'pegasus_entailment': 0.6408371962606907, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4961832061068702, 'r1_recall': 0.5284552845528455, 'r1_f1': 0.5118110236220472, 'pegasus_entailment': 0.7989411801099777, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5523809523809524, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5523809523809524, 'pegasus_entailment': 0.5678386330604553, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.775, 'r1_recall': 0.4732824427480916, 'r1_f1': 0.5876777251184834, 'pegasus_entailment': 0.4727054998278618, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3140495867768595, 'r1_recall': 0.5671641791044776, 'r1_f1': 0.4042553191489362, 'pegasus_entailment': 0.4419554229825735, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2894736842105263, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.3859649122807018, 'pegasus_entailment': 0.4621002972126007, 'pegasus_flesch_kincaid': 32, 'pegasus_coleman_liau': 21, 'pegasus_ari': 38, 'pegasus_smog': 26}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25806451612903225, 'r1_recall': 0.7017543859649122, 'r1_f1': 0.3773584905660377, 'pegasus_entailment': 0.616279861330986, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.5625, 'r1_f1': 0.5877551020408163, 'pegasus_entailment': 0.3008006915450096, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7818181818181819, 'r1_recall': 0.48314606741573035, 'r1_f1': 0.5972222222222223, 'pegasus_entailment': 0.55433922012647, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6333333333333333, 'r1_recall': 0.4662576687116564, 'r1_f1': 0.5371024734982333, 'pegasus_entailment': 0.726044887304306, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6415094339622641, 'r1_recall': 0.35233160621761656, 'r1_f1': 0.45484949832775917, 'pegasus_entailment': 0.6340672224760056, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4909090909090909, 'r1_recall': 0.5346534653465347, 'r1_f1': 0.5118483412322276, 'pegasus_entailment': 0.4082975375155608, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35947712418300654, 'r1_recall': 0.6547619047619048, 'r1_f1': 0.46413502109704646, 'pegasus_entailment': 0.4123345666698047, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.5, 'r1_f1': 0.4736842105263158, 'pegasus_entailment': 0.6782827149145305, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3380281690140845, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.39344262295081966, 'pegasus_entailment': 0.14754684269428253, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6267605633802817, 'r1_recall': 0.6013513513513513, 'r1_f1': 0.6137931034482759, 'pegasus_entailment': 0.5645301242669424, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.4580152671755725, 'r1_f1': 0.5286343612334802, 'pegasus_entailment': 0.560332209803164, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7121212121212122, 'r1_recall': 0.3983050847457627, 'r1_f1': 0.5108695652173914, 'pegasus_entailment': 0.9548970858256022, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7777777777777778, 'r1_recall': 0.3769230769230769, 'r1_f1': 0.5077720207253886, 'pegasus_entailment': 0.6044277374943098, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5408163265306123, 'r1_recall': 0.44537815126050423, 'r1_f1': 0.4884792626728111, 'pegasus_entailment': 0.4587773655851682, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7346938775510204, 'r1_recall': 0.5, 'r1_f1': 0.5950413223140496, 'pegasus_entailment': 0.7153411044273525, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5957446808510638, 'r1_recall': 0.6222222222222222, 'r1_f1': 0.608695652173913, 'pegasus_entailment': 0.3169755460694432, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45161290322580644, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.43579766536964976, 'pegasus_entailment': 0.3381445140577853, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6589147286821705, 'r1_recall': 0.4009433962264151, 'r1_f1': 0.4985337243401759, 'pegasus_entailment': 0.6678925057252248, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33766233766233766, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.3880597014925373, 'pegasus_entailment': 0.4067276641726494, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46511627906976744, 'r1_recall': 0.46875, 'r1_f1': 0.4669260700389105, 'pegasus_entailment': 0.45340456403791907, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34579439252336447, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.45121951219512196, 'pegasus_entailment': 0.5727633386850357, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7310924369747899, 'r1_recall': 0.45549738219895286, 'r1_f1': 0.5612903225806452, 'pegasus_entailment': 0.6220632692178091, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6333333333333333, 'r1_recall': 0.5170068027210885, 'r1_f1': 0.5692883895131086, 'pegasus_entailment': 0.38553042709827423, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45588235294117646, 'r1_recall': 0.4025974025974026, 'r1_f1': 0.42758620689655175, 'pegasus_entailment': 0.874851793050766, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36875, 'r1_recall': 0.7866666666666666, 'r1_f1': 0.5021276595744681, 'pegasus_entailment': 0.6777335129678249, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5984251968503937, 'r1_recall': 0.6608695652173913, 'r1_f1': 0.628099173553719, 'pegasus_entailment': 0.5237200796604157, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5945945945945946, 'r1_recall': 0.43137254901960786, 'r1_f1': 0.5000000000000001, 'pegasus_entailment': 0.6547691524028778, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5188679245283019, 'r1_recall': 0.5392156862745098, 'r1_f1': 0.5288461538461537, 'pegasus_entailment': 0.06418022233992815, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.445859872611465, 'pegasus_entailment': 0.4173084482550621, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3956043956043956, 'r1_recall': 0.5625, 'r1_f1': 0.4645161290322581, 'pegasus_entailment': 0.3455523768439889, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43, 'r1_recall': 0.5733333333333334, 'r1_f1': 0.49142857142857144, 'pegasus_entailment': 0.27242566586937755, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34513274336283184, 'r1_recall': 0.7358490566037735, 'r1_f1': 0.4698795180722891, 'pegasus_entailment': 0.86143858730793, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5670103092783505, 'r1_recall': 0.5913978494623656, 'r1_f1': 0.5789473684210525, 'pegasus_entailment': 0.6674053966999054, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43902439024390244, 'r1_recall': 0.6206896551724138, 'r1_f1': 0.5142857142857142, 'pegasus_entailment': 0.3770249326868604, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5431034482758621, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.5779816513761469, 'pegasus_entailment': 0.6137364953756332, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6296296296296297, 'r1_recall': 0.43037974683544306, 'r1_f1': 0.5112781954887219, 'pegasus_entailment': 0.5634314373135567, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3466666666666667, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.3939393939393939, 'pegasus_entailment': 0.4825938992823164, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5725190839694656, 'r1_recall': 0.5033557046979866, 'r1_f1': 0.5357142857142857, 'pegasus_entailment': 0.6616428891817728, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5316455696202531, 'r1_recall': 0.30656934306569344, 'r1_f1': 0.3888888888888889, 'pegasus_entailment': 0.6306249111890793, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6176470588235294, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.6268656716417911, 'pegasus_entailment': 0.21700024232268333, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5284552845528455, 'r1_recall': 0.5855855855855856, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.7940180897712708, 'pegasus_flesch_kincaid': 32, 'pegasus_coleman_liau': 20, 'pegasus_ari': 39, 'pegasus_smog': 28}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24285714285714285, 'r1_recall': 0.6375, 'r1_f1': 0.35172413793103446, 'pegasus_entailment': 0.9482558795383998, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.4409448818897638, 'r1_f1': 0.4534412955465587, 'pegasus_entailment': 0.8250105828046799, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7536231884057971, 'r1_recall': 0.5279187817258884, 'r1_f1': 0.6208955223880598, 'pegasus_entailment': 0.48445955770356314, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6890756302521008, 'r1_recall': 0.3374485596707819, 'r1_f1': 0.4530386740331492, 'pegasus_entailment': 0.31519676093012094, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.676056338028169, 'r1_recall': 0.34532374100719426, 'r1_f1': 0.45714285714285713, 'pegasus_entailment': 0.48386128908896353, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.031578947368421054, 'r1_recall': 0.0410958904109589, 'r1_f1': 0.03571428571428571, 'pegasus_entailment': 0.9542099833488464, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 1, 'pegasus_ari': 17, 'pegasus_smog': 8}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2828282828282828, 'r1_recall': 0.45901639344262296, 'r1_f1': 0.35, 'pegasus_entailment': 0.15300726937130094, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6875, 'r1_recall': 0.6395348837209303, 'r1_f1': 0.6626506024096386, 'pegasus_entailment': 0.6324207410216331, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4673913043478261, 'r1_recall': 0.581081081081081, 'r1_f1': 0.5180722891566265, 'pegasus_entailment': 0.2594465515576303, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5885714285714285, 'r1_recall': 0.5919540229885057, 'r1_f1': 0.5902578796561605, 'pegasus_entailment': 0.6316783428192139, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4827586206896552, 'r1_recall': 0.2916666666666667, 'r1_f1': 0.3636363636363637, 'pegasus_entailment': 0.3849963629618287, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7863247863247863, 'r1_recall': 0.4717948717948718, 'r1_f1': 0.5897435897435896, 'pegasus_entailment': 0.6674446687102318, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5531914893617021, 'r1_recall': 0.7123287671232876, 'r1_f1': 0.6227544910179641, 'pegasus_entailment': 0.49371232837438583, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49074074074074076, 'r1_recall': 0.7066666666666667, 'r1_f1': 0.5792349726775956, 'pegasus_entailment': 0.43740286622196434, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4830508474576271, 'r1_recall': 0.5, 'r1_f1': 0.49137931034482757, 'pegasus_entailment': 0.7744606733322144, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7398373983739838, 'r1_recall': 0.24202127659574468, 'r1_f1': 0.3647294589178357, 'pegasus_entailment': 0.580346517264843, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4857142857142857, 'r1_recall': 0.576271186440678, 'r1_f1': 0.5271317829457364, 'pegasus_entailment': 0.7218687931696574, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7397260273972602, 'r1_recall': 0.32142857142857145, 'r1_f1': 0.44813278008298757, 'pegasus_entailment': 0.6580447033047676, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47586206896551725, 'r1_recall': 0.5348837209302325, 'r1_f1': 0.5036496350364963, 'pegasus_entailment': 0.4769918170890638, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5109489051094891, 'r1_recall': 0.4697986577181208, 'r1_f1': 0.4895104895104895, 'pegasus_entailment': 0.7563707530498505, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6106194690265486, 'r1_recall': 0.40828402366863903, 'r1_f1': 0.48936170212765956, 'pegasus_entailment': 0.3965494744479656, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6696428571428571, 'r1_recall': 0.5725190839694656, 'r1_f1': 0.6172839506172839, 'pegasus_entailment': 0.7024544030427933, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4225352112676056, 'r1_recall': 0.24193548387096775, 'r1_f1': 0.3076923076923077, 'pegasus_entailment': 0.5976449449857076, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425531914893617, 'r1_recall': 0.7228915662650602, 'r1_f1': 0.5357142857142857, 'pegasus_entailment': 0.4587004162371159, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26373626373626374, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.36923076923076925, 'pegasus_entailment': 0.4108757358044386, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6756756756756757, 'r1_recall': 0.43103448275862066, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.26026322444279987, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6636363636363637, 'r1_recall': 0.3945945945945946, 'r1_f1': 0.49491525423728816, 'pegasus_entailment': 0.5605097077786922, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6417910447761194, 'r1_recall': 0.4479166666666667, 'r1_f1': 0.5276073619631902, 'pegasus_entailment': 0.9471827149391174, 'pegasus_flesch_kincaid': 37, 'pegasus_coleman_liau': 22, 'pegasus_ari': 44, 'pegasus_smog': 30}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7815126050420168, 'r1_recall': 0.24155844155844156, 'r1_f1': 0.369047619047619, 'pegasus_entailment': 0.329908254245917, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6770833333333334, 'r1_recall': 0.4513888888888889, 'r1_f1': 0.5416666666666666, 'pegasus_entailment': 0.5722659900784492, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2482758620689655, 'r1_recall': 0.5538461538461539, 'r1_f1': 0.34285714285714286, 'pegasus_entailment': 0.3597773537039757, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45555555555555555, 'r1_recall': 0.6833333333333333, 'r1_f1': 0.5466666666666666, 'pegasus_entailment': 0.26742803646872443, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44594594594594594, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.42580645161290326, 'pegasus_entailment': 0.2515876851975918, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5066666666666667, 'r1_recall': 0.36538461538461536, 'r1_f1': 0.4245810055865922, 'pegasus_entailment': 0.6934632062911987, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32558139534883723, 'r1_recall': 0.4883720930232558, 'r1_f1': 0.39069767441860465, 'pegasus_entailment': 0.6529766172170639, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.421875, 'r1_recall': 0.5192307692307693, 'r1_f1': 0.46551724137931033, 'pegasus_entailment': 0.40192589660485584, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5245901639344263, 'r1_recall': 0.3878787878787879, 'r1_f1': 0.445993031358885, 'pegasus_entailment': 0.6856850117444993, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4578313253012048, 'r1_recall': 0.6229508196721312, 'r1_f1': 0.5277777777777778, 'pegasus_entailment': 0.43050251858464134, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5857142857142857, 'r1_recall': 0.5466666666666666, 'r1_f1': 0.5655172413793104, 'pegasus_entailment': 0.5225172005593777, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5319148936170213, 'r1_recall': 0.5494505494505495, 'r1_f1': 0.5405405405405406, 'pegasus_entailment': 0.39293381075064343, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.544, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.53125, 'pegasus_entailment': 0.3526668002208074, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.52, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5445026178010471, 'pegasus_entailment': 0.6401330679655075, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.584070796460177, 'r1_recall': 0.6285714285714286, 'r1_f1': 0.6055045871559633, 'pegasus_entailment': 0.48934214242867063, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4375, 'r1_recall': 0.7671232876712328, 'r1_f1': 0.5572139303482587, 'pegasus_entailment': 0.4795444518327713, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5581395348837209, 'r1_recall': 0.384, 'r1_f1': 0.4549763033175356, 'pegasus_entailment': 0.25187146477401257, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5612244897959183, 'r1_recall': 0.4824561403508772, 'r1_f1': 0.5188679245283019, 'pegasus_entailment': 0.391675066947937, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35542168674698793, 'r1_recall': 0.6629213483146067, 'r1_f1': 0.4627450980392156, 'pegasus_entailment': 0.5033868892739216, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2, 'r1_recall': 0.32558139534883723, 'r1_f1': 0.24778761061946902, 'pegasus_entailment': 0.9248838722705841, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 15}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7075471698113207, 'r1_recall': 0.3393665158371041, 'r1_f1': 0.45871559633027525, 'pegasus_entailment': 0.5199355781078339, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6301369863013699, 'pegasus_entailment': 0.9620340764522552, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 22}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27835051546391754, 'r1_recall': 0.7297297297297297, 'r1_f1': 0.40298507462686567, 'pegasus_entailment': 0.3749085192879041, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 18}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2980132450331126, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.3862660944206009, 'pegasus_entailment': 0.6741462871432304, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47863247863247865, 'r1_recall': 0.5233644859813084, 'r1_f1': 0.5, 'pegasus_entailment': 0.6878381222486496, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2986111111111111, 'r1_recall': 0.5972222222222222, 'r1_f1': 0.39814814814814814, 'pegasus_entailment': 0.6571219086647033, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5638297872340425, 'r1_recall': 0.6022727272727273, 'r1_f1': 0.5824175824175825, 'pegasus_entailment': 0.48688208195380867, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 30, 'pegasus_smog': 20}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7, 'r1_recall': 0.550561797752809, 'r1_f1': 0.6163522012578616, 'pegasus_entailment': 0.41168683767318726, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2692307692307692, 'r1_recall': 0.5932203389830508, 'r1_f1': 0.3703703703703704, 'pegasus_entailment': 0.15530007786583155, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6741573033707865, 'r1_recall': 0.6060606060606061, 'r1_f1': 0.6382978723404256, 'pegasus_entailment': 0.776126429438591, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46551724137931033, 'r1_recall': 0.5625, 'r1_f1': 0.5094339622641509, 'pegasus_entailment': 0.6770926594734192, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41830065359477125, 'r1_recall': 0.6808510638297872, 'r1_f1': 0.5182186234817814, 'pegasus_entailment': 0.5247123266259829, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8616352201257862, 'r1_recall': 0.2624521072796935, 'r1_f1': 0.40234948604992654, 'pegasus_entailment': 0.565445890384061, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6524390243902439, 'r1_recall': 0.535, 'r1_f1': 0.5879120879120879, 'pegasus_entailment': 0.5532713415367263, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30357142857142855, 'r1_recall': 0.4358974358974359, 'r1_f1': 0.35789473684210527, 'pegasus_entailment': 0.11778875514864921, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6236559139784946, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5858585858585859, 'pegasus_entailment': 0.6512515544891357, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.4852941176470588, 'r1_f1': 0.4925373134328358, 'pegasus_entailment': 0.4438908211886883, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.48672566371681414, 'r1_f1': 0.5418719211822659, 'pegasus_entailment': 0.511633176356554, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47572815533980584, 'r1_recall': 0.5764705882352941, 'r1_f1': 0.5212765957446808, 'pegasus_entailment': 0.4667632281780243, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4186046511627907, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.47368421052631576, 'pegasus_entailment': 0.48165300861001015, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.4891304347826087, 'r1_f1': 0.5202312138728324, 'pegasus_entailment': 0.6083359532058239, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5274725274725275, 'r1_recall': 0.5783132530120482, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.33475450053811073, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6090909090909091, 'r1_recall': 0.5317460317460317, 'r1_f1': 0.5677966101694915, 'pegasus_entailment': 0.5171469151973724, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6206896551724138, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.4214533917605877, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5864661654135338, 'r1_recall': 0.484472049689441, 'r1_f1': 0.5306122448979592, 'pegasus_entailment': 0.5496786117553711, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42028985507246375, 'r1_recall': 0.5087719298245614, 'r1_f1': 0.46031746031746035, 'pegasus_entailment': 0.3604556878951068, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 13}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6204819277108434, 'r1_recall': 0.4557522123893805, 'r1_f1': 0.5255102040816326, 'pegasus_entailment': 0.6254832506179809, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3103448275862069, 'r1_recall': 0.6, 'r1_f1': 0.4090909090909091, 'pegasus_entailment': 0.19837059639394283, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5514018691588785, 'r1_recall': 0.5841584158415841, 'r1_f1': 0.5673076923076923, 'pegasus_entailment': 0.579101045926412, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3595505617977528, 'r1_recall': 0.6530612244897959, 'r1_f1': 0.463768115942029, 'pegasus_entailment': 0.6984294652938843, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.203125, 'r1_recall': 0.2826086956521739, 'r1_f1': 0.23636363636363636, 'pegasus_entailment': 0.8177447517712911, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6218487394957983, 'r1_recall': 0.5068493150684932, 'r1_f1': 0.5584905660377358, 'pegasus_entailment': 0.8368285894393921, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6459627329192547, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.5892351274787535, 'pegasus_entailment': 0.6935430586338043, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5254237288135594, 'r1_recall': 0.4189189189189189, 'r1_f1': 0.46616541353383456, 'pegasus_entailment': 0.34189148258883506, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4017857142857143, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.42654028436018965, 'pegasus_entailment': 0.4437068998813629, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5463917525773195, 'r1_recall': 0.6385542168674698, 'r1_f1': 0.5888888888888889, 'pegasus_entailment': 0.6052955587704977, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35772357723577236, 'r1_recall': 0.6197183098591549, 'r1_f1': 0.4536082474226804, 'pegasus_entailment': 0.4342086136341095, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.512396694214876, 'r1_recall': 0.5391304347826087, 'r1_f1': 0.5254237288135593, 'pegasus_entailment': 0.3408238925039768, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6296296296296297, 'r1_recall': 0.40476190476190477, 'r1_f1': 0.4927536231884058, 'pegasus_entailment': 0.28402944207191466, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29906542056074764, 'r1_recall': 0.6037735849056604, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.7132363468408585, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.42424242424242425, 'pegasus_entailment': 0.8700978010892868, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3923076923076923, 'r1_recall': 0.45132743362831856, 'r1_f1': 0.41975308641975306, 'pegasus_entailment': 0.4894271455705166, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39473684210526316, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.4864864864864865, 'pegasus_entailment': 0.4749680653214455, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5419354838709678, 'r1_recall': 0.3835616438356164, 'r1_f1': 0.4491978609625668, 'pegasus_entailment': 0.48808587789535524, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23076923076923078, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.3185840707964602, 'pegasus_entailment': 0.8682784835497538, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 21}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49019607843137253, 'r1_recall': 0.6024096385542169, 'r1_f1': 0.5405405405405406, 'pegasus_entailment': 0.49508877024054526, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3582089552238806, 'r1_recall': 0.4897959183673469, 'r1_f1': 0.4137931034482758, 'pegasus_entailment': 0.35937045365571973, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6493506493506493, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.6172839506172839, 'pegasus_entailment': 0.6865713596343994, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6379310344827587, 'r1_recall': 0.5736434108527132, 'r1_f1': 0.6040816326530614, 'pegasus_entailment': 0.6006013676524162, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.504950495049505, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.5425531914893617, 'pegasus_entailment': 0.8108405470848083, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6464646464646465, 'r1_recall': 0.48120300751879697, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.5616117380559444, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5945945945945946, 'r1_f1': 0.5432098765432098, 'pegasus_entailment': 0.17247513184944788, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4537037037037037, 'r1_recall': 0.5104166666666666, 'r1_f1': 0.4803921568627451, 'pegasus_entailment': 0.37727495771832764, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7176470588235294, 'r1_recall': 0.4357142857142857, 'r1_f1': 0.5422222222222223, 'pegasus_entailment': 0.8924940427144369, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46703296703296704, 'r1_recall': 0.5902777777777778, 'r1_f1': 0.5214723926380368, 'pegasus_entailment': 0.6907042860984802, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49504950495049505, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.5181347150259067, 'pegasus_entailment': 0.7772064805030823, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5542168674698795, 'r1_recall': 0.44660194174757284, 'r1_f1': 0.49462365591397855, 'pegasus_entailment': 0.712490051984787, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39473684210526316, 'r1_recall': 0.44776119402985076, 'r1_f1': 0.41958041958041953, 'pegasus_entailment': 0.4711893058071534, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4765625, 'r1_recall': 0.6703296703296703, 'r1_f1': 0.5570776255707763, 'pegasus_entailment': 0.7808398976922035, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.624, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5820895522388059, 'pegasus_entailment': 0.6613152585923672, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6739130434782609, 'r1_recall': 0.5081967213114754, 'r1_f1': 0.5794392523364487, 'pegasus_entailment': 0.4218052327632904, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6875, 'r1_recall': 0.463855421686747, 'r1_f1': 0.5539568345323741, 'pegasus_entailment': 0.36346298456192017, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5205479452054794, 'r1_recall': 0.6909090909090909, 'r1_f1': 0.59375, 'pegasus_entailment': 0.20500308523575464, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.6621621621621622, 'r1_f1': 0.547486033519553, 'pegasus_entailment': 0.5421691872179508, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5882352941176471, 'r1_recall': 0.3431372549019608, 'r1_f1': 0.43343653250773995, 'pegasus_entailment': 0.8909037113189697, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7094017094017094, 'r1_recall': 0.38425925925925924, 'r1_f1': 0.4984984984984985, 'pegasus_entailment': 0.38093746701876324, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4909090909090909, 'r1_recall': 0.4462809917355372, 'r1_f1': 0.4675324675324675, 'pegasus_entailment': 0.3786330081522465, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6422018348623854, 'r1_recall': 0.48951048951048953, 'r1_f1': 0.5555555555555556, 'pegasus_entailment': 0.1516966436058283, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42142857142857143, 'r1_recall': 0.6781609195402298, 'r1_f1': 0.5198237885462554, 'pegasus_entailment': 0.839323103427887, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41721854304635764, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.5206611570247935, 'pegasus_entailment': 0.8117801348368326, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3986013986013986, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.4653061224489796, 'pegasus_entailment': 0.3215726986527443, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5753424657534246, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.44919786096256686, 'pegasus_entailment': 0.26089430321007967, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5897435897435898, 'r1_recall': 0.46464646464646464, 'r1_f1': 0.519774011299435, 'pegasus_entailment': 0.21887610480189323, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3220338983050847, 'r1_recall': 0.42696629213483145, 'r1_f1': 0.3671497584541063, 'pegasus_entailment': 0.5952624082565308, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.675, 'r1_recall': 0.49693251533742333, 'r1_f1': 0.5724381625441696, 'pegasus_entailment': 0.3389609344303608, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.64, 'r1_recall': 0.26373626373626374, 'r1_f1': 0.37354085603112835, 'pegasus_entailment': 0.5633938908576965, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6935483870967742, 'r1_recall': 0.31272727272727274, 'r1_f1': 0.431077694235589, 'pegasus_entailment': 0.20300436913967132, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5789473684210527, 'r1_recall': 0.5045871559633027, 'r1_f1': 0.5392156862745099, 'pegasus_entailment': 0.6460630521178246, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26582278481012656, 'r1_recall': 0.3620689655172414, 'r1_f1': 0.3065693430656934, 'pegasus_entailment': 0.9707360565662384, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 17}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5813953488372093, 'r1_recall': 0.27624309392265195, 'r1_f1': 0.3745318352059925, 'pegasus_entailment': 0.688292404015859, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3445378151260504, 'r1_recall': 0.5324675324675324, 'r1_f1': 0.41836734693877553, 'pegasus_entailment': 0.4574697569012642, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32571428571428573, 'r1_recall': 0.7125, 'r1_f1': 0.4470588235294118, 'pegasus_entailment': 0.5455219112336636, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5934065934065934, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.5869565217391305, 'pegasus_entailment': 0.7388964220881462, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5096153846153846, 'r1_recall': 0.654320987654321, 'r1_f1': 0.572972972972973, 'pegasus_entailment': 0.5579134874045849, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5308641975308642, 'r1_recall': 0.4777777777777778, 'r1_f1': 0.5029239766081872, 'pegasus_entailment': 0.6428880492846171, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27956989247311825, 'r1_recall': 0.37681159420289856, 'r1_f1': 0.32098765432098764, 'pegasus_entailment': 0.4505146484589204, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3782051282051282, 'r1_recall': 0.6145833333333334, 'r1_f1': 0.46825396825396826, 'pegasus_entailment': 0.4413776679171456, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38, 'r1_recall': 0.59375, 'r1_f1': 0.46341463414634143, 'pegasus_entailment': 0.3738635601475835, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3968253968253968, 'r1_recall': 0.5494505494505495, 'r1_f1': 0.4608294930875576, 'pegasus_entailment': 0.6062497496604919, 'pegasus_flesch_kincaid': 31, 'pegasus_coleman_liau': 18, 'pegasus_ari': 39, 'pegasus_smog': 24}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44696969696969696, 'r1_recall': 0.6704545454545454, 'r1_f1': 0.5363636363636364, 'pegasus_entailment': 0.6399026811122894, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38524590163934425, 'r1_recall': 0.7580645161290323, 'r1_f1': 0.5108695652173914, 'pegasus_entailment': 0.5259238600730896, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5147058823529411, 'r1_recall': 0.6542056074766355, 'r1_f1': 0.5761316872427984, 'pegasus_entailment': 0.5157240554690361, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38028169014084506, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.40298507462686567, 'pegasus_entailment': 0.3669706713408232, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7920792079207921, 'r1_recall': 0.3018867924528302, 'r1_f1': 0.4371584699453552, 'pegasus_entailment': 0.4796195328235626, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36633663366336633, 'r1_recall': 0.578125, 'r1_f1': 0.4484848484848485, 'pegasus_entailment': 0.4862455949187279, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4148936170212766, 'r1_recall': 0.42391304347826086, 'r1_f1': 0.41935483870967744, 'pegasus_entailment': 0.8469926357269287, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.512396694214876, 'r1_recall': 0.62, 'r1_f1': 0.5610859728506787, 'pegasus_entailment': 0.5371859036386013, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4772727272727273, 'r1_recall': 0.45, 'r1_f1': 0.4632352941176471, 'pegasus_entailment': 0.7819550991058349, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5319148936170213, 'r1_recall': 0.5319148936170213, 'r1_f1': 0.5319148936170213, 'pegasus_entailment': 0.4124035630375147, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5816326530612245, 'r1_recall': 0.44881889763779526, 'r1_f1': 0.5066666666666667, 'pegasus_entailment': 0.7392638102173805, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3918918918918919, 'r1_recall': 0.4084507042253521, 'r1_f1': 0.4, 'pegasus_entailment': 0.59487184882164, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4409448818897638, 'r1_recall': 0.5957446808510638, 'r1_f1': 0.506787330316742, 'pegasus_entailment': 0.34745545871555805, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5263157894736842, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5, 'pegasus_entailment': 0.23872927762567997, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5348837209302325, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.575, 'pegasus_entailment': 0.3030800308721761, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4642857142857143, 'r1_recall': 0.582089552238806, 'r1_f1': 0.5165562913907285, 'pegasus_entailment': 0.6351023316383362, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.358974358974359, 'r1_recall': 0.4375, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.836095929145813, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5287356321839081, 'r1_recall': 0.2658959537572254, 'r1_f1': 0.3538461538461538, 'pegasus_entailment': 0.5277276933193207, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6261682242990654, 'r1_recall': 0.40606060606060607, 'r1_f1': 0.4926470588235294, 'pegasus_entailment': 0.42679300780097645, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6320754716981132, 'r1_recall': 0.6836734693877551, 'r1_f1': 0.6568627450980392, 'pegasus_entailment': 0.6183235887438059, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851063829787234, 'r1_recall': 0.29411764705882354, 'r1_f1': 0.3914590747330961, 'pegasus_entailment': 0.10104828886687756, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44871794871794873, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.4046242774566474, 'pegasus_entailment': 0.44852709472179414, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42424242424242425, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4912280701754386, 'pegasus_entailment': 0.6436878641446432, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40625, 'r1_recall': 0.4727272727272727, 'r1_f1': 0.43697478991596644, 'pegasus_entailment': 0.651074081659317, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22727272727272727, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.3289473684210526, 'pegasus_entailment': 0.37106930650770664, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4144144144144144, 'r1_recall': 0.647887323943662, 'r1_f1': 0.5054945054945055, 'pegasus_entailment': 0.9077486991882324, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32142857142857145, 'r1_recall': 0.5192307692307693, 'r1_f1': 0.39705882352941174, 'pegasus_entailment': 0.3618789967149496, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5072463768115942, 'r1_recall': 0.29914529914529914, 'r1_f1': 0.3763440860215054, 'pegasus_entailment': 0.4053036882542074, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6534653465346535, 'r1_recall': 0.5038167938931297, 'r1_f1': 0.5689655172413793, 'pegasus_entailment': 0.4550515413284302, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5405405405405406, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5063291139240507, 'pegasus_entailment': 0.5093708166386932, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 12}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6037735849056604, 'r1_recall': 0.35555555555555557, 'r1_f1': 0.44755244755244755, 'pegasus_entailment': 0.6055308878421783, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.5934065934065934, 'r1_f1': 0.5118483412322274, 'pegasus_entailment': 0.43761444091796875, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 25}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.51, 'r1_recall': 0.4636363636363636, 'r1_f1': 0.4857142857142857, 'pegasus_entailment': 0.5802631005644798, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 22}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5842696629213483, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.574585635359116, 'pegasus_entailment': 0.5011084030071894, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5058823529411764, 'r1_recall': 0.43, 'r1_f1': 0.46486486486486484, 'pegasus_entailment': 0.6636000603437424, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2708333333333333, 'r1_recall': 0.37681159420289856, 'r1_f1': 0.3151515151515151, 'pegasus_entailment': 0.6837629559449852, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5227272727272727, 'r1_recall': 0.5287356321839081, 'r1_f1': 0.5257142857142857, 'pegasus_entailment': 0.6650414168834686, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6203703703703703, 'r1_recall': 0.6568627450980392, 'r1_f1': 0.638095238095238, 'pegasus_entailment': 0.5822240188717842, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40298507462686567, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.49541284403669733, 'pegasus_entailment': 0.6191720366477966, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23255813953488372, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.2898550724637681, 'pegasus_entailment': 0.4679887555539608, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6237623762376238, 'r1_recall': 0.4405594405594406, 'r1_f1': 0.5163934426229508, 'pegasus_entailment': 0.7031949818134308, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5402298850574713, 'r1_recall': 0.5402298850574713, 'r1_f1': 0.5402298850574713, 'pegasus_entailment': 0.3125515356659889, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.4878048780487805, 'pegasus_entailment': 0.6433320247257749, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.39669421487603307, 'r1_f1': 0.45933014354066987, 'pegasus_entailment': 0.6853058040142059, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41379310344827586, 'r1_recall': 0.34615384615384615, 'r1_f1': 0.37696335078534027, 'pegasus_entailment': 0.3346194537977378, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47368421052631576, 'r1_recall': 0.2571428571428571, 'r1_f1': 0.3333333333333333, 'pegasus_entailment': 0.6736226181189219, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2892561983471074, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.36269430051813467, 'pegasus_entailment': 0.37788626505061984, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48598130841121495, 'r1_recall': 0.5842696629213483, 'r1_f1': 0.5306122448979592, 'pegasus_entailment': 0.29396875699361164, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1826086956521739, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.2625, 'pegasus_entailment': 0.6165829971432686, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45255474452554745, 'r1_recall': 0.6019417475728155, 'r1_f1': 0.5166666666666667, 'pegasus_entailment': 0.45390594253937405, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.13186813186813187, 'r1_recall': 0.34285714285714286, 'r1_f1': 0.1904761904761905, 'pegasus_entailment': 0.44790851697325706, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3472222222222222, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.42735042735042733, 'pegasus_entailment': 0.879147469997406, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22627737226277372, 'r1_recall': 0.7948717948717948, 'r1_f1': 0.3522727272727273, 'pegasus_entailment': 0.9510880907376608, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7647058823529411, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.48148148148148157, 'pegasus_entailment': 0.26776187121868134, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.6, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.8117288649082184, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32450331125827814, 'r1_recall': 0.5104166666666666, 'r1_f1': 0.3967611336032389, 'pegasus_entailment': 0.3928569592535496, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.532258064516129, 'r1_recall': 0.6055045871559633, 'r1_f1': 0.5665236051502146, 'pegasus_entailment': 0.35898205637931824, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.603448275862069, 'r1_recall': 0.5072463768115942, 'r1_f1': 0.5511811023622047, 'pegasus_entailment': 0.3799579789241155, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8791208791208791, 'r1_recall': 0.22727272727272727, 'r1_f1': 0.3611738148984198, 'pegasus_entailment': 0.9009361664454142, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4298245614035088, 'r1_recall': 0.44144144144144143, 'r1_f1': 0.4355555555555556, 'pegasus_entailment': 0.7416481897234917, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5212765957446809, 'r1_recall': 0.3288590604026846, 'r1_f1': 0.4032921810699589, 'pegasus_entailment': 0.6765744984149933, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7325581395348837, 'r1_recall': 0.4228187919463087, 'r1_f1': 0.5361702127659574, 'pegasus_entailment': 0.7686430931091308, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24691358024691357, 'r1_recall': 0.40816326530612246, 'r1_f1': 0.3076923076923077, 'pegasus_entailment': 0.199537156149745, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3884297520661157, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.48704663212435234, 'pegasus_entailment': 0.36349406590064365, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3602941176470588, 'r1_recall': 0.6049382716049383, 'r1_f1': 0.45161290322580644, 'pegasus_entailment': 0.48194907456636427, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8762886597938144, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.6882591093117408, 'pegasus_entailment': 0.5371608038743337, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4117647058823529, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.4605263157894737, 'pegasus_entailment': 0.5246486216783524, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7894736842105263, 'r1_recall': 0.5232558139534884, 'r1_f1': 0.6293706293706294, 'pegasus_entailment': 0.9063218633333842, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34965034965034963, 'r1_recall': 0.6756756756756757, 'r1_f1': 0.4608294930875576, 'pegasus_entailment': 0.7385792210698128, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5223880597014925, 'r1_recall': 0.43209876543209874, 'r1_f1': 0.47297297297297297, 'pegasus_entailment': 0.8222944339116415, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5603448275862069, 'r1_recall': 0.46099290780141844, 'r1_f1': 0.5058365758754862, 'pegasus_entailment': 0.5897003471851349, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3438914027149321, 'r1_recall': 0.5801526717557252, 'r1_f1': 0.4318181818181818, 'pegasus_entailment': 0.6571499332785606, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 20, 'pegasus_ari': 36, 'pegasus_smog': 25}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5975609756097561, 'r1_recall': 0.460093896713615, 'r1_f1': 0.519893899204244, 'pegasus_entailment': 0.5900787532329559, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5529411764705883, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.537142857142857, 'pegasus_entailment': 0.8222491343816122, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36470588235294116, 'r1_recall': 0.543859649122807, 'r1_f1': 0.4366197183098592, 'pegasus_entailment': 0.564756323893865, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.31746031746031744, 'r1_f1': 0.42105263157894735, 'pegasus_entailment': 0.5144186150282621, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6941176470588235, 'r1_recall': 0.19407894736842105, 'r1_f1': 0.3033419023136247, 'pegasus_entailment': 0.29711681852738064, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18840579710144928, 'r1_recall': 0.4126984126984127, 'r1_f1': 0.25870646766169153, 'pegasus_entailment': 0.5562828965485096, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40131578947368424, 'r1_recall': 0.6421052631578947, 'r1_f1': 0.4939271255060729, 'pegasus_entailment': 0.6066539287567139, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6782608695652174, 'r1_recall': 0.4936708860759494, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.43907816614955664, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2835820895522388, 'r1_recall': 0.3275862068965517, 'r1_f1': 0.304, 'pegasus_entailment': 0.3528770574678977, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7272727272727273, 'r1_recall': 0.35359116022099446, 'r1_f1': 0.4758364312267657, 'pegasus_entailment': 0.401650071144104, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.569620253164557, 'r1_recall': 0.31690140845070425, 'r1_f1': 0.40723981900452494, 'pegasus_entailment': 0.5625083049138387, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44761904761904764, 'r1_recall': 0.49473684210526314, 'r1_f1': 0.47000000000000003, 'pegasus_entailment': 0.29756504762917757, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5855855855855856, 'r1_recall': 0.37790697674418605, 'r1_f1': 0.45936395759717313, 'pegasus_entailment': 0.6312712550163269, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41509433962264153, 'r1_recall': 0.6197183098591549, 'r1_f1': 0.4971751412429378, 'pegasus_entailment': 0.5009271539747715, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7159090909090909, 'r1_recall': 0.30288461538461536, 'r1_f1': 0.42567567567567566, 'pegasus_entailment': 0.7563634117444357, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36464088397790057, 'r1_recall': 0.7096774193548387, 'r1_f1': 0.48175182481751827, 'pegasus_entailment': 0.6750149726867676, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36507936507936506, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.45771144278606957, 'pegasus_entailment': 0.6137096732854843, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46236559139784944, 'r1_recall': 0.6056338028169014, 'r1_f1': 0.524390243902439, 'pegasus_entailment': 0.3920397361119588, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5148514851485149, 'r1_recall': 0.5148514851485149, 'r1_f1': 0.5148514851485149, 'pegasus_entailment': 0.6513090133666992, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6938775510204082, 'r1_recall': 0.4927536231884058, 'r1_f1': 0.576271186440678, 'pegasus_entailment': 0.7587986886501312, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.4485981308411215, 'pegasus_entailment': 0.7946982562541962, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27058823529411763, 'r1_recall': 0.38333333333333336, 'r1_f1': 0.31724137931034485, 'pegasus_entailment': 0.32220791776974994, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8058252427184466, 'r1_recall': 0.46629213483146065, 'r1_f1': 0.590747330960854, 'pegasus_entailment': 0.7039458863437176, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44339622641509435, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.5251396648044692, 'pegasus_entailment': 0.4095403850078583, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4435483870967742, 'r1_recall': 0.7236842105263158, 'r1_f1': 0.55, 'pegasus_entailment': 0.21511110139545053, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5529411764705883, 'r1_recall': 0.5164835164835165, 'r1_f1': 0.5340909090909091, 'pegasus_entailment': 0.4883999414741993, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6228070175438597, 'r1_recall': 0.5916666666666667, 'r1_f1': 0.6068376068376069, 'pegasus_entailment': 0.565395787358284, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8145161290322581, 'r1_recall': 0.14326241134751774, 'r1_f1': 0.2436670687575392, 'pegasus_entailment': 0.719287283718586, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6363636363636364, 'r1_recall': 0.49295774647887325, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.5859746634960175, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.88, 'r1_recall': 0.4808743169398907, 'r1_f1': 0.6219081272084805, 'pegasus_entailment': 0.4208165916303794, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4015748031496063, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.4636363636363636, 'pegasus_entailment': 0.3654447728767991, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5929203539823009, 'r1_recall': 0.5775862068965517, 'r1_f1': 0.5851528384279475, 'pegasus_entailment': 0.5120957437902689, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4574468085106383, 'r1_recall': 0.6615384615384615, 'r1_f1': 0.540880503144654, 'pegasus_entailment': 0.32931030122563243, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48201438848920863, 'r1_recall': 0.4267515923566879, 'r1_f1': 0.4527027027027027, 'pegasus_entailment': 0.41376807913184166, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.20175438596491227, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.2839506172839506, 'pegasus_entailment': 0.39992243610322475, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4731182795698925, 'r1_recall': 0.4536082474226804, 'r1_f1': 0.46315789473684216, 'pegasus_entailment': 0.9707311391830444, 'pegasus_flesch_kincaid': 45, 'pegasus_coleman_liau': 20, 'pegasus_ari': 55, 'pegasus_smog': 32}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1743119266055046, 'r1_recall': 0.5428571428571428, 'r1_f1': 0.2638888888888889, 'pegasus_entailment': 0.4398182760924101, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43537414965986393, 'r1_recall': 0.6597938144329897, 'r1_f1': 0.5245901639344263, 'pegasus_entailment': 0.5514963768422604, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5178571428571429, 'r1_recall': 0.5132743362831859, 'r1_f1': 0.5155555555555555, 'pegasus_entailment': 0.67866450548172, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6363636363636364, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.5384615384615385, 'pegasus_entailment': 0.45638997317291796, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23232323232323232, 'r1_recall': 0.42592592592592593, 'r1_f1': 0.30065359477124176, 'pegasus_entailment': 0.39395245611667634, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5774647887323944, 'r1_recall': 0.41, 'r1_f1': 0.47953216374269003, 'pegasus_entailment': 0.8469030410051346, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.031578947368421054
MEAN
0.5039881876995551
MAX
0.88
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.0410958904109589
MEAN
0.5021844395657316
MAX
0.7971014492753623
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.03571428571428571
MEAN
0.4796578201394519
MAX
0.6995073891625615
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.06338276776174705
MEAN
0.5457424162566189
MAX
0.9890740911165873
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
17
MAX
52
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
1
MEAN
17
MAX
24
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
12
MEAN
21
MAX
64
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
8
MEAN
18
MAX
34
{}
Entered file!
Imports done!
*** RUN *** 
eval_2d
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 14:02:02.257354: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 14:02:02.804190: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/2d_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47, 'r1_recall': 0.42727272727272725, 'r1_f1': 0.4476190476190476, 'pegasus_entailment': 0.6462100222706795, 'gold_entailment': 0.3013871341943741, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6831683168316832, 'r1_recall': 0.3988439306358382, 'r1_f1': 0.5036496350364964, 'pegasus_entailment': 0.6823275983333588, 'gold_entailment': 0.684974559715816, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2366412213740458, 'r1_recall': 0.5344827586206896, 'r1_f1': 0.3280423280423281, 'pegasus_entailment': 0.5024573845522744, 'gold_entailment': 0.4384084145228068, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 14, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5514018691588785, 'r1_recall': 0.4573643410852713, 'r1_f1': 0.5, 'pegasus_entailment': 0.6802972927689552, 'gold_entailment': 0.3140990845859051, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 21, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7472527472527473, 'r1_recall': 0.39080459770114945, 'r1_f1': 0.5132075471698113, 'pegasus_entailment': 0.7570426265398661, 'gold_entailment': 0.49225770433743793, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49193548387096775, 'r1_recall': 0.46923076923076923, 'r1_f1': 0.4803149606299213, 'pegasus_entailment': 0.6383843958377838, 'gold_entailment': 0.22673117369413376, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19767441860465115, 'r1_recall': 0.53125, 'r1_f1': 0.28813559322033894, 'pegasus_entailment': 0.4868069514632225, 'gold_entailment': 0.4265684982140859, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 10, 'gold_coleman_liau': 14, 'gold_ari': 11, 'gold_smog': 15}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.11320754716981132, 'r1_recall': 0.3870967741935484, 'r1_f1': 0.17518248175182485, 'pegasus_entailment': 0.7452721372246742, 'gold_entailment': 0.6329213976860046, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5167785234899329, 'r1_f1': 0.5082508250825083, 'pegasus_entailment': 0.38809072971343994, 'gold_entailment': 0.30623316551957813, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.47101449275362317, 'r1_f1': 0.48507462686567165, 'pegasus_entailment': 0.6094476833939553, 'gold_entailment': 0.24250707030296326, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 19, 'gold_ari': 31, 'gold_smog': 24}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4573170731707317, 'r1_recall': 0.5, 'r1_f1': 0.4777070063694268, 'pegasus_entailment': 0.7366833686828613, 'gold_entailment': 0.3591098874807358, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3728813559322034, 'r1_recall': 0.5546218487394958, 'r1_f1': 0.44594594594594594, 'pegasus_entailment': 0.6903795413672924, 'gold_entailment': 0.5552245259284974, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 22, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5813953488372093, 'r1_recall': 0.4672897196261682, 'r1_f1': 0.5181347150259068, 'pegasus_entailment': 0.39664118985335034, 'gold_entailment': 0.3654167428612709, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46938775510204084, 'r1_recall': 0.5227272727272727, 'r1_f1': 0.49462365591397844, 'pegasus_entailment': 0.5068630464375019, 'gold_entailment': 0.3089908038576444, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6301369863013698, 'r1_recall': 0.23958333333333334, 'r1_f1': 0.3471698113207547, 'pegasus_entailment': 0.4393598102033138, 'gold_entailment': 0.2600487661547959, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2545454545454545, 'r1_recall': 0.4745762711864407, 'r1_f1': 0.33136094674556216, 'pegasus_entailment': 0.49628347158432007, 'gold_entailment': 0.653463751077652, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3412698412698413, 'r1_recall': 0.43434343434343436, 'r1_f1': 0.3822222222222222, 'pegasus_entailment': 0.6465807259082794, 'gold_entailment': 0.39315667748451233, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7608695652173914, 'r1_recall': 0.2348993288590604, 'r1_f1': 0.358974358974359, 'pegasus_entailment': 0.6621147990226746, 'gold_entailment': 0.26565215587615965, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5523809523809524, 'r1_recall': 0.36024844720496896, 'r1_f1': 0.43609022556390975, 'pegasus_entailment': 0.13918506974975267, 'gold_entailment': 0.14880464704973356, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5151515151515151, 'r1_recall': 0.39080459770114945, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.7065469026565552, 'gold_entailment': 0.5256461352109909, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 13, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6915887850467289, 'r1_recall': 0.4065934065934066, 'r1_f1': 0.5121107266435987, 'pegasus_entailment': 0.4760681688785553, 'gold_entailment': 0.27894865721464157, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 14, 'pegasus_ari': 22, 'pegasus_smog': 15, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 15, 'gold_ari': 28, 'gold_smog': 18}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6627906976744186, 'r1_recall': 0.38, 'r1_f1': 0.48305084745762716, 'pegasus_entailment': 0.403387863188982, 'gold_entailment': 0.20920872688293457, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5104166666666666, 'r1_recall': 0.4537037037037037, 'r1_f1': 0.4803921568627451, 'pegasus_entailment': 0.7306438684463501, 'gold_entailment': 0.6112158745527267, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46099290780141844, 'r1_recall': 0.47794117647058826, 'r1_f1': 0.4693140794223827, 'pegasus_entailment': 0.372177267074585, 'gold_entailment': 0.22806554287672043, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2608695652173913, 'r1_recall': 0.48, 'r1_f1': 0.33802816901408445, 'pegasus_entailment': 0.5641252398490906, 'gold_entailment': 0.4921550005674362, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6904761904761905, 'r1_recall': 0.4603174603174603, 'r1_f1': 0.5523809523809524, 'pegasus_entailment': 0.6955231130123138, 'gold_entailment': 0.4941124297678471, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 29, 'gold_smog': 22}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6190476190476191, 'r1_recall': 0.4744525547445255, 'r1_f1': 0.5371900826446281, 'pegasus_entailment': 0.6390072405338287, 'gold_entailment': 0.402544841170311, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.31716417910447764, 'r1_f1': 0.42079207920792083, 'pegasus_entailment': 0.4920283518731594, 'gold_entailment': 0.15343642759729514, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46153846153846156, 'r1_recall': 0.5526315789473685, 'r1_f1': 0.5029940119760479, 'pegasus_entailment': 0.3770077258348465, 'gold_entailment': 0.43283836046854657, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 16}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2949640287769784, 'r1_recall': 0.36283185840707965, 'r1_f1': 0.32539682539682535, 'pegasus_entailment': 0.68774499433736, 'gold_entailment': 0.4896189793944359, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 18}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35714285714285715, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.4225352112676057, 'pegasus_entailment': 0.3626697242259979, 'gold_entailment': 0.3821558207273483, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 14, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4647887323943662, 'r1_recall': 0.16417910447761194, 'r1_f1': 0.24264705882352944, 'pegasus_entailment': 0.5153425137201945, 'gold_entailment': 0.3002672592798869, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2830188679245283, 'r1_recall': 0.4368932038834951, 'r1_f1': 0.34351145038167935, 'pegasus_entailment': 0.6648443962136904, 'gold_entailment': 0.35212631337344646, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5106382978723404, 'r1_recall': 0.4948453608247423, 'r1_f1': 0.5026178010471205, 'pegasus_entailment': 0.5712235309183598, 'gold_entailment': 0.4046328167120616, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24096385542168675, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.32, 'pegasus_entailment': 0.7085185423493385, 'gold_entailment': 0.2631291349728902, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5348837209302325, 'r1_recall': 0.39655172413793105, 'r1_f1': 0.45544554455445546, 'pegasus_entailment': 0.3347899620421231, 'gold_entailment': 0.355423500140508, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 24}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46601941747572817, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.5581395348837209, 'pegasus_entailment': 0.8737534681955973, 'gold_entailment': 0.7590845425923666, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 24, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24503311258278146, 'r1_recall': 0.5441176470588235, 'r1_f1': 0.33789954337899536, 'pegasus_entailment': 0.45549706742167473, 'gold_entailment': 0.18092385679483414, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21804511278195488, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.3258426966292135, 'pegasus_entailment': 0.5179737014696002, 'gold_entailment': 0.3614198677241802, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5486111111111112, 'r1_recall': 0.4759036144578313, 'r1_f1': 0.5096774193548388, 'pegasus_entailment': 0.63132563829422, 'gold_entailment': 0.26724368929862974, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.711340206185567, 'r1_recall': 0.43125, 'r1_f1': 0.5369649805447471, 'pegasus_entailment': 0.4432080704718828, 'gold_entailment': 0.39831703901290894, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45161290322580644, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.4941176470588235, 'pegasus_entailment': 0.2152394379954785, 'gold_entailment': 0.24783504381775856, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3053435114503817, 'r1_recall': 0.547945205479452, 'r1_f1': 0.39215686274509803, 'pegasus_entailment': 0.3156466828991792, 'gold_entailment': 0.26692716653148335, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44155844155844154, 'r1_recall': 0.5528455284552846, 'r1_f1': 0.49097472924187724, 'pegasus_entailment': 0.40771979341904324, 'gold_entailment': 0.14326451858505607, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 21, 'gold_ari': 30, 'gold_smog': 24}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35, 'r1_recall': 0.6282051282051282, 'r1_f1': 0.4495412844036697, 'pegasus_entailment': 0.8071152567863464, 'gold_entailment': 0.3731178939342499, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 21, 'gold_ari': 29, 'gold_smog': 22}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5641025641025641, 'r1_recall': 0.29333333333333333, 'r1_f1': 0.38596491228070173, 'pegasus_entailment': 0.6423572997252146, 'gold_entailment': 0.49986565113067627, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5617977528089888, 'r1_recall': 0.423728813559322, 'r1_f1': 0.48309178743961356, 'pegasus_entailment': 0.7102321982383728, 'gold_entailment': 0.23890919983386993, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 17}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5241935483870968, 'r1_recall': 0.5855855855855856, 'r1_f1': 0.5531914893617021, 'pegasus_entailment': 0.7669362425804138, 'gold_entailment': 0.4897882901132107, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4435483870967742, 'r1_recall': 0.6547619047619048, 'r1_f1': 0.5288461538461539, 'pegasus_entailment': 0.4363531917333603, 'gold_entailment': 0.40957613786061603, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28846153846153844, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.3846153846153846, 'pegasus_entailment': 0.6906672964493433, 'gold_entailment': 0.2821902682383855, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3381294964028777, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.4413145539906103, 'pegasus_entailment': 0.7094498693943023, 'gold_entailment': 0.6054204305013021, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24666666666666667, 'r1_recall': 0.7254901960784313, 'r1_f1': 0.3681592039800995, 'pegasus_entailment': 0.6996406465768814, 'gold_entailment': 0.792603611946106, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3114754098360656, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.3877551020408163, 'pegasus_entailment': 0.5141947194933891, 'gold_entailment': 0.39345920582612354, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5104166666666666, 'r1_recall': 0.2768361581920904, 'r1_f1': 0.358974358974359, 'pegasus_entailment': 0.25464579090476036, 'gold_entailment': 0.2876678675413132, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41198501872659177, 'r1_recall': 0.6179775280898876, 'r1_f1': 0.49438202247191, 'pegasus_entailment': 0.624187582731247, 'gold_entailment': 0.30636541332517353, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 34, 'pegasus_smog': 24, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3081761006289308, 'r1_recall': 0.6805555555555556, 'r1_f1': 0.42424242424242425, 'pegasus_entailment': 0.5995994746685028, 'gold_entailment': 0.4104074438412984, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4789915966386555, 'r1_recall': 0.22709163346613545, 'r1_f1': 0.3081081081081081, 'pegasus_entailment': 0.7031030893325806, 'gold_entailment': 0.3102743032981049, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43023255813953487, 'r1_recall': 0.578125, 'r1_f1': 0.49333333333333335, 'pegasus_entailment': 0.6298947185277939, 'gold_entailment': 0.4071774184703827, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 21}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5189873417721519, 'r1_recall': 0.6776859504132231, 'r1_f1': 0.5878136200716845, 'pegasus_entailment': 0.6164811611175537, 'gold_entailment': 0.4413752779364586, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 19}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3673469387755102, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.706782054901123, 'gold_entailment': 0.33063045889139175, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 17, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3953488372093023, 'r1_recall': 0.5795454545454546, 'r1_f1': 0.4700460829493087, 'pegasus_entailment': 0.7637795686721802, 'gold_entailment': 0.7605339586734772, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 22, 'gold_ari': 32, 'gold_smog': 21}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3392857142857143, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.41304347826086957, 'pegasus_entailment': 0.46501488238573074, 'gold_entailment': 0.23567195981740952, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 25, 'gold_smog': 17}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5569620253164557, 'r1_recall': 0.2619047619047619, 'r1_f1': 0.3562753036437247, 'pegasus_entailment': 0.32807354629039764, 'gold_entailment': 0.19995360961183906, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 15}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36607142857142855, 'r1_recall': 0.422680412371134, 'r1_f1': 0.39234449760765544, 'pegasus_entailment': 0.7542191863059997, 'gold_entailment': 0.2915268565217654, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2912621359223301, 'r1_recall': 0.625, 'r1_f1': 0.3973509933774834, 'pegasus_entailment': 0.44980910792946815, 'gold_entailment': 0.44451630115509033, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5772357723577236, 'r1_recall': 0.5590551181102362, 'r1_f1': 0.568, 'pegasus_entailment': 0.742739737033844, 'gold_entailment': 0.5424046069383621, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5175438596491229, 'r1_recall': 0.5566037735849056, 'r1_f1': 0.5363636363636364, 'pegasus_entailment': 0.46275680623948573, 'gold_entailment': 0.24259153008460999, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.472, 'r1_recall': 0.6145833333333334, 'r1_f1': 0.5339366515837104, 'pegasus_entailment': 0.4616793654859066, 'gold_entailment': 0.302676934376359, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4429530201342282, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.5, 'pegasus_entailment': 0.5815305944532156, 'gold_entailment': 0.22449287275473276, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7125, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.6263736263736264, 'pegasus_entailment': 0.7999501079320908, 'gold_entailment': 0.23284465881685415, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5634920634920635, 'r1_recall': 0.42771084337349397, 'r1_f1': 0.48630136986301364, 'pegasus_entailment': 0.903419241309166, 'gold_entailment': 0.65558380314282, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.336283185840708, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.4198895027624309, 'pegasus_entailment': 0.5167441740632057, 'gold_entailment': 0.4481038972735405, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.5757575757575758, 'r1_f1': 0.47204968944099385, 'pegasus_entailment': 0.5049968719482422, 'gold_entailment': 0.3935345411300659, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 16, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5187165775401069, 'r1_recall': 0.5105263157894737, 'r1_f1': 0.5145888594164456, 'pegasus_entailment': 0.5490496677479574, 'gold_entailment': 0.24518986139446497, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23846153846153847, 'r1_recall': 0.4305555555555556, 'r1_f1': 0.3069306930693069, 'pegasus_entailment': 0.6935189664363861, 'gold_entailment': 0.4750904639561971, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 22, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3888888888888889, 'r1_recall': 0.5764705882352941, 'r1_f1': 0.46445497630331756, 'pegasus_entailment': 0.5057599544525146, 'gold_entailment': 0.4802068918943405, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3220338983050847, 'r1_recall': 0.59375, 'r1_f1': 0.41758241758241754, 'pegasus_entailment': 0.40241645723581315, 'gold_entailment': 0.38350390642881393, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36036036036036034, 'r1_recall': 0.7692307692307693, 'r1_f1': 0.4907975460122699, 'pegasus_entailment': 0.41923271864652634, 'gold_entailment': 0.6792605717976888, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37777777777777777, 'r1_recall': 0.5930232558139535, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.7822880446910858, 'gold_entailment': 0.4546938091516495, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4675324675324675, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.5, 'pegasus_entailment': 0.7196983993053436, 'gold_entailment': 0.4138560990492503, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 14, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34146341463414637, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.41791044776119407, 'pegasus_entailment': 0.5533259332180023, 'gold_entailment': 0.47620758414268494, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 13, 'gold_ari': 12, 'gold_smog': 16}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7931034482758621, 'r1_recall': 0.6699029126213593, 'r1_f1': 0.7263157894736842, 'pegasus_entailment': 0.4167242447535197, 'gold_entailment': 0.38218389948209125, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 24}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38666666666666666, 'r1_recall': 0.4461538461538462, 'r1_f1': 0.4142857142857143, 'pegasus_entailment': 0.576278398434321, 'gold_entailment': 0.5974658330281576, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2714285714285714, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.38383838383838387, 'pegasus_entailment': 0.7031093612313271, 'gold_entailment': 0.279354989528656, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 19, 'pegasus_ari': 34, 'pegasus_smog': 25, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5408163265306123, 'r1_recall': 0.5760869565217391, 'r1_f1': 0.5578947368421052, 'pegasus_entailment': 0.6811829408009847, 'gold_entailment': 0.4805448651313782, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4017094017094017, 'r1_recall': 0.5402298850574713, 'r1_f1': 0.4607843137254902, 'pegasus_entailment': 0.28446444869041443, 'gold_entailment': 0.16981217134743928, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 23, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18181818181818182, 'r1_recall': 0.2564102564102564, 'r1_f1': 0.2127659574468085, 'pegasus_entailment': 0.5907061666250228, 'gold_entailment': 0.37890899181365967, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 20, 'gold_ari': 28, 'gold_smog': 25}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21710526315789475, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.3350253807106599, 'pegasus_entailment': 0.6940640310446421, 'gold_entailment': 0.30584993958473206, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5072463768115942, 'r1_recall': 0.33653846153846156, 'r1_f1': 0.4046242774566475, 'pegasus_entailment': 0.7153089642524719, 'gold_entailment': 0.22735094982716772, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23893805309734514, 'r1_recall': 0.38571428571428573, 'r1_f1': 0.29508196721311475, 'pegasus_entailment': 0.5178673610091209, 'gold_entailment': 0.22640756766001383, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 17}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6470588235294118, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.5365853658536585, 'pegasus_entailment': 0.6392346521218618, 'gold_entailment': 0.2798034509178251, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 24, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4233128834355828, 'r1_recall': 0.5149253731343284, 'r1_f1': 0.46464646464646464, 'pegasus_entailment': 0.5619626402854919, 'gold_entailment': 0.3082592457532883, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 21}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3851851851851852, 'r1_recall': 0.7123287671232876, 'r1_f1': 0.5, 'pegasus_entailment': 0.5749521255493164, 'gold_entailment': 0.6633232533931732, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 17, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44594594594594594, 'r1_recall': 0.5641025641025641, 'r1_f1': 0.4981132075471699, 'pegasus_entailment': 0.27336106300354, 'gold_entailment': 0.24524334073066711, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.288, 'r1_recall': 0.3711340206185567, 'r1_f1': 0.3243243243243243, 'pegasus_entailment': 0.572203554213047, 'gold_entailment': 0.4576541790738702, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4520547945205479, 'r1_recall': 0.3728813559322034, 'r1_f1': 0.40866873065015485, 'pegasus_entailment': 0.4686712473630905, 'gold_entailment': 0.3325794426103433, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5076923076923077, 'r1_recall': 0.3402061855670103, 'r1_f1': 0.4074074074074074, 'pegasus_entailment': 0.3840285936991374, 'gold_entailment': 0.2113995449617505, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4676258992805755, 'r1_recall': 0.5158730158730159, 'r1_f1': 0.49056603773584906, 'pegasus_entailment': 0.6845524460077286, 'gold_entailment': 0.38706132556710926, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2846153846153846, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.37948717948717947, 'pegasus_entailment': 0.66070697568357, 'gold_entailment': 0.44052552183469135, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47959183673469385, 'r1_recall': 0.41964285714285715, 'r1_f1': 0.4476190476190476, 'pegasus_entailment': 0.9206894189119339, 'gold_entailment': 0.28921693773008883, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2125984251968504, 'r1_recall': 0.4426229508196721, 'r1_f1': 0.2872340425531915, 'pegasus_entailment': 0.6222150176763535, 'gold_entailment': 0.38626941107213497, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39097744360902253, 'r1_recall': 0.5531914893617021, 'r1_f1': 0.45814977973568277, 'pegasus_entailment': 0.6336644664406776, 'gold_entailment': 0.3160426914691925, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 15, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4727272727272727, 'r1_recall': 0.6782608695652174, 'r1_f1': 0.557142857142857, 'pegasus_entailment': 0.7586647172768911, 'gold_entailment': 0.5803951025009155, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4485294117647059, 'r1_recall': 0.5446428571428571, 'r1_f1': 0.4919354838709677, 'pegasus_entailment': 0.5735560417175293, 'gold_entailment': 0.48869555195172626, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 21, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36619718309859156, 'r1_recall': 0.65, 'r1_f1': 0.46846846846846846, 'pegasus_entailment': 0.6009318232536316, 'gold_entailment': 0.30081451311707497, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4235294117647059, 'r1_recall': 0.5581395348837209, 'r1_f1': 0.4816053511705686, 'pegasus_entailment': 0.7468185226122538, 'gold_entailment': 0.3513943385332823, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29439252336448596, 'r1_recall': 0.6116504854368932, 'r1_f1': 0.3974763406940063, 'pegasus_entailment': 0.5058307562555585, 'gold_entailment': 0.24079475402832032, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.5, 'r1_f1': 0.46511627906976744, 'pegasus_entailment': 0.4927516758441925, 'gold_entailment': 0.5192389041185379, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 19}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.56, 'r1_f1': 0.509090909090909, 'pegasus_entailment': 0.42459302544593813, 'gold_entailment': 0.09011183120310307, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 15, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26717557251908397, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.3664921465968587, 'pegasus_entailment': 0.8341983914375305, 'gold_entailment': 0.6149447411298752, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 10, 'gold_coleman_liau': 13, 'gold_ari': 11, 'gold_smog': 15}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2756756756756757, 'r1_recall': 0.7391304347826086, 'r1_f1': 0.4015748031496063, 'pegasus_entailment': 0.5774320185184478, 'gold_entailment': 0.5881199340025584, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5952380952380952, 'r1_recall': 0.5639097744360902, 'r1_f1': 0.5791505791505792, 'pegasus_entailment': 0.6911920569837093, 'gold_entailment': 0.47122012575467426, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 22, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 22}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3652173913043478, 'r1_recall': 0.5316455696202531, 'r1_f1': 0.4329896907216495, 'pegasus_entailment': 0.7594688683748245, 'gold_entailment': 0.4841296672821045, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 18, 'gold_ari': 27, 'gold_smog': 20}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5955056179775281, 'r1_f1': 0.5435897435897437, 'pegasus_entailment': 0.30115895718336105, 'gold_entailment': 0.2401788185040156, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4322033898305085, 'r1_recall': 0.3923076923076923, 'r1_f1': 0.4112903225806452, 'pegasus_entailment': 0.48930290415883065, 'gold_entailment': 0.33352289783457917, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5630252100840336, 'r1_recall': 0.37640449438202245, 'r1_f1': 0.45117845117845123, 'pegasus_entailment': 0.6926837613185247, 'gold_entailment': 0.5008164516517094, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7252747252747253, 'r1_recall': 0.375, 'r1_f1': 0.49438202247191004, 'pegasus_entailment': 0.4496954282124837, 'gold_entailment': 0.16755001566239766, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5588235294117647, 'r1_recall': 0.5671641791044776, 'r1_f1': 0.5629629629629629, 'pegasus_entailment': 0.38364835157990457, 'gold_entailment': 0.46780917420983315, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4888888888888889, 'r1_recall': 0.46808510638297873, 'r1_f1': 0.47826086956521735, 'pegasus_entailment': 0.40570129454135895, 'gold_entailment': 0.08949514664709568, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 15, 'gold_ari': 20, 'gold_smog': 15}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5966386554621849, 'r1_recall': 0.5590551181102362, 'r1_f1': 0.5772357723577236, 'pegasus_entailment': 0.4909818544983864, 'gold_entailment': 0.4954721714769091, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38405797101449274, 'r1_recall': 0.6022727272727273, 'r1_f1': 0.4690265486725664, 'pegasus_entailment': 0.7887925148010254, 'gold_entailment': 0.6117328008015951, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45112781954887216, 'r1_recall': 0.5217391304347826, 'r1_f1': 0.48387096774193544, 'pegasus_entailment': 0.4616510570049286, 'gold_entailment': 0.2227246046066284, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3046875, 'r1_recall': 0.5131578947368421, 'r1_f1': 0.38235294117647056, 'pegasus_entailment': 0.6034489214420319, 'gold_entailment': 0.22743700941403708, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19696969696969696, 'r1_recall': 0.6046511627906976, 'r1_f1': 0.2971428571428571, 'pegasus_entailment': 0.5259220719337463, 'gold_entailment': 0.333455890417099, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45652173913043476, 'r1_recall': 0.75, 'r1_f1': 0.5675675675675675, 'pegasus_entailment': 0.6258266344666481, 'gold_entailment': 0.5535382231076559, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5964912280701754, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.5551020408163264, 'pegasus_entailment': 0.5380755588412285, 'gold_entailment': 0.4908534263571103, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3602941176470588, 'r1_recall': 0.6125, 'r1_f1': 0.4537037037037037, 'pegasus_entailment': 0.4086907714605331, 'gold_entailment': 0.31836801767349243, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5648854961832062, 'r1_recall': 0.6324786324786325, 'r1_f1': 0.5967741935483871, 'pegasus_entailment': 0.6520231068134308, 'gold_entailment': 0.47240710258483887, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48623853211009177, 'r1_recall': 0.45689655172413796, 'r1_f1': 0.47111111111111115, 'pegasus_entailment': 0.8741052627563477, 'gold_entailment': 0.46467508872350055, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 18, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2440944881889764, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.33333333333333337, 'pegasus_entailment': 0.5476341098546982, 'gold_entailment': 0.2958332747220993, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 18}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6864406779661016, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.527687296416938, 'pegasus_entailment': 0.5625903010368347, 'gold_entailment': 0.5927459076046944, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5982905982905983, 'r1_recall': 0.5785123966942148, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.8832093834877014, 'gold_entailment': 0.5271413822968801, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 19, 'gold_ari': 28, 'gold_smog': 23}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6486486486486487, 'r1_recall': 0.4645161290322581, 'r1_f1': 0.5413533834586467, 'pegasus_entailment': 0.86743692557017, 'gold_entailment': 0.43093629820006235, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5882352941176471, 'r1_recall': 0.49079754601226994, 'r1_f1': 0.5351170568561874, 'pegasus_entailment': 0.37240736186504364, 'gold_entailment': 0.18741158318395415, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29775280898876405, 'r1_recall': 0.5247524752475248, 'r1_f1': 0.3799283154121864, 'pegasus_entailment': 0.6647758353501558, 'gold_entailment': 0.39910565689206123, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4722222222222222, 'r1_recall': 0.5619834710743802, 'r1_f1': 0.5132075471698113, 'pegasus_entailment': 0.42008363145093125, 'gold_entailment': 0.31492605386301875, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39705882352941174, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.47161572052401746, 'pegasus_entailment': 0.5185412624850869, 'gold_entailment': 0.27509831450879574, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5118110236220472, 'r1_recall': 0.48872180451127817, 'r1_f1': 0.5, 'pegasus_entailment': 0.8106116453806559, 'gold_entailment': 0.37685269862413406, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 24, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5648148148148148, 'r1_recall': 0.32972972972972975, 'r1_f1': 0.41638225255972694, 'pegasus_entailment': 0.31942225247621536, 'gold_entailment': 0.2168780051999622, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34177215189873417, 'r1_recall': 0.46551724137931033, 'r1_f1': 0.3941605839416058, 'pegasus_entailment': 0.5966327885786692, 'gold_entailment': 0.30599045008420944, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 13, 'gold_smog': 17}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.5113636363636364, 'r1_f1': 0.48128342245989303, 'pegasus_entailment': 0.44118570536375046, 'gold_entailment': 0.4189467752973239, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 23, 'gold_ari': 26, 'gold_smog': 25}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5053763440860215, 'r1_recall': 0.5053763440860215, 'r1_f1': 0.5053763440860215, 'pegasus_entailment': 0.6271118447184563, 'gold_entailment': 0.4522012819846471, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 26, 'gold_smog': 24}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5104166666666666, 'r1_recall': 0.4336283185840708, 'r1_f1': 0.4688995215311005, 'pegasus_entailment': 0.507217695315679, 'gold_entailment': 0.21499879658222198, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 22, 'gold_ari': 30, 'gold_smog': 26}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.525, 'r1_f1': 0.4719101123595506, 'pegasus_entailment': 0.5626743510365486, 'gold_entailment': 0.4602479517459869, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44144144144144143, 'r1_recall': 0.48514851485148514, 'r1_f1': 0.46226415094339623, 'pegasus_entailment': 0.2702656760811806, 'gold_entailment': 0.2095381644155298, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 23}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6535433070866141, 'r1_recall': 0.39712918660287083, 'r1_f1': 0.49404761904761907, 'pegasus_entailment': 0.6334074959158897, 'gold_entailment': 0.3306358501315117, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 20, 'gold_ari': 29, 'gold_smog': 25}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4642857142857143, 'r1_recall': 0.574585635359116, 'r1_f1': 0.5135802469135803, 'pegasus_entailment': 0.6525016043867383, 'gold_entailment': 0.321583217382431, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24615384615384617, 'r1_recall': 0.5423728813559322, 'r1_f1': 0.3386243386243386, 'pegasus_entailment': 0.6060717239975929, 'gold_entailment': 0.43708787858486176, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 15, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8, 'r1_recall': 0.3950617283950617, 'r1_f1': 0.5289256198347108, 'pegasus_entailment': 0.4397984544436137, 'gold_entailment': 0.43171959817409516, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 21}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5517241379310345, 'r1_recall': 0.5853658536585366, 'r1_f1': 0.5680473372781065, 'pegasus_entailment': 0.35836756229400635, 'gold_entailment': 0.29219696919123334, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 24, 'gold_smog': 23}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4117647058823529, 'r1_recall': 0.5104166666666666, 'r1_f1': 0.45581395348837206, 'pegasus_entailment': 0.3899650499224663, 'gold_entailment': 0.09420887753367424, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5697674418604651, 'r1_recall': 0.532608695652174, 'r1_f1': 0.5505617977528091, 'pegasus_entailment': 0.5922806064287821, 'gold_entailment': 0.0854463167488575, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 27, 'gold_coleman_liau': 21, 'gold_ari': 33, 'gold_smog': 27}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5546218487394958, 'r1_recall': 0.3402061855670103, 'r1_f1': 0.42172523961661346, 'pegasus_entailment': 0.5179198483626047, 'gold_entailment': 0.25255240260490347, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7096774193548387, 'r1_recall': 0.26506024096385544, 'r1_f1': 0.3859649122807018, 'pegasus_entailment': 0.37976356968283653, 'gold_entailment': 0.36935776259217945, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 22, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43820224719101125, 'r1_recall': 0.6610169491525424, 'r1_f1': 0.5270270270270271, 'pegasus_entailment': 0.6947619020938873, 'gold_entailment': 0.27391037344932556, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5131578947368421, 'r1_recall': 0.4508670520231214, 'r1_f1': 0.48000000000000004, 'pegasus_entailment': 0.41708973546822864, 'gold_entailment': 0.0960953307471105, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5432098765432098, 'r1_f1': 0.5207100591715976, 'pegasus_entailment': 0.5285243541002274, 'gold_entailment': 0.3442361056804657, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 24, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 24, 'gold_smog': 23}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4805194805194805, 'r1_recall': 0.4966442953020134, 'r1_f1': 0.4884488448844884, 'pegasus_entailment': 0.7042448669672012, 'gold_entailment': 0.32545129768550396, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4088050314465409, 'r1_recall': 0.6989247311827957, 'r1_f1': 0.5158730158730159, 'pegasus_entailment': 0.5556474804878235, 'gold_entailment': 0.2995836976915598, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4842105263157895, 'r1_recall': 0.2857142857142857, 'r1_f1': 0.359375, 'pegasus_entailment': 0.6636899759372076, 'gold_entailment': 0.25856345643599826, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2028985507246377, 'r1_recall': 0.7368421052631579, 'r1_f1': 0.3181818181818182, 'pegasus_entailment': 0.8793971240520477, 'gold_entailment': 0.6627846360206604, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 24, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49606299212598426, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.5361702127659574, 'pegasus_entailment': 0.7511053383350372, 'gold_entailment': 0.36994340519110364, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 19, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38, 'r1_recall': 0.5533980582524272, 'r1_f1': 0.4505928853754941, 'pegasus_entailment': 0.8156007379293442, 'gold_entailment': 0.524617712944746, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 24, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5042016806722689, 'r1_recall': 0.36809815950920244, 'r1_f1': 0.42553191489361697, 'pegasus_entailment': 0.6713380912939707, 'gold_entailment': 0.3468693718314171, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 17}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5514018691588785, 'r1_recall': 0.5412844036697247, 'r1_f1': 0.5462962962962962, 'pegasus_entailment': 0.5794201493263245, 'gold_entailment': 0.5177637984355291, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 15, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4489795918367347, 'r1_recall': 0.5, 'r1_f1': 0.47311827956989244, 'pegasus_entailment': 0.8301322162151337, 'gold_entailment': 0.35909820050001146, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 16, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5233644859813084, 'r1_recall': 0.37333333333333335, 'r1_f1': 0.43579766536964976, 'pegasus_entailment': 0.2965043306350708, 'gold_entailment': 0.26384046524763105, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.61, 'r1_recall': 0.4357142857142857, 'r1_f1': 0.5083333333333333, 'pegasus_entailment': 0.7344463691115379, 'gold_entailment': 0.45204315955440205, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5148514851485149, 'r1_recall': 0.348993288590604, 'r1_f1': 0.41600000000000004, 'pegasus_entailment': 0.6163754761219025, 'gold_entailment': 0.27614041417837143, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4074074074074074, 'r1_recall': 0.6043956043956044, 'r1_f1': 0.48672566371681414, 'pegasus_entailment': 0.4545196324586868, 'gold_entailment': 0.6521226018667221, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 18, 'gold_ari': 30, 'gold_smog': 22}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21487603305785125, 'r1_recall': 0.33766233766233766, 'r1_f1': 0.2626262626262626, 'pegasus_entailment': 0.8527382612228394, 'gold_entailment': 0.27501824001471203, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38524590163934425, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.48205128205128206, 'pegasus_entailment': 0.4676190987229347, 'gold_entailment': 0.1755192776521047, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6831683168316832, 'r1_recall': 0.375, 'r1_f1': 0.4842105263157894, 'pegasus_entailment': 0.6563249677419662, 'gold_entailment': 0.22899515181779861, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.391025641025641, 'r1_recall': 0.5545454545454546, 'r1_f1': 0.45864661654135336, 'pegasus_entailment': 0.7382365345954895, 'gold_entailment': 0.406961552798748, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 20, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3356643356643357, 'r1_recall': 0.3870967741935484, 'r1_f1': 0.3595505617977528, 'pegasus_entailment': 0.43178344890475273, 'gold_entailment': 0.45239967107772827, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21, 'gold_flesch_kincaid': 34, 'gold_coleman_liau': 23, 'gold_ari': 42, 'gold_smog': 28}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5225225225225225, 'r1_recall': 0.48333333333333334, 'r1_f1': 0.5021645021645021, 'pegasus_entailment': 0.5074942509333292, 'gold_entailment': 0.2623799289576709, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4235294117647059, 'r1_recall': 0.30638297872340425, 'r1_f1': 0.3555555555555555, 'pegasus_entailment': 0.642451382109097, 'gold_entailment': 0.16285268696291105, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48175182481751827, 'r1_recall': 0.4342105263157895, 'r1_f1': 0.4567474048442907, 'pegasus_entailment': 0.5702558130025863, 'gold_entailment': 0.2848923973739147, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4344262295081967, 'r1_recall': 0.6162790697674418, 'r1_f1': 0.5096153846153847, 'pegasus_entailment': 0.6376307874917984, 'gold_entailment': 0.36308820359408855, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26973684210526316, 'r1_recall': 0.5466666666666666, 'r1_f1': 0.36123348017621143, 'pegasus_entailment': 0.5575486359496912, 'gold_entailment': 0.4046943684418996, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33035714285714285, 'r1_recall': 0.4111111111111111, 'r1_f1': 0.3663366336633663, 'pegasus_entailment': 0.6667603030800819, 'gold_entailment': 0.29139344394207, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6276595744680851, 'r1_recall': 0.3597560975609756, 'r1_f1': 0.4573643410852713, 'pegasus_entailment': 0.5461943805217743, 'gold_entailment': 0.37330618873238564, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5986394557823129, 'r1_recall': 0.30662020905923343, 'r1_f1': 0.40552995391705066, 'pegasus_entailment': 0.7478941977024078, 'gold_entailment': 0.5116500842074553, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7164179104477612, 'r1_recall': 0.2681564245810056, 'r1_f1': 0.39024390243902435, 'pegasus_entailment': 0.6387999877333641, 'gold_entailment': 0.3976357417802016, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5420560747663551, 'r1_recall': 0.5087719298245614, 'r1_f1': 0.5248868778280542, 'pegasus_entailment': 0.7134885787963867, 'gold_entailment': 0.4621210604906082, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5517241379310345, 'r1_recall': 0.36923076923076925, 'r1_f1': 0.44239631336405527, 'pegasus_entailment': 0.3924296547969182, 'gold_entailment': 0.22392397597432137, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3902439024390244, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.4229074889867842, 'pegasus_entailment': 0.48276375979185104, 'gold_entailment': 0.27195907490594046, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5227272727272727, 'r1_recall': 0.5476190476190477, 'r1_f1': 0.5348837209302325, 'pegasus_entailment': 0.6094091758131981, 'gold_entailment': 0.36614870047196746, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7564102564102564, 'r1_recall': 0.36419753086419754, 'r1_f1': 0.4916666666666667, 'pegasus_entailment': 0.7618515640497208, 'gold_entailment': 0.4323510080575943, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49137931034482757, 'r1_recall': 0.7402597402597403, 'r1_f1': 0.5906735751295338, 'pegasus_entailment': 0.6064294949173927, 'gold_entailment': 0.10714052338153124, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 17, 'gold_ari': 26, 'gold_smog': 23}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5882352941176471, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.532319391634981, 'pegasus_entailment': 0.5429545529186726, 'gold_entailment': 0.23696456849575043, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45217391304347826, 'r1_recall': 0.6933333333333334, 'r1_f1': 0.5473684210526315, 'pegasus_entailment': 0.5551557938257853, 'gold_entailment': 0.3982236248751481, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5865384615384616, 'r1_recall': 0.5041322314049587, 'r1_f1': 0.5422222222222222, 'pegasus_entailment': 0.6639842003583908, 'gold_entailment': 0.3134526927024126, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45751633986928103, 'r1_recall': 0.6306306306306306, 'r1_f1': 0.5303030303030303, 'pegasus_entailment': 0.9110236465930939, 'gold_entailment': 0.6588362207015356, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 23, 'gold_ari': 30, 'gold_smog': 24}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5535714285714286, 'r1_recall': 0.3803680981595092, 'r1_f1': 0.4509090909090909, 'pegasus_entailment': 0.7889156937599182, 'gold_entailment': 0.44949556949237984, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6458333333333334, 'r1_recall': 0.3522727272727273, 'r1_f1': 0.4558823529411765, 'pegasus_entailment': 0.45168067142367363, 'gold_entailment': 0.516351729631424, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 22}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4387755102040816, 'r1_recall': 0.5375, 'r1_f1': 0.4831460674157303, 'pegasus_entailment': 0.3089930157487591, 'gold_entailment': 0.2634221116701762, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28205128205128205, 'r1_recall': 0.55, 'r1_f1': 0.3728813559322034, 'pegasus_entailment': 0.6573426226774851, 'gold_entailment': 0.2813045307993889, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 24}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4111111111111111, 'r1_recall': 0.6166666666666667, 'r1_f1': 0.4933333333333334, 'pegasus_entailment': 0.4735011011362076, 'gold_entailment': 0.21351677551865578, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42028985507246375, 'r1_recall': 0.5918367346938775, 'r1_f1': 0.4915254237288135, 'pegasus_entailment': 0.7990918517112732, 'gold_entailment': 0.4226020397618413, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5308641975308642, 'r1_recall': 0.6615384615384615, 'r1_f1': 0.589041095890411, 'pegasus_entailment': 0.532750777900219, 'gold_entailment': 0.5183585432491132, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32075471698113206, 'r1_recall': 0.7391304347826086, 'r1_f1': 0.4473684210526316, 'pegasus_entailment': 0.5506171956658363, 'gold_entailment': 0.5507700964808464, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 10, 'gold_coleman_liau': 13, 'gold_ari': 11, 'gold_smog': 15}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5128205128205128, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5194805194805194, 'pegasus_entailment': 0.6190418750047684, 'gold_entailment': 0.49503437653183935, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3951612903225806, 'r1_recall': 0.44144144144144143, 'r1_f1': 0.4170212765957446, 'pegasus_entailment': 0.5764942288398742, 'gold_entailment': 0.26543345940964563, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.3287671232876712, 'r1_f1': 0.4056338028169014, 'pegasus_entailment': 0.4480090722441673, 'gold_entailment': 0.14849109477363526, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5121951219512195, 'r1_recall': 0.5121951219512195, 'r1_f1': 0.5121951219512195, 'pegasus_entailment': 0.3336703379948934, 'gold_entailment': 0.3694454450160265, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32098765432098764, 'r1_recall': 0.5909090909090909, 'r1_f1': 0.416, 'pegasus_entailment': 0.7966315845648447, 'gold_entailment': 0.4154111072421074, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 22}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45689655172413796, 'r1_recall': 0.5247524752475248, 'r1_f1': 0.4884792626728111, 'pegasus_entailment': 0.5406582355499268, 'gold_entailment': 0.4424980990588665, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 22}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5225225225225225, 'r1_recall': 0.5370370370370371, 'r1_f1': 0.5296803652968036, 'pegasus_entailment': 0.6208218783140182, 'gold_entailment': 0.2019494716078043, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 16, 'gold_ari': 13, 'gold_smog': 16}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18, 'r1_recall': 0.5625, 'r1_f1': 0.2727272727272727, 'pegasus_entailment': 0.5420101061463356, 'gold_entailment': 0.4815022051334381, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 23, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 24, 'gold_ari': 25, 'gold_smog': 24}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4628099173553719, 'r1_recall': 0.5656565656565656, 'r1_f1': 0.5090909090909091, 'pegasus_entailment': 0.5035977631807327, 'gold_entailment': 0.334684756398201, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4491017964071856, 'r1_recall': 0.47468354430379744, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.6548269689083099, 'gold_entailment': 0.19920188188552856, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 29, 'gold_coleman_liau': 19, 'gold_ari': 34, 'gold_smog': 25}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.437125748502994, 'r1_recall': 0.4620253164556962, 'r1_f1': 0.4492307692307692, 'pegasus_entailment': 0.43438759446144104, 'gold_entailment': 0.30314900875091555, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 16, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.67, 'r1_recall': 0.3471502590673575, 'r1_f1': 0.4573378839590444, 'pegasus_entailment': 0.5290403999388218, 'gold_entailment': 0.37413563165399766, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6019417475728155, 'r1_recall': 0.5904761904761905, 'r1_f1': 0.5961538461538461, 'pegasus_entailment': 0.4225607365369797, 'gold_entailment': 0.20529814064502716, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 21, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47368421052631576, 'r1_recall': 0.504, 'r1_f1': 0.4883720930232558, 'pegasus_entailment': 0.3197208970785141, 'gold_entailment': 0.18308363687247037, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.29702970297029707, 'pegasus_entailment': 0.45912451824794215, 'gold_entailment': 0.415777750313282, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3627450980392157, 'r1_recall': 0.6065573770491803, 'r1_f1': 0.4539877300613497, 'pegasus_entailment': 0.44075412551561993, 'gold_entailment': 0.3236607809861501, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 15, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4457831325301205, 'r1_recall': 0.5967741935483871, 'r1_f1': 0.5103448275862069, 'pegasus_entailment': 0.47857003659009933, 'gold_entailment': 0.28599997516721487, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33695652173913043, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.4105960264900662, 'pegasus_entailment': 0.2498399221803993, 'gold_entailment': 0.2772010862827301, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 16}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4108527131782946, 'r1_recall': 0.4649122807017544, 'r1_f1': 0.43621399176954734, 'pegasus_entailment': 0.641083632906278, 'gold_entailment': 0.39284228285153705, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35135135135135137, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.37142857142857144, 'pegasus_entailment': 0.5456063836812973, 'gold_entailment': 0.39316630860169727, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.17699115044247787, 'r1_recall': 0.5, 'r1_f1': 0.261437908496732, 'pegasus_entailment': 0.5406945705413818, 'gold_entailment': 0.467435821890831, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 19}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.589041095890411, 'r1_recall': 0.49710982658959535, 'r1_f1': 0.5391849529780565, 'pegasus_entailment': 0.7695957294532231, 'gold_entailment': 0.3377031373480956, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4041095890410959, 'r1_recall': 0.7375, 'r1_f1': 0.5221238938053097, 'pegasus_entailment': 0.4016360929235816, 'gold_entailment': 0.31532881781458855, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 21, 'gold_ari': 20, 'gold_smog': 21}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5785714285714286, 'r1_recall': 0.4550561797752809, 'r1_f1': 0.5094339622641509, 'pegasus_entailment': 0.4429552877942721, 'gold_entailment': 0.40056494027376177, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6517857142857143, 'r1_recall': 0.453416149068323, 'r1_f1': 0.5347985347985348, 'pegasus_entailment': 0.7846530824899673, 'gold_entailment': 0.4215105963604791, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5942028985507246, 'r1_recall': 0.30597014925373134, 'r1_f1': 0.4039408866995074, 'pegasus_entailment': 0.642691453297933, 'gold_entailment': 0.5425386801362038, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7254901960784313, 'r1_recall': 0.3045267489711934, 'r1_f1': 0.42898550724637674, 'pegasus_entailment': 0.35788606355587643, 'gold_entailment': 0.22226118445396423, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 29, 'gold_coleman_liau': 21, 'gold_ari': 34, 'gold_smog': 26}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36666666666666664, 'r1_recall': 0.5365853658536586, 'r1_f1': 0.4356435643564356, 'pegasus_entailment': 0.5714231543242931, 'gold_entailment': 0.5022071997324625, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5405405405405405, 'pegasus_entailment': 0.8774466753005982, 'gold_entailment': 0.3227816931903362, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 20}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2122905027932961, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.30278884462151395, 'pegasus_entailment': 0.47027734977503616, 'gold_entailment': 0.29038501642644404, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 19}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6896551724137931, 'r1_recall': 0.17937219730941703, 'r1_f1': 0.2846975088967972, 'pegasus_entailment': 0.5317081362009048, 'gold_entailment': 0.43532520871270786, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1510791366906475, 'r1_recall': 0.18584070796460178, 'r1_f1': 0.16666666666666666, 'pegasus_entailment': 0.46044792731602985, 'gold_entailment': 0.13615373289212584, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 31, 'pegasus_smog': 24, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3055555555555556, 'r1_recall': 0.717391304347826, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.6375936269760132, 'gold_entailment': 0.6455717434485754, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 15}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6039603960396039, 'r1_recall': 0.3370165745856354, 'r1_f1': 0.4326241134751774, 'pegasus_entailment': 0.20586472873886427, 'gold_entailment': 0.20456243818625808, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7191011235955056, 'r1_recall': 0.3615819209039548, 'r1_f1': 0.481203007518797, 'pegasus_entailment': 0.28626033415397006, 'gold_entailment': 0.21028953790664673, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 24}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37777777777777777, 'r1_recall': 0.53125, 'r1_f1': 0.4415584415584416, 'pegasus_entailment': 0.5709832310676575, 'gold_entailment': 0.47842519395053384, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5714285714285714, 'r1_recall': 0.30344827586206896, 'r1_f1': 0.3963963963963964, 'pegasus_entailment': 0.5456988662481308, 'gold_entailment': 0.2756625350032534, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.15053763440860216, 'r1_recall': 0.5, 'r1_f1': 0.23140495867768596, 'pegasus_entailment': 0.3569367453455925, 'gold_entailment': 0.18995869904756546, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 10, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 14}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.14054054054054055, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.2139917695473251, 'pegasus_entailment': 0.7350147366523743, 'gold_entailment': 0.41088594356551766, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 11, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5039370078740157, 'r1_recall': 0.5378151260504201, 'r1_f1': 0.5203252032520326, 'pegasus_entailment': 0.5809047520160675, 'gold_entailment': 0.3941349231948455, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3300970873786408, 'r1_recall': 0.4788732394366197, 'r1_f1': 0.39080459770114945, 'pegasus_entailment': 0.3895431309938431, 'gold_entailment': 0.10191410531600316, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 21}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3118279569892473, 'r1_recall': 0.5272727272727272, 'r1_f1': 0.39189189189189183, 'pegasus_entailment': 0.32131071016192436, 'gold_entailment': 0.18917431433995566, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2972972972972973, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.34375, 'pegasus_entailment': 0.5890060901641846, 'gold_entailment': 0.29709105286747217, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5869565217391305, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6242774566473989, 'pegasus_entailment': 0.37539327377453446, 'gold_entailment': 0.41506119444966316, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3983739837398374, 'r1_recall': 0.5903614457831325, 'r1_f1': 0.4757281553398058, 'pegasus_entailment': 0.745312973856926, 'gold_entailment': 0.5398491621017456, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 17}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.4954954954954955, 'r1_f1': 0.5527638190954773, 'pegasus_entailment': 0.3253594630708297, 'gold_entailment': 0.16794907450675964, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7831325301204819, 'r1_recall': 0.19345238095238096, 'r1_f1': 0.31026252983293556, 'pegasus_entailment': 0.40637261668841046, 'gold_entailment': 0.4138063659722155, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4589041095890411, 'r1_recall': 0.30180180180180183, 'r1_f1': 0.36413043478260865, 'pegasus_entailment': 0.5462624371051789, 'gold_entailment': 0.522493988275528, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36036036036036034, 'r1_recall': 0.5128205128205128, 'r1_f1': 0.42328042328042326, 'pegasus_entailment': 0.6429128468036651, 'gold_entailment': 0.488946129878362, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 9, 'gold_coleman_liau': 13, 'gold_ari': 11, 'gold_smog': 13}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6029411764705882, 'r1_recall': 0.3942307692307692, 'r1_f1': 0.4767441860465116, 'pegasus_entailment': 0.22533480636775494, 'gold_entailment': 0.32151235453784466, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 14, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 16}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37037037037037035, 'r1_recall': 0.410958904109589, 'r1_f1': 0.38961038961038963, 'pegasus_entailment': 0.6121471434831619, 'gold_entailment': 0.2336575584486127, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4520547945205479, 'r1_recall': 0.5076923076923077, 'r1_f1': 0.47826086956521735, 'pegasus_entailment': 0.36243352890014646, 'gold_entailment': 0.2796338324745496, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 13, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.328, 'r1_recall': 0.5694444444444444, 'r1_f1': 0.416243654822335, 'pegasus_entailment': 0.7002076059579849, 'gold_entailment': 0.31096137563387555, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.411214953271028, 'r1_recall': 0.5432098765432098, 'r1_f1': 0.4680851063829787, 'pegasus_entailment': 0.5605013370513916, 'gold_entailment': 0.2717624434735626, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2558139534883721, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.3548387096774194, 'pegasus_entailment': 0.6855868995189667, 'gold_entailment': 0.2623667069710791, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 15}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40540540540540543, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.7606385871767998, 'gold_entailment': 0.7904463171958923, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 17, 'gold_ari': 14, 'gold_smog': 15}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5517241379310345, 'r1_recall': 0.40764331210191085, 'r1_f1': 0.46886446886446886, 'pegasus_entailment': 0.5844864472746849, 'gold_entailment': 0.3425470015832356, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6105263157894737, 'r1_recall': 0.4027777777777778, 'r1_f1': 0.48535564853556484, 'pegasus_entailment': 0.32738306280225515, 'gold_entailment': 0.06967372447252274, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35333333333333333, 'r1_recall': 0.5638297872340425, 'r1_f1': 0.4344262295081967, 'pegasus_entailment': 0.7856741845607758, 'gold_entailment': 0.13153749456008276, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 17}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5167785234899329, 'r1_recall': 0.4031413612565445, 'r1_f1': 0.45294117647058824, 'pegasus_entailment': 0.49380502849817276, 'gold_entailment': 0.2808543562889099, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23668639053254437, 'r1_recall': 0.8163265306122449, 'r1_f1': 0.3669724770642202, 'pegasus_entailment': 0.6876280270516872, 'gold_entailment': 0.14989620447158813, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3783783783783784, 'r1_recall': 0.5060240963855421, 'r1_f1': 0.4329896907216495, 'pegasus_entailment': 0.8621332844098409, 'gold_entailment': 0.5755961139996847, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6086956521739131, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.5028028873105844, 'gold_entailment': 0.14066442223265768, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 13, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 17, 'gold_ari': 15, 'gold_smog': 13}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33653846153846156, 'r1_recall': 0.43209876543209874, 'r1_f1': 0.3783783783783784, 'pegasus_entailment': 0.5192663110792637, 'gold_entailment': 0.14792985515668988, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6585365853658537, 'r1_recall': 0.39416058394160586, 'r1_f1': 0.4931506849315068, 'pegasus_entailment': 0.572172486782074, 'gold_entailment': 0.3363201156258583, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24050632911392406, 'r1_recall': 0.4318181818181818, 'r1_f1': 0.3089430894308943, 'pegasus_entailment': 0.6419264934957027, 'gold_entailment': 0.4604189097881317, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 28, 'gold_coleman_liau': 25, 'gold_ari': 35, 'gold_smog': 30}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24107142857142858, 'r1_recall': 0.4576271186440678, 'r1_f1': 0.3157894736842105, 'pegasus_entailment': 0.5163147121667861, 'gold_entailment': 0.11280431179329753, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5284552845528455, 'r1_recall': 0.48507462686567165, 'r1_f1': 0.5058365758754864, 'pegasus_entailment': 0.689821058511734, 'gold_entailment': 0.5933743516604105, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6901408450704225, 'r1_recall': 0.3141025641025641, 'r1_f1': 0.4317180616740088, 'pegasus_entailment': 0.4314277196923892, 'gold_entailment': 0.43859001994132996, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38095238095238093, 'r1_recall': 0.7384615384615385, 'r1_f1': 0.5026178010471204, 'pegasus_entailment': 0.5081214495003223, 'gold_entailment': 0.4595737084746361, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 15, 'gold_ari': 14, 'gold_smog': 15}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42045454545454547, 'r1_recall': 0.42045454545454547, 'r1_f1': 0.42045454545454547, 'pegasus_entailment': 0.7416467368602753, 'gold_entailment': 0.3277356183777253, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28225806451612906, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.33653846153846156, 'pegasus_entailment': 0.5939902126789093, 'gold_entailment': 0.39846931273738545, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 17, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5263157894736842, 'r1_recall': 0.5194805194805194, 'r1_f1': 0.522875816993464, 'pegasus_entailment': 0.6160506308078766, 'gold_entailment': 0.3041938729584217, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3055555555555556, 'r1_recall': 0.55, 'r1_f1': 0.39285714285714285, 'pegasus_entailment': 0.43667744994163515, 'gold_entailment': 0.21620116382837296, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5315315315315315, 'r1_recall': 0.3782051282051282, 'r1_f1': 0.44194756554307113, 'pegasus_entailment': 0.642387741804123, 'gold_entailment': 0.24117182344198226, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4222222222222222, 'r1_recall': 0.5, 'r1_f1': 0.4578313253012048, 'pegasus_entailment': 0.42496342957019806, 'gold_entailment': 0.3054184317588806, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 15, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2420091324200913, 'r1_recall': 0.6235294117647059, 'r1_f1': 0.3486842105263158, 'pegasus_entailment': 0.7039964348077774, 'gold_entailment': 0.25465063452720643, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6218487394957983, 'r1_recall': 0.5648854961832062, 'r1_f1': 0.5920000000000001, 'pegasus_entailment': 0.4870776854455471, 'gold_entailment': 0.5654586752255758, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 22, 'gold_ari': 32, 'gold_smog': 25}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3925233644859813, 'r1_recall': 0.39622641509433965, 'r1_f1': 0.3943661971830986, 'pegasus_entailment': 0.3811856843531132, 'gold_entailment': 0.2704683232586831, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49382716049382713, 'r1_recall': 0.4371584699453552, 'r1_f1': 0.46376811594202894, 'pegasus_entailment': 0.544019837464605, 'gold_entailment': 0.17429650947451591, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.392, 'r1_recall': 0.6447368421052632, 'r1_f1': 0.4875621890547263, 'pegasus_entailment': 0.6713415794074535, 'gold_entailment': 0.7021587789058685, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39166666666666666, 'r1_recall': 0.5108695652173914, 'r1_f1': 0.44339622641509435, 'pegasus_entailment': 0.5438551604747772, 'gold_entailment': 0.172110582391421, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6601941747572816, 'r1_recall': 0.3148148148148148, 'r1_f1': 0.426332288401254, 'pegasus_entailment': 0.7006070092320442, 'gold_entailment': 0.3658583176632722, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4782608695652174, 'r1_recall': 0.32673267326732675, 'r1_f1': 0.38823529411764707, 'pegasus_entailment': 0.4513292871415615, 'gold_entailment': 0.42512747645378113, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5882352941176471, 'r1_recall': 0.5102040816326531, 'r1_f1': 0.546448087431694, 'pegasus_entailment': 0.39967962354421616, 'gold_entailment': 0.20719465031288564, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5222222222222223, 'r1_recall': 0.6714285714285714, 'r1_f1': 0.5875, 'pegasus_entailment': 0.44305945187807083, 'gold_entailment': 0.2996755788723628, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 32, 'pegasus_smog': 25, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 22, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5775862068965517, 'r1_recall': 0.5037593984962406, 'r1_f1': 0.5381526104417671, 'pegasus_entailment': 0.5852339789271355, 'gold_entailment': 0.7466199696063995, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 25}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4105960264900662, 'r1_recall': 0.6888888888888889, 'r1_f1': 0.5145228215767634, 'pegasus_entailment': 0.6023195151771817, 'gold_entailment': 0.3253117154041926, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4247787610619469, 'r1_recall': 0.41739130434782606, 'r1_f1': 0.42105263157894735, 'pegasus_entailment': 0.7299703061580658, 'gold_entailment': 0.4088003396987915, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 21}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3026315789473684, 'r1_recall': 0.4144144144144144, 'r1_f1': 0.34980988593155893, 'pegasus_entailment': 0.45442424565553663, 'gold_entailment': 0.2999254713455836, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4791666666666667, 'r1_recall': 0.5, 'r1_f1': 0.48936170212765956, 'pegasus_entailment': 0.8090142607688904, 'gold_entailment': 0.6131554692983627, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1875, 'r1_recall': 0.6, 'r1_f1': 0.2857142857142857, 'pegasus_entailment': 0.6021363772451878, 'gold_entailment': 0.3350626900792122, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 15, 'gold_smog': 18}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3089430894308943, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.42458100558659223, 'pegasus_entailment': 0.3956485837697983, 'gold_entailment': 0.4977246622244517, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.10919540229885058, 'r1_recall': 0.40425531914893614, 'r1_f1': 0.17194570135746606, 'pegasus_entailment': 0.6479148752987385, 'gold_entailment': 0.31282685697078705, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 14, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.49295774647887325, 'r1_f1': 0.4794520547945206, 'pegasus_entailment': 0.7424024343490601, 'gold_entailment': 0.43109680972993375, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6164383561643836, 'r1_recall': 0.4918032786885246, 'r1_f1': 0.5471124620060791, 'pegasus_entailment': 0.665726512670517, 'gold_entailment': 0.4808609951287508, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6527777777777778, 'r1_recall': 0.34306569343065696, 'r1_f1': 0.44976076555023925, 'pegasus_entailment': 0.40934152342379093, 'gold_entailment': 0.3619891901810964, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 19, 'gold_ari': 31, 'gold_smog': 24}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4596774193548387, 'r1_recall': 0.6263736263736264, 'r1_f1': 0.5302325581395348, 'pegasus_entailment': 0.7093200087547302, 'gold_entailment': 0.7850863635540009, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 27, 'gold_coleman_liau': 21, 'gold_ari': 32, 'gold_smog': 26}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.375, 'r1_recall': 0.38345864661654133, 'r1_f1': 0.37918215613382905, 'pegasus_entailment': 0.6227535332242647, 'gold_entailment': 0.28110914429028827, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.5548780487804879, 'r1_f1': 0.5687500000000001, 'pegasus_entailment': 0.6146550953388215, 'gold_entailment': 0.20110664516687393, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 17, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7172413793103448, 'r1_recall': 0.5174129353233831, 'r1_f1': 0.6011560693641618, 'pegasus_entailment': 0.788996022939682, 'gold_entailment': 0.5223846832911173, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5357142857142857, 'r1_recall': 0.45, 'r1_f1': 0.4891304347826087, 'pegasus_entailment': 0.4945553181072076, 'gold_entailment': 0.37879059215386707, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 26, 'gold_smog': 25}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6857142857142857, 'r1_recall': 0.6, 'r1_f1': 0.64, 'pegasus_entailment': 0.5263141493002573, 'gold_entailment': 0.6486612757047018, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.391304347826087, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.4568527918781726, 'pegasus_entailment': 0.3395467475056648, 'gold_entailment': 0.26729970425367355, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21487603305785125, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.30769230769230765, 'pegasus_entailment': 0.8046947121620178, 'gold_entailment': 0.3085229347149531, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 17, 'gold_smog': 19}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3516483516483517, 'r1_recall': 0.5079365079365079, 'r1_f1': 0.41558441558441556, 'pegasus_entailment': 0.5954255998134613, 'gold_entailment': 0.5173936684926351, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24175824175824176, 'r1_recall': 0.6470588235294118, 'r1_f1': 0.352, 'pegasus_entailment': 0.5847499097386996, 'gold_entailment': 0.487981915473938, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 21, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2967032967032967, 'r1_recall': 0.35526315789473684, 'r1_f1': 0.3233532934131737, 'pegasus_entailment': 0.3608329650014639, 'gold_entailment': 0.084015853703022, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 16, 'gold_flesch_kincaid': 38, 'gold_coleman_liau': 19, 'gold_ari': 46, 'gold_smog': 30}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6484375, 'r1_recall': 0.45108695652173914, 'r1_f1': 0.532051282051282, 'pegasus_entailment': 0.6747437367836634, 'gold_entailment': 0.452759650349617, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 25, 'gold_smog': 19}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2671232876712329, 'r1_recall': 0.582089552238806, 'r1_f1': 0.36619718309859156, 'pegasus_entailment': 0.7015826233795711, 'gold_entailment': 0.4922631134589513, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 16}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.58, 'r1_recall': 0.34523809523809523, 'r1_f1': 0.43283582089552236, 'pegasus_entailment': 0.4550968427211046, 'gold_entailment': 0.2781446998318036, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5959595959595959, 'r1_recall': 0.44696969696969696, 'r1_f1': 0.5108225108225108, 'pegasus_entailment': 0.6210488557815552, 'gold_entailment': 0.4291631355881691, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 20, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5462962962962963, 'r1_recall': 0.37341772151898733, 'r1_f1': 0.443609022556391, 'pegasus_entailment': 0.8638228178024292, 'gold_entailment': 0.46386968791484834, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6343283582089553, 'r1_recall': 0.28716216216216217, 'r1_f1': 0.39534883720930236, 'pegasus_entailment': 0.7436498701572418, 'gold_entailment': 0.438646810559126, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4634146341463415, 'r1_recall': 0.6909090909090909, 'r1_f1': 0.5547445255474452, 'pegasus_entailment': 0.44939267449080944, 'gold_entailment': 0.5100737164417902, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.3299492385786802, 'r1_f1': 0.4318936877076412, 'pegasus_entailment': 0.3787389324977994, 'gold_entailment': 0.4287888283530871, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 21, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38392857142857145, 'r1_recall': 0.7166666666666667, 'r1_f1': 0.5, 'pegasus_entailment': 0.44183654710650444, 'gold_entailment': 0.4691280797123909, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 23, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4129032258064516, 'r1_recall': 0.5203252032520326, 'r1_f1': 0.460431654676259, 'pegasus_entailment': 0.7968209981918335, 'gold_entailment': 0.45475907623767853, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 18}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5660377358490566, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5687203791469193, 'pegasus_entailment': 0.6995966633160909, 'gold_entailment': 0.4650525897741318, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 22}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5483870967741935, 'r1_recall': 0.3893129770992366, 'r1_f1': 0.45535714285714285, 'pegasus_entailment': 0.4487587437033653, 'gold_entailment': 0.3924669126669566, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 18, 'gold_ari': 29, 'gold_smog': 20}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2711864406779661, 'r1_recall': 0.47761194029850745, 'r1_f1': 0.3459459459459459, 'pegasus_entailment': 0.49224624037742615, 'gold_entailment': 0.3106664568185806, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 16}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1722488038277512, 'r1_recall': 0.631578947368421, 'r1_f1': 0.2706766917293233, 'pegasus_entailment': 0.7352085808912913, 'gold_entailment': 0.7313263416290283, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 23, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37681159420289856, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.4126984126984127, 'pegasus_entailment': 0.6625581781069437, 'gold_entailment': 0.5977251678705215, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5287356321839081, 'r1_recall': 0.359375, 'r1_f1': 0.42790697674418604, 'pegasus_entailment': 0.2997231390327215, 'gold_entailment': 0.30997431725263597, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5079365079365079, 'r1_recall': 0.3595505617977528, 'r1_f1': 0.42105263157894735, 'pegasus_entailment': 0.5972759425640106, 'gold_entailment': 0.6007578074932098, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5263157894736842, 'r1_recall': 0.4294478527607362, 'r1_f1': 0.47297297297297297, 'pegasus_entailment': 0.6010042130947113, 'gold_entailment': 0.22417048849165438, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5408805031446541, 'r1_recall': 0.44559585492227977, 'r1_f1': 0.48863636363636365, 'pegasus_entailment': 0.6107040882110596, 'gold_entailment': 0.4027736898925569, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4642857142857143, 'r1_recall': 0.5148514851485149, 'r1_f1': 0.48826291079812206, 'pegasus_entailment': 0.25491733103990555, 'gold_entailment': 0.13440987219413122, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 23, 'gold_smog': 17}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4242424242424242, 'pegasus_entailment': 0.5251688584685326, 'gold_entailment': 0.29038257990032434, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32653061224489793, 'r1_recall': 0.35555555555555557, 'r1_f1': 0.3404255319148936, 'pegasus_entailment': 0.7538385033607483, 'gold_entailment': 0.46663959821065265, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 23, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25773195876288657, 'r1_recall': 0.49019607843137253, 'r1_f1': 0.3378378378378378, 'pegasus_entailment': 0.6180570609867573, 'gold_entailment': 0.4233155697584152, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6136363636363636, 'r1_recall': 0.36486486486486486, 'r1_f1': 0.4576271186440678, 'pegasus_entailment': 0.2971234181895852, 'gold_entailment': 0.1901720179510968, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4788732394366197, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.4981684981684981, 'pegasus_entailment': 0.3239707462489605, 'gold_entailment': 0.2626373216509819, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.580952380952381, 'r1_recall': 0.5169491525423728, 'r1_f1': 0.5470852017937219, 'pegasus_entailment': 0.3914612289518118, 'gold_entailment': 0.3600736930966377, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6822429906542056, 'r1_recall': 0.5615384615384615, 'r1_f1': 0.6160337552742616, 'pegasus_entailment': 0.40632816664874555, 'gold_entailment': 0.23444977812469006, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.416, 'r1_recall': 0.4369747899159664, 'r1_f1': 0.42622950819672134, 'pegasus_entailment': 0.3695743791759014, 'gold_entailment': 0.13267844542860985, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7075471698113207, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.6000000000000001, 'pegasus_entailment': 0.7713785966237386, 'gold_entailment': 0.6843415200710297, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5125, 'r1_recall': 0.45555555555555555, 'r1_f1': 0.4823529411764706, 'pegasus_entailment': 0.5362412109971046, 'gold_entailment': 0.22360038198530674, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 15}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42168674698795183, 'r1_recall': 0.2631578947368421, 'r1_f1': 0.32407407407407407, 'pegasus_entailment': 0.3382081439097722, 'gold_entailment': 0.3670172840356827, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6134453781512605, 'r1_recall': 0.3443396226415094, 'r1_f1': 0.44108761329305135, 'pegasus_entailment': 0.7085267901420593, 'gold_entailment': 0.5032262004911899, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31645569620253167, 'r1_recall': 0.43859649122807015, 'r1_f1': 0.36764705882352944, 'pegasus_entailment': 0.5592845578988394, 'gold_entailment': 0.7144089043140411, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3576158940397351, 'r1_recall': 0.421875, 'r1_f1': 0.3870967741935483, 'pegasus_entailment': 0.7368702015706471, 'gold_entailment': 0.33847289383411405, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3125, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.39215686274509803, 'pegasus_entailment': 0.4325894981622696, 'gold_entailment': 0.32496286928653717, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 22}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5596330275229358, 'r1_recall': 0.3193717277486911, 'r1_f1': 0.4066666666666667, 'pegasus_entailment': 0.5687056730190913, 'gold_entailment': 0.26920780007328304, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5533980582524272, 'r1_recall': 0.3877551020408163, 'r1_f1': 0.456, 'pegasus_entailment': 0.34413363970816135, 'gold_entailment': 0.24976921236763397, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 21}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4383561643835616, 'r1_recall': 0.4155844155844156, 'r1_f1': 0.4266666666666667, 'pegasus_entailment': 0.6629274288813273, 'gold_entailment': 0.24512647539377214, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.375, 'r1_recall': 0.72, 'r1_f1': 0.4931506849315069, 'pegasus_entailment': 0.6591080844402313, 'gold_entailment': 0.4238399267196655, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5223880597014925, 'r1_recall': 0.6086956521739131, 'r1_f1': 0.5622489959839357, 'pegasus_entailment': 0.7011117190122604, 'gold_entailment': 0.5407987177371979, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 15, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.584070796460177, 'r1_recall': 0.43137254901960786, 'r1_f1': 0.49624060150375937, 'pegasus_entailment': 0.5800358727574348, 'gold_entailment': 0.2715641309817632, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4230769230769231, 'r1_recall': 0.43137254901960786, 'r1_f1': 0.4271844660194175, 'pegasus_entailment': 0.528005413711071, 'gold_entailment': 0.37056516017764807, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35526315789473684, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.4060150375939849, 'pegasus_entailment': 0.4276396594941616, 'gold_entailment': 0.2580862243970235, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 21, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37777777777777777, 'r1_recall': 0.53125, 'r1_f1': 0.4415584415584416, 'pegasus_entailment': 0.5126599570115408, 'gold_entailment': 0.3131001926958561, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19736842105263158, 'r1_recall': 0.6, 'r1_f1': 0.297029702970297, 'pegasus_entailment': 0.5513418298214674, 'gold_entailment': 0.6864804625511169, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 21, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4148936170212766, 'r1_recall': 0.7358490566037735, 'r1_f1': 0.5306122448979591, 'pegasus_entailment': 0.6557199557622274, 'gold_entailment': 0.5594624578952789, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 15, 'gold_ari': 14, 'gold_smog': 17}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5357142857142857, 'r1_recall': 0.6451612903225806, 'r1_f1': 0.5853658536585367, 'pegasus_entailment': 0.6207121387124062, 'gold_entailment': 0.3539345249533653, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5974025974025974, 'r1_recall': 0.7931034482758621, 'r1_f1': 0.6814814814814815, 'pegasus_entailment': 0.43599866330623627, 'gold_entailment': 0.4754289761185646, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.676056338028169, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.5549132947976878, 'pegasus_entailment': 0.4961413502693176, 'gold_entailment': 0.42299047112464905, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 28, 'gold_coleman_liau': 18, 'gold_ari': 33, 'gold_smog': 25}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5448275862068965, 'r1_recall': 0.5, 'r1_f1': 0.5214521452145214, 'pegasus_entailment': 0.4977208375930786, 'gold_entailment': 0.1306691899895668, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.20108695652173914, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.3070539419087137, 'pegasus_entailment': 0.6363639136155447, 'gold_entailment': 0.3161046306292216, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 23, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6091954022988506, 'r1_recall': 0.35570469798657717, 'r1_f1': 0.4491525423728813, 'pegasus_entailment': 0.33396398201584815, 'gold_entailment': 0.16780944019556046, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.64, 'r1_recall': 0.35036496350364965, 'r1_f1': 0.4528301886792453, 'pegasus_entailment': 0.5379170417785645, 'gold_entailment': 0.3383861444890499, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 23}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35384615384615387, 'r1_recall': 0.696969696969697, 'r1_f1': 0.46938775510204084, 'pegasus_entailment': 0.5071307886391878, 'gold_entailment': 0.4066922143101692, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5070422535211268, 'r1_recall': 0.32432432432432434, 'r1_f1': 0.39560439560439564, 'pegasus_entailment': 0.2857563638438781, 'gold_entailment': 0.4409477949142456, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25339366515837103, 'r1_recall': 0.7, 'r1_f1': 0.37209302325581395, 'pegasus_entailment': 0.7329935828844706, 'gold_entailment': 0.3053750153630972, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48226950354609927, 'r1_recall': 0.5354330708661418, 'r1_f1': 0.5074626865671642, 'pegasus_entailment': 0.4454707637429237, 'gold_entailment': 0.44286779527153286, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7083333333333334, 'r1_recall': 0.43147208121827413, 'r1_f1': 0.5362776025236594, 'pegasus_entailment': 0.7621929705142975, 'gold_entailment': 0.5107272751629353, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6127450980392157, 'r1_recall': 0.51440329218107, 'r1_f1': 0.5592841163310962, 'pegasus_entailment': 0.6909326000346078, 'gold_entailment': 0.4860022310167551, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.49640287769784175, 'r1_f1': 0.563265306122449, 'pegasus_entailment': 0.7450132071971893, 'gold_entailment': 0.5516242782274882, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2, 'r1_recall': 0.3150684931506849, 'r1_f1': 0.2446808510638298, 'pegasus_entailment': 0.008754177062655799, 'gold_entailment': 0.006027746150114884, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 20, 'gold_ari': 27, 'gold_smog': 24}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18115942028985507, 'r1_recall': 0.4098360655737705, 'r1_f1': 0.25125628140703515, 'pegasus_entailment': 0.7628283202648163, 'gold_entailment': 0.52974933385849, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6282051282051282, 'r1_recall': 0.5697674418604651, 'r1_f1': 0.5975609756097561, 'pegasus_entailment': 0.4735037088394165, 'gold_entailment': 0.3346785356601079, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4461538461538462, 'r1_recall': 0.3918918918918919, 'r1_f1': 0.4172661870503597, 'pegasus_entailment': 0.5493090897798538, 'gold_entailment': 0.3687894716858864, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5208333333333334, 'r1_recall': 0.43103448275862066, 'r1_f1': 0.4716981132075472, 'pegasus_entailment': 0.6333610514799753, 'gold_entailment': 0.501082232221961, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 22}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46218487394957986, 'r1_recall': 0.3819444444444444, 'r1_f1': 0.41825095057034223, 'pegasus_entailment': 0.3431836627423763, 'gold_entailment': 0.17197680324316025, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7307692307692307, 'r1_recall': 0.38974358974358975, 'r1_f1': 0.5083612040133779, 'pegasus_entailment': 0.5334443628787995, 'gold_entailment': 0.4130593091249466, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 18, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2905405405405405, 'r1_recall': 0.589041095890411, 'r1_f1': 0.38914027149321273, 'pegasus_entailment': 0.32340627908706665, 'gold_entailment': 0.16610569693148136, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.494949494949495, 'r1_recall': 0.6533333333333333, 'r1_f1': 0.5632183908045977, 'pegasus_entailment': 0.6802972033619881, 'gold_entailment': 0.7484070559342703, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4772727272727273, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.4158415841584158, 'pegasus_entailment': 0.5728185381740332, 'gold_entailment': 0.4574265033006668, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6089385474860335, 'r1_recall': 0.2898936170212766, 'r1_f1': 0.3927927927927928, 'pegasus_entailment': 0.6284559890627861, 'gold_entailment': 0.3218688308261335, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.5084745762711864, 'r1_f1': 0.44776119402985076, 'pegasus_entailment': 0.6177253822485606, 'gold_entailment': 0.579842155178388, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7435897435897436, 'r1_recall': 0.34523809523809523, 'r1_f1': 0.4715447154471545, 'pegasus_entailment': 0.6795556783676148, 'gold_entailment': 0.2300636786967516, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4605263157894737, 'r1_recall': 0.5426356589147286, 'r1_f1': 0.498220640569395, 'pegasus_entailment': 0.3925118252635002, 'gold_entailment': 0.1905275784432888, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 22}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6292134831460674, 'r1_recall': 0.37583892617449666, 'r1_f1': 0.4705882352941176, 'pegasus_entailment': 0.5207180693745613, 'gold_entailment': 0.38898972421884537, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 18, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5779816513761468, 'r1_recall': 0.3727810650887574, 'r1_f1': 0.45323741007194246, 'pegasus_entailment': 0.5876799188554287, 'gold_entailment': 0.37584022113255094, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6847826086956522, 'r1_recall': 0.48091603053435117, 'r1_f1': 0.5650224215246636, 'pegasus_entailment': 0.3830054863356054, 'gold_entailment': 0.26131453812122346, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5714285714285714, 'r1_recall': 0.3225806451612903, 'r1_f1': 0.41237113402061853, 'pegasus_entailment': 0.581071212887764, 'gold_entailment': 0.3197786860788862, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37623762376237624, 'r1_recall': 0.4578313253012048, 'r1_f1': 0.4130434782608695, 'pegasus_entailment': 0.5127846747636795, 'gold_entailment': 0.21710974226395288, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21348314606741572, 'r1_recall': 0.48717948717948717, 'r1_f1': 0.296875, 'pegasus_entailment': 0.5648137889802456, 'gold_entailment': 0.09500706568360329, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.41379310344827586, 'r1_f1': 0.4660194174757281, 'pegasus_entailment': 0.477243743215998, 'gold_entailment': 0.20100929091374078, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 17, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 23}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5338983050847458, 'r1_recall': 0.34054054054054056, 'r1_f1': 0.4158415841584159, 'pegasus_entailment': 0.4980557143688202, 'gold_entailment': 0.27896776981651783, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5416666666666666, 'r1_recall': 0.40625, 'r1_f1': 0.46428571428571425, 'pegasus_entailment': 0.19115082174539566, 'gold_entailment': 0.3471570536494255, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 13, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 17, 'gold_ari': 31, 'gold_smog': 23}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7291666666666666, 'r1_recall': 0.2727272727272727, 'r1_f1': 0.39697542533081276, 'pegasus_entailment': 0.577027091383934, 'gold_entailment': 0.3101024592623991, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5643564356435643, 'r1_recall': 0.3958333333333333, 'r1_f1': 0.46530612244897956, 'pegasus_entailment': 0.5314469039440155, 'gold_entailment': 0.38492142719527084, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2897196261682243, 'r1_recall': 0.47692307692307695, 'r1_f1': 0.3604651162790698, 'pegasus_entailment': 0.31121443770825863, 'gold_entailment': 0.26408209651708603, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35772357723577236, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.48087431693989063, 'pegasus_entailment': 0.2928406372666359, 'gold_entailment': 0.33537142475446063, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23134328358208955, 'r1_recall': 0.38271604938271603, 'r1_f1': 0.2883720930232558, 'pegasus_entailment': 0.49166278665264446, 'gold_entailment': 0.19372914638370275, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 16}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.3076923076923077, 'r1_f1': 0.3902439024390244, 'pegasus_entailment': 0.39611580471197766, 'gold_entailment': 0.26411626758053897, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25210084033613445, 'r1_recall': 0.3488372093023256, 'r1_f1': 0.2926829268292683, 'pegasus_entailment': 0.4108568717326437, 'gold_entailment': 0.23622938990592957, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 22, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4540229885057471, 'r1_recall': 0.5064102564102564, 'r1_f1': 0.47878787878787876, 'pegasus_entailment': 0.5392374353749412, 'gold_entailment': 0.6125682762690953, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5813953488372093, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.5102040816326531, 'pegasus_entailment': 0.7140888273715973, 'gold_entailment': 0.20810552616603673, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.5245901639344263, 'r1_f1': 0.4076433121019108, 'pegasus_entailment': 0.8082930892705917, 'gold_entailment': 0.3498088289052248, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 18}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6259541984732825, 'r1_recall': 0.5466666666666666, 'r1_f1': 0.5836298932384341, 'pegasus_entailment': 0.539160138794354, 'gold_entailment': 0.36215030774474144, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4605263157894737, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.4191616766467066, 'pegasus_entailment': 0.20326077099889517, 'gold_entailment': 0.19201855808496476, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45925925925925926, 'r1_recall': 0.4732824427480916, 'r1_f1': 0.46616541353383456, 'pegasus_entailment': 0.35762711372226474, 'gold_entailment': 0.1894875168800354, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49504950495049505, 'r1_recall': 0.5494505494505495, 'r1_f1': 0.5208333333333334, 'pegasus_entailment': 0.671452921628952, 'gold_entailment': 0.34765756130218506, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5121951219512195, 'r1_recall': 0.6, 'r1_f1': 0.5526315789473684, 'pegasus_entailment': 0.49997057393193245, 'gold_entailment': 0.504414789378643, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3225806451612903, 'r1_recall': 0.684931506849315, 'r1_f1': 0.43859649122807015, 'pegasus_entailment': 0.809331938624382, 'gold_entailment': 0.3103514090180397, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3490566037735849, 'r1_recall': 0.296, 'r1_f1': 0.3203463203463203, 'pegasus_entailment': 0.3525695260614157, 'gold_entailment': 0.036058949772268534, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37748344370860926, 'r1_recall': 0.5, 'r1_f1': 0.43018867924528303, 'pegasus_entailment': 0.5837592652865818, 'gold_entailment': 0.15350118577480315, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4090909090909091, 'r1_recall': 0.4044943820224719, 'r1_f1': 0.4067796610169492, 'pegasus_entailment': 0.5197967067360878, 'gold_entailment': 0.48335196636617184, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 17}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21839080459770116, 'r1_recall': 0.4418604651162791, 'r1_f1': 0.2923076923076924, 'pegasus_entailment': 0.2795463493093848, 'gold_entailment': 0.16196246072649956, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.2986425339366516, 'r1_f1': 0.39879154078549855, 'pegasus_entailment': 0.3714390337467194, 'gold_entailment': 0.11191964490960042, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.509090909090909, 'r1_recall': 0.49557522123893805, 'r1_f1': 0.5022421524663676, 'pegasus_entailment': 0.2084856119006872, 'gold_entailment': 0.48218147953351337, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.12834224598930483, 'r1_recall': 0.6486486486486487, 'r1_f1': 0.2142857142857143, 'pegasus_entailment': 0.4139044154435396, 'gold_entailment': 0.2700279951095581, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 32, 'pegasus_smog': 22, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 23, 'gold_ari': 30, 'gold_smog': 22}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40816326530612246, 'r1_recall': 0.4878048780487805, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.4823575586080551, 'gold_entailment': 0.3788758839170138, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3888888888888889, 'r1_recall': 0.5887850467289719, 'r1_f1': 0.46840148698884765, 'pegasus_entailment': 0.6097147975649152, 'gold_entailment': 0.3280900061130524, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2937853107344633, 'r1_recall': 0.7222222222222222, 'r1_f1': 0.41767068273092367, 'pegasus_entailment': 0.8824774384498596, 'gold_entailment': 0.37414619078238803, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32085561497326204, 'r1_recall': 0.6818181818181818, 'r1_f1': 0.43636363636363634, 'pegasus_entailment': 0.784125566482544, 'gold_entailment': 0.2925353217869997, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5538461538461539, 'r1_recall': 0.4044943820224719, 'r1_f1': 0.4675324675324675, 'pegasus_entailment': 0.470302810271581, 'gold_entailment': 0.29283639291922253, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32, 'r1_recall': 0.6779661016949152, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.5852881570657095, 'gold_entailment': 0.47786033153533936, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 22, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4805194805194805, 'r1_recall': 0.37373737373737376, 'r1_f1': 0.42045454545454547, 'pegasus_entailment': 0.5174873123566309, 'gold_entailment': 0.6174163818359375, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 27, 'gold_coleman_liau': 21, 'gold_ari': 34, 'gold_smog': 23}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42574257425742573, 'r1_recall': 0.4479166666666667, 'r1_f1': 0.4365482233502538, 'pegasus_entailment': 0.7067344412207603, 'gold_entailment': 0.5351593792438507, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5384615384615384, 'r1_recall': 0.5957446808510638, 'r1_f1': 0.5656565656565657, 'pegasus_entailment': 0.6984736323356628, 'gold_entailment': 0.6064713448286057, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.9052631578947369, 'r1_recall': 0.16475095785440613, 'r1_f1': 0.27876823338735823, 'pegasus_entailment': 0.757181704044342, 'gold_entailment': 0.417953141964972, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5238095238095238, 'r1_recall': 0.22, 'r1_f1': 0.3098591549295775, 'pegasus_entailment': 0.4950388193130493, 'gold_entailment': 0.45835941864384544, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2824427480916031, 'r1_recall': 0.47435897435897434, 'r1_f1': 0.35406698564593303, 'pegasus_entailment': 0.15981585501382747, 'gold_entailment': 0.14512645127251744, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46808510638297873, 'r1_recall': 0.6285714285714286, 'r1_f1': 0.5365853658536586, 'pegasus_entailment': 0.5404828742146492, 'gold_entailment': 0.5499027147889137, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6266666666666667, 'r1_recall': 0.34558823529411764, 'r1_f1': 0.44549763033175355, 'pegasus_entailment': 0.5349967877070109, 'gold_entailment': 0.11736050496498744, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 25, 'gold_smog': 21}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39622641509433965, 'r1_recall': 0.5575221238938053, 'r1_f1': 0.4632352941176471, 'pegasus_entailment': 0.41784951090812683, 'gold_entailment': 0.6104061305522919, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 18, 'gold_ari': 26, 'gold_smog': 24}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2534246575342466, 'r1_recall': 0.43529411764705883, 'r1_f1': 0.3203463203463203, 'pegasus_entailment': 0.8087252676486969, 'gold_entailment': 0.26814601322015125, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3557692307692308, 'r1_recall': 0.5606060606060606, 'r1_f1': 0.43529411764705883, 'pegasus_entailment': 0.8138601332902908, 'gold_entailment': 0.1741979420185089, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.6304347826086957, 'r1_f1': 0.489451476793249, 'pegasus_entailment': 0.4164747012158235, 'gold_entailment': 0.5015948514143626, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5166666666666667, 'r1_recall': 0.37349397590361444, 'r1_f1': 0.43356643356643354, 'pegasus_entailment': 0.7297862470149994, 'gold_entailment': 0.2803896913925807, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 14, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5238095238095238, 'r1_recall': 0.3492063492063492, 'r1_f1': 0.41904761904761906, 'pegasus_entailment': 0.48528847098350525, 'gold_entailment': 0.489040890087684, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5222222222222223, 'r1_recall': 0.46078431372549017, 'r1_f1': 0.4895833333333333, 'pegasus_entailment': 0.4003884792327881, 'gold_entailment': 0.39030493795871735, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5188679245283019, 'r1_recall': 0.3416149068322981, 'r1_f1': 0.41198501872659177, 'pegasus_entailment': 0.38889366388320923, 'gold_entailment': 0.31337928473949433, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 14, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24299065420560748, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.31707317073170727, 'pegasus_entailment': 0.5293678119778633, 'gold_entailment': 0.09327826835215092, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 14, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 15, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6078431372549019, 'r1_recall': 0.2743362831858407, 'r1_f1': 0.3780487804878049, 'pegasus_entailment': 0.5085282862186432, 'gold_entailment': 0.3770707164491926, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3431372549019608, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4320987654320988, 'pegasus_entailment': 0.5689708054065704, 'gold_entailment': 0.5303966328501701, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 19, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3717948717948718, 'r1_recall': 0.5742574257425742, 'r1_f1': 0.45136186770428016, 'pegasus_entailment': 0.6643689632415771, 'gold_entailment': 0.6110110580921173, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 22}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.17218543046357615, 'r1_recall': 0.5306122448979592, 'r1_f1': 0.26, 'pegasus_entailment': 0.45549706742167473, 'gold_entailment': 0.3157336935400963, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.15789473684210525, 'r1_recall': 0.45652173913043476, 'r1_f1': 0.23463687150837986, 'pegasus_entailment': 0.6949352860450745, 'gold_entailment': 0.4996295173962911, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5806451612903226, 'r1_recall': 0.4931506849315068, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.5936173439025879, 'gold_entailment': 0.572662795583407, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5235294117647059, 'r1_recall': 0.4635416666666667, 'r1_f1': 0.4917127071823205, 'pegasus_entailment': 0.6635164668162664, 'gold_entailment': 0.3778573324282964, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 34, 'gold_coleman_liau': 22, 'gold_ari': 42, 'gold_smog': 27}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38524590163934425, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.4795918367346938, 'pegasus_entailment': 0.6313724219799042, 'gold_entailment': 0.48184068004290265, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5542168674698795, 'r1_recall': 0.46464646464646464, 'r1_f1': 0.5054945054945055, 'pegasus_entailment': 0.2317476738244295, 'gold_entailment': 0.2754053051273028, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48936170212765956, 'r1_recall': 0.5542168674698795, 'r1_f1': 0.519774011299435, 'pegasus_entailment': 0.6603608429431915, 'gold_entailment': 0.24988995492458344, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3464566929133858, 'r1_recall': 0.6197183098591549, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.5653681099414826, 'gold_entailment': 0.48210977017879486, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 21, 'gold_ari': 28, 'gold_smog': 22}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49166666666666664, 'r1_recall': 0.5130434782608696, 'r1_f1': 0.5021276595744681, 'pegasus_entailment': 0.4492626816034317, 'gold_entailment': 0.055260946508497, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5338983050847458, 'r1_recall': 0.375, 'r1_f1': 0.4405594405594406, 'pegasus_entailment': 0.4793420160810153, 'gold_entailment': 0.25876896888283746, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18518518518518517, 'r1_recall': 0.4716981132075472, 'r1_f1': 0.26595744680851063, 'pegasus_entailment': 0.6215010695159435, 'gold_entailment': 0.1271022679284215, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4632352941176471, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.5163934426229508, 'pegasus_entailment': 0.5438272781670094, 'gold_entailment': 0.4385795183479786, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5531914893617021, 'r1_recall': 0.23008849557522124, 'r1_f1': 0.325, 'pegasus_entailment': 0.6245915070176125, 'gold_entailment': 0.0030207688869268168, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 23, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23222748815165878, 'r1_recall': 0.6901408450704225, 'r1_f1': 0.3475177304964539, 'pegasus_entailment': 0.6676316149532795, 'gold_entailment': 0.5430510838826498, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5847457627118644, 'r1_recall': 0.3150684931506849, 'r1_f1': 0.4094955489614243, 'pegasus_entailment': 0.4945516809821129, 'gold_entailment': 0.5439118180010054, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.07534246575342465, 'r1_recall': 0.3142857142857143, 'r1_f1': 0.12154696132596686, 'pegasus_entailment': 0.4097841257850329, 'gold_entailment': 0.24268060674269995, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 9, 'gold_coleman_liau': 13, 'gold_ari': 9, 'gold_smog': 13}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5092592592592593, 'r1_recall': 0.6626506024096386, 'r1_f1': 0.5759162303664922, 'pegasus_entailment': 0.5110612362623215, 'gold_entailment': 0.5610564053058624, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21359223300970873, 'r1_recall': 0.4489795918367347, 'r1_f1': 0.2894736842105263, 'pegasus_entailment': 0.543281327933073, 'gold_entailment': 0.30098220705986023, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6637168141592921, 'r1_recall': 0.4411764705882353, 'r1_f1': 0.5300353356890459, 'pegasus_entailment': 0.6032962962053716, 'gold_entailment': 0.47368636541068554, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 16, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5038759689922481, 'r1_f1': 0.5019305019305019, 'pegasus_entailment': 0.8755190968513489, 'gold_entailment': 0.5917064696550369, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 18}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4778761061946903, 'r1_recall': 0.6206896551724138, 'r1_f1': 0.54, 'pegasus_entailment': 0.914416766166687, 'gold_entailment': 0.8490530649820963, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4090909090909091, 'r1_recall': 0.40601503759398494, 'r1_f1': 0.4075471698113208, 'pegasus_entailment': 0.6110731393098832, 'gold_entailment': 0.05667103157611564, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3611111111111111, 'r1_recall': 0.46846846846846846, 'r1_f1': 0.40784313725490196, 'pegasus_entailment': 0.5722842305898667, 'gold_entailment': 0.235038410872221, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4158415841584158, 'r1_recall': 0.4375, 'r1_f1': 0.4263959390862944, 'pegasus_entailment': 0.5497960448265076, 'gold_entailment': 0.2497999593615532, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 28, 'gold_coleman_liau': 20, 'gold_ari': 33, 'gold_smog': 28}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5979381443298969, 'r1_recall': 0.4142857142857143, 'r1_f1': 0.48945147679324896, 'pegasus_entailment': 0.4399411454796791, 'gold_entailment': 0.38783141374588015, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4166666666666667, 'r1_recall': 0.3819444444444444, 'r1_f1': 0.39855072463768115, 'pegasus_entailment': 0.587062531709671, 'gold_entailment': 0.2336143230398496, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.68, 'r1_recall': 0.5543478260869565, 'r1_f1': 0.6107784431137724, 'pegasus_entailment': 0.6003551532824835, 'gold_entailment': 0.3405993673950434, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4563106796116505, 'r1_recall': 0.4563106796116505, 'r1_f1': 0.4563106796116505, 'pegasus_entailment': 0.6133278086781502, 'gold_entailment': 0.4392138719558716, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3106796116504854, 'r1_recall': 0.47761194029850745, 'r1_f1': 0.3764705882352941, 'pegasus_entailment': 0.642641544342041, 'gold_entailment': 0.32964820104340714, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3904109589041096, 'r1_recall': 0.6263736263736264, 'r1_f1': 0.4810126582278481, 'pegasus_entailment': 0.35265271241466206, 'gold_entailment': 0.33860284090042114, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 17, 'gold_ari': 29, 'gold_smog': 21}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6494845360824743, 'r1_recall': 0.4405594405594406, 'r1_f1': 0.525, 'pegasus_entailment': 0.585629940032959, 'gold_entailment': 0.2162558002397418, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5149253731343284, 'r1_recall': 0.5655737704918032, 'r1_f1': 0.5390625000000001, 'pegasus_entailment': 0.30537816509604454, 'gold_entailment': 0.23924268260598183, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5590551181102362, 'r1_recall': 0.42771084337349397, 'r1_f1': 0.48464163822525597, 'pegasus_entailment': 0.45507942512631416, 'gold_entailment': 0.45338569283485414, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33783783783783783, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.3875968992248062, 'pegasus_entailment': 0.3380046859383583, 'gold_entailment': 0.21349529922008514, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2972972972972973, 'r1_recall': 0.44594594594594594, 'r1_f1': 0.35675675675675683, 'pegasus_entailment': 0.2785968668758869, 'gold_entailment': 0.2978496477007866, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5868544600938967, 'r1_recall': 0.6127450980392157, 'r1_f1': 0.5995203836930456, 'pegasus_entailment': 0.594999298453331, 'gold_entailment': 0.4090784465273221, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 21}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7125, 'r1_recall': 0.2638888888888889, 'r1_f1': 0.3851351351351351, 'pegasus_entailment': 0.1243842663243413, 'gold_entailment': 0.09437060781056061, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47692307692307695, 'r1_recall': 0.512396694214876, 'r1_f1': 0.4940239043824701, 'pegasus_entailment': 0.6027085840702057, 'gold_entailment': 0.31548629452784854, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4244604316546763, 'r1_recall': 0.4125874125874126, 'r1_f1': 0.4184397163120568, 'pegasus_entailment': 0.2941926643252373, 'gold_entailment': 0.21805720350572041, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2849162011173184, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.38345864661654133, 'pegasus_entailment': 0.7363725999991099, 'gold_entailment': 0.4973087360461553, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32967032967032966, 'r1_recall': 0.6593406593406593, 'r1_f1': 0.43956043956043955, 'pegasus_entailment': 0.559456966817379, 'gold_entailment': 0.33969739576180774, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 31, 'pegasus_smog': 24, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.509090909090909, 'r1_recall': 0.5490196078431373, 'r1_f1': 0.5283018867924528, 'pegasus_entailment': 0.5159054785966873, 'gold_entailment': 0.4959993101656437, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 15, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4322033898305085, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.4396551724137931, 'pegasus_entailment': 0.5270503908395767, 'gold_entailment': 0.23175921042760214, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5047619047619047, 'r1_recall': 0.5353535353535354, 'r1_f1': 0.5196078431372548, 'pegasus_entailment': 0.44715024655063945, 'gold_entailment': 0.3842312440276146, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.291044776119403, 'r1_recall': 0.43820224719101125, 'r1_f1': 0.34977578475336324, 'pegasus_entailment': 0.44309872823456925, 'gold_entailment': 0.39690303802490234, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 23, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6126126126126126, 'r1_recall': 0.4171779141104294, 'r1_f1': 0.49635036496350354, 'pegasus_entailment': 0.4760519042611122, 'gold_entailment': 0.15707309916615486, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5528455284552846, 'r1_recall': 0.37362637362637363, 'r1_f1': 0.4459016393442623, 'pegasus_entailment': 0.3942831791937351, 'gold_entailment': 0.28982966641585034, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6530612244897959, 'r1_recall': 0.23272727272727273, 'r1_f1': 0.3431635388739946, 'pegasus_entailment': 0.4157344713807106, 'gold_entailment': 0.4091273943583171, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4608695652173913, 'r1_recall': 0.48623853211009177, 'r1_f1': 0.47321428571428575, 'pegasus_entailment': 0.6322698220610619, 'gold_entailment': 0.3384655863046646, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 29, 'gold_coleman_liau': 21, 'gold_ari': 36, 'gold_smog': 26}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.13740458015267176, 'r1_recall': 0.3103448275862069, 'r1_f1': 0.1904761904761905, 'pegasus_entailment': 0.40813413448631763, 'gold_entailment': 0.23738127574324608, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 15, 'gold_smog': 15}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6304347826086957, 'r1_recall': 0.32044198895027626, 'r1_f1': 0.42490842490842495, 'pegasus_entailment': 0.5511225163936615, 'gold_entailment': 0.14186279326677323, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 17}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4536082474226804, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5057471264367815, 'pegasus_entailment': 0.4856631774455309, 'gold_entailment': 0.24905117228627205, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3816793893129771, 'r1_recall': 0.625, 'r1_f1': 0.47393364928909953, 'pegasus_entailment': 0.6022769113381704, 'gold_entailment': 0.2692042633891106, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5104166666666666, 'r1_recall': 0.5268817204301075, 'r1_f1': 0.5185185185185186, 'pegasus_entailment': 0.4959838308393955, 'gold_entailment': 0.28481615893542767, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2643171806167401, 'r1_recall': 0.7407407407407407, 'r1_f1': 0.3896103896103896, 'pegasus_entailment': 0.44751369101660593, 'gold_entailment': 0.529634665697813, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44537815126050423, 'r1_recall': 0.5888888888888889, 'r1_f1': 0.507177033492823, 'pegasus_entailment': 0.512638458609581, 'gold_entailment': 0.24078639596700668, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 15, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25609756097560976, 'r1_recall': 0.30434782608695654, 'r1_f1': 0.27814569536423844, 'pegasus_entailment': 0.471374798566103, 'gold_entailment': 0.3842131495475769, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14, 'gold_flesch_kincaid': 11, 'gold_coleman_liau': 14, 'gold_ari': 13, 'gold_smog': 15}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48, 'r1_recall': 0.5, 'r1_f1': 0.4897959183673469, 'pegasus_entailment': 0.558365011587739, 'gold_entailment': 0.3698856784030795, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.20786516853932585, 'r1_recall': 0.578125, 'r1_f1': 0.3057851239669422, 'pegasus_entailment': 0.562923447539409, 'gold_entailment': 0.37131911019484204, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30337078651685395, 'r1_recall': 0.5934065934065934, 'r1_f1': 0.40148698884758366, 'pegasus_entailment': 0.8339717388153076, 'gold_entailment': 0.28009699781735736, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 24, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43157894736842106, 'r1_recall': 0.4659090909090909, 'r1_f1': 0.44808743169398907, 'pegasus_entailment': 0.6993794962763786, 'gold_entailment': 0.23580307215452195, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 22, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 21, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38181818181818183, 'r1_recall': 0.6774193548387096, 'r1_f1': 0.4883720930232559, 'pegasus_entailment': 0.2777297585271299, 'gold_entailment': 0.3734826408326626, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 15, 'gold_smog': 17}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7362637362637363, 'r1_recall': 0.6261682242990654, 'r1_f1': 0.6767676767676768, 'pegasus_entailment': 0.5328755527734756, 'gold_entailment': 0.3488933175802231, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24166666666666667, 'r1_recall': 0.4603174603174603, 'r1_f1': 0.31693989071038253, 'pegasus_entailment': 0.5102778412401676, 'gold_entailment': 0.27193286269903183, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 18}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7327586206896551, 'r1_recall': 0.32075471698113206, 'r1_f1': 0.4461942257217847, 'pegasus_entailment': 0.6490030363202095, 'gold_entailment': 0.4749015782560621, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 17, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.375, 'r1_recall': 0.609375, 'r1_f1': 0.4642857142857143, 'pegasus_entailment': 0.4361689120531082, 'gold_entailment': 0.3620916288346052, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 19}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5694444444444444, 'r1_recall': 0.44565217391304346, 'r1_f1': 0.5, 'pegasus_entailment': 0.709471861521403, 'gold_entailment': 0.6610599875450134, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 22, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5148514851485149, 'r1_recall': 0.52, 'r1_f1': 0.5174129353233831, 'pegasus_entailment': 0.8152512311935425, 'gold_entailment': 0.4702746719121933, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 27, 'gold_coleman_liau': 18, 'gold_ari': 32, 'gold_smog': 24}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5564516129032258, 'r1_recall': 0.4928571428571429, 'r1_f1': 0.5227272727272727, 'pegasus_entailment': 0.405499704182148, 'gold_entailment': 0.2395800178249677, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 17, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3352601156069364, 'r1_recall': 0.6170212765957447, 'r1_f1': 0.43445692883895126, 'pegasus_entailment': 0.5422278195619583, 'gold_entailment': 0.21609190354744592, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.5669291338582677, 'r1_f1': 0.549618320610687, 'pegasus_entailment': 0.6468129009008408, 'gold_entailment': 0.40127351065166295, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3838383838383838, 'r1_recall': 0.5352112676056338, 'r1_f1': 0.44705882352941173, 'pegasus_entailment': 0.5919699271519979, 'gold_entailment': 0.4264187216758728, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 23}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4742268041237113, 'r1_recall': 0.48936170212765956, 'r1_f1': 0.481675392670157, 'pegasus_entailment': 0.38075907342135906, 'gold_entailment': 0.3166918170948823, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36893203883495146, 'r1_recall': 0.4523809523809524, 'r1_f1': 0.40641711229946526, 'pegasus_entailment': 0.5607977410157522, 'gold_entailment': 0.31284982711076736, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48148148148148145, 'r1_recall': 0.527027027027027, 'r1_f1': 0.5032258064516129, 'pegasus_entailment': 0.6221818029880524, 'gold_entailment': 0.4928501695394516, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 20, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 13, 'gold_smog': 15}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43037974683544306, 'r1_recall': 0.5074626865671642, 'r1_f1': 0.4657534246575343, 'pegasus_entailment': 0.3312552596131961, 'gold_entailment': 0.2074040025472641, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 25, 'gold_smog': 21}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2743362831858407, 'r1_recall': 0.484375, 'r1_f1': 0.3502824858757062, 'pegasus_entailment': 0.34578954987227917, 'gold_entailment': 0.33603621274232864, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4426229508196721, 'r1_recall': 0.31213872832369943, 'r1_f1': 0.36610169491525424, 'pegasus_entailment': 0.41338094025850297, 'gold_entailment': 0.144503653049469, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49557522123893805, 'r1_recall': 0.3393939393939394, 'r1_f1': 0.4028776978417266, 'pegasus_entailment': 0.6683278381824493, 'gold_entailment': 0.3736751787364483, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4277456647398844, 'r1_recall': 0.7551020408163265, 'r1_f1': 0.5461254612546125, 'pegasus_entailment': 0.5939363936583201, 'gold_entailment': 0.28692017992337543, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6721311475409836, 'r1_recall': 0.2192513368983957, 'r1_f1': 0.33064516129032256, 'pegasus_entailment': 0.6197947065035502, 'gold_entailment': 0.27037860453128815, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47959183673469385, 'r1_recall': 0.49473684210526314, 'r1_f1': 0.48704663212435234, 'pegasus_entailment': 0.17758356407284737, 'gold_entailment': 0.23752422040949264, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24285714285714285, 'r1_recall': 0.7083333333333334, 'r1_f1': 0.36170212765957444, 'pegasus_entailment': 0.4226741741100947, 'gold_entailment': 0.25105811655521393, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 24, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3137254901960784, 'r1_recall': 0.5818181818181818, 'r1_f1': 0.40764331210191085, 'pegasus_entailment': 0.8014153043429056, 'gold_entailment': 0.6228839457035065, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22131147540983606, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.32926829268292684, 'pegasus_entailment': 0.4896393343806267, 'gold_entailment': 0.5095993876457214, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27011494252873564, 'r1_recall': 0.6619718309859155, 'r1_f1': 0.3836734693877551, 'pegasus_entailment': 0.6206146895885467, 'gold_entailment': 0.3248343151062727, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 15}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3157894736842105, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.4081632653061224, 'pegasus_entailment': 0.3153091836720705, 'gold_entailment': 0.36934642493724823, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43434343434343436, 'r1_recall': 0.36752136752136755, 'r1_f1': 0.39814814814814814, 'pegasus_entailment': 0.39050168295701343, 'gold_entailment': 0.24073127657175064, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6222222222222222, 'r1_recall': 0.42748091603053434, 'r1_f1': 0.5067873303167421, 'pegasus_entailment': 0.4211320519447327, 'gold_entailment': 0.3605128042399883, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4049586776859504, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.47804878048780486, 'pegasus_entailment': 0.41603270824998617, 'gold_entailment': 0.5815115968386332, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32967032967032966, 'r1_recall': 0.5, 'r1_f1': 0.3973509933774835, 'pegasus_entailment': 0.665094935468265, 'gold_entailment': 0.3645597994327545, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.6254228552182516, 'gold_entailment': 0.48631012439727783, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.381294964028777, 'r1_recall': 0.4818181818181818, 'r1_f1': 0.42570281124497994, 'pegasus_entailment': 0.8258504420518875, 'gold_entailment': 0.528767142444849, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4537037037037037, 'r1_recall': 0.532608695652174, 'r1_f1': 0.49, 'pegasus_entailment': 0.409241758286953, 'gold_entailment': 0.41585624031722546, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3983739837398374, 'r1_recall': 0.49, 'r1_f1': 0.4394618834080717, 'pegasus_entailment': 0.8715351819992065, 'gold_entailment': 0.3940115198493004, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 24, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 20, 'gold_smog': 21}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34375, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.4, 'pegasus_entailment': 0.5981243968009948, 'gold_entailment': 0.3556235432624817, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49624060150375937, 'r1_recall': 0.7586206896551724, 'r1_f1': 0.6, 'pegasus_entailment': 0.579939566552639, 'gold_entailment': 0.4662167876958847, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 18, 'gold_ari': 29, 'gold_smog': 20}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3925925925925926, 'r1_recall': 0.5196078431372549, 'r1_f1': 0.4472573839662447, 'pegasus_entailment': 0.22010255604982376, 'gold_entailment': 0.25462247245013714, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3790322580645161, 'r1_recall': 0.5595238095238095, 'r1_f1': 0.4519230769230769, 'pegasus_entailment': 0.6571993636898696, 'gold_entailment': 0.4920095279812813, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.225, 'r1_recall': 0.5192307692307693, 'r1_f1': 0.3139534883720931, 'pegasus_entailment': 0.7686770915985107, 'gold_entailment': 0.31887493779261905, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5772357723577236, 'r1_recall': 0.4965034965034965, 'r1_f1': 0.5338345864661654, 'pegasus_entailment': 0.7048206701874733, 'gold_entailment': 0.4376957297325134, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29239766081871343, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.3875968992248062, 'pegasus_entailment': 0.7051120162010193, 'gold_entailment': 0.3547283187508583, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 20, 'gold_ari': 31, 'gold_smog': 24}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4090909090909091, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5070422535211268, 'pegasus_entailment': 0.41899701828757924, 'gold_entailment': 0.807983011007309, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5445544554455446, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.49549549549549543, 'pegasus_entailment': 0.6108551807701588, 'gold_entailment': 0.22378965041467122, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3516483516483517, 'r1_recall': 0.3076923076923077, 'r1_f1': 0.3282051282051282, 'pegasus_entailment': 0.3374539216359456, 'gold_entailment': 0.2067161425948143, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.312, 'r1_recall': 0.5571428571428572, 'r1_f1': 0.4, 'pegasus_entailment': 0.642603250220418, 'gold_entailment': 0.382634228716294, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35526315789473684, 'r1_recall': 0.375, 'r1_f1': 0.3648648648648649, 'pegasus_entailment': 0.15760429203510284, 'gold_entailment': 0.25815508017937344, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 23, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3493975903614458, 'r1_recall': 0.3258426966292135, 'r1_f1': 0.33720930232558144, 'pegasus_entailment': 0.5546744478245577, 'gold_entailment': 0.5084189753979445, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18681318681318682, 'r1_recall': 0.37777777777777777, 'r1_f1': 0.25, 'pegasus_entailment': 0.5604568086564541, 'gold_entailment': 0.2822089195251465, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 13, 'gold_smog': 14}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6842105263157895, 'r1_recall': 0.5048543689320388, 'r1_f1': 0.5810055865921787, 'pegasus_entailment': 0.39919527247548103, 'gold_entailment': 0.5719132671753565, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.11214953271028037, 'r1_recall': 0.34285714285714286, 'r1_f1': 0.16901408450704225, 'pegasus_entailment': 0.6421753644943238, 'gold_entailment': 0.38543669134378433, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 14}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32222222222222224, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.42962962962962964, 'pegasus_entailment': 0.5505838960409164, 'gold_entailment': 0.8156819939613342, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 20}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.20915032679738563, 'r1_recall': 0.8205128205128205, 'r1_f1': 0.33333333333333337, 'pegasus_entailment': 0.6048033952713012, 'gold_entailment': 0.5289949774742126, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42342342342342343, 'r1_recall': 0.31756756756756754, 'r1_f1': 0.36293436293436293, 'pegasus_entailment': 0.4191781962290406, 'gold_entailment': 0.1261486890060561, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6944444444444444, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.5347593582887701, 'pegasus_entailment': 0.6794473131497701, 'gold_entailment': 0.030226684035733344, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38596491228070173, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.419047619047619, 'pegasus_entailment': 0.3970171042717993, 'gold_entailment': 0.34974922534699243, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 23, 'gold_smog': 17}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42771084337349397, 'r1_recall': 0.6513761467889908, 'r1_f1': 0.5163636363636365, 'pegasus_entailment': 0.4454628899693489, 'gold_entailment': 0.41469674309094745, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 23, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6705882352941176, 'r1_recall': 0.41304347826086957, 'r1_f1': 0.5112107623318386, 'pegasus_entailment': 0.4180057169869542, 'gold_entailment': 0.38083052169531584, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 17}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8620689655172413, 'r1_recall': 0.21306818181818182, 'r1_f1': 0.3416856492027335, 'pegasus_entailment': 0.6231930311769247, 'gold_entailment': 0.5811411993844169, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4028776978417266, 'r1_recall': 0.5045045045045045, 'r1_f1': 0.448, 'pegasus_entailment': 0.437065730492274, 'gold_entailment': 0.2671327192336321, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4830508474576271, 'r1_recall': 0.3825503355704698, 'r1_f1': 0.4269662921348314, 'pegasus_entailment': 0.7277405261993408, 'gold_entailment': 0.3590285822749138, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 22, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6136363636363636, 'r1_recall': 0.3624161073825503, 'r1_f1': 0.45569620253164556, 'pegasus_entailment': 0.7124584913253784, 'gold_entailment': 0.5338090002536774, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22093023255813954, 'r1_recall': 0.3877551020408163, 'r1_f1': 0.2814814814814815, 'pegasus_entailment': 0.40504480339586735, 'gold_entailment': 0.325367733836174, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 19, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3082191780821918, 'r1_recall': 0.625, 'r1_f1': 0.41284403669724773, 'pegasus_entailment': 0.6485251113772392, 'gold_entailment': 0.323367103934288, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34306569343065696, 'r1_recall': 0.5802469135802469, 'r1_f1': 0.43119266055045874, 'pegasus_entailment': 0.6749836926658949, 'gold_entailment': 0.26861321926116943, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.744, 'r1_recall': 0.62, 'r1_f1': 0.6763636363636364, 'pegasus_entailment': 0.5072245746850967, 'gold_entailment': 0.537433049082756, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3014705882352941, 'r1_recall': 0.6119402985074627, 'r1_f1': 0.40394088669950734, 'pegasus_entailment': 0.6120676640421152, 'gold_entailment': 0.43329472839832306, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 23, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 20}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6886792452830188, 'r1_recall': 0.42441860465116277, 'r1_f1': 0.525179856115108, 'pegasus_entailment': 0.5528850331902504, 'gold_entailment': 0.08373854371408622, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2818181818181818, 'r1_recall': 0.4189189189189189, 'r1_f1': 0.33695652173913043, 'pegasus_entailment': 0.5363785325462231, 'gold_entailment': 0.010292821316397749, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 28, 'gold_smog': 24}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.41975308641975306, 'r1_f1': 0.3715846994535518, 'pegasus_entailment': 0.7128540754318238, 'gold_entailment': 0.40402765075365704, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 22}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49230769230769234, 'r1_recall': 0.45390070921985815, 'r1_f1': 0.47232472324723246, 'pegasus_entailment': 0.7764266282320023, 'gold_entailment': 0.5195387800534567, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 19, 'gold_ari': 26, 'gold_smog': 23}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34285714285714286, 'r1_recall': 0.4580152671755725, 'r1_f1': 0.39215686274509803, 'pegasus_entailment': 0.6934287369251251, 'gold_entailment': 0.4883141467968623, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6601941747572816, 'r1_recall': 0.3192488262910798, 'r1_f1': 0.43037974683544306, 'pegasus_entailment': 0.8006790578365326, 'gold_entailment': 0.37226772414786474, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43283582089552236, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.5178571428571429, 'pegasus_entailment': 0.3569472649445136, 'gold_entailment': 0.10590057075023651, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 23, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39759036144578314, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.4714285714285714, 'pegasus_entailment': 0.4451265906294187, 'gold_entailment': 0.30292464792728424, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 24, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5037037037037037, 'r1_recall': 0.35978835978835977, 'r1_f1': 0.41975308641975306, 'pegasus_entailment': 0.2801076263189316, 'gold_entailment': 0.4990440768500169, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6708860759493671, 'r1_recall': 0.17434210526315788, 'r1_f1': 0.27676240208877284, 'pegasus_entailment': 0.32546641398221254, 'gold_entailment': 0.29257657741092974, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.17355371900826447, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.22826086956521738, 'pegasus_entailment': 0.2991402590026458, 'gold_entailment': 0.31065098320444423, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 19, 'gold_flesch_kincaid': 11, 'gold_coleman_liau': 15, 'gold_ari': 12, 'gold_smog': 16}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46078431372549017, 'r1_recall': 0.49473684210526314, 'r1_f1': 0.47715736040609136, 'pegasus_entailment': 0.4850974529981613, 'gold_entailment': 0.3808133266866207, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.477124183006536, 'r1_recall': 0.4620253164556962, 'r1_f1': 0.4694533762057878, 'pegasus_entailment': 0.585191123187542, 'gold_entailment': 0.3235937237739563, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3258426966292135, 'r1_recall': 0.5, 'r1_f1': 0.3945578231292517, 'pegasus_entailment': 0.6635315517584482, 'gold_entailment': 0.44183626274267834, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.3314917127071823, 'r1_f1': 0.42704626334519574, 'pegasus_entailment': 0.7038951044281324, 'gold_entailment': 0.5220938473939896, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5533980582524272, 'r1_recall': 0.4014084507042254, 'r1_f1': 0.4653061224489796, 'pegasus_entailment': 0.4494342381755511, 'gold_entailment': 0.14332400332204998, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47, 'r1_recall': 0.49473684210526314, 'r1_f1': 0.482051282051282, 'pegasus_entailment': 0.5411116674542427, 'gold_entailment': 0.5525158392265439, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5371900826446281, 'r1_recall': 0.37790697674418605, 'r1_f1': 0.44368600682593856, 'pegasus_entailment': 0.8259826451539993, 'gold_entailment': 0.4581811144016683, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24087591240875914, 'r1_recall': 0.4647887323943662, 'r1_f1': 0.31730769230769235, 'pegasus_entailment': 0.804341639081637, 'gold_entailment': 0.2760143553217252, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6615384615384615, 'r1_recall': 0.41346153846153844, 'r1_f1': 0.5088757396449703, 'pegasus_entailment': 0.599988728761673, 'gold_entailment': 0.4797194190323353, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 19}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41139240506329117, 'r1_recall': 0.6989247311827957, 'r1_f1': 0.5179282868525896, 'pegasus_entailment': 0.8377589583396912, 'gold_entailment': 0.45143372025340794, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35074626865671643, 'r1_recall': 0.6266666666666667, 'r1_f1': 0.4497607655502393, 'pegasus_entailment': 0.6445653786261877, 'gold_entailment': 0.04846588708460331, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41964285714285715, 'r1_recall': 0.6619718309859155, 'r1_f1': 0.5136612021857924, 'pegasus_entailment': 0.4621994545062383, 'gold_entailment': 0.3843721052010854, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49473684210526314, 'r1_recall': 0.46534653465346537, 'r1_f1': 0.4795918367346939, 'pegasus_entailment': 0.4417561087757349, 'gold_entailment': 0.35320666059851646, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5536723163841808, 'r1_recall': 0.47342995169082125, 'r1_f1': 0.5104166666666667, 'pegasus_entailment': 0.8104444543520609, 'gold_entailment': 0.5712871874372164, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5980392156862745, 'r1_f1': 0.5446428571428571, 'pegasus_entailment': 0.5223198875784874, 'gold_entailment': 0.43225947469472886, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30701754385964913, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.40229885057471265, 'pegasus_entailment': 0.6671895782152811, 'gold_entailment': 0.6655280590057373, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 18}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5869565217391305, 'r1_recall': 0.4550561797752809, 'r1_f1': 0.5126582278481013, 'pegasus_entailment': 0.5536272004246712, 'gold_entailment': 0.15887119186421236, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4470588235294118, 'r1_recall': 0.5205479452054794, 'r1_f1': 0.48101265822784806, 'pegasus_entailment': 0.4278874218463898, 'gold_entailment': 0.12199727911502123, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34532374100719426, 'r1_recall': 0.631578947368421, 'r1_f1': 0.44651162790697674, 'pegasus_entailment': 0.6902145802974701, 'gold_entailment': 0.4415701925754547, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 17}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5569620253164557, 'r1_recall': 0.4835164835164835, 'r1_f1': 0.5176470588235295, 'pegasus_entailment': 0.6364046881596247, 'gold_entailment': 0.2905744146555662, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 14, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.5238095238095238, 'pegasus_entailment': 0.5091578935583433, 'gold_entailment': 0.35168545693159103, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 16}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.782608695652174, 'r1_recall': 0.17872340425531916, 'r1_f1': 0.2909930715935335, 'pegasus_entailment': 0.5827157916501164, 'gold_entailment': 0.27359103612517094, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35185185185185186, 'r1_recall': 0.5352112676056338, 'r1_f1': 0.4245810055865922, 'pegasus_entailment': 0.6366274684667588, 'gold_entailment': 0.3959333077073097, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6285714285714286, 'r1_recall': 0.36065573770491804, 'r1_f1': 0.45833333333333337, 'pegasus_entailment': 0.5361941426992416, 'gold_entailment': 0.35514519682952334, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46534653465346537, 'r1_recall': 0.5053763440860215, 'r1_f1': 0.48453608247422686, 'pegasus_entailment': 0.5479071736335754, 'gold_entailment': 0.23999694734811783, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 17, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 17, 'gold_ari': 30, 'gold_smog': 21}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4624277456647399, 'r1_recall': 0.6896551724137931, 'r1_f1': 0.5536332179930796, 'pegasus_entailment': 0.47555534293254215, 'gold_entailment': 0.42956183291971684, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4835164835164835, 'r1_recall': 0.676923076923077, 'r1_f1': 0.5641025641025641, 'pegasus_entailment': 0.5306324561436971, 'gold_entailment': 0.42401501536369324, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 23}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4794520547945205, 'r1_recall': 0.445859872611465, 'r1_f1': 0.46204620462046203, 'pegasus_entailment': 0.5158341765403748, 'gold_entailment': 0.36485727982861654, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22330097087378642, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.30463576158940403, 'pegasus_entailment': 0.5881428172190984, 'gold_entailment': 0.6156255602836609, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4716981132075472, 'r1_recall': 0.5154639175257731, 'r1_f1': 0.4926108374384236, 'pegasus_entailment': 0.4108647188792626, 'gold_entailment': 0.2028123838827014, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 22, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.12903225806451613, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.2012578616352201, 'pegasus_entailment': 0.46629422903060913, 'gold_entailment': 0.2142222486436367, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 22, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4186046511627907, 'r1_recall': 0.5567010309278351, 'r1_f1': 0.47787610619469023, 'pegasus_entailment': 0.8365106284618378, 'gold_entailment': 0.6082308739423752, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 23, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41818181818181815, 'r1_recall': 0.40707964601769914, 'r1_f1': 0.41255605381165916, 'pegasus_entailment': 0.4364641058491543, 'gold_entailment': 0.4653669446706772, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7021276595744681, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.5764192139737991, 'pegasus_entailment': 0.22464585630223155, 'gold_entailment': 0.18540077128758034, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25, 'r1_recall': 0.3148148148148148, 'r1_f1': 0.2786885245901639, 'pegasus_entailment': 0.3699282705783844, 'gold_entailment': 0.0619225213304162, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 16, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 22, 'gold_ari': 24, 'gold_smog': 23}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3695652173913043, 'r1_recall': 0.51, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.7995760321617127, 'gold_entailment': 0.37786152958869934, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 25, 'gold_smog': 19}
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.07534246575342465
MEAN
0.4504039205353218
MAX
0.9052631578947369
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.16417910447761194
MEAN
0.48977342339420205
MAX
0.8205128205128205
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.12154696132596686
MEAN
0.44344859587226587
MAX
0.7263157894736842
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.008754177062655799
MEAN
0.555097587153461
MAX
0.9206894189119339
** Analysing column: gold_entailment



gold_entailment
Length after nones removed
616
MIN
0.0030207688869268168
MEAN
0.36298637898846003
MAX
0.8490530649820963
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
17
MAX
28
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
13
MEAN
17
MAX
23
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
12
MEAN
20
MAX
34
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
13
MEAN
18
MAX
25
** Analysing column: gold_flesch_kincaid



gold_flesch_kincaid
Length after nones removed
616
MIN
9
MEAN
17
MAX
38
** Analysing column: gold_coleman_liau



gold_coleman_liau
Length after nones removed
616
MIN
13
MEAN
18
MAX
25
** Analysing column: gold_ari



gold_ari
Length after nones removed
616
MIN
9
MEAN
20
MAX
46
** Analysing column: gold_smog



gold_smog
Length after nones removed
616
MIN
13
MEAN
19
MAX
30
{}
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48623853211009177, 'r1_recall': 0.4818181818181818, 'r1_f1': 0.4840182648401826, 'pegasus_entailment': 0.5776585340499878, 'gold_entailment': 0.4284333050251007, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 13, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6588235294117647, 'r1_recall': 0.3236994219653179, 'r1_f1': 0.434108527131783, 'pegasus_entailment': 0.6350872330367565, 'gold_entailment': 0.5142355050359454, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2644628099173554, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.3575418994413408, 'pegasus_entailment': 0.6218796819448471, 'gold_entailment': 0.5164063846071562, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 14, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7446808510638298, 'r1_recall': 0.5426356589147286, 'r1_f1': 0.6278026905829596, 'pegasus_entailment': 0.7990065813064575, 'gold_entailment': 0.4932037750259042, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 17, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 21, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.672566371681416, 'r1_recall': 0.4367816091954023, 'r1_f1': 0.529616724738676, 'pegasus_entailment': 0.3965887241065502, 'gold_entailment': 0.5065276759366194, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4715447154471545, 'r1_recall': 0.4461538461538462, 'r1_f1': 0.45849802371541504, 'pegasus_entailment': 0.26648516207933426, 'gold_entailment': 0.21131984740495682, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.189873417721519, 'r1_recall': 0.46875, 'r1_f1': 0.2702702702702703, 'pegasus_entailment': 0.3585384860634804, 'gold_entailment': 0.4352297745645046, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 10, 'gold_coleman_liau': 14, 'gold_ari': 11, 'gold_smog': 15}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2876712328767123, 'r1_recall': 0.6774193548387096, 'r1_f1': 0.40384615384615385, 'pegasus_entailment': 0.40709395334124565, 'gold_entailment': 0.06752728670835495, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7169811320754716, 'r1_recall': 0.5100671140939598, 'r1_f1': 0.596078431372549, 'pegasus_entailment': 0.5436099320650101, 'gold_entailment': 0.6372850891202688, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5563380281690141, 'r1_recall': 0.572463768115942, 'r1_f1': 0.5642857142857143, 'pegasus_entailment': 0.5631787776947021, 'gold_entailment': 0.3198578345278899, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 19, 'gold_ari': 31, 'gold_smog': 24}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7777777777777778, 'r1_recall': 0.37333333333333335, 'r1_f1': 0.5045045045045045, 'pegasus_entailment': 0.38459283486008644, 'gold_entailment': 0.41076447665691374, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45161290322580644, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.4609053497942387, 'pegasus_entailment': 0.7864744265874227, 'gold_entailment': 0.4572588294744492, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.726027397260274, 'r1_recall': 0.4953271028037383, 'r1_f1': 0.5888888888888889, 'pegasus_entailment': 0.6612625246246656, 'gold_entailment': 0.3518748050555587, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6470588235294118, 'r1_recall': 0.5, 'r1_f1': 0.5641025641025642, 'pegasus_entailment': 0.7623180945714315, 'gold_entailment': 0.22173562071596584, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8505747126436781, 'r1_recall': 0.3854166666666667, 'r1_f1': 0.5304659498207885, 'pegasus_entailment': 0.6967844168345133, 'gold_entailment': 0.35728325648233294, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25, 'r1_recall': 0.5084745762711864, 'r1_f1': 0.33519553072625696, 'pegasus_entailment': 0.5649176072329283, 'gold_entailment': 0.005505232373252511, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43902439024390244, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.3977900552486187, 'pegasus_entailment': 0.5912778576215109, 'gold_entailment': 0.484069528679053, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7722772277227723, 'r1_recall': 0.26174496644295303, 'r1_f1': 0.3909774436090226, 'pegasus_entailment': 0.28142471238970757, 'gold_entailment': 0.40958941197022797, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6306306306306306, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.5147058823529412, 'pegasus_entailment': 0.34134733453392985, 'gold_entailment': 0.35734020599297117, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.494949494949495, 'r1_recall': 0.5632183908045977, 'r1_f1': 0.5268817204301075, 'pegasus_entailment': 0.6198220352331797, 'gold_entailment': 0.4441959811374545, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6637168141592921, 'r1_recall': 0.41208791208791207, 'r1_f1': 0.5084745762711864, 'pegasus_entailment': 0.46753083169460297, 'gold_entailment': 0.19629437290132046, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 15, 'gold_ari': 28, 'gold_smog': 18}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6014492753623188, 'r1_recall': 0.5533333333333333, 'r1_f1': 0.576388888888889, 'pegasus_entailment': 0.7947301715612411, 'gold_entailment': 0.6185178024073442, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44755244755244755, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.5099601593625498, 'pegasus_entailment': 0.5669271945953369, 'gold_entailment': 0.31062590330839157, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.69, 'r1_recall': 0.5073529411764706, 'r1_f1': 0.5847457627118644, 'pegasus_entailment': 0.37241795659065247, 'gold_entailment': 0.3561852586766084, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35051546391752575, 'r1_recall': 0.68, 'r1_f1': 0.46258503401360546, 'pegasus_entailment': 0.6448382258415222, 'gold_entailment': 0.4778066100552678, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5737704918032787, 'r1_recall': 0.37037037037037035, 'r1_f1': 0.45016077170418, 'pegasus_entailment': 0.3860257716849446, 'gold_entailment': 0.5903877660632133, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 29, 'gold_smog': 22}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5862068965517241, 'r1_recall': 0.49635036496350365, 'r1_f1': 0.5375494071146245, 'pegasus_entailment': 0.5313470080494881, 'gold_entailment': 0.47313677668571474, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7951807228915663, 'r1_recall': 0.2462686567164179, 'r1_f1': 0.37606837606837606, 'pegasus_entailment': 0.6164184510707855, 'gold_entailment': 0.5458775135603818, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5974025974025974, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.6013071895424836, 'pegasus_entailment': 0.538751224676768, 'gold_entailment': 0.28643152366081875, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 16}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3770491803278688, 'r1_recall': 0.40707964601769914, 'r1_f1': 0.39148936170212767, 'pegasus_entailment': 0.6908449649810791, 'gold_entailment': 0.5069271326065063, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 18}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4519230769230769, 'r1_recall': 0.5402298850574713, 'r1_f1': 0.49214659685863876, 'pegasus_entailment': 0.5891800597310066, 'gold_entailment': 0.6574686268965403, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5739130434782609, 'r1_recall': 0.3283582089552239, 'r1_f1': 0.4177215189873418, 'pegasus_entailment': 0.5783639311790466, 'gold_entailment': 0.6649928738673528, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4095238095238095, 'r1_recall': 0.4174757281553398, 'r1_f1': 0.4134615384615385, 'pegasus_entailment': 0.7202720940113068, 'gold_entailment': 0.4112209789454937, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3674698795180723, 'r1_recall': 0.6288659793814433, 'r1_f1': 0.4638783269961977, 'pegasus_entailment': 0.6183017671108246, 'gold_entailment': 0.08859759953338653, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32413793103448274, 'r1_recall': 0.5595238095238095, 'r1_f1': 0.4104803493449782, 'pegasus_entailment': 0.2847154259681702, 'gold_entailment': 0.1680013487736384, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5408163265306123, 'r1_recall': 0.45689655172413796, 'r1_f1': 0.4953271028037384, 'pegasus_entailment': 0.5831048339605331, 'gold_entailment': 0.3026718993981679, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 24}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4296875, 'r1_recall': 0.7971014492753623, 'r1_f1': 0.5583756345177665, 'pegasus_entailment': 0.5608726859092712, 'gold_entailment': 0.6821679373582205, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34234234234234234, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.4245810055865922, 'pegasus_entailment': 0.7213659049011767, 'gold_entailment': 0.40810126019641757, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23577235772357724, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.34523809523809523, 'pegasus_entailment': 0.4655906483530998, 'gold_entailment': 0.6502262055873871, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45901639344262296, 'r1_recall': 0.5060240963855421, 'r1_f1': 0.4813753581661891, 'pegasus_entailment': 0.8382661417126656, 'gold_entailment': 0.029503032914362848, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 23, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7171717171717171, 'r1_recall': 0.44375, 'r1_f1': 0.5482625482625482, 'pegasus_entailment': 0.5706129213795066, 'gold_entailment': 0.5620311737060547, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.5844155844155844, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.40708838154872257, 'gold_entailment': 0.37908293097279966, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3956043956043956, 'r1_recall': 0.4931506849315068, 'r1_f1': 0.43902439024390244, 'pegasus_entailment': 0.4444118719547987, 'gold_entailment': 0.2982013610502084, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7866666666666666, 'r1_recall': 0.4796747967479675, 'r1_f1': 0.5959595959595959, 'pegasus_entailment': 0.8370452523231506, 'gold_entailment': 0.4443937788407008, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 21, 'gold_ari': 30, 'gold_smog': 24}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3305785123966942, 'r1_recall': 0.5128205128205128, 'r1_f1': 0.4020100502512563, 'pegasus_entailment': 0.6187413148581982, 'gold_entailment': 0.22961276955902576, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 21, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 21, 'gold_ari': 29, 'gold_smog': 22}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46846846846846846, 'r1_recall': 0.6933333333333334, 'r1_f1': 0.5591397849462365, 'pegasus_entailment': 0.61427241563797, 'gold_entailment': 0.5292595326900482, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6595744680851063, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.5849056603773585, 'pegasus_entailment': 0.5190710723400116, 'gold_entailment': 0.16219192725839093, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 17}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42771084337349397, 'r1_recall': 0.6396396396396397, 'r1_f1': 0.5126353790613718, 'pegasus_entailment': 0.7405392527580261, 'gold_entailment': 0.554141528904438, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38926174496644295, 'r1_recall': 0.6904761904761905, 'r1_f1': 0.49785407725321895, 'pegasus_entailment': 0.6298483982682228, 'gold_entailment': 0.520937035481135, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41605839416058393, 'r1_recall': 0.5480769230769231, 'r1_f1': 0.47302904564315357, 'pegasus_entailment': 0.548842485062778, 'gold_entailment': 0.37701962391535443, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 21, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3560606060606061, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.4563106796116505, 'pegasus_entailment': 0.607223492860794, 'gold_entailment': 0.6234436432520548, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19900497512437812, 'r1_recall': 0.7843137254901961, 'r1_f1': 0.31746031746031744, 'pegasus_entailment': 0.5023507280275226, 'gold_entailment': 0.20820337533950806, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2893081761006289, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.39484978540772525, 'pegasus_entailment': 0.4229212626814842, 'gold_entailment': 0.2355069617430369, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6162790697674418, 'r1_recall': 0.2994350282485876, 'r1_f1': 0.40304182509505704, 'pegasus_entailment': 0.29961858689785004, 'gold_entailment': 0.27606385946273804, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.64375, 'r1_recall': 0.5786516853932584, 'r1_f1': 0.6094674556213018, 'pegasus_entailment': 0.4902019679546356, 'gold_entailment': 0.3164125746116042, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3617021276595745, 'r1_recall': 0.7083333333333334, 'r1_f1': 0.4788732394366197, 'pegasus_entailment': 0.5795364864170551, 'gold_entailment': 0.43442073464393616, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5911949685534591, 'r1_recall': 0.3745019920318725, 'r1_f1': 0.4585365853658537, 'pegasus_entailment': 0.6000876948237419, 'gold_entailment': 0.3794069561091336, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43157894736842106, 'r1_recall': 0.640625, 'r1_f1': 0.5157232704402516, 'pegasus_entailment': 0.4862620811909437, 'gold_entailment': 0.5141248181462288, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 21}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7345132743362832, 'r1_recall': 0.6859504132231405, 'r1_f1': 0.7094017094017094, 'pegasus_entailment': 0.45319875826438266, 'gold_entailment': 0.47109444066882133, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 19}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5742574257425742, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5631067961165049, 'pegasus_entailment': 0.4824264235794544, 'gold_entailment': 0.46931852400302887, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3591549295774648, 'r1_recall': 0.5795454545454546, 'r1_f1': 0.44347826086956527, 'pegasus_entailment': 0.7086425572633743, 'gold_entailment': 0.7641754150390625, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 22, 'gold_ari': 32, 'gold_smog': 21}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5066666666666667, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.5170068027210885, 'pegasus_entailment': 0.39562320585052174, 'gold_entailment': 0.0772534292191267, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 25, 'gold_smog': 17}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5225225225225225, 'r1_recall': 0.34523809523809523, 'r1_f1': 0.41577060931899645, 'pegasus_entailment': 0.6833944693207741, 'gold_entailment': 0.319033095613122, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 15}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4418604651162791, 'r1_recall': 0.3917525773195876, 'r1_f1': 0.4153005464480874, 'pegasus_entailment': 0.6160088951388994, 'gold_entailment': 0.37677286627391976, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3076923076923077, 'r1_recall': 0.75, 'r1_f1': 0.4363636363636364, 'pegasus_entailment': 0.5475229521592458, 'gold_entailment': 0.7838674187660217, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7549019607843137, 'r1_recall': 0.6062992125984252, 'r1_f1': 0.6724890829694323, 'pegasus_entailment': 0.5831493437290192, 'gold_entailment': 0.4276651442050934, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39473684210526316, 'r1_recall': 0.5660377358490566, 'r1_f1': 0.46511627906976744, 'pegasus_entailment': 0.8760405629873276, 'gold_entailment': 0.3882515400648117, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3563218390804598, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.4592592592592593, 'pegasus_entailment': 0.2959147404347147, 'gold_entailment': 0.34536723867058755, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7325581395348837, 'r1_recall': 0.5478260869565217, 'r1_f1': 0.626865671641791, 'pegasus_entailment': 0.2738794247270562, 'gold_entailment': 0.3109560728383561, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7966101694915254, 'r1_recall': 0.46078431372549017, 'r1_f1': 0.5838509316770185, 'pegasus_entailment': 0.5816609188914299, 'gold_entailment': 0.123036061724027, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.3373493975903614, 'r1_f1': 0.42748091603053434, 'pegasus_entailment': 0.4828009174671024, 'gold_entailment': 0.40880132040807177, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4077669902912621, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.49122807017543857, 'pegasus_entailment': 0.24761976599693297, 'gold_entailment': 0.20190025307238102, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3191489361702128, 'r1_recall': 0.6818181818181818, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.29473609558772296, 'gold_entailment': 0.2246767869219184, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 16, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6923076923076923, 'r1_recall': 0.5210526315789473, 'r1_f1': 0.5945945945945946, 'pegasus_entailment': 0.45553685538470745, 'gold_entailment': 0.3129086513072252, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.4166666666666667, 'pegasus_entailment': 0.35060054808855057, 'gold_entailment': 0.30718058347702026, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 22, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4956521739130435, 'r1_recall': 0.6705882352941176, 'r1_f1': 0.57, 'pegasus_entailment': 0.41699037204186123, 'gold_entailment': 0.4441030502319336, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35714285714285715, 'r1_recall': 0.546875, 'r1_f1': 0.43209876543209874, 'pegasus_entailment': 0.948105588555336, 'gold_entailment': 0.45756909681949764, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5409836065573771, 'r1_recall': 0.6346153846153846, 'r1_f1': 0.5840707964601771, 'pegasus_entailment': 0.4739167960360646, 'gold_entailment': 0.44624231196939945, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5185185185185185, 'r1_recall': 0.6511627906976745, 'r1_f1': 0.577319587628866, 'pegasus_entailment': 0.5669274429480234, 'gold_entailment': 0.4408782348036766, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44680851063829785, 'r1_recall': 0.6268656716417911, 'r1_f1': 0.5217391304347827, 'pegasus_entailment': 0.8823285400867462, 'gold_entailment': 0.47124032210558653, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45045045045045046, 'r1_recall': 0.6410256410256411, 'r1_f1': 0.5291005291005292, 'pegasus_entailment': 0.38218502700328827, 'gold_entailment': 0.3574437350034714, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 13, 'gold_ari': 12, 'gold_smog': 16}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8441558441558441, 'r1_recall': 0.6310679611650486, 'r1_f1': 0.7222222222222222, 'pegasus_entailment': 0.4334053322672844, 'gold_entailment': 0.15951498535772166, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 24}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28695652173913044, 'r1_recall': 0.5076923076923077, 'r1_f1': 0.3666666666666667, 'pegasus_entailment': 0.6322858929634094, 'gold_entailment': 0.3715967920919259, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5735294117647058, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.5032258064516129, 'pegasus_entailment': 0.22037683116892973, 'gold_entailment': 0.2224965455631415, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5887850467289719, 'r1_recall': 0.6847826086956522, 'r1_f1': 0.6331658291457286, 'pegasus_entailment': 0.37061692476272584, 'gold_entailment': 0.4040308119729161, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4642857142857143, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.456140350877193, 'pegasus_entailment': 0.5988945066928864, 'gold_entailment': 0.05708108423277736, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 23, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19298245614035087, 'r1_recall': 0.28205128205128205, 'r1_f1': 0.22916666666666666, 'pegasus_entailment': 0.8832955956459045, 'gold_entailment': 0.35342718847095966, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 20, 'gold_ari': 28, 'gold_smog': 25}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2909090909090909, 'r1_recall': 0.7111111111111111, 'r1_f1': 0.4129032258064516, 'pegasus_entailment': 0.7880307510495186, 'gold_entailment': 0.49168046936392784, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7634408602150538, 'r1_recall': 0.34134615384615385, 'r1_f1': 0.4717607973421926, 'pegasus_entailment': 0.6354798972606659, 'gold_entailment': 0.3413220900628302, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4725274725274725, 'r1_recall': 0.6142857142857143, 'r1_f1': 0.5341614906832297, 'pegasus_entailment': 0.6319387058028951, 'gold_entailment': 0.05042371929933628, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 17}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6453488372093024, 'r1_recall': 0.578125, 'r1_f1': 0.6098901098901099, 'pegasus_entailment': 0.6849488765001297, 'gold_entailment': 0.40099664218723774, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 26, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4358974358974359, 'r1_recall': 0.3805970149253731, 'r1_f1': 0.40637450199203184, 'pegasus_entailment': 0.3515203222632408, 'gold_entailment': 0.5819063544273376, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 13, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 21}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38848920863309355, 'r1_recall': 0.7397260273972602, 'r1_f1': 0.5094339622641509, 'pegasus_entailment': 0.5932557687163353, 'gold_entailment': 0.6098212897777557, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 17, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5679012345679012, 'r1_recall': 0.39316239316239315, 'r1_f1': 0.46464646464646464, 'pegasus_entailment': 0.6279519945383072, 'gold_entailment': 0.4593630730523728, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32727272727272727, 'r1_recall': 0.18556701030927836, 'r1_f1': 0.2368421052631579, 'pegasus_entailment': 0.989773690700531, 'gold_entailment': 0.0008654110206407495, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5642857142857143, 'r1_recall': 0.4463276836158192, 'r1_f1': 0.49842271293375395, 'pegasus_entailment': 0.7387932240962982, 'gold_entailment': 0.5791263182957967, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46788990825688076, 'r1_recall': 0.5257731958762887, 'r1_f1': 0.4951456310679612, 'pegasus_entailment': 0.5820118387540182, 'gold_entailment': 0.4793732911348343, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48695652173913045, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4647302904564315, 'pegasus_entailment': 0.7036953065544367, 'gold_entailment': 0.39366940249289784, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34782608695652173, 'r1_recall': 0.49230769230769234, 'r1_f1': 0.4076433121019108, 'pegasus_entailment': 0.8022560775279999, 'gold_entailment': 0.47808530926704407, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4069767441860465, 'r1_recall': 0.3125, 'r1_f1': 0.35353535353535354, 'pegasus_entailment': 0.7888848632574081, 'gold_entailment': 0.365379623156817, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3972602739726027, 'r1_recall': 0.47540983606557374, 'r1_f1': 0.4328358208955224, 'pegasus_entailment': 0.27943436926580034, 'gold_entailment': 0.6398592856712639, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 12, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44285714285714284, 'r1_recall': 0.32978723404255317, 'r1_f1': 0.3780487804878049, 'pegasus_entailment': 0.7204008623957634, 'gold_entailment': 0.5884177924599499, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 15, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6458333333333334, 'r1_recall': 0.5391304347826087, 'r1_f1': 0.5876777251184834, 'pegasus_entailment': 0.7017158567905426, 'gold_entailment': 0.5055292993783951, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4846153846153846, 'r1_recall': 0.5625, 'r1_f1': 0.5206611570247933, 'pegasus_entailment': 0.6186015401035547, 'gold_entailment': 0.1151046788727399, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 21, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4878048780487805, 'r1_recall': 0.75, 'r1_f1': 0.5911330049261083, 'pegasus_entailment': 0.6906870529055595, 'gold_entailment': 0.6343338117003441, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6493506493506493, 'r1_recall': 0.3875968992248062, 'r1_f1': 0.48543689320388345, 'pegasus_entailment': 0.6729603012402853, 'gold_entailment': 0.28474118933081627, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33879781420765026, 'r1_recall': 0.6019417475728155, 'r1_f1': 0.4335664335664336, 'pegasus_entailment': 0.6354487008518643, 'gold_entailment': 0.5262012198567391, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5563380281690141, 'r1_recall': 0.49375, 'r1_f1': 0.5231788079470199, 'pegasus_entailment': 0.7283593863248825, 'gold_entailment': 0.5833617951720953, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 19}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3418803418803419, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.4166666666666667, 'pegasus_entailment': 0.21197005982200304, 'gold_entailment': 0.014491177396848798, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 15, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29896907216494845, 'r1_recall': 0.48333333333333334, 'r1_f1': 0.36942675159235666, 'pegasus_entailment': 0.6654045879840851, 'gold_entailment': 0.3071797313168645, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 10, 'gold_coleman_liau': 13, 'gold_ari': 11, 'gold_smog': 15}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4888888888888889, 'r1_recall': 0.6376811594202898, 'r1_f1': 0.5534591194968553, 'pegasus_entailment': 0.9367663562297821, 'gold_entailment': 0.3754922126730283, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6746987951807228, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.5185185185185185, 'pegasus_entailment': 0.30863158591091633, 'gold_entailment': 0.5212389174848795, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 22}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4842105263157895, 'r1_recall': 0.5822784810126582, 'r1_f1': 0.5287356321839081, 'pegasus_entailment': 0.25897690607234836, 'gold_entailment': 0.3039111797697842, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 18, 'gold_ari': 27, 'gold_smog': 20}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.5617977528089888, 'r1_f1': 0.5025125628140704, 'pegasus_entailment': 0.5754958242177963, 'gold_entailment': 0.3190098814666271, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39375, 'r1_recall': 0.4846153846153846, 'r1_f1': 0.43448275862068964, 'pegasus_entailment': 0.6463600308634341, 'gold_entailment': 0.18746358792607984, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7166666666666667, 'r1_recall': 0.48314606741573035, 'r1_f1': 0.5771812080536913, 'pegasus_entailment': 0.49724017083644867, 'gold_entailment': 0.33722649621112005, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7431192660550459, 'r1_recall': 0.4602272727272727, 'r1_f1': 0.5684210526315789, 'pegasus_entailment': 0.592577901482582, 'gold_entailment': 0.4391362794807979, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5390625, 'r1_recall': 0.5149253731343284, 'r1_f1': 0.5267175572519084, 'pegasus_entailment': 0.46350657168243614, 'gold_entailment': 0.35990245764454204, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.532608695652174, 'r1_recall': 0.5212765957446809, 'r1_f1': 0.5268817204301075, 'pegasus_entailment': 0.5202566684650568, 'gold_entailment': 0.17692635022103786, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 15, 'gold_ari': 20, 'gold_smog': 15}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7352941176470589, 'r1_recall': 0.3937007874015748, 'r1_f1': 0.5128205128205129, 'pegasus_entailment': 0.5885003283619881, 'gold_entailment': 0.4228528306952545, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43089430894308944, 'r1_recall': 0.6022727272727273, 'r1_f1': 0.5023696682464455, 'pegasus_entailment': 0.7550351023674011, 'gold_entailment': 0.39883021265268326, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6041666666666666, 'r1_recall': 0.5043478260869565, 'r1_f1': 0.5497630331753554, 'pegasus_entailment': 0.7457469031214714, 'gold_entailment': 0.5673329055309295, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35555555555555557, 'r1_recall': 0.631578947368421, 'r1_f1': 0.4549763033175355, 'pegasus_entailment': 0.6502661481499672, 'gold_entailment': 0.4879330576707919, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2013888888888889, 'r1_recall': 0.6744186046511628, 'r1_f1': 0.31016042780748665, 'pegasus_entailment': 0.44677775017917154, 'gold_entailment': 0.06445643212646246, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5394736842105263, 'r1_recall': 0.7321428571428571, 'r1_f1': 0.6212121212121212, 'pegasus_entailment': 0.4951264364644885, 'gold_entailment': 0.3352990100781123, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5511811023622047, 'r1_recall': 0.5343511450381679, 'r1_f1': 0.5426356589147286, 'pegasus_entailment': 0.5429381256302198, 'gold_entailment': 0.43681256224711734, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2702702702702703, 'r1_recall': 0.625, 'r1_f1': 0.3773584905660377, 'pegasus_entailment': 0.5427135569708688, 'gold_entailment': 0.4302612642447154, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5069444444444444, 'r1_recall': 0.6239316239316239, 'r1_f1': 0.5593869731800766, 'pegasus_entailment': 0.6278312843292951, 'gold_entailment': 0.33445290227731067, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5409836065573771, 'r1_recall': 0.5689655172413793, 'r1_f1': 0.5546218487394958, 'pegasus_entailment': 0.4938943423330784, 'gold_entailment': 0.4455862045288086, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 15, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 18, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5060240963855421, 'r1_recall': 0.711864406779661, 'r1_f1': 0.5915492957746479, 'pegasus_entailment': 0.261610348476097, 'gold_entailment': 0.15887310914695263, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 18}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7008547008547008, 'r1_recall': 0.43386243386243384, 'r1_f1': 0.5359477124183006, 'pegasus_entailment': 0.053654720385869346, 'gold_entailment': 0.11314713302999735, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6160714285714286, 'r1_recall': 0.5702479338842975, 'r1_f1': 0.5922746781115881, 'pegasus_entailment': 0.6616140076269706, 'gold_entailment': 0.6595242222150167, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 19, 'gold_ari': 28, 'gold_smog': 23}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5865384615384616, 'r1_recall': 0.3935483870967742, 'r1_f1': 0.47104247104247104, 'pegasus_entailment': 0.8311738967895508, 'gold_entailment': 0.6252789007765907, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.660377358490566, 'r1_recall': 0.4294478527607362, 'r1_f1': 0.5204460966542751, 'pegasus_entailment': 0.5586045771837235, 'gold_entailment': 0.41129820172985393, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4222222222222222, 'r1_recall': 0.5643564356435643, 'r1_f1': 0.4830508474576271, 'pegasus_entailment': 0.6839616795380911, 'gold_entailment': 0.4223140552639961, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5206611570247934, 'r1_f1': 0.5101214574898786, 'pegasus_entailment': 0.7361351648966471, 'gold_entailment': 0.4409015402197838, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 22, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3155080213903743, 'r1_recall': 0.6344086021505376, 'r1_f1': 0.4214285714285714, 'pegasus_entailment': 0.5712021868675947, 'gold_entailment': 0.33789269998669624, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6339285714285714, 'r1_recall': 0.5338345864661654, 'r1_f1': 0.5795918367346938, 'pegasus_entailment': 0.9594494104385376, 'gold_entailment': 0.6491177678108215, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7471264367816092, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.4779411764705882, 'pegasus_entailment': 0.6051113456487656, 'gold_entailment': 0.3115256801247597, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.6206896551724138, 'r1_f1': 0.5806451612903226, 'pegasus_entailment': 0.4338909188906352, 'gold_entailment': 0.5717878192663193, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 13, 'gold_smog': 17}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44047619047619047, 'r1_recall': 0.42045454545454547, 'r1_f1': 0.4302325581395349, 'pegasus_entailment': 0.32417843987544376, 'gold_entailment': 0.4749525027970473, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 23, 'gold_ari': 26, 'gold_smog': 25}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40594059405940597, 'r1_recall': 0.44086021505376344, 'r1_f1': 0.422680412371134, 'pegasus_entailment': 0.5831027865409851, 'gold_entailment': 0.37156326075394946, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 26, 'gold_smog': 24}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5813953488372093, 'r1_recall': 0.4424778761061947, 'r1_f1': 0.5025125628140704, 'pegasus_entailment': 0.7518425583839417, 'gold_entailment': 0.4521738390127818, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 22, 'gold_ari': 30, 'gold_smog': 26}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6458333333333334, 'r1_recall': 0.775, 'r1_f1': 0.7045454545454546, 'pegasus_entailment': 0.5264342606067658, 'gold_entailment': 0.586473761498928, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48695652173913045, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.5185185185185186, 'pegasus_entailment': 0.7917368561029434, 'gold_entailment': 0.4214214789015906, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 23}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5870967741935483, 'r1_recall': 0.4354066985645933, 'r1_f1': 0.5, 'pegasus_entailment': 0.8533371835947037, 'gold_entailment': 0.405370357632637, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 24, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 20, 'gold_ari': 29, 'gold_smog': 25}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.635036496350365, 'r1_recall': 0.48066298342541436, 'r1_f1': 0.5471698113207547, 'pegasus_entailment': 0.33208655193448067, 'gold_entailment': 0.32253599129617216, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.576271186440678, 'r1_f1': 0.422360248447205, 'pegasus_entailment': 0.7773483693599701, 'gold_entailment': 0.3588366413023323, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7727272727272727, 'r1_recall': 0.5246913580246914, 'r1_f1': 0.6250000000000001, 'pegasus_entailment': 0.35233226865530015, 'gold_entailment': 0.31061737090349195, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 21}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.410958904109589, 'r1_recall': 0.7317073170731707, 'r1_f1': 0.5263157894736841, 'pegasus_entailment': 0.5804445445537567, 'gold_entailment': 0.4412107566992442, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 24, 'gold_smog': 23}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5353535353535354, 'r1_recall': 0.5520833333333334, 'r1_f1': 0.5435897435897437, 'pegasus_entailment': 0.5641639828681946, 'gold_entailment': 0.3748807840049267, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48148148148148145, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.52, 'pegasus_entailment': 0.6642584651708603, 'gold_entailment': 0.1286857556551695, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 27, 'gold_coleman_liau': 21, 'gold_ari': 33, 'gold_smog': 27}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7735849056603774, 'r1_recall': 0.422680412371134, 'r1_f1': 0.5466666666666666, 'pegasus_entailment': 0.4198438860476017, 'gold_entailment': 0.3943897985986301, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49230769230769234, 'r1_recall': 0.3855421686746988, 'r1_f1': 0.43243243243243246, 'pegasus_entailment': 0.4962998367846012, 'gold_entailment': 0.4200523623398372, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 23, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 22, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41414141414141414, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.5189873417721519, 'pegasus_entailment': 0.9308434327443441, 'gold_entailment': 0.009914936497807503, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7017543859649122, 'r1_recall': 0.4624277456647399, 'r1_f1': 0.5574912891986062, 'pegasus_entailment': 0.5128360688686371, 'gold_entailment': 0.26308468942131313, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4727272727272727, 'r1_recall': 0.32098765432098764, 'r1_f1': 0.3823529411764705, 'pegasus_entailment': 0.7443737586339315, 'gold_entailment': 0.5206293761730194, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 24, 'gold_smog': 23}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5798319327731093, 'r1_recall': 0.46308724832214765, 'r1_f1': 0.5149253731343284, 'pegasus_entailment': 0.5328555116429925, 'gold_entailment': 0.2835363745689392, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40441176470588236, 'r1_recall': 0.5913978494623656, 'r1_f1': 0.48034934497816595, 'pegasus_entailment': 0.22325345177281028, 'gold_entailment': 0.270995682454668, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.36024844720496896, 'r1_f1': 0.46774193548387105, 'pegasus_entailment': 0.16193794645369053, 'gold_entailment': 0.2225036503126224, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.14285714285714285, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.2165605095541401, 'pegasus_entailment': 0.7567152604460716, 'gold_entailment': 0.001480974373407662, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7411764705882353, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.6528497409326425, 'pegasus_entailment': 0.6786173780759176, 'gold_entailment': 0.39266572644313175, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 15, 'pegasus_ari': 26, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 19, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.5436893203883495, 'r1_f1': 0.5045045045045046, 'pegasus_entailment': 0.7618859827518463, 'gold_entailment': 0.824240580201149, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6262626262626263, 'r1_recall': 0.3803680981595092, 'r1_f1': 0.4732824427480916, 'pegasus_entailment': 0.6872889906167984, 'gold_entailment': 0.6633848945299784, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 17}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.544, 'r1_recall': 0.6238532110091743, 'r1_f1': 0.5811965811965812, 'pegasus_entailment': 0.46053324174135923, 'gold_entailment': 0.5554791738589605, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 15, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4556213017751479, 'r1_recall': 0.4375, 'r1_f1': 0.4463768115942029, 'pegasus_entailment': 0.340929713845253, 'gold_entailment': 0.3536142572760582, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 16, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4329896907216495, 'r1_recall': 0.28, 'r1_f1': 0.3400809716599191, 'pegasus_entailment': 0.8374154766400655, 'gold_entailment': 0.4513792507350445, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5596330275229358, 'r1_recall': 0.4357142857142857, 'r1_f1': 0.4899598393574297, 'pegasus_entailment': 0.5379457697272301, 'gold_entailment': 0.28707756226261455, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5252525252525253, 'r1_recall': 0.348993288590604, 'r1_f1': 0.41935483870967744, 'pegasus_entailment': 0.5695684075355529, 'gold_entailment': 0.5050531670451164, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33507853403141363, 'r1_recall': 0.7032967032967034, 'r1_f1': 0.4539007092198582, 'pegasus_entailment': 0.7458828985691071, 'gold_entailment': 0.5571026653051376, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 18, 'gold_ari': 30, 'gold_smog': 22}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3103448275862069, 'r1_recall': 0.7012987012987013, 'r1_f1': 0.4302788844621514, 'pegasus_entailment': 0.7712846547365189, 'gold_entailment': 0.3698735535144806, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3821138211382114, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.4795918367346939, 'pegasus_entailment': 0.6167517403761545, 'gold_entailment': 0.6255641227665668, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6767676767676768, 'r1_recall': 0.18206521739130435, 'r1_f1': 0.28693790149892934, 'pegasus_entailment': 0.710808277130127, 'gold_entailment': 0.4400969033057873, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48360655737704916, 'r1_recall': 0.5363636363636364, 'r1_f1': 0.5086206896551725, 'pegasus_entailment': 0.9679873585700989, 'gold_entailment': 0.13929199458410343, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 20, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5040650406504065, 'r1_recall': 0.5, 'r1_f1': 0.5020242914979758, 'pegasus_entailment': 0.5671283513307571, 'gold_entailment': 0.4746696650981903, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 34, 'gold_coleman_liau': 23, 'gold_ari': 42, 'gold_smog': 28}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6435643564356436, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.588235294117647, 'pegasus_entailment': 0.5552377477288246, 'gold_entailment': 0.2336856541223824, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8527131782945736, 'r1_recall': 0.46808510638297873, 'r1_f1': 0.6043956043956044, 'pegasus_entailment': 0.7436049729585648, 'gold_entailment': 0.5095073346580777, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4785276073619632, 'r1_recall': 0.5131578947368421, 'r1_f1': 0.49523809523809526, 'pegasus_entailment': 0.2570571191608906, 'gold_entailment': 0.18338259011507035, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34705882352941175, 'r1_recall': 0.686046511627907, 'r1_f1': 0.4609375, 'pegasus_entailment': 0.8001967370510101, 'gold_entailment': 0.3122670240700245, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 24, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37735849056603776, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.44198895027624313, 'pegasus_entailment': 0.613471694290638, 'gold_entailment': 0.42985916261871654, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42592592592592593, 'r1_recall': 0.5111111111111111, 'r1_f1': 0.4646464646464646, 'pegasus_entailment': 0.7761467099189758, 'gold_entailment': 0.7447324991226196, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6262626262626263, 'r1_recall': 0.3780487804878049, 'r1_f1': 0.4714828897338404, 'pegasus_entailment': 0.7720704317092896, 'gold_entailment': 0.6074502430856228, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8067226890756303, 'r1_recall': 0.3344947735191638, 'r1_f1': 0.47290640394088673, 'pegasus_entailment': 0.4899223489420755, 'gold_entailment': 0.4922215590874354, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7444444444444445, 'r1_recall': 0.3743016759776536, 'r1_f1': 0.49814126394052044, 'pegasus_entailment': 0.5254494808614254, 'gold_entailment': 0.16051801775271693, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.635593220338983, 'r1_recall': 0.6578947368421053, 'r1_f1': 0.6465517241379309, 'pegasus_entailment': 0.6169518694281578, 'gold_entailment': 0.34048312678933146, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7157894736842105, 'r1_recall': 0.5230769230769231, 'r1_f1': 0.6044444444444446, 'pegasus_entailment': 0.7436866958936056, 'gold_entailment': 0.5538119859993458, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48598130841121495, 'r1_recall': 0.5, 'r1_f1': 0.4928909952606635, 'pegasus_entailment': 0.5141741335391998, 'gold_entailment': 0.3341562694736889, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32653061224489793, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.41558441558441556, 'pegasus_entailment': 0.9363581299781799, 'gold_entailment': 0.3138007861562073, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7368421052631579, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.6086956521739131, 'pegasus_entailment': 0.6502813398838043, 'gold_entailment': 0.5176722288131714, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5258620689655172, 'r1_recall': 0.7922077922077922, 'r1_f1': 0.6321243523316062, 'pegasus_entailment': 0.23909423465374857, 'gold_entailment': 0.1279887811979279, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 17, 'gold_ari': 26, 'gold_smog': 23}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6166666666666667, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.5606060606060607, 'pegasus_entailment': 0.6333152949810028, 'gold_entailment': 0.3761278599500656, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6375, 'r1_recall': 0.68, 'r1_f1': 0.6580645161290323, 'pegasus_entailment': 0.48674211154381436, 'gold_entailment': 0.4722329992800951, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5826086956521739, 'r1_recall': 0.5537190082644629, 'r1_f1': 0.5677966101694916, 'pegasus_entailment': 0.7686481177806854, 'gold_entailment': 0.25367505609756336, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6293103448275862, 'r1_recall': 0.6576576576576577, 'r1_f1': 0.6431718061674009, 'pegasus_entailment': 0.4856155982706696, 'gold_entailment': 0.5882605759737393, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 23, 'gold_ari': 30, 'gold_smog': 24}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3775933609958506, 'r1_recall': 0.558282208588957, 'r1_f1': 0.4504950495049505, 'pegasus_entailment': 0.5759115325553077, 'gold_entailment': 0.3272162874539693, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5289855072463768, 'r1_recall': 0.4147727272727273, 'r1_f1': 0.46496815286624205, 'pegasus_entailment': 0.4558401834219694, 'gold_entailment': 0.3648712659875552, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 22}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5370370370370371, 'r1_recall': 0.725, 'r1_f1': 0.6170212765957447, 'pegasus_entailment': 0.8477127552032471, 'gold_entailment': 0.3789958581328392, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 19, 'pegasus_ari': 35, 'pegasus_smog': 24, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25984251968503935, 'r1_recall': 0.55, 'r1_f1': 0.3529411764705882, 'pegasus_entailment': 0.3334119077771902, 'gold_entailment': 0.08245798596180975, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 24}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3431372549019608, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4320987654320988, 'pegasus_entailment': 0.636118878920873, 'gold_entailment': 0.41628745570778847, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45098039215686275, 'r1_recall': 0.46938775510204084, 'r1_f1': 0.46, 'pegasus_entailment': 0.27661238946020605, 'gold_entailment': 0.1933226902037859, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5793103448275863, 'r1_recall': 0.6461538461538462, 'r1_f1': 0.6109090909090908, 'pegasus_entailment': 0.5802473098039627, 'gold_entailment': 0.4698334676878793, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26744186046511625, 'r1_recall': 0.5, 'r1_f1': 0.34848484848484845, 'pegasus_entailment': 0.9689902663230896, 'gold_entailment': 0.6138170380145311, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 10, 'gold_coleman_liau': 13, 'gold_ari': 11, 'gold_smog': 15}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425531914893617, 'r1_recall': 0.7017543859649122, 'r1_f1': 0.5298013245033113, 'pegasus_entailment': 0.7063020638057164, 'gold_entailment': 0.4329674817621708, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4513888888888889, 'r1_recall': 0.5855855855855856, 'r1_f1': 0.5098039215686275, 'pegasus_entailment': 0.37567614763975143, 'gold_entailment': 0.4111532204385315, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7421875, 'r1_recall': 0.4337899543378995, 'r1_f1': 0.547550432276657, 'pegasus_entailment': 0.49755779653787613, 'gold_entailment': 0.31305099874734876, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5238095238095238, 'r1_recall': 0.6707317073170732, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.46703894352540376, 'gold_entailment': 0.6274175808066502, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5217391304347826, 'pegasus_entailment': 0.6698445677757263, 'gold_entailment': 0.43875676579773426, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 22}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5254237288135594, 'r1_recall': 0.6138613861386139, 'r1_f1': 0.5662100456621004, 'pegasus_entailment': 0.2012036107480526, 'gold_entailment': 0.18851906061172485, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 22}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5245901639344263, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.5565217391304348, 'pegasus_entailment': 0.148892781464383, 'gold_entailment': 0.17677475263675055, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 16, 'gold_ari': 13, 'gold_smog': 16}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30864197530864196, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.3875968992248062, 'pegasus_entailment': 0.24117740616202354, 'gold_entailment': 0.334776830393821, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 24, 'gold_ari': 25, 'gold_smog': 24}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5789473684210527, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.5670103092783506, 'pegasus_entailment': 0.4717847093939781, 'gold_entailment': 0.4454313337802887, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.525, 'r1_recall': 0.6645569620253164, 'r1_f1': 0.5865921787709498, 'pegasus_entailment': 0.4405900090932846, 'gold_entailment': 0.13542329768339792, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 29, 'gold_coleman_liau': 19, 'gold_ari': 34, 'gold_smog': 25}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.45569620253164556, 'r1_f1': 0.5236363636363637, 'pegasus_entailment': 0.49487923085689545, 'gold_entailment': 0.4617698162794113, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 16, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5511363636363636, 'r1_recall': 0.5025906735751295, 'r1_f1': 0.5257452574525745, 'pegasus_entailment': 0.29461762734821867, 'gold_entailment': 0.28134285493029487, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7794117647058824, 'r1_recall': 0.5047619047619047, 'r1_f1': 0.6127167630057804, 'pegasus_entailment': 0.530771791934967, 'gold_entailment': 0.3329100493186464, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6753246753246753, 'r1_recall': 0.416, 'r1_f1': 0.5148514851485149, 'pegasus_entailment': 0.4908769230047862, 'gold_entailment': 0.4178646355867386, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4155844155844156, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.496124031007752, 'pegasus_entailment': 0.3218306914592783, 'gold_entailment': 0.02809669015308221, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2909090909090909, 'r1_recall': 0.5245901639344263, 'r1_f1': 0.3742690058479532, 'pegasus_entailment': 0.4155359868891537, 'gold_entailment': 0.01819443687175711, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 15, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4367816091954023, 'r1_recall': 0.6129032258064516, 'r1_f1': 0.5100671140939598, 'pegasus_entailment': 0.6187162047252059, 'gold_entailment': 0.4372031975071877, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2641509433962264, 'r1_recall': 0.4745762711864407, 'r1_f1': 0.33939393939393936, 'pegasus_entailment': 0.2560764290392399, 'gold_entailment': 0.29232625849545, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 16}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4830508474576271, 'r1_recall': 0.5, 'r1_f1': 0.49137931034482757, 'pegasus_entailment': 0.4594385226567586, 'gold_entailment': 0.2787841906150182, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35, 'r1_recall': 0.42424242424242425, 'r1_f1': 0.3835616438356164, 'pegasus_entailment': 0.5493820816278457, 'gold_entailment': 0.5097059905529022, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2641509433962264, 'r1_recall': 0.7, 'r1_f1': 0.3835616438356165, 'pegasus_entailment': 0.6479672193527222, 'gold_entailment': 0.44551197066903114, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 19}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43005181347150256, 'r1_recall': 0.4797687861271676, 'r1_f1': 0.453551912568306, 'pegasus_entailment': 0.37083046417683363, 'gold_entailment': 0.19915243238210678, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3828125, 'r1_recall': 0.6125, 'r1_f1': 0.4711538461538462, 'pegasus_entailment': 0.46769316991170246, 'gold_entailment': 0.3847366461995989, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 21, 'gold_ari': 20, 'gold_smog': 21}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5634920634920635, 'r1_recall': 0.398876404494382, 'r1_f1': 0.4671052631578947, 'pegasus_entailment': 0.6208313554525375, 'gold_entailment': 0.542765611410141, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6847826086956522, 'r1_recall': 0.391304347826087, 'r1_f1': 0.4980237154150197, 'pegasus_entailment': 0.30738015174865724, 'gold_entailment': 0.3746371205363955, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5031847133757962, 'r1_recall': 0.5895522388059702, 'r1_f1': 0.5429553264604812, 'pegasus_entailment': 0.46713510900735855, 'gold_entailment': 0.4230722486972809, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 24, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6442307692307693, 'r1_recall': 0.2757201646090535, 'r1_f1': 0.3861671469740634, 'pegasus_entailment': 0.42853888869285583, 'gold_entailment': 0.2520585760474205, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 29, 'gold_coleman_liau': 21, 'gold_ari': 34, 'gold_smog': 26}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5057471264367817, 'r1_recall': 0.5365853658536586, 'r1_f1': 0.5207100591715976, 'pegasus_entailment': 0.5051126380761465, 'gold_entailment': 0.5012525618076324, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6302521008403361, 'r1_recall': 0.4934210526315789, 'r1_f1': 0.5535055350553505, 'pegasus_entailment': 0.4768214076757431, 'gold_entailment': 0.3908864427357912, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 20}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2890625, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.36999999999999994, 'pegasus_entailment': 0.5657569055911154, 'gold_entailment': 0.4048581190407276, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 19}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.592, 'r1_recall': 0.33183856502242154, 'r1_f1': 0.4252873563218391, 'pegasus_entailment': 0.5065988171845675, 'gold_entailment': 0.3815760002894835, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24074074074074073, 'r1_recall': 0.23008849557522124, 'r1_f1': 0.23529411764705882, 'pegasus_entailment': 0.6262917995452881, 'gold_entailment': 0.170063110999763, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25, 'r1_recall': 0.7391304347826086, 'r1_f1': 0.37362637362637363, 'pegasus_entailment': 0.753582701086998, 'gold_entailment': 0.5207799133689454, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 15}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6396396396396397, 'r1_recall': 0.39226519337016574, 'r1_f1': 0.4863013698630136, 'pegasus_entailment': 0.4896550714969635, 'gold_entailment': 0.3061299573164433, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6571428571428571, 'r1_recall': 0.3898305084745763, 'r1_f1': 0.4893617021276596, 'pegasus_entailment': 0.441116276755929, 'gold_entailment': 0.16910113543272018, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 24}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2975609756097561, 'r1_recall': 0.6354166666666666, 'r1_f1': 0.4053156146179402, 'pegasus_entailment': 0.8695572879579332, 'gold_entailment': 0.6246634252369404, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6126126126126126, 'r1_recall': 0.4689655172413793, 'r1_f1': 0.53125, 'pegasus_entailment': 0.8037609954675039, 'gold_entailment': 0.7510646070752826, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16470588235294117, 'r1_recall': 0.5, 'r1_f1': 0.24778761061946902, 'pegasus_entailment': 0.22543554659932852, 'gold_entailment': 0.07805763185024261, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 10, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 14}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1870967741935484, 'r1_recall': 0.5, 'r1_f1': 0.27230046948356806, 'pegasus_entailment': 0.6422848502794901, 'gold_entailment': 0.38828088715672493, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16, 'gold_flesch_kincaid': 11, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6896551724137931, 'r1_recall': 0.5042016806722689, 'r1_f1': 0.5825242718446602, 'pegasus_entailment': 0.5374885350465775, 'gold_entailment': 0.46125562706341344, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3697478991596639, 'r1_recall': 0.6197183098591549, 'r1_f1': 0.4631578947368421, 'pegasus_entailment': 0.6605775579810143, 'gold_entailment': 0.8766826788584391, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 21}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28440366972477066, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.3780487804878049, 'pegasus_entailment': 0.7092878520488739, 'gold_entailment': 0.3501824140548706, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23931623931623933, 'r1_recall': 0.345679012345679, 'r1_f1': 0.2828282828282828, 'pegasus_entailment': 0.382490579970181, 'gold_entailment': 0.43237057514488697, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7619047619047619, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.6666666666666666, 'pegasus_entailment': 0.7166617214679718, 'gold_entailment': 0.2777901791851036, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47126436781609193, 'r1_recall': 0.4939759036144578, 'r1_f1': 0.4823529411764706, 'pegasus_entailment': 0.2583414101973176, 'gold_entailment': 0.32960542136182386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 17}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4888888888888889, 'r1_recall': 0.5945945945945946, 'r1_f1': 0.5365853658536586, 'pegasus_entailment': 0.4606471937149763, 'gold_entailment': 0.4020276218652725, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.82, 'r1_recall': 0.24404761904761904, 'r1_f1': 0.3761467889908257, 'pegasus_entailment': 0.5294976606965065, 'gold_entailment': 0.5425531376491893, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.25225225225225223, 'r1_f1': 0.35782747603833864, 'pegasus_entailment': 0.4455788880586624, 'gold_entailment': 0.4044804833829403, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3389830508474576, 'r1_recall': 0.5128205128205128, 'r1_f1': 0.4081632653061224, 'pegasus_entailment': 0.7300939373672009, 'gold_entailment': 0.15819273640712103, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17, 'gold_flesch_kincaid': 9, 'gold_coleman_liau': 13, 'gold_ari': 11, 'gold_smog': 13}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6271186440677966, 'r1_recall': 0.7115384615384616, 'r1_f1': 0.6666666666666666, 'pegasus_entailment': 0.5504718772135675, 'gold_entailment': 0.4064350239932537, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 16}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2331288343558282, 'r1_recall': 0.5205479452054794, 'r1_f1': 0.3220338983050847, 'pegasus_entailment': 0.5639211755866805, 'gold_entailment': 0.37724727333988994, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42168674698795183, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.47297297297297297, 'pegasus_entailment': 0.08702689819037915, 'gold_entailment': 0.14111190289258957, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6081081081081081, 'r1_recall': 0.625, 'r1_f1': 0.6164383561643835, 'pegasus_entailment': 0.6027447432279587, 'gold_entailment': 0.5571541090806326, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.6049382716049383, 'r1_f1': 0.5939393939393939, 'pegasus_entailment': 0.8534751087427139, 'gold_entailment': 0.5054758107289672, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33043478260869563, 'r1_recall': 0.5, 'r1_f1': 0.39790575916230364, 'pegasus_entailment': 0.8699091871579488, 'gold_entailment': 0.6454972103238106, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 15}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.5487804878048781, 'pegasus_entailment': 0.5013197595253587, 'gold_entailment': 0.4206629067659378, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 17, 'gold_ari': 14, 'gold_smog': 15}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.62, 'r1_recall': 0.39490445859872614, 'r1_f1': 0.4824902723735409, 'pegasus_entailment': 0.7633824944496155, 'gold_entailment': 0.6291903725692204, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7475728155339806, 'r1_recall': 0.5347222222222222, 'r1_f1': 0.6234817813765182, 'pegasus_entailment': 0.4943821653723717, 'gold_entailment': 0.6122700199484825, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41836734693877553, 'r1_recall': 0.43617021276595747, 'r1_f1': 0.42708333333333337, 'pegasus_entailment': 0.35166961851064116, 'gold_entailment': 0.01185196750642111, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 17}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.59, 'r1_recall': 0.6178010471204188, 'r1_f1': 0.6035805626598465, 'pegasus_entailment': 0.4914821854659489, 'gold_entailment': 0.23785632736980916, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2692307692307692, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.3910614525139664, 'pegasus_entailment': 0.9808341562747955, 'gold_entailment': 0.01936294138431549, 'pegasus_flesch_kincaid': 35, 'pegasus_coleman_liau': 22, 'pegasus_ari': 43, 'pegasus_smog': 29, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5733333333333334, 'r1_recall': 0.5180722891566265, 'r1_f1': 0.5443037974683543, 'pegasus_entailment': 0.561043782858178, 'gold_entailment': 0.5234314799308777, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4672897196261682, 'r1_recall': 0.6410256410256411, 'r1_f1': 0.5405405405405406, 'pegasus_entailment': 0.6239297837018967, 'gold_entailment': 0.37708954969421027, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 17, 'gold_ari': 15, 'gold_smog': 13}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5045871559633027, 'r1_recall': 0.6790123456790124, 'r1_f1': 0.5789473684210527, 'pegasus_entailment': 0.5367444299161435, 'gold_entailment': 0.44693438708782196, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5165562913907285, 'r1_recall': 0.5693430656934306, 'r1_f1': 0.5416666666666666, 'pegasus_entailment': 0.7777893662452697, 'gold_entailment': 0.46349689960479734, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24324324324324326, 'r1_recall': 0.4090909090909091, 'r1_f1': 0.3050847457627119, 'pegasus_entailment': 0.5335994704316059, 'gold_entailment': 0.07506494969129562, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 28, 'gold_coleman_liau': 25, 'gold_ari': 35, 'gold_smog': 30}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2631578947368421, 'r1_recall': 0.5084745762711864, 'r1_f1': 0.3468208092485549, 'pegasus_entailment': 0.8066587895154953, 'gold_entailment': 0.2890716725960374, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5384615384615384, 'r1_recall': 0.5746268656716418, 'r1_f1': 0.555956678700361, 'pegasus_entailment': 0.5288810759782792, 'gold_entailment': 0.5306823054949442, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6597938144329897, 'r1_recall': 0.41025641025641024, 'r1_f1': 0.5059288537549407, 'pegasus_entailment': 0.43965157369772595, 'gold_entailment': 0.16293240152299404, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38333333333333336, 'r1_recall': 0.7076923076923077, 'r1_f1': 0.49729729729729727, 'pegasus_entailment': 0.7633189161618551, 'gold_entailment': 0.5289441142231226, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 24, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 15, 'gold_ari': 14, 'gold_smog': 15}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39285714285714285, 'r1_recall': 0.5, 'r1_f1': 0.44, 'pegasus_entailment': 0.5217139100035032, 'gold_entailment': 0.3093561129644513, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5308641975308642, 'r1_recall': 0.5119047619047619, 'r1_f1': 0.5212121212121211, 'pegasus_entailment': 0.7101891239484152, 'gold_entailment': 0.5483917246262232, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 17, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36363636363636365, 'r1_recall': 0.4155844155844156, 'r1_f1': 0.38787878787878793, 'pegasus_entailment': 0.5119253508746624, 'gold_entailment': 0.25849786897500354, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2916666666666667, 'r1_recall': 0.525, 'r1_f1': 0.37500000000000006, 'pegasus_entailment': 0.5735501885414124, 'gold_entailment': 0.3306366664667924, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5148514851485149, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5810055865921788, 'pegasus_entailment': 0.7151769740240914, 'gold_entailment': 0.34429857805371283, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3877551020408163, 'r1_recall': 0.5, 'r1_f1': 0.43678160919540227, 'pegasus_entailment': 0.41372030377388, 'gold_entailment': 0.3919481833775838, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2786885245901639, 'r1_recall': 0.6, 'r1_f1': 0.3805970149253731, 'pegasus_entailment': 0.4888289677245276, 'gold_entailment': 0.4459564693272114, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6782608695652174, 'r1_recall': 0.5954198473282443, 'r1_f1': 0.6341463414634146, 'pegasus_entailment': 0.4069873919710517, 'gold_entailment': 0.49441533039013547, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 22, 'gold_ari': 32, 'gold_smog': 25}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5517241379310345, 'r1_recall': 0.4528301886792453, 'r1_f1': 0.4974093264248704, 'pegasus_entailment': 0.31677574043472606, 'gold_entailment': 0.2969045517966151, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6694214876033058, 'r1_recall': 0.4426229508196721, 'r1_f1': 0.5328947368421052, 'pegasus_entailment': 0.8042348474264145, 'gold_entailment': 0.27694701350161005, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3770491803278688, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.46464646464646464, 'pegasus_entailment': 0.3983178536097209, 'gold_entailment': 0.47234558407217264, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 22, 'pegasus_ari': 31, 'pegasus_smog': 24, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4878048780487805, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.5581395348837209, 'pegasus_entailment': 0.41429625265300274, 'gold_entailment': 0.35849029074112576, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7272727272727273, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.6299212598425198, 'pegasus_entailment': 0.4175658017396927, 'gold_entailment': 0.5060733978947004, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6101694915254238, 'r1_recall': 0.3564356435643564, 'r1_f1': 0.45, 'pegasus_entailment': 0.027322534006088972, 'gold_entailment': 0.05588476941920817, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5185185185185185, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5436893203883496, 'pegasus_entailment': 0.3227109824074432, 'gold_entailment': 0.0994844107190147, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.5625000000000001, 'pegasus_entailment': 0.6369003109866753, 'gold_entailment': 0.0996675374917686, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 22, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6592592592592592, 'r1_recall': 0.6691729323308271, 'r1_f1': 0.664179104477612, 'pegasus_entailment': 0.47892444650642574, 'gold_entailment': 0.5281771961599588, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 25}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5277777777777778, 'r1_recall': 0.4222222222222222, 'r1_f1': 0.46913580246913583, 'pegasus_entailment': 0.4055817524592082, 'gold_entailment': 0.2564845234155655, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.396284032613039, 'gold_entailment': 0.4591295897960663, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 21}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41964285714285715, 'r1_recall': 0.42342342342342343, 'r1_f1': 0.4215246636771301, 'pegasus_entailment': 0.665084034204483, 'gold_entailment': 0.51890729367733, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7358490566037735, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.6393442622950819, 'pegasus_entailment': 0.7704564929008484, 'gold_entailment': 0.5325973076202596, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23076923076923078, 'r1_recall': 0.54, 'r1_f1': 0.32335329341317365, 'pegasus_entailment': 0.10709759835153818, 'gold_entailment': 0.02856582053937018, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 15, 'gold_smog': 18}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27044025157232704, 'r1_recall': 0.7678571428571429, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.4307361841201782, 'gold_entailment': 0.34381429354349774, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2153846153846154, 'r1_recall': 0.2978723404255319, 'r1_f1': 0.25, 'pegasus_entailment': 0.38805734117825824, 'gold_entailment': 0.4855263829231262, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 14, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425, 'r1_recall': 0.4788732394366197, 'r1_f1': 0.45033112582781454, 'pegasus_entailment': 0.4726495295763016, 'gold_entailment': 0.08087711366824805, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 17, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5533980582524272, 'r1_recall': 0.3114754098360656, 'r1_f1': 0.3986013986013986, 'pegasus_entailment': 0.33548392355442047, 'gold_entailment': 0.3407306674635038, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5631067961165048, 'r1_recall': 0.4233576642335766, 'r1_f1': 0.48333333333333334, 'pegasus_entailment': 0.8609839081764221, 'gold_entailment': 0.130555992325147, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 20, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 19, 'gold_ari': 31, 'gold_smog': 24}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6764705882352942, 'r1_recall': 0.5054945054945055, 'r1_f1': 0.5786163522012578, 'pegasus_entailment': 0.6435031990210215, 'gold_entailment': 0.5267151594161987, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 27, 'gold_coleman_liau': 21, 'gold_ari': 32, 'gold_smog': 26}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5034013605442177, 'r1_recall': 0.556390977443609, 'r1_f1': 0.5285714285714286, 'pegasus_entailment': 0.4667734056711197, 'gold_entailment': 0.5137449922040105, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5325443786982249, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.5405405405405406, 'pegasus_entailment': 0.39296892533699673, 'gold_entailment': 0.2821655347943306, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 17, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7884615384615384, 'r1_recall': 0.4079601990049751, 'r1_f1': 0.5377049180327867, 'pegasus_entailment': 0.7278128067652384, 'gold_entailment': 0.27594199823215604, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 24, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3592233009708738, 'r1_recall': 0.37, 'r1_f1': 0.3645320197044335, 'pegasus_entailment': 0.38528786102930707, 'gold_entailment': 0.2942257250348727, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 26, 'gold_smog': 25}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6231884057971014, 'r1_recall': 0.5375, 'r1_f1': 0.5771812080536913, 'pegasus_entailment': 0.4951770300976932, 'gold_entailment': 0.5575645267963409, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.449438202247191, 'r1_recall': 0.4878048780487805, 'r1_f1': 0.4678362573099415, 'pegasus_entailment': 0.036385397892445326, 'gold_entailment': 0.21970761958800722, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 25, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2823529411764706, 'r1_recall': 0.5, 'r1_f1': 0.3609022556390977, 'pegasus_entailment': 0.21853036747779697, 'gold_entailment': 0.1416958992679914, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 17, 'gold_smog': 19}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3046875, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.4083769633507853, 'pegasus_entailment': 0.6752748680301011, 'gold_entailment': 0.32572677250330645, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.225, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.31578947368421056, 'pegasus_entailment': 0.15956347668543458, 'gold_entailment': 0.07542950293282047, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 21, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3835616438356164, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.3758389261744966, 'pegasus_entailment': 0.38182199001312256, 'gold_entailment': 0.04064810276031494, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 38, 'gold_coleman_liau': 19, 'gold_ari': 46, 'gold_smog': 30}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6057692307692307, 'r1_recall': 0.3423913043478261, 'r1_f1': 0.43750000000000006, 'pegasus_entailment': 0.6280152425169945, 'gold_entailment': 0.5992544293403625, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 25, 'gold_smog': 19}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2391304347826087, 'r1_recall': 0.3283582089552239, 'r1_f1': 0.2767295597484277, 'pegasus_entailment': 0.33417019844055174, 'gold_entailment': 0.16365988552570343, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 16}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6814159292035398, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.5480427046263345, 'pegasus_entailment': 0.479865600168705, 'gold_entailment': 0.382345041881005, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6141732283464567, 'r1_recall': 0.5909090909090909, 'r1_f1': 0.6023166023166022, 'pegasus_entailment': 0.28141659051179885, 'gold_entailment': 0.29884912772104144, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 20, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6923076923076923, 'r1_recall': 0.45569620253164556, 'r1_f1': 0.549618320610687, 'pegasus_entailment': 0.3308212459087372, 'gold_entailment': 0.6176746189594269, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6831683168316832, 'r1_recall': 0.23310810810810811, 'r1_f1': 0.34760705289672544, 'pegasus_entailment': 0.6380592361092567, 'gold_entailment': 0.365424092572469, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3577981651376147, 'r1_recall': 0.7090909090909091, 'r1_f1': 0.475609756097561, 'pegasus_entailment': 0.5887458583872233, 'gold_entailment': 0.338435849485298, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7333333333333333, 'r1_recall': 0.39086294416243655, 'r1_f1': 0.509933774834437, 'pegasus_entailment': 0.20490989042446017, 'gold_entailment': 0.2021928975979487, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 21, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34615384615384615, 'r1_recall': 0.6, 'r1_f1': 0.43902439024390244, 'pegasus_entailment': 0.06493831301728885, 'gold_entailment': 0.048695915611460805, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 23, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5714285714285714, 'r1_recall': 0.4878048780487805, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.7332732230424881, 'gold_entailment': 0.725471094250679, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 18}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5742574257425742, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5631067961165049, 'pegasus_entailment': 0.5579222937424978, 'gold_entailment': 0.44354602694511414, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 23, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 22}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7368421052631579, 'r1_recall': 0.5343511450381679, 'r1_f1': 0.6194690265486725, 'pegasus_entailment': 0.28946630097925663, 'gold_entailment': 0.37624027331670123, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 18, 'gold_ari': 29, 'gold_smog': 20}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34951456310679613, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.4235294117647059, 'pegasus_entailment': 0.36451474018394947, 'gold_entailment': 0.40991804003715515, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 16}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24375, 'r1_recall': 0.6842105263157895, 'r1_f1': 0.35944700460829493, 'pegasus_entailment': 0.43909582992394763, 'gold_entailment': 0.6405704021453857, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 21, 'pegasus_ari': 36, 'pegasus_smog': 25, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 23, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3046875, 'r1_recall': 0.6842105263157895, 'r1_f1': 0.42162162162162165, 'pegasus_entailment': 0.6631737500429153, 'gold_entailment': 0.6222971975803375, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5619047619047619, 'r1_recall': 0.4609375, 'r1_f1': 0.5064377682403434, 'pegasus_entailment': 0.2649472542107105, 'gold_entailment': 0.28554567992687224, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6692913385826772, 'r1_recall': 0.47752808988764045, 'r1_f1': 0.5573770491803278, 'pegasus_entailment': 0.5736024053767323, 'gold_entailment': 0.6158444344997406, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5850340136054422, 'r1_recall': 0.5276073619631901, 'r1_f1': 0.5548387096774194, 'pegasus_entailment': 0.7714420159657797, 'gold_entailment': 0.4366451442241669, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6178861788617886, 'r1_recall': 0.39378238341968913, 'r1_f1': 0.4810126582278481, 'pegasus_entailment': 0.7864760756492615, 'gold_entailment': 0.4550936213797993, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.472, 'r1_recall': 0.5841584158415841, 'r1_f1': 0.5221238938053097, 'pegasus_entailment': 0.7424290895462036, 'gold_entailment': 0.08544209351142247, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 15, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 23, 'gold_smog': 17}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4188034188034188, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.48756218905472637, 'pegasus_entailment': 0.4023629905035098, 'gold_entailment': 0.3632155954837799, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.373015873015873, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.4351851851851852, 'pegasus_entailment': 0.7226472187787294, 'gold_entailment': 0.6624298505485058, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 23, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2736842105263158, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.3561643835616438, 'pegasus_entailment': 0.11675985405842464, 'gold_entailment': 0.27595046907663345, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6118421052631579, 'r1_recall': 0.6283783783783784, 'r1_f1': 0.62, 'pegasus_entailment': 0.6362300763527552, 'gold_entailment': 0.3641702277319772, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5703703703703704, 'r1_recall': 0.5877862595419847, 'r1_f1': 0.5789473684210527, 'pegasus_entailment': 0.720140489935875, 'gold_entailment': 0.346959562599659, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5784313725490197, 'r1_recall': 0.5, 'r1_f1': 0.5363636363636364, 'pegasus_entailment': 0.8698602616786957, 'gold_entailment': 0.03591304668225348, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8, 'r1_recall': 0.5230769230769231, 'r1_f1': 0.6325581395348837, 'pegasus_entailment': 0.5753185078501701, 'gold_entailment': 0.3154743850231171, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5647058823529412, 'r1_recall': 0.40336134453781514, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.24264019075781107, 'gold_entailment': 0.39928197488188744, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6956521739130435, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.6177606177606177, 'pegasus_entailment': 0.5201976792886853, 'gold_entailment': 0.37492545396089555, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5161290322580645, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5245901639344263, 'pegasus_entailment': 0.2776159793138504, 'gold_entailment': 0.19206691207364202, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 15}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.6541353383458647, 'r1_f1': 0.6258992805755396, 'pegasus_entailment': 0.701292042930921, 'gold_entailment': 0.443665087223053, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5202702702702703, 'r1_recall': 0.3632075471698113, 'r1_f1': 0.4277777777777778, 'pegasus_entailment': 0.7876913448174795, 'gold_entailment': 0.48462880328297614, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3023255813953488, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.3636363636363636, 'pegasus_entailment': 0.3516860917210579, 'gold_entailment': 0.648234635591507, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5086206896551724, 'r1_recall': 0.4609375, 'r1_f1': 0.48360655737704916, 'pegasus_entailment': 0.7063781172037125, 'gold_entailment': 0.37827932396903635, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22023809523809523, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.3288888888888889, 'pegasus_entailment': 0.49173719584941866, 'gold_entailment': 0.30084139481186867, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 22}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6915887850467289, 'r1_recall': 0.387434554973822, 'r1_f1': 0.4966442953020135, 'pegasus_entailment': 0.4860863536596298, 'gold_entailment': 0.36655490951878683, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4880952380952381, 'r1_recall': 0.5578231292517006, 'r1_f1': 0.5206349206349206, 'pegasus_entailment': 0.43276001885533333, 'gold_entailment': 0.3166217717031638, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 21}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4431137724550898, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.46105919003115264, 'pegasus_entailment': 0.8728111743927002, 'gold_entailment': 0.5257430076599121, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41605839416058393, 'r1_recall': 0.76, 'r1_f1': 0.5377358490566038, 'pegasus_entailment': 0.8480560630559921, 'gold_entailment': 0.5537057756446302, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.553030303030303, 'r1_recall': 0.6347826086956522, 'r1_f1': 0.5910931174089068, 'pegasus_entailment': 0.6458246197019305, 'gold_entailment': 0.32668511755764484, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 15, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.616822429906542, 'r1_recall': 0.43137254901960786, 'r1_f1': 0.5076923076923077, 'pegasus_entailment': 0.7097740322351456, 'gold_entailment': 0.37749894335865974, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5370370370370371, 'r1_recall': 0.5686274509803921, 'r1_f1': 0.5523809523809524, 'pegasus_entailment': 0.09025252256542445, 'gold_entailment': 0.3003640715032816, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3069306930693069, 'r1_recall': 0.543859649122807, 'r1_f1': 0.3924050632911393, 'pegasus_entailment': 0.3961614891886711, 'gold_entailment': 0.24751507739226022, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 21, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43023255813953487, 'r1_recall': 0.578125, 'r1_f1': 0.49333333333333335, 'pegasus_entailment': 0.48122696205973625, 'gold_entailment': 0.27557611442171037, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4787234042553192, 'r1_recall': 0.6, 'r1_f1': 0.5325443786982249, 'pegasus_entailment': 0.28445637474457425, 'gold_entailment': 0.2210256028920412, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 21, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47619047619047616, 'r1_recall': 0.7547169811320755, 'r1_f1': 0.5839416058394161, 'pegasus_entailment': 0.8553995341062546, 'gold_entailment': 0.7505869269371033, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 15, 'gold_ari': 14, 'gold_smog': 17}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5486725663716814, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6019417475728155, 'pegasus_entailment': 0.4613921120762825, 'gold_entailment': 0.2753560334444046, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5064935064935064, 'r1_recall': 0.6724137931034483, 'r1_f1': 0.5777777777777778, 'pegasus_entailment': 0.4831901916768402, 'gold_entailment': 0.6944848448038101, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6938775510204082, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6799999999999999, 'pegasus_entailment': 0.4707633312791586, 'gold_entailment': 0.48433642089366913, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 28, 'gold_coleman_liau': 18, 'gold_ari': 33, 'gold_smog': 25}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.65, 'r1_recall': 0.41139240506329117, 'r1_f1': 0.5038759689922481, 'pegasus_entailment': 0.6501880008727312, 'gold_entailment': 0.2958093211054802, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3142857142857143, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.40740740740740744, 'pegasus_entailment': 0.23922596328581372, 'gold_entailment': 0.24630354903638363, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 23, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5869565217391305, 'r1_recall': 0.5436241610738255, 'r1_f1': 0.5644599303135888, 'pegasus_entailment': 0.5400812506675721, 'gold_entailment': 0.4694910109043121, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5445544554455446, 'r1_recall': 0.40145985401459855, 'r1_f1': 0.46218487394957986, 'pegasus_entailment': 0.6341959804296493, 'gold_entailment': 0.3086937256157398, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 23}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.6818181818181818, 'r1_f1': 0.576923076923077, 'pegasus_entailment': 0.22790134645765647, 'gold_entailment': 0.32550959661602974, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851063829787234, 'r1_recall': 0.4954954954954955, 'r1_f1': 0.5365853658536586, 'pegasus_entailment': 0.6454927722613016, 'gold_entailment': 0.626514345407486, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2824858757062147, 'r1_recall': 0.625, 'r1_f1': 0.38910505836575876, 'pegasus_entailment': 0.662777203321457, 'gold_entailment': 0.2518798417877406, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5384615384615384, 'r1_recall': 0.3858267716535433, 'r1_f1': 0.4495412844036697, 'pegasus_entailment': 0.6673648655414581, 'gold_entailment': 0.46485574756349834, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7142857142857143, 'r1_recall': 0.45685279187817257, 'r1_f1': 0.5572755417956656, 'pegasus_entailment': 0.48399512097239494, 'gold_entailment': 0.47930464381352067, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7226890756302521, 'r1_recall': 0.35390946502057613, 'r1_f1': 0.47513812154696133, 'pegasus_entailment': 0.48341700434684753, 'gold_entailment': 0.19440931314602494, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7721518987341772, 'r1_recall': 0.43884892086330934, 'r1_f1': 0.5596330275229358, 'pegasus_entailment': 0.4624102876987308, 'gold_entailment': 0.5317986130539794, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1875, 'r1_recall': 0.2465753424657534, 'r1_f1': 0.21301775147928995, 'pegasus_entailment': 0.002802051545586437, 'gold_entailment': 0.011228120458933214, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 20, 'gold_ari': 27, 'gold_smog': 24}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29213483146067415, 'r1_recall': 0.4262295081967213, 'r1_f1': 0.3466666666666666, 'pegasus_entailment': 0.12440862786024809, 'gold_entailment': 0.05375770421233028, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 14, 'pegasus_ari': 11, 'pegasus_smog': 12, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5252525252525253, 'r1_recall': 0.6046511627906976, 'r1_f1': 0.5621621621621622, 'pegasus_entailment': 0.6038991049863398, 'gold_entailment': 0.34510510445882875, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4673913043478261, 'r1_recall': 0.581081081081081, 'r1_f1': 0.5180722891566265, 'pegasus_entailment': 0.26027009015281993, 'gold_entailment': 0.21066339313983917, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7303370786516854, 'r1_recall': 0.3735632183908046, 'r1_f1': 0.49429657794676807, 'pegasus_entailment': 0.44532370115630326, 'gold_entailment': 0.25103636607527735, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 22}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45217391304347826, 'r1_recall': 0.3611111111111111, 'r1_f1': 0.4015444015444015, 'pegasus_entailment': 0.19654152039438486, 'gold_entailment': 0.2533270694315434, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6936936936936937, 'r1_recall': 0.39487179487179486, 'r1_f1': 0.5032679738562091, 'pegasus_entailment': 0.7262692302465439, 'gold_entailment': 0.4992276310920715, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 18, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5609756097560976, 'r1_recall': 0.6301369863013698, 'r1_f1': 0.5935483870967743, 'pegasus_entailment': 0.5703517124056816, 'gold_entailment': 0.557810865342617, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4594594594594595, 'r1_recall': 0.68, 'r1_f1': 0.5483870967741935, 'pegasus_entailment': 0.4544612541794777, 'gold_entailment': 0.33694658692305285, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49019607843137253, 'r1_recall': 0.43859649122807015, 'r1_f1': 0.46296296296296297, 'pegasus_entailment': 0.7797038406133652, 'gold_entailment': 0.6019188389182091, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7586206896551724, 'r1_recall': 0.17553191489361702, 'r1_f1': 0.28509719222462204, 'pegasus_entailment': 0.4930597096681595, 'gold_entailment': 0.5267946179956198, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4430379746835443, 'r1_recall': 0.5932203389830508, 'r1_f1': 0.5072463768115942, 'pegasus_entailment': 0.7786299586296082, 'gold_entailment': 0.7776883641878763, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5702479338842975, 'r1_recall': 0.4107142857142857, 'r1_f1': 0.4775086505190311, 'pegasus_entailment': 0.7133971899747849, 'gold_entailment': 0.4468252675142139, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5172413793103449, 'r1_recall': 0.46511627906976744, 'r1_f1': 0.4897959183673469, 'pegasus_entailment': 0.5425601094961167, 'gold_entailment': 0.3347137368284166, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 22}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45098039215686275, 'r1_recall': 0.46308724832214765, 'r1_f1': 0.45695364238410596, 'pegasus_entailment': 0.762558114528656, 'gold_entailment': 0.41083624213933945, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 18, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5317919075144508, 'r1_recall': 0.5443786982248521, 'r1_f1': 0.5380116959064327, 'pegasus_entailment': 0.4170837886631489, 'gold_entailment': 0.24450431444815227, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.591304347826087, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.5528455284552846, 'pegasus_entailment': 0.4893946126103401, 'gold_entailment': 0.28794454857707025, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 17, 'pegasus_ari': 35, 'pegasus_smog': 24, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40425531914893614, 'r1_recall': 0.3064516129032258, 'r1_f1': 0.34862385321100914, 'pegasus_entailment': 0.7241023977597555, 'gold_entailment': 0.4554596294959386, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41353383458646614, 'r1_recall': 0.6626506024096386, 'r1_f1': 0.5092592592592593, 'pegasus_entailment': 0.43734047282487154, 'gold_entailment': 0.4315773434937, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27058823529411763, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.3709677419354838, 'pegasus_entailment': 0.33076416701078415, 'gold_entailment': 0.16193843260407448, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5287356321839081, 'r1_recall': 0.39655172413793105, 'r1_f1': 0.4532019704433498, 'pegasus_entailment': 0.3575606355443597, 'gold_entailment': 0.2951561287045479, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 23}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5899280575539568, 'r1_recall': 0.44324324324324327, 'r1_f1': 0.5061728395061729, 'pegasus_entailment': 0.5705349400639534, 'gold_entailment': 0.4292580485343933, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7142857142857143, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.6954572548468908, 'gold_entailment': 0.03789310979967316, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 17, 'gold_ari': 31, 'gold_smog': 23}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6985294117647058, 'r1_recall': 0.24675324675324675, 'r1_f1': 0.36468330134357, 'pegasus_entailment': 0.49483497589826586, 'gold_entailment': 0.2790159705807181, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6915887850467289, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.5896414342629482, 'pegasus_entailment': 0.6116052567958832, 'gold_entailment': 0.5134633978207906, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2781954887218045, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.37373737373737365, 'pegasus_entailment': 0.8069819062948227, 'gold_entailment': 0.562969450528423, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42105263157894735, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5161290322580646, 'pegasus_entailment': 0.45717047809739597, 'gold_entailment': 0.1043025025477012, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43529411764705883, 'r1_recall': 0.4567901234567901, 'r1_f1': 0.4457831325301204, 'pegasus_entailment': 0.3351326098976036, 'gold_entailment': 0.1214962319645565, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 16}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5402298850574713, 'r1_recall': 0.4519230769230769, 'r1_f1': 0.49214659685863876, 'pegasus_entailment': 0.6541886428991953, 'gold_entailment': 0.616302140057087, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3008849557522124, 'r1_recall': 0.3953488372093023, 'r1_f1': 0.3417085427135678, 'pegasus_entailment': 0.4357873033732176, 'gold_entailment': 0.29490005150437354, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 22, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3534136546184739, 'r1_recall': 0.5641025641025641, 'r1_f1': 0.4345679012345679, 'pegasus_entailment': 0.5457244999706745, 'gold_entailment': 0.4125517872827394, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6260162601626016, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.5347222222222222, 'pegasus_entailment': 0.6071138282616934, 'gold_entailment': 0.4158506244421005, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43529411764705883, 'r1_recall': 0.6065573770491803, 'r1_f1': 0.5068493150684932, 'pegasus_entailment': 0.5521021974273026, 'gold_entailment': 0.4851773475529626, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 18}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5370370370370371, 'r1_recall': 0.58, 'r1_f1': 0.5576923076923077, 'pegasus_entailment': 0.7414882580439249, 'gold_entailment': 0.41309917469819385, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32098765432098764, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.41106719367588934, 'pegasus_entailment': 0.5106127460797628, 'gold_entailment': 0.20260049868375063, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6071428571428571, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.559670781893004, 'pegasus_entailment': 0.5555204749107361, 'gold_entailment': 0.3080955110490322, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40869565217391307, 'r1_recall': 0.5164835164835165, 'r1_f1': 0.45631067961165056, 'pegasus_entailment': 0.7398494124412537, 'gold_entailment': 0.4313918612897396, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3287671232876712, 'r1_recall': 0.6857142857142857, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.4439875949174166, 'gold_entailment': 0.41617411375045776, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3741496598639456, 'r1_recall': 0.7534246575342466, 'r1_f1': 0.5, 'pegasus_entailment': 0.7049635410308838, 'gold_entailment': 0.3223854328195254, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.352, 'r1_f1': 0.374468085106383, 'pegasus_entailment': 0.3241395130753517, 'gold_entailment': 0.06820030277594924, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.5526315789473685, 'r1_f1': 0.5575221238938053, 'pegasus_entailment': 0.3384713400155306, 'gold_entailment': 0.21651930436491967, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3433734939759036, 'r1_recall': 0.6404494382022472, 'r1_f1': 0.44705882352941173, 'pegasus_entailment': 0.5056167755808149, 'gold_entailment': 0.30615380592644215, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 17}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22058823529411764, 'r1_recall': 0.3488372093023256, 'r1_f1': 0.27027027027027023, 'pegasus_entailment': 0.41605519875884056, 'gold_entailment': 0.6204044967889786, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 11, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6772151898734177, 'r1_recall': 0.4841628959276018, 'r1_f1': 0.5646437994722955, 'pegasus_entailment': 0.5005088597536087, 'gold_entailment': 0.46828600640098256, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6301369863013699, 'pegasus_entailment': 0.9620340764522552, 'gold_entailment': 0.20556215631465116, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21100917431192662, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.31506849315068497, 'pegasus_entailment': 0.37340215779840946, 'gold_entailment': 0.14195217192173004, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 23, 'gold_ari': 30, 'gold_smog': 22}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3087248322147651, 'r1_recall': 0.5609756097560976, 'r1_f1': 0.39826839826839827, 'pegasus_entailment': 0.6795563280582428, 'gold_entailment': 0.6221201717853546, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 14, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3435897435897436, 'r1_recall': 0.6261682242990654, 'r1_f1': 0.44370860927152317, 'pegasus_entailment': 0.37561421575290815, 'gold_entailment': 0.3418553307652473, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2887700534759358, 'r1_recall': 0.75, 'r1_f1': 0.41698841698841693, 'pegasus_entailment': 0.7246039807796478, 'gold_entailment': 0.40916750331719715, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6578947368421053, 'r1_recall': 0.5681818181818182, 'r1_f1': 0.6097560975609756, 'pegasus_entailment': 0.5111315511167049, 'gold_entailment': 0.21223137056222185, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7313432835820896, 'r1_recall': 0.550561797752809, 'r1_f1': 0.6282051282051283, 'pegasus_entailment': 0.4239158183336258, 'gold_entailment': 0.46024508277575177, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2876712328767123, 'r1_recall': 0.711864406779661, 'r1_f1': 0.4097560975609756, 'pegasus_entailment': 0.4204851971298922, 'gold_entailment': 0.09280480972180764, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6086956521739131, 'r1_recall': 0.5656565656565656, 'r1_f1': 0.5863874345549738, 'pegasus_entailment': 0.7097718380391598, 'gold_entailment': 0.41423723474144936, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 27, 'gold_coleman_liau': 21, 'gold_ari': 34, 'gold_smog': 23}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44339622641509435, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.46534653465346537, 'pegasus_entailment': 0.8817660361528397, 'gold_entailment': 0.7657084316015244, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4676258992805755, 'r1_recall': 0.6914893617021277, 'r1_f1': 0.5579399141630901, 'pegasus_entailment': 0.7239193320274353, 'gold_entailment': 0.2498886790126562, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.935251798561151, 'r1_recall': 0.24904214559386972, 'r1_f1': 0.39334341906202724, 'pegasus_entailment': 0.6042165532708168, 'gold_entailment': 0.5441024252213538, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5894039735099338, 'r1_recall': 0.445, 'r1_f1': 0.5071225071225072, 'pegasus_entailment': 0.5345028409113487, 'gold_entailment': 0.3538168952282932, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2900763358778626, 'r1_recall': 0.48717948717948717, 'r1_f1': 0.36363636363636365, 'pegasus_entailment': 0.0946352229054485, 'gold_entailment': 0.06342596793547273, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5975609756097561, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.5240641711229946, 'pegasus_entailment': 0.51763414144516, 'gold_entailment': 0.611433457583189, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6972477064220184, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.6204081632653061, 'pegasus_entailment': 0.466560497879982, 'gold_entailment': 0.5192978878815969, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 25, 'gold_smog': 21}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42934782608695654, 'r1_recall': 0.6991150442477876, 'r1_f1': 0.531986531986532, 'pegasus_entailment': 0.6267152607440949, 'gold_entailment': 0.40948309501012164, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 18, 'gold_ari': 26, 'gold_smog': 24}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.64, 'r1_recall': 0.5647058823529412, 'r1_f1': 0.6000000000000001, 'pegasus_entailment': 0.3788183505336444, 'gold_entailment': 0.32802048822244007, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43023255813953487, 'r1_recall': 0.5606060606060606, 'r1_f1': 0.48684210526315785, 'pegasus_entailment': 0.4885625522583723, 'gold_entailment': 0.21223004907369614, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.569620253164557, 'r1_recall': 0.4891304347826087, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.5793258175253868, 'gold_entailment': 0.7248006363709768, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.4819277108433735, 'r1_f1': 0.4371584699453552, 'pegasus_entailment': 0.5791305601596832, 'gold_entailment': 0.3935668667157491, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.673469387755102, 'r1_recall': 0.5238095238095238, 'r1_f1': 0.5892857142857143, 'pegasus_entailment': 0.6231166154146195, 'gold_entailment': 0.6145972410837809, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.57, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.5643564356435642, 'pegasus_entailment': 0.5941494703292847, 'gold_entailment': 0.3382012148698171, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6056338028169014, 'r1_recall': 0.5341614906832298, 'r1_f1': 0.5676567656765676, 'pegasus_entailment': 0.5430236130952835, 'gold_entailment': 0.5509413719177246, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3855421686746988, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.45714285714285713, 'pegasus_entailment': 0.818808913230896, 'gold_entailment': 0.015305309556424618, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 15, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5654008438818565, 'r1_recall': 0.5929203539823009, 'r1_f1': 0.5788336933045356, 'pegasus_entailment': 0.454907956905663, 'gold_entailment': 0.47390027557100567, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 31, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40540540540540543, 'r1_recall': 0.5, 'r1_f1': 0.4477611940298507, 'pegasus_entailment': 0.113208650611341, 'gold_entailment': 0.06970329419709742, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 19, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5607476635514018, 'r1_recall': 0.594059405940594, 'r1_f1': 0.5769230769230769, 'pegasus_entailment': 0.7046860307455063, 'gold_entailment': 0.709111491839091, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 22}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3162393162393162, 'r1_recall': 0.7551020408163265, 'r1_f1': 0.4457831325301204, 'pegasus_entailment': 0.8129373788833618, 'gold_entailment': 0.47197216004133224, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.14285714285714285, 'r1_recall': 0.5, 'r1_f1': 0.22222222222222224, 'pegasus_entailment': 0.7653952687978745, 'gold_entailment': 0.24597783324619135, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5736434108527132, 'r1_recall': 0.5068493150684932, 'r1_f1': 0.5381818181818183, 'pegasus_entailment': 0.7966068685054779, 'gold_entailment': 0.470033744815737, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.4739583333333333, 'r1_f1': 0.5229885057471264, 'pegasus_entailment': 0.688457652926445, 'gold_entailment': 0.2965553005536397, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 23, 'gold_flesch_kincaid': 34, 'gold_coleman_liau': 22, 'gold_ari': 42, 'gold_smog': 27}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49411764705882355, 'r1_recall': 0.5675675675675675, 'r1_f1': 0.5283018867924529, 'pegasus_entailment': 0.6126361563801765, 'gold_entailment': 0.33680439181625843, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41818181818181815, 'r1_recall': 0.46464646464646464, 'r1_f1': 0.44019138755980863, 'pegasus_entailment': 0.4561115155617396, 'gold_entailment': 0.17230367908875147, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 23, 'pegasus_ari': 30, 'pegasus_smog': 24, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48514851485148514, 'r1_recall': 0.5903614457831325, 'r1_f1': 0.532608695652174, 'pegasus_entailment': 0.448513007722795, 'gold_entailment': 0.0969966563085715, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38095238095238093, 'r1_recall': 0.676056338028169, 'r1_f1': 0.4873096446700507, 'pegasus_entailment': 0.3329376397388322, 'gold_entailment': 0.4708811789751053, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 14, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 21, 'gold_ari': 28, 'gold_smog': 22}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5980392156862745, 'r1_recall': 0.5304347826086957, 'r1_f1': 0.5622119815668202, 'pegasus_entailment': 0.19891514480113984, 'gold_entailment': 0.11063961265608668, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5922330097087378, 'r1_recall': 0.3630952380952381, 'r1_f1': 0.4501845018450184, 'pegasus_entailment': 0.2944875567087105, 'gold_entailment': 0.361225243125643, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2, 'r1_recall': 0.4339622641509434, 'r1_f1': 0.2738095238095238, 'pegasus_entailment': 0.7070168256759644, 'gold_entailment': 0.12078769411891699, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4845360824742268, 'r1_recall': 0.4351851851851852, 'r1_f1': 0.4585365853658536, 'pegasus_entailment': 0.8895871837933859, 'gold_entailment': 0.20391795504838228, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 23, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5263157894736842, 'r1_recall': 0.4424778761061947, 'r1_f1': 0.4807692307692308, 'pegasus_entailment': 0.780542810757955, 'gold_entailment': 0.364722965285182, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3620689655172414, 'r1_recall': 0.5915492957746479, 'r1_f1': 0.4491978609625668, 'pegasus_entailment': 0.47822532430291176, 'gold_entailment': 0.5614807506402334, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49101796407185627, 'r1_recall': 0.3744292237442922, 'r1_f1': 0.4248704663212435, 'pegasus_entailment': 0.40427444204688073, 'gold_entailment': 0.383820455107424, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22784810126582278, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.3157894736842105, 'pegasus_entailment': 0.8817067344983419, 'gold_entailment': 0.6938924491405487, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 21, 'gold_flesch_kincaid': 9, 'gold_coleman_liau': 13, 'gold_ari': 9, 'gold_smog': 13}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6057692307692307, 'r1_recall': 0.7590361445783133, 'r1_f1': 0.6737967914438502, 'pegasus_entailment': 0.8419237732887268, 'gold_entailment': 0.7516689300537109, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4067796610169492, 'r1_recall': 0.4897959183673469, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.3468850329518318, 'gold_entailment': 0.1950661651790142, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5806451612903226, 'r1_recall': 0.6352941176470588, 'r1_f1': 0.6067415730337079, 'pegasus_entailment': 0.4668327954908212, 'gold_entailment': 0.4683189569041133, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 16, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6890756302521008, 'r1_recall': 0.6356589147286822, 'r1_f1': 0.6612903225806451, 'pegasus_entailment': 0.5892683118581772, 'gold_entailment': 0.5860727459192276, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 18}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4322033898305085, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.49756097560975604, 'pegasus_entailment': 0.7105352878570557, 'gold_entailment': 0.39479096233844757, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5079365079365079, 'r1_recall': 0.48120300751879697, 'r1_f1': 0.49420849420849416, 'pegasus_entailment': 0.7977589249610901, 'gold_entailment': 0.2461542603559792, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5423728813559322, 'r1_recall': 0.5765765765765766, 'r1_f1': 0.5589519650655022, 'pegasus_entailment': 0.16075385212898255, 'gold_entailment': 0.1530832452699542, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5875, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.5340909090909091, 'pegasus_entailment': 0.3766850898973644, 'gold_entailment': 0.17934280633926392, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 28, 'gold_coleman_liau': 20, 'gold_ari': 33, 'gold_smog': 28}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6902654867256637, 'r1_recall': 0.5571428571428572, 'r1_f1': 0.616600790513834, 'pegasus_entailment': 0.6810897037386894, 'gold_entailment': 0.5997754693031311, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40939597315436244, 'r1_recall': 0.4236111111111111, 'r1_f1': 0.41638225255972694, 'pegasus_entailment': 0.6686475078264872, 'gold_entailment': 0.42755897467335063, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.632183908045977, 'r1_recall': 0.5978260869565217, 'r1_f1': 0.6145251396648045, 'pegasus_entailment': 0.6972609013319016, 'gold_entailment': 0.23393024897086434, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.581081081081081, 'r1_recall': 0.4174757281553398, 'r1_f1': 0.48587570621468923, 'pegasus_entailment': 0.615912077948451, 'gold_entailment': 0.4376660879701376, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37209302325581395, 'r1_recall': 0.47761194029850745, 'r1_f1': 0.4183006535947712, 'pegasus_entailment': 0.5406750552356243, 'gold_entailment': 0.2765434585356464, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4909090909090909, 'r1_recall': 0.5934065934065934, 'r1_f1': 0.5373134328358209, 'pegasus_entailment': 0.8839104294776916, 'gold_entailment': 0.5161614641547203, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 17, 'gold_ari': 29, 'gold_smog': 21}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6239316239316239, 'r1_recall': 0.5104895104895105, 'r1_f1': 0.5615384615384617, 'pegasus_entailment': 0.6604979634284973, 'gold_entailment': 0.28219225639477374, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6262626262626263, 'r1_recall': 0.5081967213114754, 'r1_f1': 0.5610859728506787, 'pegasus_entailment': 0.42296793311834335, 'gold_entailment': 0.347453810274601, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6517857142857143, 'r1_recall': 0.4397590361445783, 'r1_f1': 0.5251798561151079, 'pegasus_entailment': 0.3389860957860947, 'gold_entailment': 0.3915687263011932, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5507246376811594, 'r1_recall': 0.6909090909090909, 'r1_f1': 0.6129032258064516, 'pegasus_entailment': 0.23103238300730786, 'gold_entailment': 0.05040660931263119, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42105263157894735, 'r1_recall': 0.6486486486486487, 'r1_f1': 0.5106382978723405, 'pegasus_entailment': 0.47034930903464556, 'gold_entailment': 0.22660833969712257, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6326530612244898, 'r1_recall': 0.45588235294117646, 'r1_f1': 0.5299145299145299, 'pegasus_entailment': 0.8514506459236145, 'gold_entailment': 0.5134935312800937, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 21}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6733333333333333, 'r1_recall': 0.4675925925925926, 'r1_f1': 0.5519125683060109, 'pegasus_entailment': 0.5302981100976467, 'gold_entailment': 0.2667830880964175, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5607476635514018, 'r1_recall': 0.49586776859504134, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.40714678168296814, 'gold_entailment': 0.2104253532985846, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6507936507936508, 'r1_recall': 0.5734265734265734, 'r1_f1': 0.6096654275092936, 'pegasus_entailment': 0.27045184342811507, 'gold_entailment': 0.2679916364806039, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4766355140186916, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.5257731958762886, 'pegasus_entailment': 0.904844323794047, 'gold_entailment': 0.6752299120028814, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33663366336633666, 'r1_recall': 0.7472527472527473, 'r1_f1': 0.4641638225255973, 'pegasus_entailment': 0.8180527091026306, 'gold_entailment': 0.4372362007076542, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 20, 'pegasus_ari': 34, 'pegasus_smog': 24, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43410852713178294, 'r1_recall': 0.5490196078431373, 'r1_f1': 0.48484848484848486, 'pegasus_entailment': 0.2711918268352747, 'gold_entailment': 0.22105926414951682, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 15, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5357142857142857, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.21198144368827343, 'gold_entailment': 0.1052451857055227, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 24, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7017543859649122, 'r1_recall': 0.40404040404040403, 'r1_f1': 0.5128205128205128, 'pegasus_entailment': 0.24543481692671776, 'gold_entailment': 0.19042814783751966, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3368421052631579, 'r1_recall': 0.3595505617977528, 'r1_f1': 0.34782608695652173, 'pegasus_entailment': 0.5907532125711441, 'gold_entailment': 0.5516887530684471, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7211538461538461, 'r1_recall': 0.4601226993865031, 'r1_f1': 0.5617977528089888, 'pegasus_entailment': 0.3592535872012377, 'gold_entailment': 0.3285668392976125, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6078431372549019, 'r1_recall': 0.34065934065934067, 'r1_f1': 0.43661971830985913, 'pegasus_entailment': 0.4683259390294552, 'gold_entailment': 0.3943267799913883, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7954545454545454, 'r1_recall': 0.2545454545454545, 'r1_f1': 0.3856749311294766, 'pegasus_entailment': 0.24319838359951973, 'gold_entailment': 0.22338404092523786, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.5504587155963303, 'r1_f1': 0.48192771084337344, 'pegasus_entailment': 0.6738460138440132, 'gold_entailment': 0.682251513004303, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 29, 'gold_coleman_liau': 21, 'gold_ari': 36, 'gold_smog': 26}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19811320754716982, 'r1_recall': 0.3620689655172414, 'r1_f1': 0.25609756097560976, 'pegasus_entailment': 0.46135734766721725, 'gold_entailment': 0.5682575106620789, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 15, 'gold_smog': 15}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6266666666666667, 'r1_recall': 0.2596685082872928, 'r1_f1': 0.3671875, 'pegasus_entailment': 0.596230814854304, 'gold_entailment': 0.25041912496089935, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 17}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28125, 'r1_recall': 0.5844155844155844, 'r1_f1': 0.37974683544303794, 'pegasus_entailment': 0.5533402800559998, 'gold_entailment': 0.4478014186024666, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39436619718309857, 'r1_recall': 0.7, 'r1_f1': 0.5045045045045045, 'pegasus_entailment': 0.5491376556456089, 'gold_entailment': 0.3254823461174965, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6292134831460674, 'r1_recall': 0.6021505376344086, 'r1_f1': 0.6153846153846154, 'pegasus_entailment': 0.7965782359242439, 'gold_entailment': 0.27453804831020534, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.654320987654321, 'r1_f1': 0.4416666666666667, 'pegasus_entailment': 0.308673994615674, 'gold_entailment': 0.26193892024457455, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35833333333333334, 'r1_recall': 0.4777777777777778, 'r1_f1': 0.40952380952380957, 'pegasus_entailment': 0.20282562674644092, 'gold_entailment': 0.16501388256438076, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 15, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2653061224489796, 'r1_recall': 0.37681159420289856, 'r1_f1': 0.31137724550898205, 'pegasus_entailment': 0.4143473831936717, 'gold_entailment': 0.09620473627001047, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 11, 'gold_coleman_liau': 14, 'gold_ari': 13, 'gold_smog': 15}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38666666666666666, 'r1_recall': 0.6041666666666666, 'r1_f1': 0.4715447154471545, 'pegasus_entailment': 0.3155415877699852, 'gold_entailment': 0.5355753810144961, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3888888888888889, 'r1_recall': 0.546875, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.18169837165623903, 'gold_entailment': 0.1330608675877253, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3151515151515151, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.40624999999999994, 'pegasus_entailment': 0.6681450208028158, 'gold_entailment': 0.2678331434726715, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 19, 'pegasus_ari': 35, 'pegasus_smog': 25, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.410958904109589, 'r1_recall': 0.6818181818181818, 'r1_f1': 0.5128205128205128, 'pegasus_entailment': 0.6296381533145905, 'gold_entailment': 0.3203612625598907, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 21, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33766233766233766, 'r1_recall': 0.8387096774193549, 'r1_f1': 0.4814814814814815, 'pegasus_entailment': 0.5219065588898957, 'gold_entailment': 0.15059137297794223, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 15, 'gold_smog': 17}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5161290322580645, 'r1_recall': 0.7476635514018691, 'r1_f1': 0.6106870229007633, 'pegasus_entailment': 0.45285505056381226, 'gold_entailment': 0.274391021206975, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.367816091954023, 'r1_recall': 0.5079365079365079, 'r1_f1': 0.42666666666666664, 'pegasus_entailment': 0.5665963316336274, 'gold_entailment': 0.3084476888179779, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 18}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6258503401360545, 'r1_recall': 0.3471698113207547, 'r1_f1': 0.44660194174757284, 'pegasus_entailment': 0.4804023529092471, 'gold_entailment': 0.38931646943092346, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 17, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23741007194244604, 'r1_recall': 0.515625, 'r1_f1': 0.32512315270935965, 'pegasus_entailment': 0.5180015861988068, 'gold_entailment': 0.4917273670434952, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 19}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36, 'r1_recall': 0.391304347826087, 'r1_f1': 0.37499999999999994, 'pegasus_entailment': 0.7970127016305923, 'gold_entailment': 0.5962326377630234, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 22, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5309734513274337, 'r1_recall': 0.6, 'r1_f1': 0.5633802816901409, 'pegasus_entailment': 0.463740274310112, 'gold_entailment': 0.3709367960691452, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 18, 'gold_flesch_kincaid': 27, 'gold_coleman_liau': 18, 'gold_ari': 32, 'gold_smog': 24}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.4142857142857143, 'r1_f1': 0.453125, 'pegasus_entailment': 0.5003923639655113, 'gold_entailment': 0.5594767034053802, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 17, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5125, 'r1_recall': 0.43617021276595747, 'r1_f1': 0.47126436781609193, 'pegasus_entailment': 0.39241076335310937, 'gold_entailment': 0.25764474521080655, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4338235294117647, 'r1_recall': 0.4645669291338583, 'r1_f1': 0.44866920152091255, 'pegasus_entailment': 0.7338042248040437, 'gold_entailment': 0.2558267756830901, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36363636363636365, 'r1_recall': 0.4507042253521127, 'r1_f1': 0.40251572327044033, 'pegasus_entailment': 0.9140934199094772, 'gold_entailment': 0.0324706481769681, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 23}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40425531914893614, 'r1_recall': 0.6063829787234043, 'r1_f1': 0.4851063829787234, 'pegasus_entailment': 0.39520569145679474, 'gold_entailment': 0.2473367303609848, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45918367346938777, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.49450549450549447, 'pegasus_entailment': 0.49284169264137745, 'gold_entailment': 0.4142226353287697, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46078431372549017, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.5340909090909092, 'pegasus_entailment': 0.31159678963012993, 'gold_entailment': 0.23467694036662579, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 13, 'gold_smog': 15}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4523809523809524, 'r1_recall': 0.5671641791044776, 'r1_f1': 0.5033112582781457, 'pegasus_entailment': 0.5754340688387553, 'gold_entailment': 0.6108939349651337, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 25, 'gold_smog': 21}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32710280373831774, 'r1_recall': 0.546875, 'r1_f1': 0.40935672514619886, 'pegasus_entailment': 0.5939240083098412, 'gold_entailment': 0.5735413432121277, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49324324324324326, 'r1_recall': 0.42196531791907516, 'r1_f1': 0.45482866043613707, 'pegasus_entailment': 0.6805567038910729, 'gold_entailment': 0.5312270628554481, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6448598130841121, 'r1_recall': 0.41818181818181815, 'r1_f1': 0.5073529411764705, 'pegasus_entailment': 0.5150900483131409, 'gold_entailment': 0.27409292245283723, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6941176470588235, 'r1_recall': 0.6020408163265306, 'r1_f1': 0.6448087431693988, 'pegasus_entailment': 0.5036765271797776, 'gold_entailment': 0.5668495271820575, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 16, 'pegasus_ari': 27, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5202702702702703, 'r1_recall': 0.4117647058823529, 'r1_f1': 0.45970149253731346, 'pegasus_entailment': 0.3335065692663193, 'gold_entailment': 0.16268663108348846, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4536082474226804, 'r1_recall': 0.4631578947368421, 'r1_f1': 0.45833333333333326, 'pegasus_entailment': 0.05501187569461763, 'gold_entailment': 0.23660295041433224, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4083333333333333, 'r1_recall': 0.6805555555555556, 'r1_f1': 0.5104166666666666, 'pegasus_entailment': 0.6565840418140093, 'gold_entailment': 0.43387224276860553, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 30, 'pegasus_smog': 23, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1782178217821782, 'r1_recall': 0.32727272727272727, 'r1_f1': 0.23076923076923075, 'pegasus_entailment': 0.6031137928366661, 'gold_entailment': 0.0739024356007576, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2074074074074074, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.3163841807909604, 'pegasus_entailment': 0.5742225144058466, 'gold_entailment': 0.647544264793396, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43157894736842106, 'r1_recall': 0.5774647887323944, 'r1_f1': 0.4939759036144578, 'pegasus_entailment': 0.6189037651056424, 'gold_entailment': 0.30830344930291176, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 15}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36046511627906974, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.4492753623188406, 'pegasus_entailment': 0.4594225753098726, 'gold_entailment': 0.37678176164627075, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.4188034188034188, 'r1_f1': 0.4414414414414415, 'pegasus_entailment': 0.36486006947234273, 'gold_entailment': 0.12309609251096845, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6283185840707964, 'r1_recall': 0.5419847328244275, 'r1_f1': 0.5819672131147541, 'pegasus_entailment': 0.44732254184782505, 'gold_entailment': 0.2847847950955232, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5263157894736842, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.5586592178770949, 'pegasus_entailment': 0.5608211711514741, 'gold_entailment': 0.2260827108596762, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5597014925373134, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.4777070063694267, 'pegasus_entailment': 0.5713464140892028, 'gold_entailment': 0.3337388758858045, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5308056872037915, 'pegasus_entailment': 0.33102769986726344, 'gold_entailment': 0.42708516617616016, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4672131147540984, 'r1_recall': 0.5181818181818182, 'r1_f1': 0.49137931034482757, 'pegasus_entailment': 0.53441097214818, 'gold_entailment': 0.3546060845255852, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5137614678899083, 'r1_recall': 0.6086956521739131, 'r1_f1': 0.5572139303482587, 'pegasus_entailment': 0.5978433092435201, 'gold_entailment': 0.36207106802612543, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3983050847457627, 'r1_recall': 0.47, 'r1_f1': 0.4311926605504587, 'pegasus_entailment': 0.7795324921607971, 'gold_entailment': 0.7059247344732285, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 20, 'gold_smog': 21}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32038834951456313, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.3837209302325582, 'pegasus_entailment': 0.822136826813221, 'gold_entailment': 0.042697695549577475, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48598130841121495, 'r1_recall': 0.5977011494252874, 'r1_f1': 0.5360824742268042, 'pegasus_entailment': 0.8651788036028544, 'gold_entailment': 0.5504623651504517, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 18, 'gold_ari': 29, 'gold_smog': 20}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5537190082644629, 'r1_recall': 0.6568627450980392, 'r1_f1': 0.6008968609865472, 'pegasus_entailment': 0.7818095286687216, 'gold_entailment': 0.49091561883687973, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 23, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4297520661157025, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.5073170731707317, 'pegasus_entailment': 0.5124848112463951, 'gold_entailment': 0.31659936904907227, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.208, 'r1_recall': 0.5, 'r1_f1': 0.2937853107344633, 'pegasus_entailment': 0.5631636708974839, 'gold_entailment': 0.24063342002530894, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5612244897959183, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.45643153526970953, 'pegasus_entailment': 0.6546362116932869, 'gold_entailment': 0.569461053609848, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4296875, 'r1_recall': 0.632183908045977, 'r1_f1': 0.5116279069767442, 'pegasus_entailment': 0.26799532026052475, 'gold_entailment': 0.2231418564915657, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 22, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 20, 'gold_ari': 31, 'gold_smog': 24}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4153846153846154, 'r1_recall': 0.5, 'r1_f1': 0.453781512605042, 'pegasus_entailment': 0.6649755040804545, 'gold_entailment': 0.3185800868086517, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4129032258064516, 'r1_recall': 0.5289256198347108, 'r1_f1': 0.463768115942029, 'pegasus_entailment': 0.5115553677082062, 'gold_entailment': 0.4658358118363789, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4305555555555556, 'r1_recall': 0.2980769230769231, 'r1_f1': 0.3522727272727273, 'pegasus_entailment': 0.3176162876188755, 'gold_entailment': 0.055620395888884865, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5362318840579711, 'r1_recall': 0.5285714285714286, 'r1_f1': 0.5323741007194245, 'pegasus_entailment': 0.7025187412897745, 'gold_entailment': 0.6810179849465688, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2582781456953642, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.34977578475336324, 'pegasus_entailment': 0.854777971903483, 'gold_entailment': 0.2654717544404169, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 24, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 23, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5730337078651685, 'r1_recall': 0.5730337078651685, 'r1_f1': 0.5730337078651685, 'pegasus_entailment': 0.39690743945539, 'gold_entailment': 0.40812284126877785, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23376623376623376, 'r1_recall': 0.4, 'r1_f1': 0.29508196721311475, 'pegasus_entailment': 0.42175460420548916, 'gold_entailment': 0.029046474490314722, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 15, 'pegasus_ari': 24, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 13, 'gold_smog': 14}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5121951219512195, 'r1_recall': 0.6116504854368932, 'r1_f1': 0.5575221238938053, 'pegasus_entailment': 0.5621548414230346, 'gold_entailment': 0.35991270840168, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.09090909090909091, 'r1_recall': 0.4, 'r1_f1': 0.14814814814814814, 'pegasus_entailment': 0.538336917757988, 'gold_entailment': 0.3291983865201473, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 14}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.4752475247524753, 'pegasus_entailment': 0.6735477894544601, 'gold_entailment': 0.38239416666328907, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 20}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2543859649122807, 'r1_recall': 0.7435897435897436, 'r1_f1': 0.3790849673202614, 'pegasus_entailment': 0.7352018840610981, 'gold_entailment': 0.9853993058204651, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5647058823529412, 'r1_recall': 0.32432432432432434, 'r1_f1': 0.4120171673819743, 'pegasus_entailment': 0.35761159658432007, 'gold_entailment': 0.2105733464871134, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5754716981132075, 'r1_recall': 0.5304347826086957, 'r1_f1': 0.5520361990950227, 'pegasus_entailment': 0.9463396966457367, 'gold_entailment': 0.5669945493340492, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3525641025641026, 'r1_recall': 0.5729166666666666, 'r1_f1': 0.43650793650793657, 'pegasus_entailment': 0.38645248115062714, 'gold_entailment': 0.10255175119770381, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 23, 'gold_smog': 17}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6363636363636364, 'r1_recall': 0.5779816513761468, 'r1_f1': 0.6057692307692307, 'pegasus_entailment': 0.4083650171756744, 'gold_entailment': 0.312678004304568, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6388888888888888, 'r1_recall': 0.5, 'r1_f1': 0.5609756097560975, 'pegasus_entailment': 0.5443898504599929, 'gold_entailment': 0.27103747334331274, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 17}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8651685393258427, 'r1_recall': 0.21875, 'r1_f1': 0.3492063492063492, 'pegasus_entailment': 0.6374139590188861, 'gold_entailment': 0.4598361019577299, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4015151515151515, 'r1_recall': 0.4774774774774775, 'r1_f1': 0.43621399176954734, 'pegasus_entailment': 0.711170324257442, 'gold_entailment': 0.6340701162815094, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6233766233766234, 'r1_recall': 0.3221476510067114, 'r1_f1': 0.42477876106194684, 'pegasus_entailment': 0.6643380969762802, 'gold_entailment': 0.33112673163414, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7209302325581395, 'r1_recall': 0.4161073825503356, 'r1_f1': 0.5276595744680851, 'pegasus_entailment': 0.7100167691707611, 'gold_entailment': 0.705031442642212, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 13, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2786885245901639, 'r1_recall': 0.3469387755102041, 'r1_f1': 0.3090909090909091, 'pegasus_entailment': 0.33462226390838623, 'gold_entailment': 0.5220200717449188, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 19, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4132231404958678, 'r1_recall': 0.6944444444444444, 'r1_f1': 0.5181347150259067, 'pegasus_entailment': 0.5476490706205368, 'gold_entailment': 0.40603379905223846, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3096774193548387, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.4067796610169492, 'pegasus_entailment': 0.405851025134325, 'gold_entailment': 0.29830346753199893, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.762962962962963, 'r1_recall': 0.6866666666666666, 'r1_f1': 0.7228070175438596, 'pegasus_entailment': 0.502617295521001, 'gold_entailment': 0.47936743795871734, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43434343434343436, 'r1_recall': 0.6417910447761194, 'r1_f1': 0.5180722891566265, 'pegasus_entailment': 0.44455485604703426, 'gold_entailment': 0.07090111635625362, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 20}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851063829787234, 'r1_recall': 0.6395348837209303, 'r1_f1': 0.6111111111111112, 'pegasus_entailment': 0.7395394206047058, 'gold_entailment': 0.3346955570547531, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38524590163934425, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.4795918367346938, 'pegasus_entailment': 0.7704614996910095, 'gold_entailment': 0.7705883085727692, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 28, 'gold_smog': 24}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5217391304347826, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.48, 'pegasus_entailment': 0.8096733490626017, 'gold_entailment': 0.6366370419661204, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 22}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5698924731182796, 'r1_recall': 0.375886524822695, 'r1_f1': 0.452991452991453, 'pegasus_entailment': 0.616427555680275, 'gold_entailment': 0.57144362727801, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 19, 'gold_ari': 26, 'gold_smog': 23}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2616279069767442, 'r1_recall': 0.6870229007633588, 'r1_f1': 0.37894736842105264, 'pegasus_entailment': 0.6032745639483134, 'gold_entailment': 0.37712031540771324, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 33, 'pegasus_smog': 25, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5818181818181818, 'r1_recall': 0.4507042253521127, 'r1_f1': 0.5079365079365079, 'pegasus_entailment': 0.6065057069063187, 'gold_entailment': 0.5980380347796849, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 23, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5393258426966293, 'pegasus_entailment': 0.9374534785747528, 'gold_entailment': 0.298493883262078, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 24, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.367816091954023, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.6281761825084686, 'gold_entailment': 0.4943763851188123, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 24, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6382978723404256, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.5604746267199516, 'gold_entailment': 0.359744131565094, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6303030303030303, 'r1_recall': 0.34210526315789475, 'r1_f1': 0.4434968017057569, 'pegasus_entailment': 0.5943877995014191, 'gold_entailment': 0.21861272491514683, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2204724409448819, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.29473684210526313, 'pegasus_entailment': 0.5179110914468765, 'gold_entailment': 0.38893143522242707, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 11, 'gold_coleman_liau': 15, 'gold_ari': 12, 'gold_smog': 16}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35555555555555557, 'r1_recall': 0.6736842105263158, 'r1_f1': 0.4654545454545455, 'pegasus_entailment': 0.5424168209234873, 'gold_entailment': 0.23273458459880203, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6808510638297872, 'r1_recall': 0.4050632911392405, 'r1_f1': 0.5079365079365079, 'pegasus_entailment': 0.5256333807483315, 'gold_entailment': 0.48381292819976807, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3076923076923077, 'r1_recall': 0.41379310344827586, 'r1_f1': 0.35294117647058826, 'pegasus_entailment': 0.41848411336541175, 'gold_entailment': 0.22208488592877984, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7638888888888888, 'r1_recall': 0.30386740331491713, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.42523420602083206, 'gold_entailment': 0.33659833752446705, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.4225352112676056, 'r1_f1': 0.47619047619047616, 'pegasus_entailment': 0.563409103701512, 'gold_entailment': 0.14822833737707697, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43137254901960786, 'r1_recall': 0.4631578947368421, 'r1_f1': 0.4467005076142132, 'pegasus_entailment': 0.5023513436317444, 'gold_entailment': 0.16808209009468555, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6020408163265306, 'r1_recall': 0.3430232558139535, 'r1_f1': 0.437037037037037, 'pegasus_entailment': 0.7113199383020401, 'gold_entailment': 0.5804830528795719, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47126436781609193, 'r1_recall': 0.5774647887323944, 'r1_f1': 0.5189873417721519, 'pegasus_entailment': 0.5303116559982299, 'gold_entailment': 0.3049267878135045, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7333333333333333, 'r1_recall': 0.2644230769230769, 'r1_f1': 0.3886925795053003, 'pegasus_entailment': 0.7814111113548279, 'gold_entailment': 0.6673712246119976, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 19}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40268456375838924, 'r1_recall': 0.6451612903225806, 'r1_f1': 0.49586776859504134, 'pegasus_entailment': 0.7751800537109375, 'gold_entailment': 0.44503366500139235, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39655172413793105, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.4816753926701571, 'pegasus_entailment': 0.5255487179383636, 'gold_entailment': 0.2099466621875763, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48514851485148514, 'r1_recall': 0.6901408450704225, 'r1_f1': 0.5697674418604651, 'pegasus_entailment': 0.5260464770253748, 'gold_entailment': 0.09788094185447942, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5301204819277109, 'r1_recall': 0.43564356435643564, 'r1_f1': 0.4782608695652174, 'pegasus_entailment': 0.4756608363240957, 'gold_entailment': 0.3044598922133446, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6967213114754098, 'r1_recall': 0.4106280193236715, 'r1_f1': 0.5167173252279635, 'pegasus_entailment': 0.7188791275024414, 'gold_entailment': 0.43964487065871555, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39097744360902253, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.4425531914893617, 'pegasus_entailment': 0.6978340347607931, 'gold_entailment': 0.4419879138469696, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3, 'r1_recall': 0.4, 'r1_f1': 0.34285714285714286, 'pegasus_entailment': 0.3303643986582756, 'gold_entailment': 0.3868693709373474, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 18}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4271356783919598, 'r1_recall': 0.47752808988764045, 'r1_f1': 0.4509283819628647, 'pegasus_entailment': 0.8528198003768921, 'gold_entailment': 0.5138355136538545, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 33, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5882352941176471, 'r1_recall': 0.547945205479452, 'r1_f1': 0.5673758865248226, 'pegasus_entailment': 0.4537524878978729, 'gold_entailment': 0.2963012382388115, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44761904761904764, 'r1_recall': 0.618421052631579, 'r1_f1': 0.5193370165745856, 'pegasus_entailment': 0.3181113596074283, 'gold_entailment': 0.6093170940876007, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 17}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5698924731182796, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.5760869565217391, 'pegasus_entailment': 0.4741951674222946, 'gold_entailment': 0.46453017741441727, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 14, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4838709677419355, 'r1_recall': 0.625, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.4669484317302704, 'gold_entailment': 0.34870303608477116, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 16}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.76, 'r1_recall': 0.16170212765957448, 'r1_f1': 0.26666666666666666, 'pegasus_entailment': 0.8152911265691122, 'gold_entailment': 0.4361045848239552, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.582089552238806, 'r1_recall': 0.5492957746478874, 'r1_f1': 0.5652173913043479, 'pegasus_entailment': 0.5908023218313853, 'gold_entailment': 0.5687469020485878, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8365384615384616, 'r1_recall': 0.47540983606557374, 'r1_f1': 0.6062717770034843, 'pegasus_entailment': 0.42466316372156143, 'gold_entailment': 0.36526453495025635, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43636363636363634, 'r1_recall': 0.5161290322580645, 'r1_f1': 0.4729064039408867, 'pegasus_entailment': 0.4304949749882023, 'gold_entailment': 0.18208953738212585, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 17, 'gold_ari': 30, 'gold_smog': 21}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6893203883495146, 'r1_recall': 0.6120689655172413, 'r1_f1': 0.6484018264840183, 'pegasus_entailment': 0.4802610632032156, 'gold_entailment': 0.6374240289442241, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.575, 'r1_recall': 0.7076923076923077, 'r1_f1': 0.6344827586206897, 'pegasus_entailment': 0.4300629520788789, 'gold_entailment': 0.029122572392225266, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 23}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.4012738853503185, 'r1_f1': 0.42424242424242425, 'pegasus_entailment': 0.45643903501331806, 'gold_entailment': 0.29728448018431664, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16551724137931034, 'r1_recall': 0.5, 'r1_f1': 0.24870466321243523, 'pegasus_entailment': 0.6642348617315292, 'gold_entailment': 0.18130562454462051, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4880952380952381, 'r1_recall': 0.422680412371134, 'r1_f1': 0.4530386740331492, 'pegasus_entailment': 0.9837111632029215, 'gold_entailment': 0.12387602793751284, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 22, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.12264150943396226, 'r1_recall': 0.37142857142857144, 'r1_f1': 0.18439716312056736, 'pegasus_entailment': 0.39196261391043663, 'gold_entailment': 0.2706492837751284, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 22, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5544554455445545, 'r1_recall': 0.5773195876288659, 'r1_f1': 0.5656565656565656, 'pegasus_entailment': 0.5776856616139412, 'gold_entailment': 0.4429062962299213, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.5575221238938053, 'r1_f1': 0.543103448275862, 'pegasus_entailment': 0.4961768090724945, 'gold_entailment': 0.48534930497407913, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6194690265486725, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.564516129032258, 'pegasus_entailment': 0.5379573325626552, 'gold_entailment': 0.09014320905165125, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21428571428571427, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.27631578947368424, 'pegasus_entailment': 0.4725279920268804, 'gold_entailment': 0.12715866789221764, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 22, 'gold_ari': 24, 'gold_smog': 23}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5176470588235295, 'r1_recall': 0.44, 'r1_f1': 0.47567567567567565, 'pegasus_entailment': 0.502842354006134, 'gold_entailment': 0.3927481472492218, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 25, 'gold_smog': 19}
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.09090909090909091
MEAN
0.49614463965394695
MAX
0.935251798561151
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.16170212765957448
MEAN
0.5199183241363002
MAX
0.8387096774193549
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.14814814814814814
MEAN
0.4841095531911738
MAX
0.7228070175438596
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.002802051545586437
MEAN
0.5468577120635669
MAX
0.989773690700531
** Analysing column: gold_entailment



gold_entailment
Length after nones removed
616
MIN
0.0008654110206407495
MEAN
0.37267368104078724
MAX
0.9853993058204651
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
17
MAX
35
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
13
MEAN
17
MAX
23
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
11
MEAN
20
MAX
43
/home/fsuser/dissertation/230731_fs_eval/GRAPHS.py:13: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax = plt.subplots(figsize=(20,20))
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
11
MEAN
18
MAX
29
** Analysing column: gold_flesch_kincaid



gold_flesch_kincaid
Length after nones removed
616
MIN
9
MEAN
17
MAX
38
** Analysing column: gold_coleman_liau



gold_coleman_liau
Length after nones removed
616
MIN
13
MEAN
18
MAX
25
** Analysing column: gold_ari



gold_ari
Length after nones removed
616
MIN
9
MEAN
20
MAX
46
** Analysing column: gold_smog



gold_smog
Length after nones removed
616
MIN
13
MEAN
19
MAX
30
{}
Entered file!
Imports done!
*** RUN *** 
eval_3d
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 14:17:02.151518: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 14:17:02.705473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/3d_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.452991452991453, 'r1_recall': 0.4818181818181818, 'r1_f1': 0.46696035242290745, 'pegasus_entailment': 0.7296104729175568, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5462962962962963, 'r1_recall': 0.34104046242774566, 'r1_f1': 0.4199288256227758, 'pegasus_entailment': 0.8104942291975021, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2748091603053435, 'r1_recall': 0.6206896551724138, 'r1_f1': 0.380952380952381, 'pegasus_entailment': 0.6762833197911581, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5538461538461539, 'r1_recall': 0.27906976744186046, 'r1_f1': 0.37113402061855666, 'pegasus_entailment': 0.7425490915775299, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.821917808219178, 'r1_recall': 0.3448275862068966, 'r1_f1': 0.48582995951417, 'pegasus_entailment': 0.6808921992778778, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5151515151515151, 'r1_recall': 0.3923076923076923, 'r1_f1': 0.4454148471615721, 'pegasus_entailment': 0.6303942240774632, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.15, 'r1_recall': 0.46875, 'r1_f1': 0.22727272727272727, 'pegasus_entailment': 0.5556291490793228, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.12121212121212122, 'r1_recall': 0.3870967741935484, 'r1_f1': 0.18461538461538463, 'pegasus_entailment': 0.8895091613133749, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5547445255474452, 'r1_recall': 0.5100671140939598, 'r1_f1': 0.5314685314685315, 'pegasus_entailment': 0.5077430009841919, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5121951219512195, 'r1_recall': 0.45652173913043476, 'r1_f1': 0.48275862068965514, 'pegasus_entailment': 0.3682744252229376, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6136363636363636, 'r1_recall': 0.36, 'r1_f1': 0.453781512605042, 'pegasus_entailment': 0.5499296933412552, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28634361233480177, 'r1_recall': 0.5462184873949579, 'r1_f1': 0.37572254335260113, 'pegasus_entailment': 0.459307380951941, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5211267605633803, 'r1_recall': 0.34579439252336447, 'r1_f1': 0.4157303370786517, 'pegasus_entailment': 0.367402787009875, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 14}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.6477272727272727, 'r1_f1': 0.5158371040723981, 'pegasus_entailment': 0.5289653152227402, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6282051282051282, 'r1_recall': 0.2552083333333333, 'r1_f1': 0.362962962962963, 'pegasus_entailment': 0.33071008045226336, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24528301886792453, 'r1_recall': 0.4406779661016949, 'r1_f1': 0.3151515151515151, 'pegasus_entailment': 0.5048170040051142, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2733333333333333, 'r1_recall': 0.41414141414141414, 'r1_f1': 0.3293172690763052, 'pegasus_entailment': 0.6659090697765351, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7894736842105263, 'r1_recall': 0.20134228187919462, 'r1_f1': 0.32085561497326204, 'pegasus_entailment': 0.44497637699047726, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.391304347826087, 'r1_f1': 0.4846153846153846, 'pegasus_entailment': 0.19701014955838522, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43157894736842106, 'r1_recall': 0.47126436781609193, 'r1_f1': 0.4505494505494505, 'pegasus_entailment': 0.763683557510376, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.3956043956043956, 'r1_f1': 0.4816053511705686, 'pegasus_entailment': 0.5210766106843948, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5333333333333333, 'r1_recall': 0.32, 'r1_f1': 0.4, 'pegasus_entailment': 0.41332136560231447, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.46296296296296297, 'r1_f1': 0.505050505050505, 'pegasus_entailment': 0.7834581931432089, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.41916167664670656, 'r1_recall': 0.5147058823529411, 'r1_f1': 0.46204620462046203, 'pegasus_entailment': 0.4325258235136668, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24468085106382978, 'r1_recall': 0.46, 'r1_f1': 0.3194444444444444, 'pegasus_entailment': 0.36696444600820544, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.751937984496124, 'r1_recall': 0.5132275132275133, 'r1_f1': 0.6100628930817611, 'pegasus_entailment': 0.8108319640159607, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 21}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5578947368421052, 'r1_recall': 0.38686131386861317, 'r1_f1': 0.4568965517241379, 'pegasus_entailment': 0.526767373085022, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6484375, 'r1_recall': 0.30970149253731344, 'r1_f1': 0.4191919191919192, 'pegasus_entailment': 0.36972617246210576, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44554455445544555, 'r1_recall': 0.5921052631578947, 'r1_f1': 0.5084745762711864, 'pegasus_entailment': 0.43301569297909737, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33548387096774196, 'r1_recall': 0.46017699115044247, 'r1_f1': 0.3880597014925373, 'pegasus_entailment': 0.8628777980804443, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3223684210526316, 'r1_recall': 0.5632183908045977, 'r1_f1': 0.41004184100418417, 'pegasus_entailment': 0.5606266967952251, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5104166666666666, 'r1_recall': 0.24378109452736318, 'r1_f1': 0.32996632996632996, 'pegasus_entailment': 0.4753386899828911, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3564356435643564, 'r1_recall': 0.34951456310679613, 'r1_f1': 0.35294117647058826, 'pegasus_entailment': 0.6365843365589777, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42105263157894735, 'r1_recall': 0.4948453608247423, 'r1_f1': 0.4549763033175355, 'pegasus_entailment': 0.6990611379345258, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31343283582089554, 'r1_recall': 0.5, 'r1_f1': 0.3853211009174312, 'pegasus_entailment': 0.5048946633934974, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42105263157894735, 'r1_recall': 0.41379310344827586, 'r1_f1': 0.4173913043478261, 'pegasus_entailment': 0.4824780863709748, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4857142857142857, 'r1_recall': 0.7391304347826086, 'r1_f1': 0.5862068965517241, 'pegasus_entailment': 0.7089571058750153, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 21, 'pegasus_ari': 36, 'pegasus_smog': 28}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2980132450331126, 'r1_recall': 0.6617647058823529, 'r1_f1': 0.410958904109589, 'pegasus_entailment': 0.6135639846324921, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22448979591836735, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.3076923076923077, 'pegasus_entailment': 0.3715767504181713, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5403225806451613, 'r1_recall': 0.4036144578313253, 'r1_f1': 0.46206896551724136, 'pegasus_entailment': 0.6205034032464027, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5120481927710844, 'r1_recall': 0.53125, 'r1_f1': 0.5214723926380368, 'pegasus_entailment': 0.5004202574491501, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37962962962962965, 'r1_recall': 0.5324675324675324, 'r1_f1': 0.44324324324324327, 'pegasus_entailment': 0.25967721295143875, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4044943820224719, 'r1_recall': 0.4931506849315068, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.482457130914554, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46808510638297873, 'r1_recall': 0.5365853658536586, 'r1_f1': 0.5, 'pegasus_entailment': 0.42933772057294844, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.3825136612021858, 'pegasus_entailment': 0.8241195797920227, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4700854700854701, 'r1_recall': 0.36666666666666664, 'r1_f1': 0.41198501872659177, 'pegasus_entailment': 0.7439350883165995, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 17}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5596330275229358, 'r1_recall': 0.5169491525423728, 'r1_f1': 0.5374449339207048, 'pegasus_entailment': 0.5073488384485245, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46956521739130436, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.47787610619469023, 'pegasus_entailment': 0.7107761383056641, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49504950495049505, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.5405405405405405, 'pegasus_entailment': 0.4241748775045077, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4, 'r1_recall': 0.5192307692307693, 'r1_f1': 0.4518828451882846, 'pegasus_entailment': 0.4870630204677582, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39805825242718446, 'r1_recall': 0.5540540540540541, 'r1_f1': 0.4632768361581921, 'pegasus_entailment': 0.5721572190523148, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.36363636363636365, 'pegasus_entailment': 0.5755782946944237, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34408602150537637, 'r1_recall': 0.43243243243243246, 'r1_f1': 0.3832335329341318, 'pegasus_entailment': 0.6173699448506037, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.09655172413793103, 'r1_recall': 0.07909604519774012, 'r1_f1': 0.08695652173913043, 'pegasus_entailment': 0.6433130204677582, 'pegasus_flesch_kincaid': 35, 'pegasus_coleman_liau': 19, 'pegasus_ari': 44, 'pegasus_smog': 26}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5895522388059702, 'r1_recall': 0.4438202247191011, 'r1_f1': 0.5064102564102564, 'pegasus_entailment': 0.2261183401569724, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.376, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.47715736040609136, 'pegasus_entailment': 0.651435598731041, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5050505050505051, 'r1_recall': 0.199203187250996, 'r1_f1': 0.28571428571428575, 'pegasus_entailment': 0.7333675175905228, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30927835051546393, 'r1_recall': 0.46875, 'r1_f1': 0.3726708074534162, 'pegasus_entailment': 0.5626148402690887, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6470588235294118, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.5339805825242718, 'pegasus_entailment': 0.5285998607675234, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3170731707317073, 'r1_recall': 0.49523809523809526, 'r1_f1': 0.3866171003717472, 'pegasus_entailment': 0.5412067733705044, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28402366863905326, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.3735408560311284, 'pegasus_entailment': 0.8348911702632904, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2740740740740741, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.357487922705314, 'pegasus_entailment': 0.4726611152291298, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6216216216216216, 'r1_recall': 0.27380952380952384, 'r1_f1': 0.38016528925619836, 'pegasus_entailment': 0.18345040579636893, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3867924528301887, 'r1_recall': 0.422680412371134, 'r1_f1': 0.40394088669950734, 'pegasus_entailment': 0.6923707835376263, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3008849557522124, 'r1_recall': 0.7083333333333334, 'r1_f1': 0.422360248447205, 'pegasus_entailment': 0.46096929609775544, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6146788990825688, 'r1_recall': 0.5275590551181102, 'r1_f1': 0.5677966101694915, 'pegasus_entailment': 0.7480721026659012, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4835164835164835, 'r1_recall': 0.41509433962264153, 'r1_f1': 0.4467005076142132, 'pegasus_entailment': 0.5921343192458153, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3923076923076923, 'r1_recall': 0.53125, 'r1_f1': 0.4513274336283186, 'pegasus_entailment': 0.5375052988529205, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45038167938931295, 'r1_recall': 0.5130434782608696, 'r1_f1': 0.4796747967479675, 'pegasus_entailment': 0.449872562289238, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7352941176470589, 'r1_recall': 0.24509803921568626, 'r1_f1': 0.3676470588235294, 'pegasus_entailment': 0.4345088005065918, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5371900826446281, 'r1_recall': 0.39156626506024095, 'r1_f1': 0.4529616724738676, 'pegasus_entailment': 0.9407915711402893, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18421052631578946, 'r1_recall': 0.10294117647058823, 'r1_f1': 0.1320754716981132, 'pegasus_entailment': 0.07242672145366669, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 15, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1981981981981982, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.2485875706214689, 'pegasus_entailment': 0.7499231894810995, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5660377358490566, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.5157593123209169, 'pegasus_entailment': 0.6731424480676651, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2796610169491525, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.34736842105263155, 'pegasus_entailment': 0.6926125188668569, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5934065934065934, 'r1_recall': 0.6352941176470588, 'r1_f1': 0.6136363636363635, 'pegasus_entailment': 0.5404153734445571, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2975206611570248, 'r1_recall': 0.5625, 'r1_f1': 0.38918918918918916, 'pegasus_entailment': 0.3985534782210986, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3870967741935484, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.496551724137931, 'pegasus_entailment': 0.3650090601295233, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.362962962962963, 'r1_recall': 0.5697674418604651, 'r1_f1': 0.4434389140271493, 'pegasus_entailment': 0.7115890920162201, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3305084745762712, 'r1_recall': 0.582089552238806, 'r1_f1': 0.42162162162162165, 'pegasus_entailment': 0.8241239935159683, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31451612903225806, 'r1_recall': 0.5, 'r1_f1': 0.38613861386138615, 'pegasus_entailment': 0.5877894933025042, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7272727272727273, 'r1_recall': 0.5436893203883495, 'r1_f1': 0.6222222222222222, 'pegasus_entailment': 0.38551707069079083, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26495726495726496, 'r1_recall': 0.47692307692307695, 'r1_f1': 0.34065934065934067, 'pegasus_entailment': 0.6814400305350622, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.294478527607362, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.384, 'pegasus_entailment': 0.5299329409996668, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 22, 'pegasus_ari': 37, 'pegasus_smog': 26}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4076923076923077, 'r1_recall': 0.5760869565217391, 'r1_f1': 0.4774774774774775, 'pegasus_entailment': 0.5914989213148752, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35294117647058826, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.4077669902912622, 'pegasus_entailment': 0.44093815609812737, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1774193548387097, 'r1_recall': 0.28205128205128205, 'r1_f1': 0.21782178217821782, 'pegasus_entailment': 0.6354042619466782, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2719298245614035, 'r1_recall': 0.6888888888888889, 'r1_f1': 0.389937106918239, 'pegasus_entailment': 0.6484917849302292, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7183098591549296, 'r1_recall': 0.24519230769230768, 'r1_f1': 0.3655913978494624, 'pegasus_entailment': 0.4322586723913749, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3076923076923077, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.36781609195402304, 'pegasus_entailment': 0.5669613420963288, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6025641025641025, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.5402298850574712, 'pegasus_entailment': 0.706926666200161, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 25}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.5149253731343284, 'r1_f1': 0.46779661016949153, 'pegasus_entailment': 0.7181894779205322, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35833333333333334, 'r1_recall': 0.589041095890411, 'r1_f1': 0.4455958549222798, 'pegasus_entailment': 0.5475587596495947, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47058823529411764, 'r1_recall': 0.47863247863247865, 'r1_f1': 0.4745762711864407, 'pegasus_entailment': 0.44526965320110323, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2727272727272727, 'r1_recall': 0.4329896907216495, 'r1_f1': 0.3346613545816733, 'pegasus_entailment': 0.717925488948822, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47093023255813954, 'r1_recall': 0.4576271186440678, 'r1_f1': 0.4641833810888252, 'pegasus_entailment': 0.5496900486094611, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4122137404580153, 'r1_recall': 0.5567010309278351, 'r1_f1': 0.4736842105263158, 'pegasus_entailment': 0.5840481562273843, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4236111111111111, 'r1_recall': 0.48412698412698413, 'r1_f1': 0.45185185185185184, 'pegasus_entailment': 0.6830300927162171, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2905982905982906, 'r1_recall': 0.5230769230769231, 'r1_f1': 0.37362637362637363, 'pegasus_entailment': 0.5308386236429214, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44565217391304346, 'r1_recall': 0.36607142857142855, 'r1_f1': 0.4019607843137254, 'pegasus_entailment': 0.7104179942980409, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.17751479289940827, 'r1_recall': 0.4918032786885246, 'r1_f1': 0.2608695652173913, 'pegasus_entailment': 0.6730005123785564, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35714285714285715, 'r1_recall': 0.425531914893617, 'r1_f1': 0.3883495145631068, 'pegasus_entailment': 0.6421816945075989, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5196850393700787, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.7606447398662567, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.475177304964539, 'r1_recall': 0.5982142857142857, 'r1_f1': 0.5296442687747035, 'pegasus_entailment': 0.6114844501018524, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4375, 'r1_recall': 0.6125, 'r1_f1': 0.5104166666666667, 'pegasus_entailment': 0.5234163701534271, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4863013698630137, 'r1_recall': 0.5503875968992248, 'r1_f1': 0.5163636363636362, 'pegasus_entailment': 0.6568351447582245, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3125, 'r1_recall': 0.6310679611650486, 'r1_f1': 0.41800643086816724, 'pegasus_entailment': 0.5709255884091059, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6333333333333333, 'r1_recall': 0.11875, 'r1_f1': 0.19999999999999998, 'pegasus_entailment': 0.17738641798496246, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 19, 'pegasus_smog': 14}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4857142857142857, 'r1_recall': 0.4533333333333333, 'r1_f1': 0.4689655172413793, 'pegasus_entailment': 0.4986675555507342, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3181818181818182, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4117647058823529, 'pegasus_entailment': 0.7340369820594788, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25609756097560976, 'r1_recall': 0.6086956521739131, 'r1_f1': 0.3605150214592275, 'pegasus_entailment': 0.4890533037483692, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5263157894736842, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.6555710658431053, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3028571428571429, 'r1_recall': 0.6708860759493671, 'r1_f1': 0.41732283464566927, 'pegasus_entailment': 0.7103840808073679, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4090909090909091, 'r1_recall': 0.6067415730337079, 'r1_f1': 0.4886877828054299, 'pegasus_entailment': 0.5478459432721138, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4819277108433735, 'r1_recall': 0.3076923076923077, 'r1_f1': 0.37558685446009393, 'pegasus_entailment': 0.487032026052475, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6637931034482759, 'r1_recall': 0.43258426966292135, 'r1_f1': 0.5238095238095238, 'pegasus_entailment': 0.5676081269979477, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6633663366336634, 'r1_recall': 0.3806818181818182, 'r1_f1': 0.483754512635379, 'pegasus_entailment': 0.3132822315674275, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5221238938053098, 'r1_recall': 0.44029850746268656, 'r1_f1': 0.4777327935222672, 'pegasus_entailment': 0.5220712162554264, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3888888888888889, 'r1_recall': 0.3723404255319149, 'r1_f1': 0.3804347826086956, 'pegasus_entailment': 0.5011689372360706, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6329113924050633, 'r1_recall': 0.3937007874015748, 'r1_f1': 0.48543689320388356, 'pegasus_entailment': 0.42666281908750536, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48936170212765956, 'r1_recall': 0.5227272727272727, 'r1_f1': 0.5054945054945055, 'pegasus_entailment': 0.7944252043962479, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 23, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26666666666666666, 'r1_recall': 0.06956521739130435, 'r1_f1': 0.1103448275862069, 'pegasus_entailment': 0.030488310381770134, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3211009174311927, 'r1_recall': 0.4605263157894737, 'r1_f1': 0.37837837837837834, 'pegasus_entailment': 0.6329360753297806, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1917808219178082, 'r1_recall': 0.6511627906976745, 'r1_f1': 0.2962962962962963, 'pegasus_entailment': 0.5088697125514349, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23270440251572327, 'r1_recall': 0.6607142857142857, 'r1_f1': 0.3441860465116279, 'pegasus_entailment': 0.7443707585334778, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.575, 'r1_recall': 0.5267175572519084, 'r1_f1': 0.5498007968127488, 'pegasus_entailment': 0.5858420670032501, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34615384615384615, 'r1_recall': 0.5625, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.5195885617285967, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5433070866141733, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.5655737704918032, 'pegasus_entailment': 0.6583363056182862, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4453125, 'r1_recall': 0.49137931034482757, 'r1_f1': 0.4672131147540983, 'pegasus_entailment': 0.7388230085372924, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1927710843373494, 'r1_recall': 0.5423728813559322, 'r1_f1': 0.28444444444444444, 'pegasus_entailment': 0.6821476705372334, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4857142857142857, 'r1_recall': 0.08994708994708994, 'r1_f1': 0.15178571428571427, 'pegasus_entailment': 0.10133828222751617, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5528455284552846, 'r1_recall': 0.5619834710743802, 'r1_f1': 0.5573770491803279, 'pegasus_entailment': 0.8738860011100769, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5764705882352941, 'r1_recall': 0.3161290322580645, 'r1_f1': 0.4083333333333333, 'pegasus_entailment': 0.7633835872014364, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4292682926829268, 'r1_recall': 0.5398773006134969, 'r1_f1': 0.4782608695652174, 'pegasus_entailment': 0.39567665904760363, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 25}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27184466019417475, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.36482084690553745, 'pegasus_entailment': 0.5568706807163026, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.423841059602649, 'r1_recall': 0.5289256198347108, 'r1_f1': 0.4705882352941177, 'pegasus_entailment': 0.236974308666374, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4166666666666667, 'r1_recall': 0.5376344086021505, 'r1_f1': 0.4694835680751174, 'pegasus_entailment': 0.46353981643915176, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4838709677419355, 'r1_recall': 0.11278195488721804, 'r1_f1': 0.18292682926829268, 'pegasus_entailment': 0.8278164863586426, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5258620689655172, 'r1_recall': 0.32972972972972975, 'r1_f1': 0.4053156146179402, 'pegasus_entailment': 0.3587086915969849, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.39655172413793105, 'r1_f1': 0.3066666666666667, 'pegasus_entailment': 0.5383249707520008, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4657534246575342, 'r1_recall': 0.38636363636363635, 'r1_f1': 0.422360248447205, 'pegasus_entailment': 0.4862709641456604, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.5161290322580645, 'r1_f1': 0.5303867403314917, 'pegasus_entailment': 0.42779335044324396, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48148148148148145, 'r1_recall': 0.34513274336283184, 'r1_f1': 0.40206185567010305, 'pegasus_entailment': 0.4321998618543148, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5268817204301075, 'r1_recall': 0.6125, 'r1_f1': 0.5664739884393064, 'pegasus_entailment': 0.5468026865273714, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 23, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47368421052631576, 'r1_recall': 0.44554455445544555, 'r1_f1': 0.45918367346938777, 'pegasus_entailment': 0.2790111154317856, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7079646017699115, 'r1_recall': 0.3827751196172249, 'r1_f1': 0.49689440993788814, 'pegasus_entailment': 0.8328346610069275, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.626984126984127, 'r1_recall': 0.43646408839779005, 'r1_f1': 0.5146579804560261, 'pegasus_entailment': 0.6847728192806244, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21897810218978103, 'r1_recall': 0.5084745762711864, 'r1_f1': 0.30612244897959184, 'pegasus_entailment': 0.6644143164157867, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.64, 'r1_recall': 0.2962962962962963, 'r1_f1': 0.4050632911392405, 'pegasus_entailment': 0.3772385244568189, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3884297520661157, 'r1_recall': 0.573170731707317, 'r1_f1': 0.4630541871921182, 'pegasus_entailment': 0.4565323293209076, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45544554455445546, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.467005076142132, 'pegasus_entailment': 0.4769060850143433, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5116279069767442, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.49438202247191015, 'pegasus_entailment': 0.3698021173477173, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6186440677966102, 'r1_recall': 0.37628865979381443, 'r1_f1': 0.46794871794871795, 'pegasus_entailment': 0.5279631884768605, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6486486486486487, 'r1_recall': 0.2891566265060241, 'r1_f1': 0.4, 'pegasus_entailment': 0.3985052816569805, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5324675324675324, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.6029411764705882, 'pegasus_entailment': 0.6347346206506094, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.4161849710982659, 'r1_f1': 0.4914675767918089, 'pegasus_entailment': 0.4688829034566879, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49333333333333335, 'r1_recall': 0.4567901234567901, 'r1_f1': 0.47435897435897434, 'pegasus_entailment': 0.4702818691730499, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.559322033898305, 'r1_recall': 0.4429530201342282, 'r1_f1': 0.4943820224719102, 'pegasus_entailment': 0.6836972832679749, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4122137404580153, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.48214285714285715, 'pegasus_entailment': 0.6750225871801376, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49572649572649574, 'r1_recall': 0.36024844720496896, 'r1_f1': 0.4172661870503597, 'pegasus_entailment': 0.7078497807184855, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2465753424657534, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.3243243243243243, 'pegasus_entailment': 0.852165699005127, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 23, 'pegasus_ari': 30, 'pegasus_smog': 26}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4014084507042254, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.456, 'pegasus_entailment': 0.7224539071321487, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42045454545454547, 'r1_recall': 0.3592233009708738, 'r1_f1': 0.38743455497382195, 'pegasus_entailment': 0.6716849058866501, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6237623762376238, 'r1_recall': 0.38650306748466257, 'r1_f1': 0.4772727272727272, 'pegasus_entailment': 0.7125743542398725, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3472222222222222, 'r1_recall': 0.45871559633027525, 'r1_f1': 0.3952569169960474, 'pegasus_entailment': 0.5790574729442597, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6036036036036037, 'r1_recall': 0.3806818181818182, 'r1_f1': 0.4668989547038328, 'pegasus_entailment': 0.8525155633687973, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49107142857142855, 'r1_recall': 0.36666666666666664, 'r1_f1': 0.4198473282442748, 'pegasus_entailment': 0.547780176003774, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5531914893617021, 'r1_recall': 0.37142857142857144, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.5736875399947167, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47706422018348627, 'r1_recall': 0.348993288590604, 'r1_f1': 0.4031007751937985, 'pegasus_entailment': 0.61720010638237, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.35664335664335667, 'r1_recall': 0.5604395604395604, 'r1_f1': 0.43589743589743596, 'pegasus_entailment': 0.6662983447313309, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27419354838709675, 'r1_recall': 0.44155844155844154, 'r1_f1': 0.3383084577114428, 'pegasus_entailment': 0.4989254713058472, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32786885245901637, 'r1_recall': 0.547945205479452, 'r1_f1': 0.4102564102564103, 'pegasus_entailment': 0.2909152880311012, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7372262773722628, 'r1_recall': 0.27445652173913043, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.5598242901265621, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3575418994413408, 'r1_recall': 0.5818181818181818, 'r1_f1': 0.4429065743944637, 'pegasus_entailment': 0.7764005859692892, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34, 'r1_recall': 0.4112903225806452, 'r1_f1': 0.3722627737226278, 'pegasus_entailment': 0.5114860355854034, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3872832369942196, 'r1_recall': 0.5583333333333333, 'r1_f1': 0.45733788395904434, 'pegasus_entailment': 0.7611515283584595, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47619047619047616, 'r1_recall': 0.2978723404255319, 'r1_f1': 0.36649214659685864, 'pegasus_entailment': 0.6968324154615402, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.28125, 'r1_recall': 0.05921052631578947, 'r1_f1': 0.09782608695652172, 'pegasus_entailment': 0.35217854380607605, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40625, 'r1_recall': 0.6046511627906976, 'r1_f1': 0.48598130841121495, 'pegasus_entailment': 0.7357776090502739, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27906976744186046, 'r1_recall': 0.48, 'r1_f1': 0.35294117647058815, 'pegasus_entailment': 0.8502203524112701, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37, 'r1_recall': 0.4111111111111111, 'r1_f1': 0.3894736842105263, 'pegasus_entailment': 0.5148711621761322, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6385542168674698, 'r1_recall': 0.3231707317073171, 'r1_f1': 0.42914979757085014, 'pegasus_entailment': 0.5959145903587342, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4723926380368098, 'r1_recall': 0.2682926829268293, 'r1_f1': 0.34222222222222226, 'pegasus_entailment': 0.7806395505155835, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6883116883116883, 'r1_recall': 0.29608938547486036, 'r1_f1': 0.4140625, 'pegasus_entailment': 0.6134298071265221, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4661016949152542, 'r1_recall': 0.4824561403508772, 'r1_f1': 0.4741379310344827, 'pegasus_entailment': 0.7454120367765427, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5126050420168067, 'r1_recall': 0.46923076923076923, 'r1_f1': 0.4899598393574297, 'pegasus_entailment': 0.3034320753067732, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.35, 'r1_recall': 0.47115384615384615, 'r1_f1': 0.4016393442622951, 'pegasus_entailment': 0.6678821682929993, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.5174129353233831, 'pegasus_entailment': 0.5781162208877504, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7096774193548387, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.5176470588235293, 'pegasus_entailment': 0.6373165895541509, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49411764705882355, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5185185185185186, 'pegasus_entailment': 0.39610952138900757, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.5128205128205129, 'pegasus_entailment': 0.4865333180253704, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47368421052631576, 'r1_recall': 0.6, 'r1_f1': 0.5294117647058824, 'pegasus_entailment': 0.5331951715052128, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.53, 'r1_recall': 0.4380165289256198, 'r1_f1': 0.4796380090497738, 'pegasus_entailment': 0.4940069106717904, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49612403100775193, 'r1_recall': 0.5765765765765766, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.6721354871988297, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4925373134328358, 'r1_recall': 0.4049079754601227, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.6565751135349274, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 26}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6354166666666666, 'r1_recall': 0.3465909090909091, 'r1_f1': 0.44852941176470595, 'pegasus_entailment': 0.3949599141875903, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4205607476635514, 'r1_recall': 0.5625, 'r1_f1': 0.4812834224598931, 'pegasus_entailment': 0.20865577831864357, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29069767441860467, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.3424657534246575, 'pegasus_entailment': 0.7851862708727518, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3372093023255814, 'r1_recall': 0.48333333333333334, 'r1_f1': 0.3972602739726028, 'pegasus_entailment': 0.5802171789109707, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39568345323741005, 'r1_recall': 0.5612244897959183, 'r1_f1': 0.4641350210970464, 'pegasus_entailment': 0.8297614097595215, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5285714285714286, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.5481481481481482, 'pegasus_entailment': 0.512443582713604, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2608695652173913, 'r1_recall': 0.5217391304347826, 'r1_f1': 0.3478260869565218, 'pegasus_entailment': 0.40821152925491333, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46078431372549017, 'r1_recall': 0.41228070175438597, 'r1_f1': 0.4351851851851852, 'pegasus_entailment': 0.5507958203554153, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29444444444444445, 'r1_recall': 0.4774774774774775, 'r1_f1': 0.3642611683848797, 'pegasus_entailment': 0.5854848442333085, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44385026737967914, 'r1_recall': 0.3789954337899543, 'r1_f1': 0.40886699507389157, 'pegasus_entailment': 0.4794778525829315, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4074074074074074, 'r1_recall': 0.5365853658536586, 'r1_f1': 0.4631578947368421, 'pegasus_entailment': 0.6885942816734314, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3081081081081081, 'r1_recall': 0.6477272727272727, 'r1_f1': 0.4175824175824176, 'pegasus_entailment': 0.6608763728290796, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4094488188976378, 'r1_recall': 0.5148514851485149, 'r1_f1': 0.456140350877193, 'pegasus_entailment': 0.448859678581357, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4351851851851852, 'r1_f1': 0.46534653465346537, 'pegasus_entailment': 0.4783617357412974, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1794871794871795, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.2745098039215686, 'pegasus_entailment': 0.6134362425655127, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5157894736842106, 'r1_recall': 0.494949494949495, 'r1_f1': 0.5051546391752577, 'pegasus_entailment': 0.5208682827651501, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 22}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4852941176470588, 'r1_recall': 0.4177215189873418, 'r1_f1': 0.4489795918367347, 'pegasus_entailment': 0.5100228960315386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5504587155963303, 'r1_recall': 0.379746835443038, 'r1_f1': 0.44943820224719105, 'pegasus_entailment': 0.4767592430114746, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6629213483146067, 'r1_recall': 0.30569948186528495, 'r1_f1': 0.41843971631205673, 'pegasus_entailment': 0.5923029750585556, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46296296296296297, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.4694835680751174, 'pegasus_entailment': 0.4353679120540619, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.448, 'r1_f1': 0.4890829694323144, 'pegasus_entailment': 0.3389626294374466, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2818181818181818, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.382716049382716, 'pegasus_entailment': 0.4259387910366058, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.5081967213114754, 'r1_f1': 0.40259740259740256, 'pegasus_entailment': 0.2682318054139614, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4146341463414634, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.4722222222222222, 'pegasus_entailment': 0.580700010061264, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.15384615384615385, 'r1_recall': 0.5423728813559322, 'r1_f1': 0.2397003745318352, 'pegasus_entailment': 0.5655870474874973, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3983050847457627, 'r1_recall': 0.41228070175438597, 'r1_f1': 0.4051724137931034, 'pegasus_entailment': 0.5906015386184057, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32941176470588235, 'r1_recall': 0.2828282828282828, 'r1_f1': 0.30434782608695654, 'pegasus_entailment': 0.40897978842258453, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24242424242424243, 'r1_recall': 0.6, 'r1_f1': 0.3453237410071942, 'pegasus_entailment': 0.4323601151506106, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5266666666666666, 'r1_recall': 0.45664739884393063, 'r1_f1': 0.4891640866873065, 'pegasus_entailment': 0.79862712820371, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.39705882352941174, 'r1_recall': 0.675, 'r1_f1': 0.5, 'pegasus_entailment': 0.4787945728749037, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5677966101694916, 'r1_recall': 0.37640449438202245, 'r1_f1': 0.45270270270270274, 'pegasus_entailment': 0.5714413672685623, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6509433962264151, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.5168539325842696, 'pegasus_entailment': 0.5677987227216363, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.632183908045977, 'r1_recall': 0.41044776119402987, 'r1_f1': 0.497737556561086, 'pegasus_entailment': 0.5853941105306149, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6410256410256411, 'r1_recall': 0.30864197530864196, 'r1_f1': 0.4166666666666667, 'pegasus_entailment': 0.41688785205284756, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4019607843137255, 'r1_recall': 0.5, 'r1_f1': 0.4456521739130435, 'pegasus_entailment': 0.38496283292770384, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5398230088495575, 'r1_recall': 0.40131578947368424, 'r1_f1': 0.46037735849056605, 'pegasus_entailment': 0.9031522125005722, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23333333333333334, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.3153153153153153, 'pegasus_entailment': 0.38797949879829374, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4628099173553719, 'r1_recall': 0.25112107623318386, 'r1_f1': 0.3255813953488372, 'pegasus_entailment': 0.70290363766253, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2926829268292683, 'r1_recall': 0.21238938053097345, 'r1_f1': 0.24615384615384617, 'pegasus_entailment': 0.3582110879942775, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3055555555555556, 'r1_recall': 0.717391304347826, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.5772921741008759, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6607142857142857, 'r1_recall': 0.20441988950276244, 'r1_f1': 0.3122362869198312, 'pegasus_entailment': 0.2962099015712738, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4550898203592814, 'r1_recall': 0.4293785310734463, 'r1_f1': 0.4418604651162791, 'pegasus_entailment': 0.5283807466427485, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44, 'r1_recall': 0.5729166666666666, 'r1_f1': 0.4977375565610859, 'pegasus_entailment': 0.6142178537944952, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43137254901960786, 'r1_recall': 0.45517241379310347, 'r1_f1': 0.4429530201342282, 'pegasus_entailment': 0.5606622497240702, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.16, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.25, 'pegasus_entailment': 0.5018989779055119, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.17721518987341772, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.2592592592592593, 'pegasus_entailment': 0.7448794543743134, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38202247191011235, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.4579124579124579, 'pegasus_entailment': 0.486340818926692, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 18, 'pegasus_ari': 37, 'pegasus_smog': 24}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1971153846153846, 'r1_recall': 0.5774647887323944, 'r1_f1': 0.2939068100358423, 'pegasus_entailment': 0.5956377825803227, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2716049382716049, 'r1_recall': 0.4, 'r1_f1': 0.3235294117647059, 'pegasus_entailment': 0.46346148662269115, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2755102040816326, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.3016759776536313, 'pegasus_entailment': 0.48749491572380066, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 11, 'pegasus_ari': 12, 'pegasus_smog': 14}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5084745762711864, 'r1_recall': 0.7407407407407407, 'r1_f1': 0.6030150753768845, 'pegasus_entailment': 0.2552589546889067, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49333333333333335, 'r1_recall': 0.4457831325301205, 'r1_f1': 0.4683544303797468, 'pegasus_entailment': 0.5815407385428747, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5308641975308642, 'r1_recall': 0.38738738738738737, 'r1_f1': 0.4479166666666667, 'pegasus_entailment': 0.2266738973557949, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7373737373737373, 'r1_recall': 0.21726190476190477, 'r1_f1': 0.335632183908046, 'pegasus_entailment': 0.40700519923120737, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5585585585585585, 'r1_recall': 0.27927927927927926, 'r1_f1': 0.37237237237237236, 'pegasus_entailment': 0.5079845388730367, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3008130081300813, 'r1_recall': 0.47435897435897434, 'r1_f1': 0.3681592039800995, 'pegasus_entailment': 0.7712350636720657, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.3076923076923077, 'r1_f1': 0.3636363636363637, 'pegasus_entailment': 0.19409624859690666, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3614457831325301, 'r1_recall': 0.410958904109589, 'r1_f1': 0.38461538461538464, 'pegasus_entailment': 0.5525447279214859, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3391304347826087, 'r1_recall': 0.6, 'r1_f1': 0.43333333333333335, 'pegasus_entailment': 0.45181107946804594, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2611464968152866, 'r1_recall': 0.5694444444444444, 'r1_f1': 0.3580786026200874, 'pegasus_entailment': 0.7092477440834045, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3884297520661157, 'r1_recall': 0.5802469135802469, 'r1_f1': 0.46534653465346537, 'pegasus_entailment': 0.40968044102191925, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25862068965517243, 'r1_recall': 0.5921052631578947, 'r1_f1': 0.36000000000000004, 'pegasus_entailment': 0.5754541337490082, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37168141592920356, 'r1_recall': 0.5, 'r1_f1': 0.4263959390862944, 'pegasus_entailment': 0.7932758703827858, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5486725663716814, 'r1_recall': 0.39490445859872614, 'r1_f1': 0.45925925925925926, 'pegasus_entailment': 0.4399439294356853, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.725, 'r1_recall': 0.4027777777777778, 'r1_f1': 0.5178571428571429, 'pegasus_entailment': 0.1799251526594162, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.375, 'r1_recall': 0.5425531914893617, 'r1_f1': 0.4434782608695652, 'pegasus_entailment': 0.7735954761505127, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.36649214659685864, 'r1_f1': 0.4651162790697675, 'pegasus_entailment': 0.3456770420074463, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.21710526315789475, 'r1_recall': 0.673469387755102, 'r1_f1': 0.32835820895522383, 'pegasus_entailment': 0.7109680324792862, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3548387096774194, 'r1_recall': 0.5301204819277109, 'r1_f1': 0.4251207729468599, 'pegasus_entailment': 0.7281151190400124, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5419354838709678, 'pegasus_entailment': 0.429520380217582, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 12}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23880597014925373, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.3404255319148936, 'pegasus_entailment': 0.5727211594581604, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7070707070707071, 'r1_recall': 0.5109489051094891, 'r1_f1': 0.5932203389830508, 'pegasus_entailment': 0.5548003676036993, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2413793103448276, 'r1_recall': 0.4772727272727273, 'r1_f1': 0.32061068702290074, 'pegasus_entailment': 0.7251284569501877, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23711340206185566, 'r1_recall': 0.3898305084745763, 'r1_f1': 0.2948717948717949, 'pegasus_entailment': 0.5119171266754469, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5660377358490566, 'r1_recall': 0.44776119402985076, 'r1_f1': 0.5, 'pegasus_entailment': 0.5932556316256523, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5470085470085471, 'r1_recall': 0.41025641025641024, 'r1_f1': 0.46886446886446886, 'pegasus_entailment': 0.35101085156202316, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3484848484848485, 'r1_recall': 0.7076923076923077, 'r1_f1': 0.46700507614213205, 'pegasus_entailment': 0.5868493854999542, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.336, 'r1_recall': 0.4772727272727273, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.7152120669682821, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4050632911392405, 'r1_recall': 0.38095238095238093, 'r1_f1': 0.39263803680981596, 'pegasus_entailment': 0.23637856543064117, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19815668202764977, 'r1_recall': 0.5584415584415584, 'r1_f1': 0.2925170068027211, 'pegasus_entailment': 0.6683940663933754, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 20, 'pegasus_ari': 36, 'pegasus_smog': 24}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38613861386138615, 'r1_recall': 0.4875, 'r1_f1': 0.430939226519337, 'pegasus_entailment': 0.607247973481814, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5481481481481482, 'r1_recall': 0.47435897435897434, 'r1_f1': 0.5085910652920963, 'pegasus_entailment': 0.5383799386521181, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33653846153846156, 'r1_recall': 0.4605263157894737, 'r1_f1': 0.3888888888888889, 'pegasus_entailment': 0.3122583366930485, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4205607476635514, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.46874999999999994, 'pegasus_entailment': 0.6081736162304878, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4178082191780822, 'r1_recall': 0.46564885496183206, 'r1_f1': 0.44043321299638993, 'pegasus_entailment': 0.716307532787323, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38613861386138615, 'r1_recall': 0.36792452830188677, 'r1_f1': 0.37681159420289856, 'pegasus_entailment': 0.34384166821837425, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.532258064516129, 'r1_recall': 0.36065573770491804, 'r1_f1': 0.42996742671009774, 'pegasus_entailment': 0.5841748838623365, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33088235294117646, 'r1_recall': 0.5921052631578947, 'r1_f1': 0.42452830188679247, 'pegasus_entailment': 0.7879538178443909, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41304347826086957, 'r1_recall': 0.41304347826086957, 'r1_f1': 0.41304347826086957, 'pegasus_entailment': 0.5314286615699529, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6868686868686869, 'r1_recall': 0.3148148148148148, 'r1_f1': 0.43174603174603177, 'pegasus_entailment': 0.6144606247544289, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46875, 'r1_recall': 0.44554455445544555, 'r1_f1': 0.45685279187817257, 'pegasus_entailment': 0.6009777329862118, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4782608695652174, 'r1_recall': 0.11224489795918367, 'r1_f1': 0.18181818181818182, 'pegasus_entailment': 0.14959746599197388, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47368421052631576, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.4931506849315068, 'pegasus_entailment': 0.5008636573329568, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4962962962962963, 'r1_recall': 0.5037593984962406, 'r1_f1': 0.5, 'pegasus_entailment': 0.5085950257877508, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4144144144144144, 'r1_recall': 0.5111111111111111, 'r1_f1': 0.4577114427860697, 'pegasus_entailment': 0.6150293350219727, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43103448275862066, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.43290043290043284, 'pegasus_entailment': 0.6922184526920319, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2789115646258503, 'r1_recall': 0.36936936936936937, 'r1_f1': 0.3178294573643411, 'pegasus_entailment': 0.3506540894508362, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3776223776223776, 'r1_recall': 0.391304347826087, 'r1_f1': 0.3843416370106761, 'pegasus_entailment': 0.8123953580856323, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2, 'r1_recall': 0.42, 'r1_f1': 0.2709677419354839, 'pegasus_entailment': 0.5522477477788925, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.17050691244239632, 'r1_recall': 0.6607142857142857, 'r1_f1': 0.27106227106227104, 'pegasus_entailment': 0.5636316575109959, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.14423076923076922, 'r1_recall': 0.3191489361702128, 'r1_f1': 0.19867549668874174, 'pegasus_entailment': 0.3243995070457458, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41025641025641024, 'r1_recall': 0.4507042253521127, 'r1_f1': 0.4295302013422819, 'pegasus_entailment': 0.5003953296691179, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5775862068965517, 'r1_recall': 0.366120218579235, 'r1_f1': 0.44816053511705684, 'pegasus_entailment': 0.6339911408722401, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5806451612903226, 'r1_recall': 0.39416058394160586, 'r1_f1': 0.46956521739130436, 'pegasus_entailment': 0.5356666147708893, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3025210084033613, 'r1_recall': 0.3956043956043956, 'r1_f1': 0.34285714285714286, 'pegasus_entailment': 0.703679159283638, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4108527131782946, 'r1_recall': 0.39849624060150374, 'r1_f1': 0.4045801526717557, 'pegasus_entailment': 0.4540139262874921, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.6402439024390244, 'r1_f1': 0.6382978723404255, 'pegasus_entailment': 0.6170196086168289, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6099290780141844, 'r1_recall': 0.42786069651741293, 'r1_f1': 0.5029239766081871, 'pegasus_entailment': 0.6665075355105929, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43478260869565216, 'r1_recall': 0.4, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.42354570887982845, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5737704918032787, 'r1_recall': 0.4375, 'r1_f1': 0.49645390070921985, 'pegasus_entailment': 0.5212833434343338, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 13}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40816326530612246, 'r1_recall': 0.4878048780487805, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.3806541860103607, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20491803278688525, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.29411764705882354, 'pegasus_entailment': 0.7467644095420838, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31868131868131866, 'r1_recall': 0.4603174603174603, 'r1_f1': 0.37662337662337664, 'pegasus_entailment': 0.7871616125106812, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18333333333333332, 'r1_recall': 0.6470588235294118, 'r1_f1': 0.2857142857142857, 'pegasus_entailment': 0.6768849492073059, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3076923076923077, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.35555555555555557, 'pegasus_entailment': 0.39485378714744, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6136363636363636, 'r1_recall': 0.44021739130434784, 'r1_f1': 0.5126582278481013, 'pegasus_entailment': 0.7566522359848022, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40476190476190477, 'r1_recall': 0.5074626865671642, 'r1_f1': 0.4503311258278146, 'pegasus_entailment': 0.6956368585427603, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46875, 'r1_recall': 0.35714285714285715, 'r1_f1': 0.40540540540540543, 'pegasus_entailment': 0.3111882957164198, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36065573770491804, 'r1_recall': 0.5, 'r1_f1': 0.41904761904761906, 'pegasus_entailment': 0.8167998393376669, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45454545454545453, 'r1_recall': 0.41139240506329117, 'r1_f1': 0.4318936877076412, 'pegasus_entailment': 0.4964904508420399, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6923076923076923, 'r1_recall': 0.21283783783783783, 'r1_f1': 0.3255813953488372, 'pegasus_entailment': 0.5933242380619049, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4482758620689655, 'r1_recall': 0.7090909090909091, 'r1_f1': 0.5492957746478873, 'pegasus_entailment': 0.5868682488799095, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5846153846153846, 'r1_recall': 0.19289340101522842, 'r1_f1': 0.2900763358778626, 'pegasus_entailment': 0.4310218095779419, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2676056338028169, 'r1_recall': 0.6333333333333333, 'r1_f1': 0.37623762376237624, 'pegasus_entailment': 0.5501702517271042, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4649122807017544, 'r1_recall': 0.43089430894308944, 'r1_f1': 0.4472573839662447, 'pegasus_entailment': 0.6209712237119674, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5473684210526316, 'r1_recall': 0.49523809523809526, 'r1_f1': 0.52, 'pegasus_entailment': 0.6545297205448151, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4782608695652174, 'r1_recall': 0.33587786259541985, 'r1_f1': 0.3946188340807175, 'pegasus_entailment': 0.3557061031460762, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20382165605095542, 'r1_recall': 0.47761194029850745, 'r1_f1': 0.2857142857142857, 'pegasus_entailment': 0.6208609044551849, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1807909604519774, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.27350427350427353, 'pegasus_entailment': 0.7953728692872184, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40476190476190477, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.48226950354609927, 'pegasus_entailment': 0.724506696065267, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.484375, 'r1_f1': 0.49206349206349204, 'pegasus_entailment': 0.35776331392116845, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5728155339805825, 'r1_recall': 0.33146067415730335, 'r1_f1': 0.4199288256227757, 'pegasus_entailment': 0.5082070417702198, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5030674846625767, 'r1_recall': 0.5030674846625767, 'r1_f1': 0.5030674846625767, 'pegasus_entailment': 0.5522112001975378, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.559322033898305, 'r1_recall': 0.34196891191709844, 'r1_f1': 0.42443729903536975, 'pegasus_entailment': 0.6495350301265717, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43846153846153846, 'r1_recall': 0.5643564356435643, 'r1_f1': 0.4935064935064935, 'pegasus_entailment': 0.415099036693573, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4380952380952381, 'r1_recall': 0.5476190476190477, 'r1_f1': 0.4867724867724868, 'pegasus_entailment': 0.41620427668094634, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2653061224489796, 'r1_recall': 0.43333333333333335, 'r1_f1': 0.3291139240506329, 'pegasus_entailment': 0.7197128434975942, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26956521739130435, 'r1_recall': 0.6078431372549019, 'r1_f1': 0.37349397590361444, 'pegasus_entailment': 0.8394506573677063, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.631578947368421, 'r1_recall': 0.32432432432432434, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.29319759011268615, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.4788732394366197, 'pegasus_entailment': 0.48445288091897964, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37857142857142856, 'r1_recall': 0.4491525423728814, 'r1_f1': 0.4108527131782946, 'pegasus_entailment': 0.582177729656299, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7735849056603774, 'r1_recall': 0.3153846153846154, 'r1_f1': 0.44808743169398907, 'pegasus_entailment': 0.3929060213267803, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4673913043478261, 'r1_recall': 0.36134453781512604, 'r1_f1': 0.40758293838862564, 'pegasus_entailment': 0.22791106684599072, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6901408450704225, 'r1_recall': 0.3402777777777778, 'r1_f1': 0.4558139534883721, 'pegasus_entailment': 0.6729864180088043, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43137254901960786, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.45833333333333326, 'pegasus_entailment': 0.5293272510170937, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4657534246575342, 'r1_recall': 0.2556390977443609, 'r1_f1': 0.3300970873786408, 'pegasus_entailment': 0.5388985453173518, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5726495726495726, 'r1_recall': 0.3160377358490566, 'r1_f1': 0.40729483282674767, 'pegasus_entailment': 0.6706782579421997, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3177570093457944, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.4146341463414634, 'pegasus_entailment': 0.5957774966955185, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37267080745341613, 'r1_recall': 0.46875, 'r1_f1': 0.4152249134948096, 'pegasus_entailment': 0.6840613663196564, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.445859872611465, 'pegasus_entailment': 0.4456978077068925, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23529411764705882, 'r1_recall': 0.041884816753926704, 'r1_f1': 0.07111111111111111, 'pegasus_entailment': 0.04707127436995506, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5268817204301075, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.4083333333333334, 'pegasus_entailment': 0.3905753493309021, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48672566371681414, 'r1_recall': 0.35714285714285715, 'r1_f1': 0.41198501872659177, 'pegasus_entailment': 0.6207771549622217, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3828125, 'r1_recall': 0.6533333333333333, 'r1_f1': 0.4827586206896552, 'pegasus_entailment': 0.6542603939771652, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4742268041237113, 'r1_recall': 0.4, 'r1_f1': 0.43396226415094336, 'pegasus_entailment': 0.6036318875849247, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6237623762376238, 'r1_recall': 0.4117647058823529, 'r1_f1': 0.4960629921259842, 'pegasus_entailment': 0.5497986814007163, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3402061855670103, 'r1_recall': 0.3235294117647059, 'r1_f1': 0.3316582914572864, 'pegasus_entailment': 0.4859067810078462, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4067796610169492, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.4137931034482759, 'pegasus_entailment': 0.2448982410132885, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40860215053763443, 'r1_recall': 0.59375, 'r1_f1': 0.48407643312101906, 'pegasus_entailment': 0.7189782977104187, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2638888888888889, 'r1_recall': 0.5066666666666667, 'r1_f1': 0.3470319634703196, 'pegasus_entailment': 0.4962162636220455, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.25984251968503935, 'r1_recall': 0.6226415094339622, 'r1_f1': 0.36666666666666664, 'pegasus_entailment': 0.6288610577583313, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4842105263157895, 'r1_recall': 0.4946236559139785, 'r1_f1': 0.4893617021276596, 'pegasus_entailment': 0.5132266916334629, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45714285714285713, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.5, 'pegasus_entailment': 0.5058462500572205, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.49019607843137253, 'r1_f1': 0.5649717514124294, 'pegasus_entailment': 0.3303785959724337, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5327102803738317, 'r1_recall': 0.36075949367088606, 'r1_f1': 0.43018867924528303, 'pegasus_entailment': 0.4121605470776558, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29896907216494845, 'r1_recall': 0.5087719298245614, 'r1_f1': 0.3766233766233766, 'pegasus_entailment': 0.7604764252901077, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4883720930232558, 'r1_recall': 0.4228187919463087, 'r1_f1': 0.45323741007194246, 'pegasus_entailment': 0.44426470436155796, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.36496350364963503, 'r1_f1': 0.4405286343612335, 'pegasus_entailment': 0.5495590567588806, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30327868852459017, 'r1_recall': 0.5606060606060606, 'r1_f1': 0.3936170212765957, 'pegasus_entailment': 0.6049522360165914, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5757575757575758, 'r1_recall': 0.34234234234234234, 'r1_f1': 0.42937853107344637, 'pegasus_entailment': 0.3808814063668251, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.21428571428571427, 'r1_recall': 0.075, 'r1_f1': 0.1111111111111111, 'pegasus_entailment': 0.0406779982149601, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6455696202531646, 'r1_recall': 0.4015748031496063, 'r1_f1': 0.49514563106796117, 'pegasus_entailment': 0.4319703672081232, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.717391304347826, 'r1_recall': 0.3350253807106599, 'r1_f1': 0.45674740484429066, 'pegasus_entailment': 0.6542486548423767, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6597222222222222, 'r1_recall': 0.39094650205761317, 'r1_f1': 0.49095607235142114, 'pegasus_entailment': 0.580893611907959, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.45323741007194246, 'r1_f1': 0.5163934426229508, 'pegasus_entailment': 0.6679912656545639, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1559633027522936, 'r1_recall': 0.2328767123287671, 'r1_f1': 0.18681318681318682, 'pegasus_entailment': 0.0050088192510884255, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20134228187919462, 'r1_recall': 0.4918032786885246, 'r1_f1': 0.28571428571428564, 'pegasus_entailment': 0.7935367027918497, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 22}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4878048780487805, 'r1_recall': 0.46511627906976744, 'r1_f1': 0.4761904761904762, 'pegasus_entailment': 0.37883253892262775, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4065934065934066, 'r1_recall': 0.5, 'r1_f1': 0.4484848484848485, 'pegasus_entailment': 0.5584347564727068, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5164835164835165, 'r1_recall': 0.27011494252873564, 'r1_f1': 0.3547169811320755, 'pegasus_entailment': 0.8079738914966583, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5172413793103449, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.5190311418685121, 'pegasus_entailment': 0.340911863637822, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7169811320754716, 'r1_recall': 0.38974358974358975, 'r1_f1': 0.5049833887043189, 'pegasus_entailment': 0.49040182679891586, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5324675324675324, 'r1_recall': 0.5616438356164384, 'r1_f1': 0.5466666666666667, 'pegasus_entailment': 0.15110259549692273, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4146341463414634, 'r1_recall': 0.68, 'r1_f1': 0.5151515151515151, 'pegasus_entailment': 0.8042595585187277, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3103448275862069, 'r1_recall': 0.07894736842105263, 'r1_f1': 0.1258741258741259, 'pegasus_entailment': 0.07427885383367538, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6601941747572816, 'r1_recall': 0.18085106382978725, 'r1_f1': 0.2839248434237996, 'pegasus_entailment': 0.8478739559650421, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 21, 'pegasus_ari': 35, 'pegasus_smog': 27}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39344262295081966, 'r1_recall': 0.4067796610169492, 'r1_f1': 0.4, 'pegasus_entailment': 0.74375319480896, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5578947368421052, 'r1_recall': 0.31547619047619047, 'r1_f1': 0.403041825095057, 'pegasus_entailment': 0.5525944903492928, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5824175824175825, 'r1_recall': 0.4108527131782946, 'r1_f1': 0.48181818181818187, 'pegasus_entailment': 0.49569511860609056, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5590551181102362, 'r1_recall': 0.47651006711409394, 'r1_f1': 0.5144927536231884, 'pegasus_entailment': 0.544487626850605, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41711229946524064, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.43820224719101125, 'pegasus_entailment': 0.6584864134589831, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6041666666666666, 'r1_recall': 0.44274809160305345, 'r1_f1': 0.5110132158590309, 'pegasus_entailment': 0.4535941373556852, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49473684210526314, 'r1_recall': 0.3790322580645161, 'r1_f1': 0.4292237442922374, 'pegasus_entailment': 0.4714683383703232, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3939393939393939, 'r1_recall': 0.46987951807228917, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.3465320348739624, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.3414634146341463, 'pegasus_entailment': 0.622921209782362, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5670103092783505, 'r1_recall': 0.47413793103448276, 'r1_f1': 0.516431924882629, 'pegasus_entailment': 0.32362470030784607, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5841584158415841, 'r1_recall': 0.31891891891891894, 'r1_f1': 0.4125874125874126, 'pegasus_entailment': 0.34701680205762386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43103448275862066, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.4716981132075472, 'pegasus_entailment': 0.4819010039791465, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5985915492957746, 'r1_recall': 0.22077922077922077, 'r1_f1': 0.3225806451612903, 'pegasus_entailment': 0.5643002798315138, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.39344262295081966, 'pegasus_entailment': 0.657067745923996, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23741007194244604, 'r1_recall': 0.5076923076923077, 'r1_f1': 0.3235294117647059, 'pegasus_entailment': 0.33135034143924713, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39285714285714285, 'r1_recall': 0.55, 'r1_f1': 0.45833333333333337, 'pegasus_entailment': 0.37084841759254533, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2440944881889764, 'r1_recall': 0.38271604938271603, 'r1_f1': 0.29807692307692313, 'pegasus_entailment': 0.5940401069819927, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 13, 'pegasus_ari': 12, 'pegasus_smog': 12}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4805194805194805, 'r1_recall': 0.3557692307692308, 'r1_f1': 0.4088397790055249, 'pegasus_entailment': 0.42647180954615277, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.30303030303030304, 'r1_recall': 0.3488372093023256, 'r1_f1': 0.32432432432432434, 'pegasus_entailment': 0.2153715844033286, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5533980582524272, 'r1_recall': 0.36538461538461536, 'r1_f1': 0.4401544401544401, 'pegasus_entailment': 0.5119348257780075, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5877862595419847, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.5202702702702703, 'pegasus_entailment': 0.5827861825625101, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2702702702702703, 'r1_recall': 0.4918032786885246, 'r1_f1': 0.3488372093023256, 'pegasus_entailment': 0.8022416979074478, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5504587155963303, 'r1_recall': 0.4, 'r1_f1': 0.46332046332046334, 'pegasus_entailment': 0.642160398264726, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 13}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34782608695652173, 'r1_recall': 0.43956043956043955, 'r1_f1': 0.3883495145631068, 'pegasus_entailment': 0.10297342836856842, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41964285714285715, 'r1_recall': 0.35877862595419846, 'r1_f1': 0.3868312757201646, 'pegasus_entailment': 0.6564562491008213, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32748538011695905, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.42748091603053434, 'pegasus_entailment': 0.5786510159571966, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3684210526315789, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.4117647058823529, 'pegasus_entailment': 0.6963444203138351, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4148936170212766, 'r1_recall': 0.5342465753424658, 'r1_f1': 0.467065868263473, 'pegasus_entailment': 0.6000431482680142, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32608695652173914, 'r1_recall': 0.36, 'r1_f1': 0.34220532319391633, 'pegasus_entailment': 0.06465862412005663, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5842696629213483, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.5123152709359605, 'pegasus_entailment': 0.31110429647378623, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4691358024691358, 'r1_recall': 0.42696629213483145, 'r1_f1': 0.4470588235294117, 'pegasus_entailment': 0.5402243256568908, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23076923076923078, 'r1_recall': 0.4883720930232558, 'r1_f1': 0.3134328358208955, 'pegasus_entailment': 0.2977465717121959, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5517241379310345, 'r1_recall': 0.36199095022624433, 'r1_f1': 0.4371584699453552, 'pegasus_entailment': 0.32101942896842955, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4014084507042254, 'r1_recall': 0.504424778761062, 'r1_f1': 0.4470588235294118, 'pegasus_entailment': 0.37584326043725014, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1095890410958904, 'r1_recall': 0.43243243243243246, 'r1_f1': 0.17486338797814208, 'pegasus_entailment': 0.5961054530926049, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.5048987492918968, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36, 'r1_recall': 0.5887850467289719, 'r1_f1': 0.44680851063829785, 'pegasus_entailment': 0.6074484544140952, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.24285714285714285, 'r1_recall': 0.7083333333333334, 'r1_f1': 0.36170212765957444, 'pegasus_entailment': 0.9155974302973066, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4013605442176871, 'r1_recall': 0.6704545454545454, 'r1_f1': 0.502127659574468, 'pegasus_entailment': 0.5002622272198399, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40875912408759124, 'r1_recall': 0.6292134831460674, 'r1_f1': 0.49557522123893805, 'pegasus_entailment': 0.4104733355343342, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3274336283185841, 'r1_recall': 0.6271186440677966, 'r1_f1': 0.4302325581395349, 'pegasus_entailment': 0.6575958907604218, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5432098765432098, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4888888888888889, 'pegasus_entailment': 0.6929896995425224, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3543307086614173, 'r1_recall': 0.46875, 'r1_f1': 0.4035874439461883, 'pegasus_entailment': 0.699138845716204, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5391304347826087, 'r1_recall': 0.6595744680851063, 'r1_f1': 0.5933014354066986, 'pegasus_entailment': 0.6301655471324921, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8409090909090909, 'r1_recall': 0.1417624521072797, 'r1_f1': 0.24262295081967217, 'pegasus_entailment': 0.7729265451431274, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5301204819277109, 'r1_recall': 0.22, 'r1_f1': 0.3109540636042403, 'pegasus_entailment': 0.543868562579155, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35185185185185186, 'r1_recall': 0.48717948717948717, 'r1_f1': 0.40860215053763443, 'pegasus_entailment': 0.2588733856876691, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3870967741935484, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.6095601737499237, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6842105263157895, 'r1_recall': 0.2867647058823529, 'r1_f1': 0.40414507772020725, 'pegasus_entailment': 0.49467436969280243, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44594594594594594, 'r1_recall': 0.584070796460177, 'r1_f1': 0.5057471264367815, 'pegasus_entailment': 0.5386092126369476, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30303030303030304, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.3686635944700461, 'pegasus_entailment': 0.6509828828275204, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31654676258992803, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.4292682926829268, 'pegasus_entailment': 0.6718974250058333, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4019607843137255, 'r1_recall': 0.44565217391304346, 'r1_f1': 0.422680412371134, 'pegasus_entailment': 0.29751764237880707, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43902439024390244, 'r1_recall': 0.43373493975903615, 'r1_f1': 0.4363636363636364, 'pegasus_entailment': 0.5353312840064367, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5130434782608696, 'r1_recall': 0.46825396825396826, 'r1_f1': 0.4896265560165975, 'pegasus_entailment': 0.31519482135772703, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5425531914893617, 'r1_recall': 0.5, 'r1_f1': 0.5204081632653061, 'pegasus_entailment': 0.3589504975825548, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.3167701863354037, 'r1_f1': 0.4146341463414634, 'pegasus_entailment': 0.36106419563293457, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26373626373626374, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.32432432432432434, 'pegasus_entailment': 0.49518488608300687, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.18421052631578946, 'r1_recall': 0.030973451327433628, 'r1_f1': 0.05303030303030303, 'pegasus_entailment': 0.14875231683254242, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 12, 'pegasus_ari': 13, 'pegasus_smog': 12}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3918918918918919, 'r1_recall': 0.48333333333333334, 'r1_f1': 0.43283582089552236, 'pegasus_entailment': 0.4485287796705961, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5340909090909091, 'r1_recall': 0.46534653465346537, 'r1_f1': 0.4973544973544973, 'pegasus_entailment': 0.6887708827853203, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2185430463576159, 'r1_recall': 0.673469387755102, 'r1_f1': 0.33, 'pegasus_entailment': 0.6135639846324921, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18478260869565216, 'r1_recall': 0.3695652173913043, 'r1_f1': 0.24637681159420283, 'pegasus_entailment': 0.46858827769756317, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5035460992907801, 'r1_recall': 0.4863013698630137, 'r1_f1': 0.49477351916376305, 'pegasus_entailment': 0.5733778402209282, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43162393162393164, 'r1_recall': 0.5260416666666666, 'r1_f1': 0.47417840375586856, 'pegasus_entailment': 0.6125304911817823, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3194444444444444, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.4220183486238532, 'pegasus_entailment': 0.6834634900093078, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39849624060150374, 'r1_recall': 0.5353535353535354, 'r1_f1': 0.45689655172413796, 'pegasus_entailment': 0.544262558221817, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47058823529411764, 'r1_recall': 0.3855421686746988, 'r1_f1': 0.423841059602649, 'pegasus_entailment': 0.5446513146162033, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42574257425742573, 'r1_recall': 0.6056338028169014, 'r1_f1': 0.5, 'pegasus_entailment': 0.5728964619338512, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39263803680981596, 'r1_recall': 0.5565217391304348, 'r1_f1': 0.460431654676259, 'pegasus_entailment': 0.47885565938694136, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7021276595744681, 'r1_recall': 0.39285714285714285, 'r1_f1': 0.5038167938931297, 'pegasus_entailment': 0.18232524084548155, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1891891891891892, 'r1_recall': 0.39622641509433965, 'r1_f1': 0.2560975609756098, 'pegasus_entailment': 0.6154837384819984, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32515337423312884, 'r1_recall': 0.49074074074074076, 'r1_f1': 0.39114391143911437, 'pegasus_entailment': 0.6261491306746999, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 23}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5531914893617021, 'r1_recall': 0.23008849557522124, 'r1_f1': 0.325, 'pegasus_entailment': 0.4980853018350899, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23076923076923078, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.3383458646616541, 'pegasus_entailment': 0.6026576519012451, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5795454545454546, 'r1_recall': 0.2328767123287671, 'r1_f1': 0.3322475570032573, 'pegasus_entailment': 0.703728124499321, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.08653846153846154, 'r1_recall': 0.2571428571428571, 'r1_f1': 0.1294964028776978, 'pegasus_entailment': 0.5467697158455849, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5675675675675675, 'r1_recall': 0.25301204819277107, 'r1_f1': 0.35, 'pegasus_entailment': 0.05108678340911865, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2184873949579832, 'r1_recall': 0.5306122448979592, 'r1_f1': 0.30952380952380953, 'pegasus_entailment': 0.5600412860512733, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6578947368421053, 'r1_recall': 0.4411764705882353, 'r1_f1': 0.5281690140845071, 'pegasus_entailment': 0.5214961305260658, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48872180451127817, 'r1_recall': 0.5038759689922481, 'r1_f1': 0.49618320610687017, 'pegasus_entailment': 0.7546520804365476, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37593984962406013, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.8290695771574974, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4392523364485981, 'r1_recall': 0.3533834586466165, 'r1_f1': 0.39166666666666666, 'pegasus_entailment': 0.6637011170387268, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5853658536585366, 'r1_recall': 0.43243243243243246, 'r1_f1': 0.49740932642487046, 'pegasus_entailment': 0.22954754158854485, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37681159420289856, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.24902122219403586, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3865979381443299, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.4491017964071856, 'pegasus_entailment': 0.592412429196494, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47, 'r1_recall': 0.3263888888888889, 'r1_f1': 0.3852459016393443, 'pegasus_entailment': 0.6217985649903616, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33636363636363636, 'r1_recall': 0.40217391304347827, 'r1_f1': 0.3663366336633663, 'pegasus_entailment': 0.7800544947385788, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45161290322580644, 'r1_recall': 0.4077669902912621, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.5544122364372015, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.216, 'r1_recall': 0.40298507462686567, 'r1_f1': 0.28124999999999994, 'pegasus_entailment': 0.574660811573267, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38345864661654133, 'r1_recall': 0.5604395604395604, 'r1_f1': 0.4553571428571429, 'pegasus_entailment': 0.515544080734253, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5752212389380531, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.5078125, 'pegasus_entailment': 0.32424039393663406, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5053763440860215, 'r1_recall': 0.38524590163934425, 'r1_f1': 0.4372093023255814, 'pegasus_entailment': 0.2758622944355011, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5319148936170213, 'r1_recall': 0.30120481927710846, 'r1_f1': 0.3846153846153847, 'pegasus_entailment': 0.4033430330455303, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2948717948717949, 'r1_recall': 0.41818181818181815, 'r1_f1': 0.3458646616541353, 'pegasus_entailment': 0.422566931694746, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3956043956043956, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.43636363636363634, 'pegasus_entailment': 0.3740781595309575, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5181347150259067, 'r1_recall': 0.49019607843137253, 'r1_f1': 0.5037783375314862, 'pegasus_entailment': 0.6709670101602873, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7471264367816092, 'r1_recall': 0.30092592592592593, 'r1_f1': 0.4290429042904291, 'pegasus_entailment': 0.29679388329386713, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48148148148148145, 'r1_recall': 0.4297520661157025, 'r1_f1': 0.4541484716157205, 'pegasus_entailment': 0.6088345572352409, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45695364238410596, 'r1_recall': 0.4825174825174825, 'r1_f1': 0.46938775510204084, 'pegasus_entailment': 0.2560047060251236, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3176470588235294, 'r1_recall': 0.6206896551724138, 'r1_f1': 0.42023346303501946, 'pegasus_entailment': 0.8200766841570536, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3972602739726027, 'r1_recall': 0.6373626373626373, 'r1_f1': 0.4894514767932489, 'pegasus_entailment': 0.5399036824703216, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49107142857142855, 'r1_recall': 0.5392156862745098, 'r1_f1': 0.514018691588785, 'pegasus_entailment': 0.6226053237915039, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44554455445544555, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.4186046511627907, 'pegasus_entailment': 0.5975712180137634, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.52, 'r1_recall': 0.5252525252525253, 'r1_f1': 0.5226130653266332, 'pegasus_entailment': 0.5615451484918594, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2727272727272727, 'r1_recall': 0.3707865168539326, 'r1_f1': 0.3142857142857143, 'pegasus_entailment': 0.4057633446529508, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.625, 'r1_recall': 0.36809815950920244, 'r1_f1': 0.46332046332046334, 'pegasus_entailment': 0.3877374803026517, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5826086956521739, 'r1_recall': 0.36813186813186816, 'r1_f1': 0.4511784511784512, 'pegasus_entailment': 0.39660301556189853, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6238532110091743, 'r1_recall': 0.24727272727272728, 'r1_f1': 0.3541666666666667, 'pegasus_entailment': 0.736794725060463, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.611764705882353, 'r1_recall': 0.47706422018348627, 'r1_f1': 0.5360824742268041, 'pegasus_entailment': 0.6691330869992574, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18181818181818182, 'r1_recall': 0.3448275862068966, 'r1_f1': 0.23809523809523808, 'pegasus_entailment': 0.23208479546010494, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.34806629834254144, 'r1_f1': 0.4228187919463087, 'pegasus_entailment': 0.5718771112816674, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37373737373737376, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.42045454545454547, 'pegasus_entailment': 0.32209496665745974, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37593984962406013, 'r1_recall': 0.625, 'r1_f1': 0.4694835680751173, 'pegasus_entailment': 0.576982706785202, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6712328767123288, 'r1_recall': 0.5268817204301075, 'r1_f1': 0.5903614457831325, 'pegasus_entailment': 0.29460061093171436, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.417910447761194, 'pegasus_entailment': 0.4344587524731954, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5568181818181818, 'r1_recall': 0.5444444444444444, 'r1_f1': 0.550561797752809, 'pegasus_entailment': 0.4270073473453522, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30434782608695654, 'r1_recall': 0.4057971014492754, 'r1_f1': 0.3478260869565218, 'pegasus_entailment': 0.4371202103793621, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45263157894736844, 'r1_recall': 0.4479166666666667, 'r1_f1': 0.450261780104712, 'pegasus_entailment': 0.3432462140917778, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21839080459770116, 'r1_recall': 0.59375, 'r1_f1': 0.31932773109243695, 'pegasus_entailment': 0.543654078617692, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3466666666666667, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.4315352697095436, 'pegasus_entailment': 0.6355585008859634, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4583333333333333, 'r1_recall': 0.5, 'r1_f1': 0.4782608695652174, 'pegasus_entailment': 0.6764287501573563, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 22}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3364485981308411, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.42603550295857995, 'pegasus_entailment': 0.24848564551211894, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.686046511627907, 'r1_recall': 0.5514018691588785, 'r1_f1': 0.6113989637305699, 'pegasus_entailment': 0.4344220484296481, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.49206349206349204, 'r1_f1': 0.3315508021390374, 'pegasus_entailment': 0.5516899630427361, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.2943396226415094, 'r1_f1': 0.39493670886075943, 'pegasus_entailment': 0.7545876145362854, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.59375, 'r1_f1': 0.42696629213483145, 'pegasus_entailment': 0.43132815913607675, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39669421487603307, 'r1_recall': 0.5217391304347826, 'r1_f1': 0.4507042253521127, 'pegasus_entailment': 0.4991380994518598, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5824175824175825, 'r1_recall': 0.53, 'r1_f1': 0.5549738219895288, 'pegasus_entailment': 0.6579312384128571, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5412844036697247, 'r1_recall': 0.42142857142857143, 'r1_f1': 0.4738955823293173, 'pegasus_entailment': 0.531237006187439, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4453125, 'r1_recall': 0.6063829787234043, 'r1_f1': 0.5135135135135135, 'pegasus_entailment': 0.4015967417508364, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4276729559748428, 'r1_recall': 0.5354330708661418, 'r1_f1': 0.4755244755244756, 'pegasus_entailment': 0.567006778717041, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35185185185185186, 'r1_recall': 0.5352112676056338, 'r1_f1': 0.4245810055865922, 'pegasus_entailment': 0.7527713775634766, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3231707317073171, 'r1_recall': 0.5638297872340425, 'r1_f1': 0.4108527131782945, 'pegasus_entailment': 0.7753735979398092, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3274336283185841, 'r1_recall': 0.44047619047619047, 'r1_f1': 0.3756345177664974, 'pegasus_entailment': 0.5341894570738077, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41379310344827586, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.4472049689440994, 'pegasus_entailment': 0.26057420174280804, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.410958904109589, 'r1_recall': 0.44776119402985076, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.26260897268851596, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2978723404255319, 'r1_recall': 0.4375, 'r1_f1': 0.3544303797468354, 'pegasus_entailment': 0.35714262500405314, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3825503355704698, 'r1_recall': 0.32947976878612717, 'r1_f1': 0.3540372670807453, 'pegasus_entailment': 0.39109589299187064, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4722222222222222, 'r1_recall': 0.3090909090909091, 'r1_f1': 0.37362637362637363, 'pegasus_entailment': 0.7201465368270874, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6, 'r1_recall': 0.1836734693877551, 'r1_f1': 0.28125, 'pegasus_entailment': 0.06939207762479782, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 24, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5402298850574713, 'r1_recall': 0.25133689839572193, 'r1_f1': 0.3430656934306569, 'pegasus_entailment': 0.8071490923563639, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45977011494252873, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.4395604395604395, 'pegasus_entailment': 0.26983938552439213, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3464566929133858, 'r1_recall': 0.6111111111111112, 'r1_f1': 0.4422110552763819, 'pegasus_entailment': 0.5883654057979584, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 22, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.323943661971831, 'r1_recall': 0.41818181818181815, 'r1_f1': 0.36507936507936506, 'pegasus_entailment': 0.6531852930784225, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18181818181818182, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.27586206896551724, 'pegasus_entailment': 0.3180764466524124, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2608695652173913, 'r1_recall': 0.5915492957746479, 'r1_f1': 0.36206896551724144, 'pegasus_entailment': 0.620578225169863, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24271844660194175, 'r1_recall': 0.4807692307692308, 'r1_f1': 0.32258064516129037, 'pegasus_entailment': 0.36141351610422134, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4246575342465753, 'r1_recall': 0.26495726495726496, 'r1_f1': 0.32631578947368417, 'pegasus_entailment': 0.43059178069233894, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45925925925925926, 'r1_recall': 0.4732824427480916, 'r1_f1': 0.46616541353383456, 'pegasus_entailment': 0.6863189339637756, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.4642857142857143, 'r1_f1': 0.3880597014925373, 'pegasus_entailment': 0.5171146414109639, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3835616438356164, 'r1_recall': 0.3111111111111111, 'r1_f1': 0.34355828220858897, 'pegasus_entailment': 0.6442289735589709, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36065573770491804, 'r1_recall': 0.4835164835164835, 'r1_f1': 0.4131455399061033, 'pegasus_entailment': 0.7570720314979553, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3131868131868132, 'r1_recall': 0.5181818181818182, 'r1_f1': 0.3904109589041096, 'pegasus_entailment': 0.8065514266490936, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4672897196261682, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.5025125628140703, 'pegasus_entailment': 0.540150153140227, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46236559139784944, 'r1_recall': 0.43, 'r1_f1': 0.44559585492227977, 'pegasus_entailment': 0.5960810383160909, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3076923076923077, 'r1_recall': 0.34782608695652173, 'r1_f1': 0.32653061224489793, 'pegasus_entailment': 0.7555141299962997, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4880952380952381, 'r1_recall': 0.47126436781609193, 'r1_f1': 0.47953216374269, 'pegasus_entailment': 0.4222039766609669, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42105263157894735, 'r1_recall': 0.39215686274509803, 'r1_f1': 0.4060913705583757, 'pegasus_entailment': 0.26685271225869656, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3813559322033898, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.44554455445544555, 'pegasus_entailment': 0.6636962071061134, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21839080459770116, 'r1_recall': 0.36538461538461536, 'r1_f1': 0.2733812949640288, 'pegasus_entailment': 0.5379913852189891, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5412844036697247, 'r1_recall': 0.4125874125874126, 'r1_f1': 0.46825396825396826, 'pegasus_entailment': 0.5645531006157398, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3401360544217687, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.4273504273504274, 'pegasus_entailment': 0.764346107840538, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3076923076923077, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.42105263157894735, 'pegasus_entailment': 0.4489696907500426, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5510204081632653, 'r1_recall': 0.4462809917355372, 'r1_f1': 0.4931506849315068, 'pegasus_entailment': 0.7057108208537102, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.325, 'r1_recall': 0.375, 'r1_f1': 0.34821428571428575, 'pegasus_entailment': 0.3814058875044187, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2777777777777778, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.3879310344827587, 'pegasus_entailment': 0.4652883768081665, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.304, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.3857868020304569, 'pegasus_entailment': 0.4182082874079545, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.379746835443038, 'r1_recall': 0.33707865168539325, 'r1_f1': 0.35714285714285715, 'pegasus_entailment': 0.3715304657816887, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.17045454545454544, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.22556390977443605, 'pegasus_entailment': 0.6159248687326908, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.627906976744186, 'r1_recall': 0.5242718446601942, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.7191497981548309, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.10204081632653061, 'r1_recall': 0.2857142857142857, 'r1_f1': 0.15037593984962405, 'pegasus_entailment': 0.5855597972869873, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22321428571428573, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.3184713375796179, 'pegasus_entailment': 0.5538528673350811, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2857142857142857, 'r1_recall': 0.717948717948718, 'r1_f1': 0.40875912408759124, 'pegasus_entailment': 0.582681941134589, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38636363636363635, 'r1_recall': 0.34459459459459457, 'r1_f1': 0.3642857142857142, 'pegasus_entailment': 0.560765764862299, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.550561797752809, 'r1_recall': 0.4260869565217391, 'r1_f1': 0.48039215686274506, 'pegasus_entailment': 0.9072685837745667, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34615384615384615, 'r1_recall': 0.375, 'r1_f1': 0.35999999999999993, 'pegasus_entailment': 0.5639748811721802, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42038216560509556, 'r1_recall': 0.6055045871559633, 'r1_f1': 0.4962406015037594, 'pegasus_entailment': 0.46686889976263046, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5617977528089888, 'r1_recall': 0.36231884057971014, 'r1_f1': 0.44052863436123346, 'pegasus_entailment': 0.451266385614872, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8181818181818182, 'r1_recall': 0.20454545454545456, 'r1_f1': 0.3272727272727273, 'pegasus_entailment': 0.7868400335311889, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42342342342342343, 'r1_recall': 0.42342342342342343, 'r1_f1': 0.42342342342342343, 'pegasus_entailment': 0.3637737203389406, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4948453608247423, 'r1_recall': 0.3221476510067114, 'r1_f1': 0.3902439024390244, 'pegasus_entailment': 0.6188257038593292, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.627906976744186, 'r1_recall': 0.3624161073825503, 'r1_f1': 0.45957446808510644, 'pegasus_entailment': 0.6916134804487228, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23595505617977527, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.30434782608695654, 'pegasus_entailment': 0.2919319085776806, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31851851851851853, 'r1_recall': 0.5972222222222222, 'r1_f1': 0.41545893719806765, 'pegasus_entailment': 0.5898906787236532, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 32, 'pegasus_smog': 23}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37606837606837606, 'r1_recall': 0.5432098765432098, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.7915166765451431, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6696428571428571, 'r1_recall': 0.5, 'r1_f1': 0.5725190839694656, 'pegasus_entailment': 0.6676193326711655, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35353535353535354, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.4216867469879518, 'pegasus_entailment': 0.5187254715710878, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6947368421052632, 'r1_recall': 0.38372093023255816, 'r1_f1': 0.4943820224719101, 'pegasus_entailment': 0.5007333805163702, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2857142857142857, 'r1_recall': 0.4594594594594595, 'r1_f1': 0.3523316062176165, 'pegasus_entailment': 0.26006012453581207, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3302752293577982, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.37894736842105264, 'pegasus_entailment': 0.8058730612198511, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4632352941176471, 'r1_recall': 0.44680851063829785, 'r1_f1': 0.4548736462093863, 'pegasus_entailment': 0.6637018203735352, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.3816793893129771, 'r1_f1': 0.35587188612099646, 'pegasus_entailment': 0.5371903240680694, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5741935483870968, 'r1_recall': 0.41784037558685444, 'r1_f1': 0.483695652173913, 'pegasus_entailment': 0.5481704927980899, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2874251497005988, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.3735408560311284, 'pegasus_entailment': 0.5514379382133484, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35526315789473684, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.4060150375939849, 'pegasus_entailment': 0.38227421293656033, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5026737967914439, 'r1_recall': 0.4973544973544973, 'r1_f1': 0.4999999999999999, 'pegasus_entailment': 0.4392912741750479, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6753246753246753, 'r1_recall': 0.17105263157894737, 'r1_f1': 0.2729658792650919, 'pegasus_entailment': 0.27714360039681196, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22, 'r1_recall': 0.3492063492063492, 'r1_f1': 0.26993865030674846, 'pegasus_entailment': 0.33360290341079235, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4233576642335766, 'r1_recall': 0.6105263157894737, 'r1_f1': 0.5, 'pegasus_entailment': 0.4142983540892601, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.379746835443038, 'r1_f1': 0.45627376425855515, 'pegasus_entailment': 0.40544256269931794, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24468085106382978, 'r1_recall': 0.39655172413793105, 'r1_f1': 0.3026315789473684, 'pegasus_entailment': 0.8078293144702912, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4864864864864865, 'r1_recall': 0.2983425414364641, 'r1_f1': 0.3698630136986301, 'pegasus_entailment': 0.8147161364555359, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5510204081632653, 'r1_recall': 0.38028169014084506, 'r1_f1': 0.45, 'pegasus_entailment': 0.5335850603878498, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30327868852459017, 'r1_recall': 0.3894736842105263, 'r1_f1': 0.3410138248847926, 'pegasus_entailment': 0.6920096531510354, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49645390070921985, 'r1_recall': 0.4069767441860465, 'r1_f1': 0.4472843450479233, 'pegasus_entailment': 0.6089031957089901, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24025974025974026, 'r1_recall': 0.5211267605633803, 'r1_f1': 0.3288888888888889, 'pegasus_entailment': 0.8271451642115911, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7073170731707317, 'r1_recall': 0.27884615384615385, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.5866522267460823, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41509433962264153, 'r1_recall': 0.4731182795698925, 'r1_f1': 0.44221105527638194, 'pegasus_entailment': 0.5441472135484219, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.271523178807947, 'r1_recall': 0.5466666666666666, 'r1_f1': 0.36283185840707965, 'pegasus_entailment': 0.747107744216919, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39, 'r1_recall': 0.5492957746478874, 'r1_f1': 0.45614035087719296, 'pegasus_entailment': 0.3519461303949356, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3424657534246575, 'r1_recall': 0.49504950495049505, 'r1_f1': 0.4048582995951417, 'pegasus_entailment': 0.4720592988388879, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6990291262135923, 'r1_recall': 0.34782608695652173, 'r1_f1': 0.4645161290322581, 'pegasus_entailment': 0.6907226622104645, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.432, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.47577092511013214, 'pegasus_entailment': 0.5737574510276318, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4069767441860465, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4794520547945206, 'pegasus_entailment': 0.7027035802602768, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5950413223140496, 'r1_recall': 0.4044943820224719, 'r1_f1': 0.4816053511705686, 'pegasus_entailment': 0.6256922110915184, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4594594594594595, 'r1_recall': 0.4657534246575342, 'r1_f1': 0.4625850340136054, 'pegasus_entailment': 0.488211914896965, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.0, 'r1_recall': 0.0, 'r1_f1': 0.0, 'pegasus_entailment': 0.7364089488983154, 'pegasus_flesch_kincaid': 62, 'pegasus_coleman_liau': 18, 'pegasus_ari': 79, 'pegasus_smog': 30}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5978260869565217, 'r1_recall': 0.6043956043956044, 'r1_f1': 0.6010928961748634, 'pegasus_entailment': 0.7065839568773905, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6164383561643836, 'r1_recall': 0.375, 'r1_f1': 0.46632124352331605, 'pegasus_entailment': 0.8231759866078695, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7707006369426752, 'r1_recall': 0.17163120567375886, 'r1_f1': 0.28074245939675174, 'pegasus_entailment': 0.6069829892367125, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4098360655737705, 'r1_recall': 0.352112676056338, 'r1_f1': 0.3787878787878788, 'pegasus_entailment': 0.6757364347577095, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5379746835443038, 'r1_recall': 0.4644808743169399, 'r1_f1': 0.49853372434017595, 'pegasus_entailment': 0.4739221880833308, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5362318840579711, 'r1_recall': 0.3978494623655914, 'r1_f1': 0.4567901234567901, 'pegasus_entailment': 0.5445841625332832, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45112781954887216, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.4819277108433735, 'pegasus_entailment': 0.4836172088980675, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21014492753623187, 'r1_recall': 0.4461538461538462, 'r1_f1': 0.28571428571428575, 'pegasus_entailment': 0.8083700452532087, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6213592233009708, 'r1_recall': 0.40764331210191085, 'r1_f1': 0.4923076923076922, 'pegasus_entailment': 0.432745087146759, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20535714285714285, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.2875, 'pegasus_entailment': 0.542569363117218, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3893805309734513, 'r1_recall': 0.4536082474226804, 'r1_f1': 0.41904761904761906, 'pegasus_entailment': 0.4746653698384762, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 25}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1568627450980392, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.2335766423357664, 'pegasus_entailment': 0.4610407739877701, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5098039215686274, 'r1_recall': 0.5360824742268041, 'r1_f1': 0.5226130653266332, 'pegasus_entailment': 0.9117299467325211, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 22}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.34513274336283184, 'r1_f1': 0.4083769633507853, 'pegasus_entailment': 0.6383435229460398, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7538461538461538, 'r1_recall': 0.362962962962963, 'r1_f1': 0.49000000000000005, 'pegasus_entailment': 0.21813106474777064, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2602739726027397, 'r1_recall': 0.35185185185185186, 'r1_f1': 0.2992125984251969, 'pegasus_entailment': 0.49749530851840973, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4214876033057851, 'r1_recall': 0.51, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.691747729976972, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
** Analysing column: malformed_chain



malformed_chain
Length after nones removed
616
MIN
0
MEAN
0
MAX
1
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.0
MEAN
0.4326130414436159
MAX
0.8409090909090909
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.0
MEAN
0.4524040523086409
MAX
0.7407407407407407
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.0
MEAN
0.41537895318090545
MAX
0.6382978723404255
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.0050088192510884255
MEAN
0.5423090794082156
MAX
0.9407915711402893
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
11
MEAN
17
MAX
62
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
11
MEAN
17
MAX
24
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
12
MEAN
20
MAX
79
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
12
MEAN
18
MAX
30
{}
Entered file!
Imports done!
*** RUN *** 
eval_4d
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 14:22:10.249772: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 14:22:10.833566: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/4d_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3968253968253968, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.423728813559322, 'pegasus_entailment': 0.6824628710746765, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5686274509803921, 'r1_recall': 0.3352601156069364, 'r1_f1': 0.42181818181818187, 'pegasus_entailment': 0.6357372179627419, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2013888888888889, 'r1_recall': 0.5, 'r1_f1': 0.28712871287128716, 'pegasus_entailment': 0.5819186195731163, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6732673267326733, 'r1_recall': 0.5271317829457365, 'r1_f1': 0.5913043478260869, 'pegasus_entailment': 0.5527933140595754, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6704545454545454, 'r1_recall': 0.3390804597701149, 'r1_f1': 0.45038167938931295, 'pegasus_entailment': 0.7077048818270365, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4956521739130435, 'r1_recall': 0.43846153846153846, 'r1_f1': 0.46530612244897956, 'pegasus_entailment': 0.5917217507958412, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18681318681318682, 'r1_recall': 0.53125, 'r1_f1': 0.2764227642276423, 'pegasus_entailment': 0.6640037298202515, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.14423076923076922, 'r1_recall': 0.4838709677419355, 'r1_f1': 0.2222222222222222, 'pegasus_entailment': 0.8895704746246338, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4726027397260274, 'r1_recall': 0.46308724832214765, 'r1_f1': 0.46779661016949153, 'pegasus_entailment': 0.5217778205871582, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42592592592592593, 'r1_recall': 0.5, 'r1_f1': 0.46, 'pegasus_entailment': 0.6698823645710945, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4423076923076923, 'r1_recall': 0.46, 'r1_f1': 0.4509803921568628, 'pegasus_entailment': 0.7962338551878929, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33663366336633666, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.4236760124610592, 'pegasus_entailment': 0.7047677887603641, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 17, 'pegasus_ari': 32, 'pegasus_smog': 24}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5657894736842105, 'r1_recall': 0.40186915887850466, 'r1_f1': 0.46994535519125674, 'pegasus_entailment': 0.3507819523413976, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 13}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.366412213740458, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.4383561643835617, 'pegasus_entailment': 0.6351138800382614, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7051282051282052, 'r1_recall': 0.2864583333333333, 'r1_f1': 0.4074074074074074, 'pegasus_entailment': 0.46189987659454346, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23404255319148937, 'r1_recall': 0.3728813559322034, 'r1_f1': 0.28758169934640526, 'pegasus_entailment': 0.520737536251545, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3942307692307692, 'r1_recall': 0.41414141414141414, 'r1_f1': 0.4039408866995074, 'pegasus_entailment': 0.6556699424982071, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7391304347826086, 'r1_recall': 0.22818791946308725, 'r1_f1': 0.34871794871794876, 'pegasus_entailment': 0.4098669911424319, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6753246753246753, 'r1_recall': 0.32298136645962733, 'r1_f1': 0.43697478991596644, 'pegasus_entailment': 0.12367593124508858, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 16}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4605263157894737, 'r1_recall': 0.40229885057471265, 'r1_f1': 0.42944785276073616, 'pegasus_entailment': 0.7320020397504171, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 13}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6728971962616822, 'r1_recall': 0.3956043956043956, 'r1_f1': 0.49826989619377154, 'pegasus_entailment': 0.6945527866482735, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6941176470588235, 'r1_recall': 0.3933333333333333, 'r1_f1': 0.502127659574468, 'pegasus_entailment': 0.3755478113889694, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.494949494949495, 'r1_recall': 0.4537037037037037, 'r1_f1': 0.4734299516908212, 'pegasus_entailment': 0.7169430454572042, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46621621621621623, 'r1_recall': 0.5073529411764706, 'r1_f1': 0.4859154929577465, 'pegasus_entailment': 0.36052846163511276, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2696629213483146, 'r1_recall': 0.48, 'r1_f1': 0.3453237410071942, 'pegasus_entailment': 0.44015560299158096, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6896551724137931, 'r1_recall': 0.42328042328042326, 'r1_f1': 0.5245901639344263, 'pegasus_entailment': 0.8394994735717773, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 19, 'pegasus_ari': 37, 'pegasus_smog': 23}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5434782608695652, 'r1_recall': 0.5474452554744526, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.6514834821224212, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5914634146341463, 'r1_recall': 0.3619402985074627, 'r1_f1': 0.449074074074074, 'pegasus_entailment': 0.45928845927119255, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3783783783783784, 'r1_recall': 0.5526315789473685, 'r1_f1': 0.44919786096256686, 'pegasus_entailment': 0.4816153173645337, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.384, 'r1_recall': 0.4247787610619469, 'r1_f1': 0.40336134453781514, 'pegasus_entailment': 0.8379521846771241, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3157894736842105, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.38181818181818183, 'pegasus_entailment': 0.5964014157652855, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4861111111111111, 'r1_recall': 0.17412935323383086, 'r1_f1': 0.2564102564102564, 'pegasus_entailment': 0.62885682284832, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35964912280701755, 'r1_recall': 0.39805825242718446, 'r1_f1': 0.3778801843317972, 'pegasus_entailment': 0.812696119149526, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5287356321839081, 'r1_recall': 0.4742268041237113, 'r1_f1': 0.4999999999999999, 'pegasus_entailment': 0.5352401168396076, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3282442748091603, 'r1_recall': 0.5119047619047619, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.5466520696878433, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4536082474226804, 'r1_recall': 0.3793103448275862, 'r1_f1': 0.41314553990610325, 'pegasus_entailment': 0.42226370175679523, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4807692307692308, 'r1_recall': 0.7246376811594203, 'r1_f1': 0.5780346820809249, 'pegasus_entailment': 0.8628832101821899, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 24}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31654676258992803, 'r1_recall': 0.6470588235294118, 'r1_f1': 0.42512077294685996, 'pegasus_entailment': 0.5812278650701046, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.14, 'r1_recall': 0.6222222222222222, 'r1_f1': 0.2285714285714286, 'pegasus_entailment': 0.5523331721002857, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5727272727272728, 'r1_recall': 0.3795180722891566, 'r1_f1': 0.4565217391304348, 'pegasus_entailment': 0.45125485584139824, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4827586206896552, 'r1_recall': 0.525, 'r1_f1': 0.5029940119760479, 'pegasus_entailment': 0.5438863515853882, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4636363636363636, 'r1_recall': 0.6623376623376623, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.2089083706960082, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33663366336633666, 'r1_recall': 0.4657534246575342, 'r1_f1': 0.3908045977011495, 'pegasus_entailment': 0.38147178509583074, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43283582089552236, 'r1_recall': 0.4715447154471545, 'r1_f1': 0.4513618677042801, 'pegasus_entailment': 0.23926043547689915, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24257425742574257, 'r1_recall': 0.6282051282051282, 'r1_f1': 0.35, 'pegasus_entailment': 0.7855468307222638, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5465116279069767, 'r1_recall': 0.31333333333333335, 'r1_f1': 0.3983050847457627, 'pegasus_entailment': 0.6910236279169718, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3806818181818182, 'r1_recall': 0.5677966101694916, 'r1_f1': 0.45578231292517013, 'pegasus_entailment': 0.45380348215500516, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4041095890410959, 'r1_recall': 0.5315315315315315, 'r1_f1': 0.45914396887159536, 'pegasus_entailment': 0.786008107662201, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.453781512605042, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.5320197044334976, 'pegasus_entailment': 0.6405413647492727, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23107569721115537, 'r1_recall': 0.5576923076923077, 'r1_f1': 0.32676056338028164, 'pegasus_entailment': 0.6056472318513053, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2304147465437788, 'r1_recall': 0.6756756756756757, 'r1_f1': 0.3436426116838488, 'pegasus_entailment': 0.6639643354075295, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1935483870967742, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.2742857142857143, 'pegasus_entailment': 0.6519939303398132, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3106060606060606, 'r1_recall': 0.5540540540540541, 'r1_f1': 0.39805825242718446, 'pegasus_entailment': 0.6344876140356064, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6233766233766234, 'r1_recall': 0.2711864406779661, 'r1_f1': 0.37795275590551186, 'pegasus_entailment': 0.482756644487381, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.411522633744856, 'r1_recall': 0.5617977528089888, 'r1_f1': 0.4750593824228029, 'pegasus_entailment': 0.5882798373699188, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 32, 'pegasus_smog': 23}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32142857142857145, 'r1_recall': 0.625, 'r1_f1': 0.42452830188679247, 'pegasus_entailment': 0.3380267731845379, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48148148148148145, 'r1_recall': 0.2589641434262948, 'r1_f1': 0.3367875647668394, 'pegasus_entailment': 0.7365295737981796, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3883495145631068, 'r1_recall': 0.625, 'r1_f1': 0.47904191616766467, 'pegasus_entailment': 0.5925164620081583, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5703703703703704, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.6015625000000001, 'pegasus_entailment': 0.5874987598508596, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35526315789473684, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.4202334630350194, 'pegasus_entailment': 0.6291459143161774, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3202247191011236, 'r1_recall': 0.6477272727272727, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.7546314239501953, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2748091603053435, 'r1_recall': 0.5, 'r1_f1': 0.35467980295566504, 'pegasus_entailment': 0.4571150243282318, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.2857142857142857, 'r1_f1': 0.38095238095238093, 'pegasus_entailment': 0.41356510917345685, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4274193548387097, 'r1_recall': 0.5463917525773195, 'r1_f1': 0.4796380090497738, 'pegasus_entailment': 0.5119503989815712, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32710280373831774, 'r1_recall': 0.7291666666666666, 'r1_f1': 0.4516129032258064, 'pegasus_entailment': 0.6208116710186005, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.594059405940594, 'r1_recall': 0.47244094488188976, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.7910556495189667, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.5283018867924528, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.7260216474533081, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39285714285714285, 'r1_recall': 0.5729166666666666, 'r1_f1': 0.46610169491525416, 'pegasus_entailment': 0.4481425344944, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4473684210526316, 'r1_recall': 0.591304347826087, 'r1_f1': 0.5093632958801498, 'pegasus_entailment': 0.39982687756419183, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5728155339805825, 'r1_recall': 0.5784313725490197, 'r1_f1': 0.575609756097561, 'pegasus_entailment': 0.6029195711016655, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5317460317460317, 'r1_recall': 0.4036144578313253, 'r1_f1': 0.45890410958904115, 'pegasus_entailment': 0.9272778332233429, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37373737373737376, 'r1_recall': 0.5441176470588235, 'r1_f1': 0.4431137724550898, 'pegasus_entailment': 0.6709582606951395, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.5909090909090909, 'r1_f1': 0.4262295081967213, 'pegasus_entailment': 0.6957962960004807, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5128205128205128, 'r1_recall': 0.3157894736842105, 'r1_f1': 0.3908794788273615, 'pegasus_entailment': 0.545222540696462, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2236024844720497, 'r1_recall': 0.5, 'r1_f1': 0.3090128755364807, 'pegasus_entailment': 0.8380198329687119, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 30, 'pegasus_smog': 22}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42105263157894735, 'r1_recall': 0.5647058823529412, 'r1_f1': 0.4824120603015075, 'pegasus_entailment': 0.555965625991424, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30344827586206896, 'r1_recall': 0.6875, 'r1_f1': 0.4210526315789474, 'pegasus_entailment': 0.30820968747138977, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3592233009708738, 'r1_recall': 0.7115384615384616, 'r1_f1': 0.47741935483870973, 'pegasus_entailment': 0.2992688212543726, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4948453608247423, 'r1_recall': 0.5581395348837209, 'r1_f1': 0.5245901639344261, 'pegasus_entailment': 0.6558303609490395, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4166666666666667, 'r1_recall': 0.6716417910447762, 'r1_f1': 0.5142857142857143, 'pegasus_entailment': 0.7738731503486633, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4838709677419355, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.6561595102151235, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.6796116504854369, 'r1_f1': 0.6730769230769231, 'pegasus_entailment': 0.46234702070554096, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2714285714285714, 'r1_recall': 0.5846153846153846, 'r1_f1': 0.37073170731707317, 'pegasus_entailment': 0.6708033631245295, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26666666666666666, 'r1_recall': 0.6436781609195402, 'r1_f1': 0.37710437710437705, 'pegasus_entailment': 0.6879108622670174, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 19, 'pegasus_ari': 34, 'pegasus_smog': 25}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43902439024390244, 'r1_recall': 0.5869565217391305, 'r1_f1': 0.5023255813953489, 'pegasus_entailment': 0.6672496497631073, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36792452830188677, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.40414507772020725, 'pegasus_entailment': 0.244438286870718, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1826086956521739, 'r1_recall': 0.2692307692307692, 'r1_f1': 0.21761658031088082, 'pegasus_entailment': 0.7111127078533173, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2909090909090909, 'r1_recall': 0.7111111111111111, 'r1_f1': 0.4129032258064516, 'pegasus_entailment': 0.47958563764890033, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5603448275862069, 'r1_recall': 0.3125, 'r1_f1': 0.4012345679012346, 'pegasus_entailment': 0.4275381252169609, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.275, 'r1_recall': 0.4714285714285714, 'r1_f1': 0.34736842105263155, 'pegasus_entailment': 0.6869345426559448, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5702479338842975, 'r1_recall': 0.359375, 'r1_f1': 0.44089456869009586, 'pegasus_entailment': 0.3744824416935444, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.43283582089552236, 'r1_f1': 0.464, 'pegasus_entailment': 0.6149995774030685, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2648401826484018, 'r1_recall': 0.7945205479452054, 'r1_f1': 0.3972602739726027, 'pegasus_entailment': 0.7273949533700943, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 19, 'pegasus_ari': 35, 'pegasus_smog': 26}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5064935064935064, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.40206185567010305, 'pegasus_entailment': 0.1687775726119677, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29850746268656714, 'r1_recall': 0.41237113402061853, 'r1_f1': 0.3463203463203463, 'pegasus_entailment': 0.47307115606963634, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4794520547945205, 'r1_recall': 0.3954802259887006, 'r1_f1': 0.43343653250773995, 'pegasus_entailment': 0.4550042629241943, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4608695652173913, 'r1_recall': 0.5463917525773195, 'r1_f1': 0.5, 'pegasus_entailment': 0.46111805737018585, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4748201438848921, 'r1_recall': 0.5238095238095238, 'r1_f1': 0.4981132075471698, 'pegasus_entailment': 0.6859835907816887, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.308411214953271, 'r1_recall': 0.5076923076923077, 'r1_f1': 0.38372093023255816, 'pegasus_entailment': 0.6116788923740387, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4424778761061947, 'r1_recall': 0.44642857142857145, 'r1_f1': 0.44444444444444453, 'pegasus_entailment': 0.9184784144163132, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.17391304347826086, 'r1_recall': 0.45901639344262296, 'r1_f1': 0.2522522522522523, 'pegasus_entailment': 0.7221678520242373, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47107438016528924, 'r1_recall': 0.6063829787234043, 'r1_f1': 0.5302325581395348, 'pegasus_entailment': 0.6475442409515381, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.6, 'r1_f1': 0.6, 'pegasus_entailment': 0.74935682117939, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45985401459854014, 'r1_recall': 0.5625, 'r1_f1': 0.5060240963855421, 'pegasus_entailment': 0.5207260958850384, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40298507462686567, 'r1_recall': 0.675, 'r1_f1': 0.5046728971962616, 'pegasus_entailment': 0.6098280698060989, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4859154929577465, 'r1_recall': 0.5348837209302325, 'r1_f1': 0.5092250922509224, 'pegasus_entailment': 0.6512914150953293, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2723404255319149, 'r1_recall': 0.6213592233009708, 'r1_f1': 0.37869822485207105, 'pegasus_entailment': 0.5136680517877851, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 16, 'pegasus_ari': 29, 'pegasus_smog': 20}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4174757281553398, 'r1_recall': 0.5375, 'r1_f1': 0.46994535519125685, 'pegasus_entailment': 0.499687996506691, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5945945945945946, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.5906040268456377, 'pegasus_entailment': 0.2716812137514353, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3130434782608696, 'r1_recall': 0.6, 'r1_f1': 0.4114285714285714, 'pegasus_entailment': 0.8348277360200882, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3416149068322981, 'r1_recall': 0.7971014492753623, 'r1_f1': 0.47826086956521746, 'pegasus_entailment': 0.45278621315956114, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5873015873015873, 'r1_recall': 0.556390977443609, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.7812831848859787, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34265734265734266, 'r1_recall': 0.620253164556962, 'r1_f1': 0.4414414414414414, 'pegasus_entailment': 0.6752449333667755, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4722222222222222, 'r1_recall': 0.5730337078651685, 'r1_f1': 0.5177664974619289, 'pegasus_entailment': 0.4677061066031456, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5068493150684932, 'r1_recall': 0.2846153846153846, 'r1_f1': 0.3645320197044335, 'pegasus_entailment': 0.6288884729146957, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6346153846153846, 'r1_recall': 0.3707865168539326, 'r1_f1': 0.4680851063829787, 'pegasus_entailment': 0.6255332380533218, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7029702970297029, 'r1_recall': 0.4034090909090909, 'r1_f1': 0.5126353790613718, 'pegasus_entailment': 0.5473453005154928, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5095541401273885, 'r1_recall': 0.5970149253731343, 'r1_f1': 0.5498281786941581, 'pegasus_entailment': 0.5061024948954582, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 17, 'pegasus_ari': 32, 'pegasus_smog': 22}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5531914893617021, 'r1_f1': 0.5252525252525252, 'pegasus_entailment': 0.3639340711136659, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6391752577319587, 'r1_recall': 0.4881889763779528, 'r1_f1': 0.5535714285714286, 'pegasus_entailment': 0.5840713456273079, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35802469135802467, 'r1_recall': 0.6590909090909091, 'r1_f1': 0.464, 'pegasus_entailment': 0.7155413776636124, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.46956521739130436, 'r1_f1': 0.5046728971962616, 'pegasus_entailment': 0.4201439917087555, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2582781456953642, 'r1_recall': 0.5131578947368421, 'r1_f1': 0.3436123348017621, 'pegasus_entailment': 0.7307795782883962, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23076923076923078, 'r1_recall': 0.627906976744186, 'r1_f1': 0.33749999999999997, 'pegasus_entailment': 0.5469348579645157, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21428571428571427, 'r1_recall': 0.75, 'r1_f1': 0.3333333333333333, 'pegasus_entailment': 0.692457507054011, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5846153846153846, 'r1_recall': 0.5801526717557252, 'r1_f1': 0.582375478927203, 'pegasus_entailment': 0.5199411734938622, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36220472440944884, 'r1_recall': 0.575, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.5018838588148355, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4935064935064935, 'r1_recall': 0.6495726495726496, 'r1_f1': 0.5608856088560885, 'pegasus_entailment': 0.6280867010354996, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5172413793103449, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.5172413793103449, 'pegasus_entailment': 0.8495633602142334, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19463087248322147, 'r1_recall': 0.4915254237288136, 'r1_f1': 0.2788461538461538, 'pegasus_entailment': 0.7905048926671346, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 25}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6635514018691588, 'r1_recall': 0.37566137566137564, 'r1_f1': 0.47972972972972977, 'pegasus_entailment': 0.7368868514895439, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5104895104895105, 'r1_recall': 0.6033057851239669, 'r1_f1': 0.5530303030303031, 'pegasus_entailment': 0.8710180997848511, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6947368421052632, 'r1_recall': 0.4258064516129032, 'r1_f1': 0.528, 'pegasus_entailment': 0.9108580549558004, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4540540540540541, 'r1_recall': 0.5153374233128835, 'r1_f1': 0.4827586206896552, 'pegasus_entailment': 0.48352392129600047, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 25}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33962264150943394, 'r1_recall': 0.5346534653465347, 'r1_f1': 0.41538461538461535, 'pegasus_entailment': 0.59184155985713, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3717277486910995, 'r1_recall': 0.5867768595041323, 'r1_f1': 0.4551282051282052, 'pegasus_entailment': 0.3255526236219642, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.44642857142857145, 'r1_recall': 0.5376344086021505, 'r1_f1': 0.48780487804878053, 'pegasus_entailment': 0.5299431700259447, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5641025641025641, 'r1_recall': 0.49624060150375937, 'r1_f1': 0.528, 'pegasus_entailment': 0.7933502594629923, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 25}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4936708860759494, 'r1_recall': 0.42162162162162165, 'r1_f1': 0.45481049562682213, 'pegasus_entailment': 0.5158432573080063, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29292929292929293, 'r1_recall': 0.5, 'r1_f1': 0.36942675159235666, 'pegasus_entailment': 0.5437066406011581, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40860215053763443, 'r1_recall': 0.4318181818181818, 'r1_f1': 0.4198895027624309, 'pegasus_entailment': 0.6041301091512045, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 24}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5432098765432098, 'r1_recall': 0.4731182795698925, 'r1_f1': 0.5057471264367815, 'pegasus_entailment': 0.641731878121694, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45454545454545453, 'r1_recall': 0.4424778761061947, 'r1_f1': 0.44843049327354256, 'pegasus_entailment': 0.21802380681037903, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4166666666666667, 'r1_recall': 0.5625, 'r1_f1': 0.4787234042553191, 'pegasus_entailment': 0.48097849637269974, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4945054945054945, 'r1_recall': 0.44554455445544555, 'r1_f1': 0.46875, 'pegasus_entailment': 0.21232455472151437, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5411764705882353, 'r1_recall': 0.44019138755980863, 'r1_f1': 0.48548812664907653, 'pegasus_entailment': 0.619049554069837, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5546875, 'r1_recall': 0.39226519337016574, 'r1_f1': 0.4595469255663431, 'pegasus_entailment': 0.7513683557510376, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.16666666666666666, 'r1_recall': 0.4745762711864407, 'r1_f1': 0.24669603524229072, 'pegasus_entailment': 0.7099157571792603, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6442307692307693, 'r1_recall': 0.41358024691358025, 'r1_f1': 0.5037593984962406, 'pegasus_entailment': 0.556444471081098, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4563106796116505, 'r1_recall': 0.573170731707317, 'r1_f1': 0.5081081081081081, 'pegasus_entailment': 0.3860044330358505, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.4479166666666667, 'r1_f1': 0.38222222222222224, 'pegasus_entailment': 0.5132814149061838, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5402298850574713, 'r1_recall': 0.5108695652173914, 'r1_f1': 0.5251396648044694, 'pegasus_entailment': 0.5189878270030022, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.3711340206185567, 'r1_f1': 0.44171779141104295, 'pegasus_entailment': 0.6399687826633453, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.29518072289156627, 'r1_f1': 0.40329218106995884, 'pegasus_entailment': 0.36372479796409607, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43157894736842106, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.5324675324675325, 'pegasus_entailment': 0.7651903629302979, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5352112676056338, 'r1_recall': 0.4393063583815029, 'r1_f1': 0.48253968253968255, 'pegasus_entailment': 0.46635784829656285, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45569620253164556, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.44999999999999996, 'pegasus_entailment': 0.48639512062072754, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5818181818181818, 'r1_recall': 0.42953020134228187, 'r1_f1': 0.49420849420849416, 'pegasus_entailment': 0.7912209928035736, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38571428571428573, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.463519313304721, 'pegasus_entailment': 0.6803560554981232, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5230769230769231, 'r1_recall': 0.422360248447205, 'r1_f1': 0.4673539518900344, 'pegasus_entailment': 0.6953776776790619, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18791946308724833, 'r1_recall': 0.7368421052631579, 'r1_f1': 0.29946524064171126, 'pegasus_entailment': 0.8741945922374725, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 23, 'pegasus_ari': 30, 'pegasus_smog': 25}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5274725274725275, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4824120603015075, 'pegasus_entailment': 0.6484984997659922, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3270440251572327, 'r1_recall': 0.5048543689320388, 'r1_f1': 0.3969465648854962, 'pegasus_entailment': 0.8586050629615783, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5739130434782609, 'r1_recall': 0.4049079754601227, 'r1_f1': 0.4748201438848921, 'pegasus_entailment': 0.8403865993022919, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43283582089552236, 'r1_recall': 0.5321100917431193, 'r1_f1': 0.47736625514403286, 'pegasus_entailment': 0.8101166784763336, 'pegasus_flesch_kincaid': 34, 'pegasus_coleman_liau': 18, 'pegasus_ari': 41, 'pegasus_smog': 27}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5298507462686567, 'r1_recall': 0.4034090909090909, 'r1_f1': 0.4580645161290322, 'pegasus_entailment': 0.6484633516520262, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.4, 'r1_f1': 0.46511627906976744, 'pegasus_entailment': 0.35678994841873646, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6129032258064516, 'r1_recall': 0.40714285714285714, 'r1_f1': 0.4892703862660944, 'pegasus_entailment': 0.5301507357507944, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5087719298245614, 'r1_recall': 0.38926174496644295, 'r1_f1': 0.44106463878326996, 'pegasus_entailment': 0.5932484567165375, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3472222222222222, 'r1_recall': 0.5494505494505495, 'r1_f1': 0.425531914893617, 'pegasus_entailment': 0.6721979677677155, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3026315789473684, 'r1_recall': 0.2987012987012987, 'r1_f1': 0.3006535947712418, 'pegasus_entailment': 0.697330430150032, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 13, 'pegasus_ari': 12, 'pegasus_smog': 16}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3357142857142857, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.4413145539906103, 'pegasus_entailment': 0.49902207404375076, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.722972972972973, 'r1_recall': 0.2907608695652174, 'r1_f1': 0.4147286821705426, 'pegasus_entailment': 0.5575394749641418, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3836477987421384, 'r1_recall': 0.5545454545454546, 'r1_f1': 0.4535315985130112, 'pegasus_entailment': 0.7143666744232178, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3007518796992481, 'r1_recall': 0.3225806451612903, 'r1_f1': 0.311284046692607, 'pegasus_entailment': 0.49537107944488523, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6326530612244898, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.5688073394495414, 'pegasus_entailment': 0.6046841790278753, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4539877300613497, 'r1_recall': 0.3148936170212766, 'r1_f1': 0.371859296482412, 'pegasus_entailment': 0.6383329331874847, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5121951219512195, 'r1_recall': 0.4144736842105263, 'r1_f1': 0.4581818181818182, 'pegasus_entailment': 0.3470785127331813, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42528735632183906, 'r1_recall': 0.43023255813953487, 'r1_f1': 0.4277456647398844, 'pegasus_entailment': 0.7831079959869385, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3252032520325203, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.40404040404040403, 'pegasus_entailment': 0.7673445492982864, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36633663366336633, 'r1_recall': 0.4111111111111111, 'r1_f1': 0.387434554973822, 'pegasus_entailment': 0.5234202668070793, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.3048780487804878, 'r1_f1': 0.39370078740157477, 'pegasus_entailment': 0.5305498749017715, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49411764705882355, 'r1_recall': 0.2926829268292683, 'r1_f1': 0.3676148796498906, 'pegasus_entailment': 0.8773038029670716, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6428571428571429, 'r1_recall': 0.3016759776536313, 'r1_f1': 0.41064638783269963, 'pegasus_entailment': 0.6157128885388374, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.53, 'r1_recall': 0.4649122807017544, 'r1_f1': 0.4953271028037384, 'pegasus_entailment': 0.6833080053329468, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.4545454545454546, 'pegasus_entailment': 0.3834381525715192, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.352, 'r1_recall': 0.4230769230769231, 'r1_f1': 0.38427947598253276, 'pegasus_entailment': 0.683808259665966, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5797101449275363, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5228758169934641, 'pegasus_entailment': 0.6074614226818085, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6869565217391305, 'r1_recall': 0.4876543209876543, 'r1_f1': 0.5703971119133574, 'pegasus_entailment': 0.7062834153572718, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4222222222222222, 'r1_recall': 0.7402597402597403, 'r1_f1': 0.5377358490566039, 'pegasus_entailment': 0.5432080663740635, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6770833333333334, 'r1_recall': 0.4513888888888889, 'r1_f1': 0.5416666666666666, 'pegasus_entailment': 0.49320675525814295, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4942528735632184, 'r1_recall': 0.5733333333333334, 'r1_f1': 0.5308641975308641, 'pegasus_entailment': 0.23694773763418198, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 16, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6181818181818182, 'r1_recall': 0.5619834710743802, 'r1_f1': 0.5887445887445888, 'pegasus_entailment': 0.5619906070642173, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4794520547945205, 'r1_recall': 0.6306306306306306, 'r1_f1': 0.5447470817120623, 'pegasus_entailment': 0.8994577527046204, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.49079754601226994, 'r1_f1': 0.49535603715170273, 'pegasus_entailment': 0.5775211110711098, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5982142857142857, 'r1_recall': 0.3806818181818182, 'r1_f1': 0.46527777777777773, 'pegasus_entailment': 0.4774711982657512, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38095238095238093, 'r1_recall': 0.6, 'r1_f1': 0.4660194174757281, 'pegasus_entailment': 0.3170567639172077, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26732673267326734, 'r1_recall': 0.45, 'r1_f1': 0.33540372670807456, 'pegasus_entailment': 0.6648279130458832, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3655913978494624, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.7547224462032318, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44715447154471544, 'r1_recall': 0.5612244897959183, 'r1_f1': 0.4977375565610859, 'pegasus_entailment': 0.7800070494413376, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5374149659863946, 'r1_recall': 0.6076923076923076, 'r1_f1': 0.5703971119133574, 'pegasus_entailment': 0.5509300778309504, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 19, 'pegasus_ari': 32, 'pegasus_smog': 24}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.4507042253521127, 'pegasus_entailment': 0.5549934307734171, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48760330578512395, 'r1_recall': 0.5175438596491229, 'r1_f1': 0.5021276595744681, 'pegasus_entailment': 0.4413235694169998, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3223684210526316, 'r1_recall': 0.44144144144144143, 'r1_f1': 0.3726235741444867, 'pegasus_entailment': 0.6065176486968994, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5255474452554745, 'r1_recall': 0.3287671232876712, 'r1_f1': 0.4044943820224719, 'pegasus_entailment': 0.4354793168604374, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5540540540540541, 'r1_recall': 0.5, 'r1_f1': 0.5256410256410257, 'pegasus_entailment': 0.24436848362286887, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3431952662721893, 'r1_recall': 0.6590909090909091, 'r1_f1': 0.4513618677042801, 'pegasus_entailment': 0.8201033075650533, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 18, 'pegasus_ari': 35, 'pegasus_smog': 25}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4266666666666667, 'r1_recall': 0.6336633663366337, 'r1_f1': 0.5099601593625499, 'pegasus_entailment': 0.5850139458974203, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 21, 'pegasus_ari': 34, 'pegasus_smog': 27}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49514563106796117, 'r1_recall': 0.4722222222222222, 'r1_f1': 0.4834123222748815, 'pegasus_entailment': 0.614153541624546, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2109375, 'r1_recall': 0.5625, 'r1_f1': 0.3068181818181818, 'pegasus_entailment': 0.5658971901450839, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4217687074829932, 'r1_recall': 0.6262626262626263, 'r1_f1': 0.5040650406504066, 'pegasus_entailment': 0.4652121990919113, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45394736842105265, 'r1_recall': 0.43670886075949367, 'r1_f1': 0.44516129032258067, 'pegasus_entailment': 0.6166246434052786, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3939393939393939, 'r1_recall': 0.41139240506329117, 'r1_f1': 0.4024767801857585, 'pegasus_entailment': 0.5007608667016029, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.37823834196891193, 'r1_f1': 0.4306784660766962, 'pegasus_entailment': 0.5021910846233368, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.675, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.5837837837837838, 'pegasus_entailment': 0.34159062554438907, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.453781512605042, 'r1_recall': 0.432, 'r1_f1': 0.4426229508196721, 'pegasus_entailment': 0.24460200841228166, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25210084033613445, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.3508771929824561, 'pegasus_entailment': 0.3313531638123095, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2814814814814815, 'r1_recall': 0.6229508196721312, 'r1_f1': 0.38775510204081637, 'pegasus_entailment': 0.43183411955833434, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3125, 'r1_recall': 0.5645161290322581, 'r1_f1': 0.40229885057471265, 'pegasus_entailment': 0.5294145550578833, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1893491124260355, 'r1_recall': 0.5423728813559322, 'r1_f1': 0.2807017543859649, 'pegasus_entailment': 0.32071146679421264, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49056603773584906, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.4727272727272727, 'pegasus_entailment': 0.6223471760749817, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36538461538461536, 'r1_recall': 0.3838383838383838, 'r1_f1': 0.37438423645320196, 'pegasus_entailment': 0.4895460208257039, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2222222222222222, 'r1_recall': 0.6, 'r1_f1': 0.32432432432432434, 'pegasus_entailment': 0.529063805937767, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47761194029850745, 'r1_recall': 0.5549132947976878, 'r1_f1': 0.5133689839572192, 'pegasus_entailment': 0.8267014026641846, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42748091603053434, 'r1_recall': 0.7, 'r1_f1': 0.5308056872037914, 'pegasus_entailment': 0.4964873883873224, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5645161290322581, 'r1_recall': 0.39325842696629215, 'r1_f1': 0.46357615894039744, 'pegasus_entailment': 0.5166783556342125, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6698113207547169, 'r1_recall': 0.4409937888198758, 'r1_f1': 0.5318352059925093, 'pegasus_entailment': 0.5882354566827417, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5853658536585366, 'r1_recall': 0.3582089552238806, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.47889408965905506, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5833333333333334, 'r1_recall': 0.3168724279835391, 'r1_f1': 0.4106666666666666, 'pegasus_entailment': 0.5465928196907044, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38461538461538464, 'r1_recall': 0.4878048780487805, 'r1_f1': 0.4301075268817205, 'pegasus_entailment': 0.5677998140454292, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6052631578947368, 'r1_recall': 0.45394736842105265, 'r1_f1': 0.518796992481203, 'pegasus_entailment': 0.8344534575939179, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3018867924528302, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.3595505617977528, 'pegasus_entailment': 0.410344036668539, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4583333333333333, 'r1_recall': 0.24663677130044842, 'r1_f1': 0.3206997084548105, 'pegasus_entailment': 0.6149827813108762, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1956521739130435, 'r1_recall': 0.1592920353982301, 'r1_f1': 0.17560975609756097, 'pegasus_entailment': 0.26743745245039463, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2857142857142857, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.4050632911392405, 'pegasus_entailment': 0.6303880512714386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6593406593406593, 'r1_recall': 0.3314917127071823, 'r1_f1': 0.4411764705882353, 'pegasus_entailment': 0.30529781182607013, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6146788990825688, 'r1_recall': 0.3785310734463277, 'r1_f1': 0.4685314685314685, 'pegasus_entailment': 0.05268533527851105, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3798449612403101, 'r1_recall': 0.5104166666666666, 'r1_f1': 0.43555555555555553, 'pegasus_entailment': 0.599535446614027, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4068965517241379, 'r1_f1': 0.44866920152091255, 'pegasus_entailment': 0.4874484002590179, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.15315315315315314, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.2446043165467626, 'pegasus_entailment': 0.5922622121870518, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.43103448275862066, 'r1_f1': 0.3164556962025316, 'pegasus_entailment': 0.5572028135259947, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39655172413793105, 'r1_recall': 0.5798319327731093, 'r1_f1': 0.4709897610921502, 'pegasus_entailment': 0.5499162894363204, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 18, 'pegasus_ari': 36, 'pegasus_smog': 23}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28703703703703703, 'r1_recall': 0.43661971830985913, 'r1_f1': 0.34636871508379885, 'pegasus_entailment': 0.47950727740923565, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2872340425531915, 'r1_recall': 0.4909090909090909, 'r1_f1': 0.36241610738255037, 'pegasus_entailment': 0.3267084062099457, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21774193548387097, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.2634146341463415, 'pegasus_entailment': 0.5806071077074323, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5504587155963303, 'r1_recall': 0.7407407407407407, 'r1_f1': 0.631578947368421, 'pegasus_entailment': 0.33222929798066614, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46, 'r1_recall': 0.5542168674698795, 'r1_f1': 0.5027322404371585, 'pegasus_entailment': 0.8068022131919861, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6455696202531646, 'r1_recall': 0.4594594594594595, 'r1_f1': 0.5368421052631579, 'pegasus_entailment': 0.1039400032411019, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7471264367816092, 'r1_recall': 0.19345238095238096, 'r1_f1': 0.3073286052009457, 'pegasus_entailment': 0.39634081224600476, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.28378378378378377, 'r1_f1': 0.3716814159292035, 'pegasus_entailment': 0.4781278133392334, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24864864864864866, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.34980988593155893, 'pegasus_entailment': 0.7397907291139875, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5066666666666667, 'r1_recall': 0.36538461538461536, 'r1_f1': 0.4245810055865922, 'pegasus_entailment': 0.13564915931783617, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.4520547945205479, 'r1_f1': 0.38372093023255816, 'pegasus_entailment': 0.5741937547922135, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3917525773195876, 'r1_recall': 0.5846153846153846, 'r1_f1': 0.4691358024691358, 'pegasus_entailment': 0.4293230672677358, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26582278481012656, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.3652173913043478, 'pegasus_entailment': 0.7476684749126434, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41964285714285715, 'r1_recall': 0.5802469135802469, 'r1_f1': 0.48704663212435234, 'pegasus_entailment': 0.5047798243661722, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.267515923566879, 'r1_recall': 0.5526315789473685, 'r1_f1': 0.3605150214592275, 'pegasus_entailment': 0.5981065601110458, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3157894736842105, 'r1_recall': 0.5, 'r1_f1': 0.3870967741935484, 'pegasus_entailment': 0.6460579201579094, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7228915662650602, 'r1_recall': 0.3821656050955414, 'r1_f1': 0.5, 'pegasus_entailment': 0.7580114801724752, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7160493827160493, 'r1_recall': 0.4027777777777778, 'r1_f1': 0.5155555555555555, 'pegasus_entailment': 0.3124244795180857, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 13}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3581081081081081, 'r1_recall': 0.5638297872340425, 'r1_f1': 0.4380165289256198, 'pegasus_entailment': 0.7876935501893362, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48677248677248675, 'r1_recall': 0.4816753926701571, 'r1_f1': 0.4842105263157894, 'pegasus_entailment': 0.48507613795144217, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3275862068965517, 'r1_recall': 0.7755102040816326, 'r1_f1': 0.46060606060606063, 'pegasus_entailment': 0.6348278522491455, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3291139240506329, 'r1_recall': 0.6265060240963856, 'r1_f1': 0.4315352697095436, 'pegasus_entailment': 0.6758895337581634, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5119047619047619, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.5308641975308642, 'pegasus_entailment': 0.39433990940451624, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2876712328767123, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.37004405286343617, 'pegasus_entailment': 0.5438168719410896, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7307692307692307, 'r1_recall': 0.41605839416058393, 'r1_f1': 0.5302325581395348, 'pegasus_entailment': 0.5818230137228966, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2441860465116279, 'r1_recall': 0.4772727272727273, 'r1_f1': 0.3230769230769231, 'pegasus_entailment': 0.5661984086036682, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22115384615384615, 'r1_recall': 0.3898305084745763, 'r1_f1': 0.28220858895705525, 'pegasus_entailment': 0.5195902585983276, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5238095238095238, 'r1_recall': 0.4925373134328358, 'r1_f1': 0.5076923076923077, 'pegasus_entailment': 0.6636623203754425, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.3717948717948718, 'r1_f1': 0.477366255144033, 'pegasus_entailment': 0.5094960257411003, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3977272727272727, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.45751633986928103, 'pegasus_entailment': 0.5160984359681606, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34306569343065696, 'r1_recall': 0.5340909090909091, 'r1_f1': 0.4177777777777778, 'pegasus_entailment': 0.8770654052495956, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3522727272727273, 'r1_recall': 0.36904761904761907, 'r1_f1': 0.36046511627906974, 'pegasus_entailment': 0.44501233597596485, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2987012987012987, 'r1_recall': 0.5974025974025974, 'r1_f1': 0.39826839826839827, 'pegasus_entailment': 0.5135655283927918, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3723404255319149, 'r1_recall': 0.4375, 'r1_f1': 0.4022988505747126, 'pegasus_entailment': 0.5286263227462769, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42567567567567566, 'r1_recall': 0.40384615384615385, 'r1_f1': 0.4144736842105263, 'pegasus_entailment': 0.5362426578998566, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36363636363636365, 'r1_recall': 0.6842105263157895, 'r1_f1': 0.4748858447488585, 'pegasus_entailment': 0.4765148043632507, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41739130434782606, 'r1_recall': 0.5647058823529412, 'r1_f1': 0.4799999999999999, 'pegasus_entailment': 0.5509168267250061, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5084745762711864, 'r1_recall': 0.4580152671755725, 'r1_f1': 0.48192771084337344, 'pegasus_entailment': 0.7158144176006317, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38596491228070173, 'r1_recall': 0.41509433962264153, 'r1_f1': 0.4, 'pegasus_entailment': 0.3513455558568239, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5058823529411764, 'r1_recall': 0.46994535519125685, 'r1_f1': 0.48725212464589235, 'pegasus_entailment': 0.5070300400257111, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29936305732484075, 'r1_recall': 0.618421052631579, 'r1_f1': 0.40343347639484983, 'pegasus_entailment': 0.8700178146362305, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40268456375838924, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.4979253112033194, 'pegasus_entailment': 0.5542606314023336, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5833333333333334, 'r1_recall': 0.35648148148148145, 'r1_f1': 0.44252873563218387, 'pegasus_entailment': 0.6888301551342011, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42452830188679247, 'r1_recall': 0.44554455445544555, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.49548901338130236, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5897435897435898, 'r1_recall': 0.46938775510204084, 'r1_f1': 0.5227272727272727, 'pegasus_entailment': 0.4346776207288106, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29310344827586204, 'r1_recall': 0.7285714285714285, 'r1_f1': 0.41803278688524587, 'pegasus_entailment': 0.6065086583451679, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.40077821011673154, 'r1_recall': 0.7744360902255639, 'r1_f1': 0.5282051282051282, 'pegasus_entailment': 0.6234767166050997, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4835164835164835, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.4861878453038674, 'pegasus_entailment': 0.6091569438576698, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38738738738738737, 'r1_recall': 0.3739130434782609, 'r1_f1': 0.3805309734513274, 'pegasus_entailment': 0.6163176568225026, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.3302752293577982, 'pegasus_entailment': 0.3723489735275507, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4370860927152318, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.45674740484429066, 'pegasus_entailment': 0.8969698548316956, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 21, 'pegasus_ari': 34, 'pegasus_smog': 24}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.29, 'r1_recall': 0.58, 'r1_f1': 0.3866666666666667, 'pegasus_entailment': 0.2552949278615415, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21348314606741572, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.3247863247863248, 'pegasus_entailment': 0.4763862192630768, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18947368421052632, 'r1_recall': 0.3829787234042553, 'r1_f1': 0.2535211267605634, 'pegasus_entailment': 0.37597400695085526, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 30, 'pegasus_smog': 19}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48, 'r1_recall': 0.5070422535211268, 'r1_f1': 0.4931506849315068, 'pegasus_entailment': 0.7480948269367218, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5759493670886076, 'r1_recall': 0.4972677595628415, 'r1_f1': 0.5337243401759532, 'pegasus_entailment': 0.6734031438827515, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4506172839506173, 'r1_recall': 0.5328467153284672, 'r1_f1': 0.4882943143812709, 'pegasus_entailment': 0.6203620073695978, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4329896907216495, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.44680851063829785, 'pegasus_entailment': 0.6662890712420145, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4198473282442748, 'r1_recall': 0.41353383458646614, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.44465828835964205, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5743243243243243, 'r1_recall': 0.5182926829268293, 'r1_f1': 0.5448717948717948, 'pegasus_entailment': 0.71657395362854, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.69375, 'r1_recall': 0.5522388059701493, 'r1_f1': 0.6149584487534625, 'pegasus_entailment': 0.762406176328659, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34959349593495936, 'r1_recall': 0.43, 'r1_f1': 0.3856502242152467, 'pegasus_entailment': 0.495508648455143, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6233766233766234, 'r1_recall': 0.6, 'r1_f1': 0.6114649681528662, 'pegasus_entailment': 0.4482438067595164, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4339622641509434, 'r1_recall': 0.5609756097560976, 'r1_f1': 0.4893617021276596, 'pegasus_entailment': 0.32097773253917694, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.16025641025641027, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.2450980392156863, 'pegasus_entailment': 0.7812059819698334, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3026315789473684, 'r1_recall': 0.36507936507936506, 'r1_f1': 0.33093525179856115, 'pegasus_entailment': 0.49072156349817914, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21782178217821782, 'r1_recall': 0.6470588235294118, 'r1_f1': 0.32592592592592595, 'pegasus_entailment': 0.6100705688198408, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31683168316831684, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.36158192090395475, 'pegasus_entailment': 0.26895213406533003, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6126760563380281, 'r1_recall': 0.47282608695652173, 'r1_f1': 0.5337423312883435, 'pegasus_entailment': 0.7562690717833382, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2897196261682243, 'r1_recall': 0.4626865671641791, 'r1_f1': 0.3563218390804598, 'pegasus_entailment': 0.8258875966072082, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.549618320610687, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.4816053511705685, 'pegasus_entailment': 0.47294656932353973, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5213675213675214, 'r1_recall': 0.4621212121212121, 'r1_f1': 0.48995983935742976, 'pegasus_entailment': 0.7540914177894592, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6226415094339622, 'r1_recall': 0.4177215189873418, 'r1_f1': 0.4999999999999999, 'pegasus_entailment': 0.6798119942347208, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6301369863013698, 'r1_recall': 0.3108108108108108, 'r1_f1': 0.41628959276018096, 'pegasus_entailment': 0.7354023307561874, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43209876543209874, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.5147058823529411, 'pegasus_entailment': 0.4167813044041395, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6710526315789473, 'r1_recall': 0.25888324873096447, 'r1_f1': 0.37362637362637363, 'pegasus_entailment': 0.36677392820517224, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3445378151260504, 'r1_recall': 0.6833333333333333, 'r1_f1': 0.4581005586592179, 'pegasus_entailment': 0.4451665077358484, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39855072463768115, 'r1_recall': 0.44715447154471544, 'r1_f1': 0.421455938697318, 'pegasus_entailment': 0.7706815361976623, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5299145299145299, 'r1_recall': 0.5904761904761905, 'r1_f1': 0.5585585585585586, 'pegasus_entailment': 0.502412024885416, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5154639175257731, 'r1_recall': 0.3816793893129771, 'r1_f1': 0.4385964912280702, 'pegasus_entailment': 0.40684792399406433, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2328767123287671, 'r1_recall': 0.5074626865671642, 'r1_f1': 0.3192488262910798, 'pegasus_entailment': 0.5701463669538498, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1787709497206704, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.2711864406779661, 'pegasus_entailment': 0.814157920224326, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.375, 'r1_recall': 0.631578947368421, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.6463349014520645, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4603174603174603, 'r1_recall': 0.453125, 'r1_f1': 0.4566929133858268, 'pegasus_entailment': 0.4527120254933834, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.625, 'r1_recall': 0.33707865168539325, 'r1_f1': 0.43795620437956206, 'pegasus_entailment': 0.4014117121696472, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4896551724137931, 'r1_recall': 0.43558282208588955, 'r1_f1': 0.461038961038961, 'pegasus_entailment': 0.5930702735980352, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5939849624060151, 'r1_recall': 0.40932642487046633, 'r1_f1': 0.4846625766871166, 'pegasus_entailment': 0.4385196268558502, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44360902255639095, 'r1_recall': 0.5841584158415841, 'r1_f1': 0.5042735042735043, 'pegasus_entailment': 0.4391835754116376, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27932960893854747, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.3802281368821293, 'pegasus_entailment': 0.3889525185028712, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3, 'r1_recall': 0.36666666666666664, 'r1_f1': 0.32999999999999996, 'pegasus_entailment': 0.7155306786298752, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2564102564102564, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.35714285714285715, 'pegasus_entailment': 0.8606987357139587, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5315315315315315, 'r1_recall': 0.39864864864864863, 'r1_f1': 0.45559845559845563, 'pegasus_entailment': 0.410373505204916, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5343511450381679, 'r1_recall': 0.5343511450381679, 'r1_f1': 0.5343511450381679, 'pegasus_entailment': 0.4352313160896301, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.584070796460177, 'r1_recall': 0.559322033898305, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.46509765088558197, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.660377358490566, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5932203389830508, 'pegasus_entailment': 0.511324460307757, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4172661870503597, 'r1_recall': 0.48739495798319327, 'r1_f1': 0.4496124031007752, 'pegasus_entailment': 0.369128296772639, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 21, 'pegasus_ari': 32, 'pegasus_smog': 25}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7238095238095238, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.6104417670682731, 'pegasus_entailment': 0.5978423655033112, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5119047619047619, 'r1_recall': 0.4777777777777778, 'r1_f1': 0.49425287356321834, 'pegasus_entailment': 0.6112783451875051, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 14}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38, 'r1_recall': 0.2857142857142857, 'r1_f1': 0.3261802575107296, 'pegasus_entailment': 0.24893486003081003, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.59375, 'r1_recall': 0.3584905660377358, 'r1_f1': 0.4470588235294118, 'pegasus_entailment': 0.6237784400582314, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30973451327433627, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.411764705882353, 'pegasus_entailment': 0.48908229619264604, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4, 'r1_recall': 0.390625, 'r1_f1': 0.3952569169960474, 'pegasus_entailment': 0.5870988756418228, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.445859872611465, 'pegasus_entailment': 0.42484929226338863, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5467625899280576, 'r1_recall': 0.39790575916230364, 'r1_f1': 0.46060606060606063, 'pegasus_entailment': 0.45981679260730746, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5686274509803921, 'r1_recall': 0.3945578231292517, 'r1_f1': 0.465863453815261, 'pegasus_entailment': 0.368163975328207, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5888888888888889, 'r1_recall': 0.34415584415584416, 'r1_f1': 0.4344262295081967, 'pegasus_entailment': 0.5220521613955498, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3816793893129771, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.48543689320388345, 'pegasus_entailment': 0.6588200986385345, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4430379746835443, 'r1_recall': 0.6086956521739131, 'r1_f1': 0.5128205128205128, 'pegasus_entailment': 0.791531252861023, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6055045871559633, 'r1_recall': 0.43137254901960786, 'r1_f1': 0.5038167938931297, 'pegasus_entailment': 0.5750640749931335, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21621621621621623, 'r1_recall': 0.1568627450980392, 'r1_f1': 0.18181818181818182, 'pegasus_entailment': 0.7377347275614738, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35526315789473684, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.4060150375939849, 'pegasus_entailment': 0.4276396594941616, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37962962962962965, 'r1_recall': 0.640625, 'r1_f1': 0.4767441860465116, 'pegasus_entailment': 0.5634049504995347, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21782178217821782, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.3176895306859206, 'pegasus_entailment': 0.5899829609053475, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3185840707964602, 'r1_recall': 0.6792452830188679, 'r1_f1': 0.43373493975903615, 'pegasus_entailment': 0.5873812933762869, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6129032258064516, 'r1_recall': 0.6129032258064516, 'r1_f1': 0.6129032258064516, 'pegasus_entailment': 0.7356514732042948, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5280898876404494, 'r1_recall': 0.8103448275862069, 'r1_f1': 0.6394557823129251, 'pegasus_entailment': 0.6260584592819214, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.675, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.5934065934065933, 'pegasus_entailment': 0.47326292283833027, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5323741007194245, 'r1_recall': 0.46835443037974683, 'r1_f1': 0.4983164983164983, 'pegasus_entailment': 0.4997821867465973, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30357142857142855, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.40236686390532544, 'pegasus_entailment': 0.6699685603380203, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.575, 'r1_recall': 0.46308724832214765, 'r1_f1': 0.5130111524163568, 'pegasus_entailment': 0.4360080696642399, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.509090909090909, 'r1_recall': 0.20437956204379562, 'r1_f1': 0.29166666666666663, 'pegasus_entailment': 0.5641390308737755, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 12, 'pegasus_smog': 14}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31333333333333335, 'r1_recall': 0.7121212121212122, 'r1_f1': 0.43518518518518523, 'pegasus_entailment': 0.5821136116981507, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5060240963855421, 'r1_recall': 0.3783783783783784, 'r1_f1': 0.4329896907216495, 'pegasus_entailment': 0.2701499251027902, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2765957446808511, 'r1_recall': 0.65, 'r1_f1': 0.3880597014925373, 'pegasus_entailment': 0.7377073764801025, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.47244094488188976, 'r1_f1': 0.48582995951417, 'pegasus_entailment': 0.5576547428965568, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6225165562913907, 'r1_recall': 0.47715736040609136, 'r1_f1': 0.5402298850574713, 'pegasus_entailment': 0.5417874827980995, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6134969325153374, 'r1_recall': 0.411522633744856, 'r1_f1': 0.4926108374384237, 'pegasus_entailment': 0.6553518652915955, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6545454545454545, 'r1_recall': 0.5179856115107914, 'r1_f1': 0.5783132530120482, 'pegasus_entailment': 0.5687953531742096, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 18, 'pegasus_ari': 34, 'pegasus_smog': 24}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1503267973856209, 'r1_recall': 0.3150684931506849, 'r1_f1': 0.20353982300884957, 'pegasus_entailment': 0.0056686064635869116, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.16233766233766234, 'r1_recall': 0.4098360655737705, 'r1_f1': 0.23255813953488372, 'pegasus_entailment': 0.9129552841186523, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39416058394160586, 'r1_recall': 0.627906976744186, 'r1_f1': 0.4843049327354261, 'pegasus_entailment': 0.4997490160167217, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42391304347826086, 'r1_recall': 0.527027027027027, 'r1_f1': 0.4698795180722891, 'pegasus_entailment': 0.5294752791523933, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4965986394557823, 'r1_recall': 0.41954022988505746, 'r1_f1': 0.45482866043613707, 'pegasus_entailment': 0.7592558860778809, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.53125, 'r1_recall': 0.3541666666666667, 'r1_f1': 0.425, 'pegasus_entailment': 0.43699680641293526, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6862745098039216, 'r1_recall': 0.358974358974359, 'r1_f1': 0.4713804713804714, 'pegasus_entailment': 0.6077426895499229, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4017857142857143, 'r1_recall': 0.6164383561643836, 'r1_f1': 0.48648648648648657, 'pegasus_entailment': 0.14859412014484405, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43243243243243246, 'r1_recall': 0.64, 'r1_f1': 0.5161290322580645, 'pegasus_entailment': 0.6869301199913025, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42276422764227645, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.4388185654008439, 'pegasus_entailment': 0.7717792093753815, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7954545454545454, 'r1_recall': 0.18617021276595744, 'r1_f1': 0.3017241379310345, 'pegasus_entailment': 0.7618614832560221, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40789473684210525, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.4592592592592593, 'pegasus_entailment': 0.7718746066093445, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5818181818181818, 'r1_recall': 0.38095238095238093, 'r1_f1': 0.46043165467625896, 'pegasus_entailment': 0.6056304574012756, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36538461538461536, 'r1_recall': 0.5891472868217055, 'r1_f1': 0.4510385756676558, 'pegasus_entailment': 0.48989000419775647, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5488721804511278, 'r1_recall': 0.4899328859060403, 'r1_f1': 0.5177304964539007, 'pegasus_entailment': 0.5326553792692721, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.51875, 'r1_recall': 0.4911242603550296, 'r1_f1': 0.5045592705167173, 'pegasus_entailment': 0.7575118939081827, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 24}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4868421052631579, 'r1_recall': 0.5648854961832062, 'r1_f1': 0.5229681978798586, 'pegasus_entailment': 0.3696348664040367, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45918367346938777, 'r1_recall': 0.3629032258064516, 'r1_f1': 0.40540540540540543, 'pegasus_entailment': 0.5528269819915295, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4056603773584906, 'r1_recall': 0.5180722891566265, 'r1_f1': 0.45502645502645506, 'pegasus_entailment': 0.4012715555727482, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.15873015873015872, 'r1_recall': 0.5128205128205128, 'r1_f1': 0.2424242424242424, 'pegasus_entailment': 0.534749872982502, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6233766233766234, 'r1_recall': 0.41379310344827586, 'r1_f1': 0.4974093264248705, 'pegasus_entailment': 0.5041040241718292, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5193798449612403, 'r1_recall': 0.3621621621621622, 'r1_f1': 0.4267515923566879, 'pegasus_entailment': 0.5107179582118988, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.4761904761904762, 'pegasus_entailment': 0.459998682141304, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6028708133971292, 'r1_recall': 0.32727272727272727, 'r1_f1': 0.4242424242424242, 'pegasus_entailment': 0.7005586326122284, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.3819444444444444, 'r1_f1': 0.45267489711934156, 'pegasus_entailment': 0.45800042152404785, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.27380952380952384, 'r1_recall': 0.35384615384615387, 'r1_f1': 0.30872483221476515, 'pegasus_entailment': 0.24303116897741953, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42574257425742573, 'r1_recall': 0.7166666666666667, 'r1_f1': 0.5341614906832298, 'pegasus_entailment': 0.3125486026207606, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22695035460992907, 'r1_recall': 0.3950617283950617, 'r1_f1': 0.2882882882882883, 'pegasus_entailment': 0.7344982862472534, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4461538461538462, 'r1_recall': 0.27884615384615385, 'r1_f1': 0.3431952662721893, 'pegasus_entailment': 0.4833751991391182, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27586206896551724, 'r1_recall': 0.37209302325581395, 'r1_f1': 0.31683168316831684, 'pegasus_entailment': 0.3330857499502599, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4431137724550898, 'r1_recall': 0.47435897435897434, 'r1_f1': 0.45820433436532504, 'pegasus_entailment': 0.6368607640266418, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5723684210526315, 'r1_recall': 0.5272727272727272, 'r1_f1': 0.5488958990536277, 'pegasus_entailment': 0.707263731956482, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33695652173913043, 'r1_recall': 0.5081967213114754, 'r1_f1': 0.40522875816993464, 'pegasus_entailment': 0.7862899005413055, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5490196078431373, 'r1_recall': 0.56, 'r1_f1': 0.5544554455445545, 'pegasus_entailment': 0.5483228074652808, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.328125, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.3835616438356165, 'pegasus_entailment': 0.11411979829426855, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45925925925925926, 'r1_recall': 0.4732824427480916, 'r1_f1': 0.46616541353383456, 'pegasus_entailment': 0.41062010700503987, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38095238095238093, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.4415491670370102, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35507246376811596, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.40329218106995884, 'pegasus_entailment': 0.6935667574405671, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3508771929824561, 'r1_recall': 0.547945205479452, 'r1_f1': 0.42780748663101603, 'pegasus_entailment': 0.8299745718638102, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48514851485148514, 'r1_recall': 0.392, 'r1_f1': 0.4336283185840708, 'pegasus_entailment': 0.11854314431548119, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4603174603174603, 'r1_recall': 0.5087719298245614, 'r1_f1': 0.48333333333333334, 'pegasus_entailment': 0.516285128891468, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4326923076923077, 'r1_recall': 0.5056179775280899, 'r1_f1': 0.4663212435233161, 'pegasus_entailment': 0.6029918566346169, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22093023255813954, 'r1_recall': 0.4418604651162791, 'r1_f1': 0.2945736434108527, 'pegasus_entailment': 0.2599411392584443, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5620915032679739, 'r1_recall': 0.3891402714932127, 'r1_f1': 0.45989304812834225, 'pegasus_entailment': 0.3158192917704582, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4954128440366973, 'r1_recall': 0.4778761061946903, 'r1_f1': 0.48648648648648657, 'pegasus_entailment': 0.3149028620682657, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.08588957055214724, 'r1_recall': 0.3783783783783784, 'r1_f1': 0.14, 'pegasus_entailment': 0.7381334702173868, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39805825242718446, 'r1_recall': 0.5, 'r1_f1': 0.4432432432432432, 'pegasus_entailment': 0.5738617107272148, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3803680981595092, 'r1_recall': 0.5794392523364486, 'r1_f1': 0.45925925925925926, 'pegasus_entailment': 0.5571430772542953, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2398190045248869, 'r1_recall': 0.7361111111111112, 'r1_f1': 0.36177474402730375, 'pegasus_entailment': 0.9280461147427559, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36129032258064514, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.4609053497942387, 'pegasus_entailment': 0.4778699353337288, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.56, 'r1_recall': 0.47191011235955055, 'r1_f1': 0.5121951219512195, 'pegasus_entailment': 0.43460412323474884, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28378378378378377, 'r1_recall': 0.711864406779661, 'r1_f1': 0.40579710144927533, 'pegasus_entailment': 0.5732134938240051, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5308641975308642, 'r1_recall': 0.43434343434343436, 'r1_f1': 0.4777777777777778, 'pegasus_entailment': 0.7116994857788086, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36363636363636365, 'r1_recall': 0.375, 'r1_f1': 0.3692307692307692, 'pegasus_entailment': 0.8535113334655762, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.54, 'r1_recall': 0.574468085106383, 'r1_f1': 0.5567010309278351, 'pegasus_entailment': 0.5541311427950859, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6065573770491803, 'r1_recall': 0.1417624521072797, 'r1_f1': 0.2298136645962733, 'pegasus_entailment': 0.6864154934883118, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49142857142857144, 'r1_recall': 0.43, 'r1_f1': 0.4586666666666666, 'pegasus_entailment': 0.685875877737999, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36538461538461536, 'r1_recall': 0.48717948717948717, 'r1_f1': 0.4175824175824176, 'pegasus_entailment': 0.05701292306184769, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5327102803738317, 'r1_recall': 0.5428571428571428, 'r1_f1': 0.5377358490566037, 'pegasus_entailment': 0.7408960461616516, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.684931506849315, 'r1_recall': 0.36764705882352944, 'r1_f1': 0.47846889952153104, 'pegasus_entailment': 0.6554058839877447, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36597938144329895, 'r1_recall': 0.6283185840707964, 'r1_f1': 0.46254071661237783, 'pegasus_entailment': 0.509281779328982, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31496062992125984, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.37735849056603776, 'pegasus_entailment': 0.8102506200472513, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 19}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3282442748091603, 'r1_recall': 0.6515151515151515, 'r1_f1': 0.4365482233502538, 'pegasus_entailment': 0.8580109179019928, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34074074074074073, 'r1_recall': 0.5, 'r1_f1': 0.4052863436123348, 'pegasus_entailment': 0.47666681557893753, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43373493975903615, 'r1_recall': 0.43373493975903615, 'r1_f1': 0.43373493975903615, 'pegasus_entailment': 0.5982267955938975, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49504950495049505, 'r1_recall': 0.3968253968253968, 'r1_f1': 0.44052863436123346, 'pegasus_entailment': 0.42182695865631104, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.4117647058823529, 'r1_f1': 0.4883720930232558, 'pegasus_entailment': 0.3165529929101467, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5294117647058824, 'r1_recall': 0.33540372670807456, 'r1_f1': 0.41064638783269963, 'pegasus_entailment': 0.3962335079908371, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 13}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23275862068965517, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.3121387283236994, 'pegasus_entailment': 0.4113833077251911, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 13}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5153846153846153, 'r1_recall': 0.29646017699115046, 'r1_f1': 0.37640449438202245, 'pegasus_entailment': 0.5407160988875798, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26515151515151514, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.36458333333333337, 'pegasus_entailment': 0.560765166580677, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34146341463414637, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.4226415094339623, 'pegasus_entailment': 0.6236448138952255, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22302158273381295, 'r1_recall': 0.6326530612244898, 'r1_f1': 0.3297872340425532, 'pegasus_entailment': 0.5812278650701046, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20952380952380953, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.2913907284768212, 'pegasus_entailment': 0.7328237295150757, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4931506849315068, 'r1_f1': 0.496551724137931, 'pegasus_entailment': 0.5661196336150169, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.52, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.5306122448979592, 'pegasus_entailment': 0.4987135112285614, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45652173913043476, 'r1_recall': 0.5675675675675675, 'r1_f1': 0.506024096385542, 'pegasus_entailment': 0.4802439386645953, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5172413793103449, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.4838709677419355, 'pegasus_entailment': 0.2806133007009824, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5154639175257731, 'r1_recall': 0.6024096385542169, 'r1_f1': 0.5555555555555557, 'pegasus_entailment': 0.6526040732860565, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49019607843137253, 'r1_recall': 0.704225352112676, 'r1_f1': 0.5780346820809248, 'pegasus_entailment': 0.5493941903114319, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4088050314465409, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.4744525547445256, 'pegasus_entailment': 0.39803769971643177, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.55, 'r1_recall': 0.3273809523809524, 'r1_f1': 0.4104477611940299, 'pegasus_entailment': 0.3909111022949219, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.17419354838709677, 'r1_recall': 0.5094339622641509, 'r1_f1': 0.25961538461538464, 'pegasus_entailment': 0.6707237064838409, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46153846153846156, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.504201680672269, 'pegasus_entailment': 0.5337561905384064, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6410256410256411, 'r1_recall': 0.22123893805309736, 'r1_f1': 0.32894736842105265, 'pegasus_entailment': 0.7481263875961304, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24444444444444444, 'r1_recall': 0.6197183098591549, 'r1_f1': 0.35059760956175295, 'pegasus_entailment': 0.6403546205588749, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5904761904761905, 'r1_recall': 0.2831050228310502, 'r1_f1': 0.38271604938271603, 'pegasus_entailment': 0.5259489119052887, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.0891089108910891, 'r1_recall': 0.2571428571428571, 'r1_f1': 0.1323529411764706, 'pegasus_entailment': 0.357968058437109, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42748091603053434, 'r1_recall': 0.6746987951807228, 'r1_f1': 0.5233644859813084, 'pegasus_entailment': 0.58500255048275, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18421052631578946, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.27860696517412936, 'pegasus_entailment': 0.6417243219912052, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7165354330708661, 'r1_recall': 0.5352941176470588, 'r1_f1': 0.6127946127946128, 'pegasus_entailment': 0.5547810064163059, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5339805825242718, 'r1_recall': 0.4263565891472868, 'r1_f1': 0.47413793103448276, 'pegasus_entailment': 0.8425373435020447, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4864864864864865, 'r1_recall': 0.6206896551724138, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.8793637752532959, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3485714285714286, 'r1_recall': 0.45864661654135336, 'r1_f1': 0.3961038961038961, 'pegasus_entailment': 0.6271793810384614, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43795620437956206, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.4838709677419355, 'pegasus_entailment': 0.4666520468890667, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4387755102040816, 'r1_recall': 0.4479166666666667, 'r1_f1': 0.44329896907216493, 'pegasus_entailment': 0.32903582602739334, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4233128834355828, 'r1_recall': 0.4928571428571429, 'r1_f1': 0.4554455445544554, 'pegasus_entailment': 0.5338326692581177, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3918918918918919, 'r1_recall': 0.2013888888888889, 'r1_f1': 0.2660550458715597, 'pegasus_entailment': 0.6565234959125519, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6428571428571429, 'r1_recall': 0.4891304347826087, 'r1_f1': 0.5555555555555556, 'pegasus_entailment': 0.5704731345176697, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4396551724137931, 'r1_recall': 0.49514563106796117, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.6268593892455101, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31521739130434784, 'r1_recall': 0.43283582089552236, 'r1_f1': 0.3647798742138365, 'pegasus_entailment': 0.5502661516269048, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4369747899159664, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.49523809523809526, 'pegasus_entailment': 0.4985958725214005, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5882352941176471, 'r1_recall': 0.34965034965034963, 'r1_f1': 0.43859649122807015, 'pegasus_entailment': 0.31213129311800003, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6388888888888888, 'r1_recall': 0.5655737704918032, 'r1_f1': 0.5999999999999999, 'pegasus_entailment': 0.3434752017259598, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5855855855855856, 'r1_recall': 0.39156626506024095, 'r1_f1': 0.4693140794223827, 'pegasus_entailment': 0.5925109386444092, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3229166666666667, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.41059602649006627, 'pegasus_entailment': 0.39554800689220426, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2916666666666667, 'r1_recall': 0.47297297297297297, 'r1_f1': 0.36082474226804123, 'pegasus_entailment': 0.3200051374733448, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6714285714285714, 'r1_recall': 0.46078431372549017, 'r1_f1': 0.5465116279069767, 'pegasus_entailment': 0.7007773220539093, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5230769230769231, 'r1_recall': 0.3148148148148148, 'r1_f1': 0.3930635838150289, 'pegasus_entailment': 0.2852798327803612, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4701492537313433, 'r1_recall': 0.5206611570247934, 'r1_f1': 0.4941176470588236, 'pegasus_entailment': 0.5470733564347029, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45323741007194246, 'r1_recall': 0.4405594405594406, 'r1_f1': 0.4468085106382979, 'pegasus_entailment': 0.18881770595908165, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3617021276595745, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.4473684210526315, 'pegasus_entailment': 0.8386676073074341, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5221238938053098, 'r1_recall': 0.6483516483516484, 'r1_f1': 0.5784313725490197, 'pegasus_entailment': 0.4219191273053487, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4015748031496063, 'r1_recall': 0.5, 'r1_f1': 0.4454148471615721, 'pegasus_entailment': 0.5286959335207939, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.416, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.4351464435146443, 'pegasus_entailment': 0.4927102029323578, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5416666666666666, 'r1_recall': 0.5252525252525253, 'r1_f1': 0.5333333333333332, 'pegasus_entailment': 0.5605950467288494, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2807017543859649, 'r1_recall': 0.3595505617977528, 'r1_f1': 0.31527093596059114, 'pegasus_entailment': 0.6902764439582825, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6379310344827587, 'r1_recall': 0.4539877300613497, 'r1_f1': 0.5304659498207885, 'pegasus_entailment': 0.6492913862069448, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5701754385964912, 'r1_recall': 0.35714285714285715, 'r1_f1': 0.43918918918918914, 'pegasus_entailment': 0.5480795130133629, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5460122699386503, 'r1_recall': 0.3236363636363636, 'r1_f1': 0.4063926940639269, 'pegasus_entailment': 0.6516650458797812, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.41284403669724773, 'r1_f1': 0.45226130653266333, 'pegasus_entailment': 0.8042064706484476, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.16, 'r1_recall': 0.27586206896551724, 'r1_f1': 0.20253164556962025, 'pegasus_entailment': 0.6287918388843536, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 22}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5317460317460317, 'r1_recall': 0.3701657458563536, 'r1_f1': 0.4364820846905537, 'pegasus_entailment': 0.5462090025345484, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38095238095238093, 'r1_recall': 0.5194805194805194, 'r1_f1': 0.43956043956043955, 'pegasus_entailment': 0.4885949678719044, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3656716417910448, 'r1_recall': 0.6125, 'r1_f1': 0.45794392523364486, 'pegasus_entailment': 0.685079038143158, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46835443037974683, 'r1_recall': 0.3978494623655914, 'r1_f1': 0.43023255813953487, 'pegasus_entailment': 0.757545068860054, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32954545454545453, 'r1_recall': 0.7160493827160493, 'r1_f1': 0.45136186770428016, 'pegasus_entailment': 0.5962459345658621, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4485981308411215, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.4873096446700508, 'pegasus_entailment': 0.4809526868164539, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26881720430107525, 'r1_recall': 0.36231884057971014, 'r1_f1': 0.3086419753086419, 'pegasus_entailment': 0.41100579127669334, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43243243243243246, 'r1_recall': 0.5, 'r1_f1': 0.463768115942029, 'pegasus_entailment': 0.4995548754930496, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.29508196721311475, 'r1_recall': 0.5625, 'r1_f1': 0.3870967741935484, 'pegasus_entailment': 0.7077323079109192, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3058823529411765, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.3984674329501916, 'pegasus_entailment': 0.7015162333846092, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46, 'r1_recall': 0.5227272727272727, 'r1_f1': 0.4893617021276596, 'pegasus_entailment': 0.7065130844712257, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4095238095238095, 'r1_recall': 0.6935483870967742, 'r1_f1': 0.5149700598802395, 'pegasus_entailment': 0.4112146405968815, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7560975609756098, 'r1_recall': 0.5794392523364486, 'r1_f1': 0.656084656084656, 'pegasus_entailment': 0.5874106884002686, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25396825396825395, 'r1_recall': 0.5079365079365079, 'r1_f1': 0.3386243386243386, 'pegasus_entailment': 0.43273871690034865, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.72, 'r1_recall': 0.27169811320754716, 'r1_f1': 0.39452054794520547, 'pegasus_entailment': 0.6213047653436661, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.319672131147541, 'r1_recall': 0.609375, 'r1_f1': 0.41935483870967744, 'pegasus_entailment': 0.48132994771003723, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.42391304347826086, 'r1_f1': 0.4588235294117647, 'pegasus_entailment': 0.7894439895947775, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.55, 'r1_f1': 0.5238095238095238, 'pegasus_entailment': 0.8104147762060165, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5053763440860215, 'r1_recall': 0.3357142857142857, 'r1_f1': 0.40343347639484983, 'pegasus_entailment': 0.6362489424645901, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36942675159235666, 'r1_recall': 0.6170212765957447, 'r1_f1': 0.46215139442231074, 'pegasus_entailment': 0.5150635199887412, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42777777777777776, 'r1_recall': 0.6062992125984252, 'r1_f1': 0.501628664495114, 'pegasus_entailment': 0.49465897182623547, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3979591836734694, 'r1_recall': 0.5492957746478874, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.5799070994059244, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39090909090909093, 'r1_recall': 0.4574468085106383, 'r1_f1': 0.42156862745098045, 'pegasus_entailment': 0.6940194845199585, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3247863247863248, 'r1_recall': 0.4523809523809524, 'r1_f1': 0.3781094527363184, 'pegasus_entailment': 0.5837008456389109, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.547945205479452, 'pegasus_entailment': 0.48639654119809467, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4020618556701031, 'r1_recall': 0.582089552238806, 'r1_f1': 0.475609756097561, 'pegasus_entailment': 0.4746134951710701, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4264705882352941, 'r1_recall': 0.453125, 'r1_f1': 0.43939393939393934, 'pegasus_entailment': 0.20600310154259205, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4050632911392405, 'r1_recall': 0.3699421965317919, 'r1_f1': 0.38670694864048333, 'pegasus_entailment': 0.41128528863191605, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.30303030303030304, 'r1_f1': 0.37735849056603776, 'pegasus_entailment': 0.6719743236899376, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5726495726495726, 'r1_recall': 0.6836734693877551, 'r1_f1': 0.6232558139534883, 'pegasus_entailment': 0.4036777839064598, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5949367088607594, 'r1_recall': 0.25133689839572193, 'r1_f1': 0.3533834586466166, 'pegasus_entailment': 0.6943537394205729, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5111111111111111, 'r1_recall': 0.4842105263157895, 'r1_f1': 0.4972972972972973, 'pegasus_entailment': 0.15894924383610487, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35036496350364965, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.4593301435406699, 'pegasus_entailment': 0.5170886740088463, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 24}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35294117647058826, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.8018541733423868, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.17857142857142858, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.27472527472527475, 'pegasus_entailment': 0.5309349472324053, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 32, 'pegasus_smog': 24}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3057324840764331, 'r1_recall': 0.676056338028169, 'r1_f1': 0.4210526315789474, 'pegasus_entailment': 0.6732198894023895, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2246376811594203, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.3263157894736842, 'pegasus_entailment': 0.4503844641149044, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 15}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46875, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.4225352112676056, 'pegasus_entailment': 0.4799688495695591, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6951219512195121, 'r1_recall': 0.4351145038167939, 'r1_f1': 0.5352112676056339, 'pegasus_entailment': 0.5969661176204681, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34532374100719426, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.43049327354260086, 'pegasus_entailment': 0.48278824736674625, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3374485596707819, 'r1_recall': 0.45555555555555555, 'r1_f1': 0.3877068557919622, 'pegasus_entailment': 0.641519695520401, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31451612903225806, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.3627906976744186, 'pegasus_entailment': 0.3157916124910116, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3870967741935484, 'r1_recall': 0.43636363636363634, 'r1_f1': 0.41025641025641024, 'pegasus_entailment': 0.7822289824485779, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4036697247706422, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.4378109452736319, 'pegasus_entailment': 0.5696486756205559, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.40869565217391307, 'r1_recall': 0.47, 'r1_f1': 0.43720930232558136, 'pegasus_entailment': 0.8863131006558737, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2786885245901639, 'r1_recall': 0.4927536231884058, 'r1_f1': 0.35602094240837695, 'pegasus_entailment': 0.5108659267425537, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.6097754538059235, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3472222222222222, 'r1_recall': 0.49019607843137253, 'r1_f1': 0.40650406504065045, 'pegasus_entailment': 0.5120568536221981, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3853211009174312, 'r1_recall': 0.5, 'r1_f1': 0.43523316062176165, 'pegasus_entailment': 0.6004068362526596, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19117647058823528, 'r1_recall': 0.5, 'r1_f1': 0.2765957446808511, 'pegasus_entailment': 0.8319883942604065, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.576271186440678, 'r1_recall': 0.4755244755244755, 'r1_f1': 0.5210727969348659, 'pegasus_entailment': 0.7222629487514496, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3161764705882353, 'r1_recall': 0.4942528735632184, 'r1_f1': 0.38565022421524664, 'pegasus_entailment': 0.537621259689331, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 21}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2932330827067669, 'r1_recall': 0.7222222222222222, 'r1_f1': 0.4171122994652406, 'pegasus_entailment': 0.433865325525403, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4461538461538462, 'r1_recall': 0.4793388429752066, 'r1_f1': 0.4621513944223108, 'pegasus_entailment': 0.7460129737854004, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38372093023255816, 'r1_recall': 0.3173076923076923, 'r1_f1': 0.3473684210526316, 'pegasus_entailment': 0.27430416891972226, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23243243243243245, 'r1_recall': 0.6142857142857143, 'r1_f1': 0.33725490196078434, 'pegasus_entailment': 0.7179190516471863, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3258426966292135, 'r1_recall': 0.4027777777777778, 'r1_f1': 0.36024844720496896, 'pegasus_entailment': 0.2572345808148384, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4939759036144578, 'r1_recall': 0.4606741573033708, 'r1_f1': 0.47674418604651164, 'pegasus_entailment': 0.5117090851068496, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1595744680851064, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.21582733812949642, 'pegasus_entailment': 0.4703440247103572, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6341463414634146, 'r1_recall': 0.5048543689320388, 'r1_f1': 0.5621621621621622, 'pegasus_entailment': 0.40784965828061104, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 15, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.096, 'r1_recall': 0.34285714285714286, 'r1_f1': 0.15000000000000002, 'pegasus_entailment': 0.8680659681558609, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2897196261682243, 'r1_recall': 0.6888888888888889, 'r1_f1': 0.40789473684210525, 'pegasus_entailment': 0.6589789837598801, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23958333333333334, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.34074074074074073, 'pegasus_entailment': 0.6864294409751892, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46153846153846156, 'r1_recall': 0.32432432432432434, 'r1_f1': 0.38095238095238093, 'pegasus_entailment': 0.5010225968435407, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6626506024096386, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.5555555555555556, 'pegasus_entailment': 0.7159710191190243, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38095238095238093, 'r1_recall': 0.5, 'r1_f1': 0.4324324324324324, 'pegasus_entailment': 0.3237232381477952, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37823834196891193, 'r1_recall': 0.6697247706422018, 'r1_f1': 0.48344370860927155, 'pegasus_entailment': 0.4175611183047295, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5841584158415841, 'r1_recall': 0.427536231884058, 'r1_f1': 0.49372384937238495, 'pegasus_entailment': 0.5738877455393473, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8627450980392157, 'r1_recall': 0.25, 'r1_f1': 0.3876651982378855, 'pegasus_entailment': 0.7523957341909409, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3423913043478261, 'r1_recall': 0.5675675675675675, 'r1_f1': 0.42711864406779654, 'pegasus_entailment': 0.5178330285208566, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 15, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5217391304347826, 'r1_recall': 0.40268456375838924, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.717230761051178, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5565217391304348, 'r1_recall': 0.42953020134228187, 'r1_f1': 0.48484848484848486, 'pegasus_entailment': 0.6266189416249593, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23943661971830985, 'r1_recall': 0.3469387755102041, 'r1_f1': 0.2833333333333333, 'pegasus_entailment': 0.20536347726980844, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.376, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.47715736040609136, 'pegasus_entailment': 0.6153819064299265, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36220472440944884, 'r1_recall': 0.5679012345679012, 'r1_f1': 0.4423076923076923, 'pegasus_entailment': 0.8667020797729492, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7456140350877193, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.6439393939393938, 'pegasus_entailment': 0.678423007329305, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4375, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.47619047619047616, 'pegasus_entailment': 0.5074019357562065, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6822429906542056, 'r1_recall': 0.42441860465116277, 'r1_f1': 0.5232974910394265, 'pegasus_entailment': 0.5912971720099449, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2702702702702703, 'r1_recall': 0.40540540540540543, 'r1_f1': 0.32432432432432434, 'pegasus_entailment': 0.4283098742986719, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3464566929133858, 'r1_recall': 0.5432098765432098, 'r1_f1': 0.423076923076923, 'pegasus_entailment': 0.860005795955658, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6266666666666667, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.43518518518518523, 'pegasus_entailment': 0.45874395594000816, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38848920863309355, 'r1_recall': 0.4122137404580153, 'r1_f1': 0.4, 'pegasus_entailment': 0.6802885830402374, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6261682242990654, 'r1_recall': 0.3145539906103286, 'r1_f1': 0.41874999999999996, 'pegasus_entailment': 0.660820260643959, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6052631578947368, 'r1_recall': 0.5111111111111111, 'r1_f1': 0.5542168674698796, 'pegasus_entailment': 0.4378681778907776, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4857142857142857, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.5354330708661418, 'pegasus_entailment': 0.261933612326781, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5128205128205128, 'r1_recall': 0.42328042328042326, 'r1_f1': 0.463768115942029, 'pegasus_entailment': 0.46818788970510167, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7008547008547008, 'r1_recall': 0.26973684210526316, 'r1_f1': 0.3895486935866983, 'pegasus_entailment': 0.37353979237377644, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.17391304347826086, 'r1_recall': 0.38095238095238093, 'r1_f1': 0.2388059701492537, 'pegasus_entailment': 0.43062706167499226, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 15, 'pegasus_ari': 28, 'pegasus_smog': 18}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48672566371681414, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.5288461538461539, 'pegasus_entailment': 0.7837449113527933, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4873417721518987, 'r1_f1': 0.4935897435897436, 'pegasus_entailment': 0.42688311263918877, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31521739130434784, 'r1_recall': 0.5, 'r1_f1': 0.38666666666666666, 'pegasus_entailment': 0.6884965101877848, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5309734513274337, 'r1_recall': 0.3314917127071823, 'r1_f1': 0.40816326530612246, 'pegasus_entailment': 0.7359732290108999, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46258503401360546, 'r1_recall': 0.4788732394366197, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.4178690383210778, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4631578947368421, 'r1_f1': 0.4808743169398907, 'pegasus_entailment': 0.5001506224274636, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4806201550387597, 'r1_recall': 0.36046511627906974, 'r1_f1': 0.4119601328903655, 'pegasus_entailment': 0.7545133978128433, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20238095238095238, 'r1_recall': 0.4788732394366197, 'r1_f1': 0.28451882845188287, 'pegasus_entailment': 0.7323256110151609, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6083333333333333, 'r1_recall': 0.35096153846153844, 'r1_f1': 0.44512195121951215, 'pegasus_entailment': 0.5621624663472176, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36619718309859156, 'r1_recall': 0.5591397849462365, 'r1_f1': 0.4425531914893617, 'pegasus_entailment': 0.8670334219932556, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.25316455696202533, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.3433476394849786, 'pegasus_entailment': 0.84941299756368, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45454545454545453, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.5294117647058822, 'pegasus_entailment': 0.30721643194556236, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3918918918918919, 'r1_recall': 0.5742574257425742, 'r1_f1': 0.465863453815261, 'pegasus_entailment': 0.594660472869873, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7567567567567568, 'r1_recall': 0.4057971014492754, 'r1_f1': 0.5283018867924528, 'pegasus_entailment': 0.8109438866376877, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.453781512605042, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.48868778280542985, 'pegasus_entailment': 0.7373379270235697, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26732673267326734, 'r1_recall': 0.45, 'r1_f1': 0.33540372670807456, 'pegasus_entailment': 0.741004467010498, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5612903225806452, 'r1_recall': 0.4887640449438202, 'r1_f1': 0.5225225225225225, 'pegasus_entailment': 0.6211662366986275, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4090909090909091, 'r1_recall': 0.6164383561643836, 'r1_f1': 0.4918032786885246, 'pegasus_entailment': 0.4814765527844429, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3424657534246575, 'r1_recall': 0.6578947368421053, 'r1_f1': 0.45045045045045046, 'pegasus_entailment': 0.5830058604478836, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45925925925925926, 'r1_recall': 0.6813186813186813, 'r1_f1': 0.5486725663716815, 'pegasus_entailment': 0.677553141117096, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5684210526315789, 'r1_recall': 0.45, 'r1_f1': 0.5023255813953489, 'pegasus_entailment': 0.5579778080185255, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7715736040609137, 'r1_recall': 0.21560283687943263, 'r1_f1': 0.3370288248337029, 'pegasus_entailment': 0.6686703994870186, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5214285714285715, 'r1_recall': 0.5140845070422535, 'r1_f1': 0.5177304964539008, 'pegasus_entailment': 0.6917146941026052, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3786407766990291, 'r1_recall': 0.21311475409836064, 'r1_f1': 0.2727272727272727, 'pegasus_entailment': 0.676158090432485, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 15}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43820224719101125, 'r1_recall': 0.41935483870967744, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.6923532262444496, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45751633986928103, 'r1_recall': 0.603448275862069, 'r1_f1': 0.5204460966542751, 'pegasus_entailment': 0.47304921721418697, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.6615384615384615, 'r1_f1': 0.5695364238410596, 'pegasus_entailment': 0.458989957968394, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6039603960396039, 'r1_recall': 0.3885350318471338, 'r1_f1': 0.4728682170542636, 'pegasus_entailment': 0.6202299296855927, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19672131147540983, 'r1_recall': 0.5, 'r1_f1': 0.2823529411764706, 'pegasus_entailment': 0.6186832413077354, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4537037037037037, 'r1_recall': 0.5051546391752577, 'r1_f1': 0.4780487804878049, 'pegasus_entailment': 0.406642468025287, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.14, 'r1_recall': 0.4, 'r1_f1': 0.20740740740740743, 'pegasus_entailment': 0.3783918159703414, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.424, 'r1_recall': 0.5463917525773195, 'r1_f1': 0.4774774774774774, 'pegasus_entailment': 0.8074815198779106, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4528301886792453, 'r1_recall': 0.4247787610619469, 'r1_f1': 0.4383561643835617, 'pegasus_entailment': 0.4488039723946713, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6947368421052632, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.5739130434782609, 'pegasus_entailment': 0.21892840322107077, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23, 'r1_recall': 0.42592592592592593, 'r1_f1': 0.29870129870129875, 'pegasus_entailment': 0.35629877001047133, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3629032258064516, 'r1_recall': 0.45, 'r1_f1': 0.4017857142857143, 'pegasus_entailment': 0.7941794157028198, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
** Analysing column: malformed_chain



malformed_chain
Length after nones removed
616
MIN
0
MEAN
0
MAX
1
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.08588957055214724
MEAN
0.4387622995620573
MAX
0.8627450980392157
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.1417624521072797
MEAN
0.48941609924205437
MAX
0.8103448275862069
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.1323529411764706
MEAN
0.43812710618481265
MAX
0.6730769230769231
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.0056686064635869116
MEAN
0.5649938705826156
MAX
0.9280461147427559
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
11
MEAN
18
MAX
34
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
13
MEAN
17
MAX
23
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
12
MEAN
21
MAX
41
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
13
MEAN
19
MAX
27
{}
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4146341463414634, 'r1_recall': 0.4636363636363636, 'r1_f1': 0.43776824034334766, 'pegasus_entailment': 0.7444711327552795, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 15}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5652173913043478, 'r1_recall': 0.37572254335260113, 'r1_f1': 0.4513888888888889, 'pegasus_entailment': 0.6694509238004684, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3561643835616438, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.3969465648854962, 'pegasus_entailment': 0.6127078235149384, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6792452830188679, 'r1_recall': 0.5581395348837209, 'r1_f1': 0.6127659574468084, 'pegasus_entailment': 0.6228114019613713, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7078651685393258, 'r1_recall': 0.3620689655172414, 'r1_f1': 0.47908745247148293, 'pegasus_entailment': 0.5705259641011556, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.4018275409936905, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18, 'r1_recall': 0.5625, 'r1_f1': 0.2727272727272727, 'pegasus_entailment': 0.5000313106924296, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20618556701030927, 'r1_recall': 0.6451612903225806, 'r1_f1': 0.31249999999999994, 'pegasus_entailment': 0.5283948604483157, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6548672566371682, 'r1_recall': 0.4966442953020134, 'r1_f1': 0.564885496183206, 'pegasus_entailment': 0.7190784414609274, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5737704918032787, 'r1_recall': 0.5072463768115942, 'r1_f1': 0.5384615384615384, 'pegasus_entailment': 0.6827211181322733, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6931818181818182, 'r1_recall': 0.4066666666666667, 'r1_f1': 0.5126050420168068, 'pegasus_entailment': 0.5561190942923228, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6354166666666666, 'r1_recall': 0.5126050420168067, 'r1_f1': 0.5674418604651162, 'pegasus_entailment': 0.6767682234446207, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7571428571428571, 'r1_recall': 0.4953271028037383, 'r1_f1': 0.5988700564971752, 'pegasus_entailment': 0.6891614298025767, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.620253164556962, 'r1_recall': 0.5568181818181818, 'r1_f1': 0.5868263473053892, 'pegasus_entailment': 0.4852171043554942, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6145833333333334, 'r1_recall': 0.3072916666666667, 'r1_f1': 0.40972222222222227, 'pegasus_entailment': 0.7371505697568258, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2807017543859649, 'r1_recall': 0.5423728813559322, 'r1_f1': 0.3699421965317919, 'pegasus_entailment': 0.6367162838578224, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39325842696629215, 'r1_recall': 0.35353535353535354, 'r1_f1': 0.3723404255319149, 'pegasus_entailment': 0.6331592947244644, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6804123711340206, 'r1_recall': 0.2214765100671141, 'r1_f1': 0.3341772151898735, 'pegasus_entailment': 0.30583305408557254, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5373134328358209, 'r1_recall': 0.4472049689440994, 'r1_f1': 0.488135593220339, 'pegasus_entailment': 0.3529582768678665, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4205607476635514, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.46391752577319584, 'pegasus_entailment': 0.6059127709362656, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6180555555555556, 'r1_recall': 0.489010989010989, 'r1_f1': 0.5460122699386503, 'pegasus_entailment': 0.3458660587668419, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 13, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.4266666666666667, 'r1_f1': 0.4353741496598639, 'pegasus_entailment': 0.8732439279556274, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 33, 'pegasus_smog': 24}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3404255319148936, 'r1_recall': 0.2962962962962963, 'r1_f1': 0.3168316831683168, 'pegasus_entailment': 0.6889724880456924, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7107438016528925, 'r1_recall': 0.6323529411764706, 'r1_f1': 0.6692607003891051, 'pegasus_entailment': 0.48394931356112164, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31683168316831684, 'r1_recall': 0.64, 'r1_f1': 0.42384105960264906, 'pegasus_entailment': 0.807329973578453, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6935483870967742, 'r1_recall': 0.6825396825396826, 'r1_f1': 0.6880000000000001, 'pegasus_entailment': 0.6238576732575893, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5725806451612904, 'r1_recall': 0.5182481751824818, 'r1_f1': 0.5440613026819924, 'pegasus_entailment': 0.45341491848230364, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.717948717948718, 'r1_recall': 0.31343283582089554, 'r1_f1': 0.43636363636363645, 'pegasus_entailment': 0.627209926644961, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3, 'r1_recall': 0.5921052631578947, 'r1_f1': 0.3982300884955752, 'pegasus_entailment': 0.7906872729460398, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40384615384615385, 'r1_recall': 0.37168141592920356, 'r1_f1': 0.38709677419354843, 'pegasus_entailment': 0.7101313769817352, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4175824175824176, 'r1_recall': 0.4367816091954023, 'r1_f1': 0.4269662921348315, 'pegasus_entailment': 0.5147378593683243, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5421052631578948, 'r1_recall': 0.5124378109452736, 'r1_f1': 0.5268542199488492, 'pegasus_entailment': 0.6923885010182858, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3, 'r1_recall': 0.34951456310679613, 'r1_f1': 0.32286995515695066, 'pegasus_entailment': 0.780769693851471, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.416, 'r1_recall': 0.5360824742268041, 'r1_f1': 0.4684684684684684, 'pegasus_entailment': 0.47935664653778076, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.294478527607362, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.38866396761133604, 'pegasus_entailment': 0.456091596186161, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46956521739130436, 'r1_recall': 0.46551724137931033, 'r1_f1': 0.4675324675324675, 'pegasus_entailment': 0.535964785516262, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.37662337662337664, 'r1_recall': 0.8405797101449275, 'r1_f1': 0.5201793721973094, 'pegasus_entailment': 0.5887601256370545, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2777777777777778, 'r1_recall': 0.5147058823529411, 'r1_f1': 0.36082474226804123, 'pegasus_entailment': 0.6260082311928272, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23076923076923078, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.3510638297872341, 'pegasus_entailment': 0.659473828971386, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45145631067961167, 'r1_recall': 0.5602409638554217, 'r1_f1': 0.5000000000000001, 'pegasus_entailment': 0.9156578481197357, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5308641975308642, 'r1_recall': 0.5375, 'r1_f1': 0.5341614906832298, 'pegasus_entailment': 0.7012334540486336, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.7012987012987013, 'r1_f1': 0.5837837837837838, 'pegasus_entailment': 0.9336663782596588, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40860215053763443, 'r1_recall': 0.5205479452054794, 'r1_f1': 0.45783132530120485, 'pegasus_entailment': 0.4045109028617541, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7808219178082192, 'r1_recall': 0.4634146341463415, 'r1_f1': 0.5816326530612245, 'pegasus_entailment': 0.8440303206443787, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3543307086614173, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.4390243902439024, 'pegasus_entailment': 0.5529226124286651, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.543046357615894, 'r1_recall': 0.5466666666666666, 'r1_f1': 0.5448504983388706, 'pegasus_entailment': 0.575241819024086, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6483516483516484, 'r1_recall': 0.5, 'r1_f1': 0.5645933014354068, 'pegasus_entailment': 0.5230681200822195, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48226950354609927, 'r1_recall': 0.6126126126126126, 'r1_f1': 0.5396825396825397, 'pegasus_entailment': 0.6138130307197571, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38926174496644295, 'r1_recall': 0.6904761904761905, 'r1_f1': 0.49785407725321895, 'pegasus_entailment': 0.5555731505155563, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3902439024390244, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.4229074889867842, 'pegasus_entailment': 0.3853693772107363, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45263157894736844, 'r1_recall': 0.581081081081081, 'r1_f1': 0.5088757396449705, 'pegasus_entailment': 0.36142235808074474, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2, 'r1_recall': 0.7058823529411765, 'r1_f1': 0.3116883116883117, 'pegasus_entailment': 0.45659031509421766, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3484848484848485, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.44660194174757284, 'pegasus_entailment': 0.3955013729631901, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6511627906976745, 'r1_recall': 0.3163841807909605, 'r1_f1': 0.4258555133079849, 'pegasus_entailment': 0.278866421431303, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.449438202247191, 'r1_f1': 0.5369127516778522, 'pegasus_entailment': 0.48353951424360275, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5263157894736842, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.5405405405405405, 'pegasus_entailment': 0.32739364604155224, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6823529411764706, 'r1_recall': 0.23107569721115537, 'r1_f1': 0.34523809523809523, 'pegasus_entailment': 0.23368429640928903, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3402061855670103, 'r1_recall': 0.515625, 'r1_f1': 0.4099378881987578, 'pegasus_entailment': 0.672908385284245, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6046511627906976, 'r1_recall': 0.6446280991735537, 'r1_f1': 0.624, 'pegasus_entailment': 0.5473072727521261, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 20}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5137614678899083, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5233644859813085, 'pegasus_entailment': 0.49624938052147627, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38461538461538464, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.776798889040947, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32456140350877194, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.3978494623655914, 'pegasus_entailment': 0.3130284771323204, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5142857142857142, 'r1_recall': 0.32142857142857145, 'r1_f1': 0.3956043956043956, 'pegasus_entailment': 0.715877503156662, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5180722891566265, 'r1_recall': 0.44329896907216493, 'r1_f1': 0.47777777777777775, 'pegasus_entailment': 0.6111564586559931, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32075471698113206, 'r1_recall': 0.7083333333333334, 'r1_f1': 0.44155844155844154, 'pegasus_entailment': 0.5098614792029063, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6728971962616822, 'r1_recall': 0.5669291338582677, 'r1_f1': 0.6153846153846154, 'pegasus_entailment': 0.549334429204464, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4954954954954955, 'r1_recall': 0.5188679245283019, 'r1_f1': 0.5069124423963134, 'pegasus_entailment': 0.8990023136138916, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45081967213114754, 'r1_recall': 0.5729166666666666, 'r1_f1': 0.5045871559633027, 'pegasus_entailment': 0.505346400042375, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5752212389380531, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.5701754385964912, 'pegasus_entailment': 0.27101567389036063, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4017857142857143, 'r1_recall': 0.4411764705882353, 'r1_f1': 0.42056074766355145, 'pegasus_entailment': 0.8930995663007101, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.49404761904761907, 'r1_recall': 0.5, 'r1_f1': 0.4970059880239521, 'pegasus_entailment': 0.6968116909265518, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22842639593908629, 'r1_recall': 0.6617647058823529, 'r1_f1': 0.33962264150943394, 'pegasus_entailment': 0.5560828531160951, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3050847457627119, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.391304347826087, 'pegasus_entailment': 0.24512859154492617, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6854838709677419, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.5414012738853503, 'pegasus_entailment': 0.4907299454013507, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 19}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2905405405405405, 'r1_recall': 0.5972222222222222, 'r1_f1': 0.3909090909090909, 'pegasus_entailment': 0.4785392791032791, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4027777777777778, 'r1_recall': 0.6823529411764706, 'r1_f1': 0.5065502183406113, 'pegasus_entailment': 0.4213678588469823, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30434782608695654, 'r1_recall': 0.65625, 'r1_f1': 0.4158415841584159, 'pegasus_entailment': 0.9490441977977753, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34375, 'r1_recall': 0.4230769230769231, 'r1_f1': 0.3793103448275862, 'pegasus_entailment': 0.9164540966351827, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40559440559440557, 'r1_recall': 0.6744186046511628, 'r1_f1': 0.5065502183406113, 'pegasus_entailment': 0.5925259962677956, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33884297520661155, 'r1_recall': 0.6119402985074627, 'r1_f1': 0.4361702127659574, 'pegasus_entailment': 0.708044508472085, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.425, 'r1_recall': 0.6538461538461539, 'r1_f1': 0.5151515151515152, 'pegasus_entailment': 0.4596976935863495, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 24}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.69, 'r1_recall': 0.6699029126213593, 'r1_f1': 0.6798029556650246, 'pegasus_entailment': 0.34361235424876213, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3185840707964602, 'r1_recall': 0.5538461538461539, 'r1_f1': 0.4044943820224719, 'pegasus_entailment': 0.464577279984951, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4752475247524752, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.5106382978723404, 'pegasus_entailment': 0.4700566254556179, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.6195652173913043, 'r1_f1': 0.6096256684491979, 'pegasus_entailment': 0.4873967071374257, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3387096774193548, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.39810426540284355, 'pegasus_entailment': 0.5543115228414536, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24, 'r1_recall': 0.23076923076923078, 'r1_f1': 0.23529411764705882, 'pegasus_entailment': 0.8791715900103251, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 22, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3835616438356164, 'r1_recall': 0.6222222222222222, 'r1_f1': 0.4745762711864407, 'pegasus_entailment': 0.9701667726039886, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7954545454545454, 'r1_recall': 0.33653846153846156, 'r1_f1': 0.47297297297297297, 'pegasus_entailment': 0.6153529584407806, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2396694214876033, 'r1_recall': 0.4142857142857143, 'r1_f1': 0.3036649214659686, 'pegasus_entailment': 0.7938768863677979, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5233644859813084, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.746991787637983, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 26}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.509090909090909, 'r1_recall': 0.417910447761194, 'r1_f1': 0.4590163934426229, 'pegasus_entailment': 0.34556247293949127, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40298507462686567, 'r1_recall': 0.7397260273972602, 'r1_f1': 0.5217391304347826, 'pegasus_entailment': 0.8667904138565063, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5544554455445545, 'r1_recall': 0.47863247863247865, 'r1_f1': 0.5137614678899082, 'pegasus_entailment': 0.7130399122834206, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32075471698113206, 'r1_recall': 0.17525773195876287, 'r1_f1': 0.22666666666666666, 'pegasus_entailment': 0.9918626844882965, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.578125, 'r1_recall': 0.4180790960451977, 'r1_f1': 0.4852459016393443, 'pegasus_entailment': 0.7186873108148575, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4631578947368421, 'r1_recall': 0.4536082474226804, 'r1_f1': 0.45833333333333326, 'pegasus_entailment': 0.3519315365701914, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5632183908045977, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.460093896713615, 'pegasus_entailment': 0.8869929611682892, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3225806451612903, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.379746835443038, 'pegasus_entailment': 0.7117458656430244, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40186915887850466, 'r1_recall': 0.38392857142857145, 'r1_f1': 0.3926940639269407, 'pegasus_entailment': 0.8189968764781952, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 34, 'pegasus_smog': 22}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42168674698795183, 'r1_recall': 0.5737704918032787, 'r1_f1': 0.4861111111111111, 'pegasus_entailment': 0.7396999970078468, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4329896907216495, 'r1_recall': 0.44680851063829785, 'r1_f1': 0.4397905759162304, 'pegasus_entailment': 0.6870561316609383, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3883495145631068, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.49844236760124605, 'pegasus_entailment': 0.7300601303577423, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47619047619047616, 'r1_recall': 0.625, 'r1_f1': 0.5405405405405405, 'pegasus_entailment': 0.5985491080209613, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 25}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5304347826086957, 'r1_recall': 0.7625, 'r1_f1': 0.6256410256410256, 'pegasus_entailment': 0.67937882989645, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6125, 'r1_recall': 0.3798449612403101, 'r1_f1': 0.46889952153110054, 'pegasus_entailment': 0.5997485915819804, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.436241610738255, 'r1_recall': 0.6310679611650486, 'r1_f1': 0.5158730158730159, 'pegasus_entailment': 0.6224416553974151, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5120481927710844, 'r1_recall': 0.53125, 'r1_f1': 0.5214723926380368, 'pegasus_entailment': 0.7196571926275889, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40625, 'r1_recall': 0.52, 'r1_f1': 0.45614035087719296, 'pegasus_entailment': 0.03347761929035187, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25862068965517243, 'r1_recall': 0.25, 'r1_f1': 0.25423728813559326, 'pegasus_entailment': 0.9320093989372253, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5154639175257731, 'r1_recall': 0.7246376811594203, 'r1_f1': 0.6024096385542168, 'pegasus_entailment': 0.926842674612999, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6016260162601627, 'r1_recall': 0.556390977443609, 'r1_f1': 0.578125, 'pegasus_entailment': 0.5499982476234436, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6081081081081081, 'r1_recall': 0.569620253164557, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.5723429152742028, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.421875, 'r1_recall': 0.6067415730337079, 'r1_f1': 0.4976958525345621, 'pegasus_entailment': 0.6047394394874572, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43243243243243246, 'r1_recall': 0.36923076923076925, 'r1_f1': 0.3983402489626556, 'pegasus_entailment': 0.75539231300354, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6231884057971014, 'r1_recall': 0.48314606741573035, 'r1_f1': 0.5443037974683544, 'pegasus_entailment': 0.5312754288315773, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6733333333333333, 'r1_recall': 0.5738636363636364, 'r1_f1': 0.6196319018404909, 'pegasus_entailment': 0.7308745384216309, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.625, 'r1_recall': 0.41044776119402987, 'r1_f1': 0.49549549549549554, 'pegasus_entailment': 0.4275934983044863, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.453781512605042, 'r1_recall': 0.574468085106383, 'r1_f1': 0.5070422535211269, 'pegasus_entailment': 0.480677576106973, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7045454545454546, 'r1_recall': 0.4881889763779528, 'r1_f1': 0.5767441860465117, 'pegasus_entailment': 0.8098782896995544, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4244604316546763, 'r1_recall': 0.6704545454545454, 'r1_f1': 0.5198237885462554, 'pegasus_entailment': 0.782235344250997, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6024096385542169, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.5050505050505051, 'pegasus_entailment': 0.8495800296465555, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36885245901639346, 'r1_recall': 0.5921052631578947, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.6261117719113827, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2204724409448819, 'r1_recall': 0.6511627906976745, 'r1_f1': 0.3294117647058823, 'pegasus_entailment': 0.5305761978030205, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5735294117647058, 'r1_recall': 0.6964285714285714, 'r1_f1': 0.6290322580645161, 'pegasus_entailment': 0.8588724732398987, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6262626262626263, 'r1_recall': 0.4732824427480916, 'r1_f1': 0.5391304347826086, 'pegasus_entailment': 0.559096023440361, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.344, 'r1_recall': 0.5375, 'r1_f1': 0.4195121951219512, 'pegasus_entailment': 0.536765918135643, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4859154929577465, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.5328185328185329, 'pegasus_entailment': 0.8355384111404419, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5074626865671642, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.544, 'pegasus_entailment': 0.6181278750300407, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4418604651162791, 'r1_recall': 0.6440677966101694, 'r1_f1': 0.5241379310344827, 'pegasus_entailment': 0.26443818025290966, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.71, 'r1_recall': 0.37566137566137564, 'r1_f1': 0.4913494809688581, 'pegasus_entailment': 0.0877784825861454, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 22}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5163934426229508, 'r1_recall': 0.5206611570247934, 'r1_f1': 0.5185185185185185, 'pegasus_entailment': 0.7610556524246931, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5471698113207547, 'r1_recall': 0.3741935483870968, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.744743545850118, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 14, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6633663366336634, 'r1_recall': 0.4110429447852761, 'r1_f1': 0.5075757575757576, 'pegasus_entailment': 0.4674163207411766, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5882352941176471, 'r1_recall': 0.39603960396039606, 'r1_f1': 0.4733727810650888, 'pegasus_entailment': 0.5762543578942617, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4105960264900662, 'r1_recall': 0.512396694214876, 'r1_f1': 0.45588235294117646, 'pegasus_entailment': 0.8319357872009278, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3105263157894737, 'r1_recall': 0.6344086021505376, 'r1_f1': 0.41696113074204955, 'pegasus_entailment': 0.6642813632885615, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5966386554621849, 'r1_recall': 0.5338345864661654, 'r1_f1': 0.5634920634920635, 'pegasus_entailment': 0.7798850893974304, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7558139534883721, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.47970479704797053, 'pegasus_entailment': 0.4791891574859619, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3508771929824561, 'r1_recall': 0.6896551724137931, 'r1_f1': 0.46511627906976744, 'pegasus_entailment': 0.6791091933846474, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.41, 'r1_recall': 0.4659090909090909, 'r1_f1': 0.43617021276595747, 'pegasus_entailment': 0.47817930206656456, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3805309734513274, 'r1_recall': 0.46236559139784944, 'r1_f1': 0.4174757281553398, 'pegasus_entailment': 0.335289865732193, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5132743362831859, 'r1_f1': 0.5065502183406114, 'pegasus_entailment': 0.6930526793003082, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5272727272727272, 'r1_recall': 0.725, 'r1_f1': 0.6105263157894736, 'pegasus_entailment': 0.37229938556750614, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5346534653465347, 'r1_f1': 0.5167464114832536, 'pegasus_entailment': 0.7208705147107443, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.45933014354066987, 'r1_f1': 0.526027397260274, 'pegasus_entailment': 0.8503865897655487, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6148148148148148, 'r1_recall': 0.4585635359116022, 'r1_f1': 0.5253164556962026, 'pegasus_entailment': 0.37509792546431225, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32978723404255317, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.4052287581699346, 'pegasus_entailment': 0.5841076727956533, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7872340425531915, 'r1_recall': 0.4567901234567901, 'r1_f1': 0.578125, 'pegasus_entailment': 0.21755847707390785, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4811320754716981, 'r1_recall': 0.6219512195121951, 'r1_f1': 0.5425531914893618, 'pegasus_entailment': 0.47795233502984047, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49019607843137253, 'r1_recall': 0.2604166666666667, 'r1_f1': 0.3401360544217687, 'pegasus_entailment': 0.6426375806331635, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4198473282442748, 'r1_recall': 0.5978260869565217, 'r1_f1': 0.4932735426008969, 'pegasus_entailment': 0.6229214668273926, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6593406593406593, 'r1_recall': 0.30927835051546393, 'r1_f1': 0.42105263157894735, 'pegasus_entailment': 0.36372576157251996, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.591304347826087, 'r1_recall': 0.40963855421686746, 'r1_f1': 0.4839857651245552, 'pegasus_entailment': 0.5027884542942047, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39805825242718446, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.5061728395061729, 'pegasus_entailment': 0.7526588340600332, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6601941747572816, 'r1_recall': 0.3930635838150289, 'r1_f1': 0.49275362318840576, 'pegasus_entailment': 0.4800668756167094, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4864864864864865, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4645161290322581, 'pegasus_entailment': 0.5389042297999064, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4883720930232558, 'r1_recall': 0.4228187919463087, 'r1_f1': 0.45323741007194246, 'pegasus_entailment': 0.5840649530291557, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45161290322580644, 'r1_recall': 0.6021505376344086, 'r1_f1': 0.5161290322580645, 'pegasus_entailment': 0.3514923349488527, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.49107142857142855, 'r1_recall': 0.3416149068322981, 'r1_f1': 0.40293040293040294, 'pegasus_entailment': 0.2430663749575615, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.18072289156626506, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.24793388429752067, 'pegasus_entailment': 0.32958969349662465, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6105263157894737, 'r1_recall': 0.5370370370370371, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.7250311851501465, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5294117647058824, 'r1_recall': 0.5242718446601942, 'r1_f1': 0.5268292682926828, 'pegasus_entailment': 0.7936188727617264, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4350282485875706, 'r1_recall': 0.4723926380368098, 'r1_f1': 0.45294117647058824, 'pegasus_entailment': 0.8101469228665034, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45925925925925926, 'r1_recall': 0.5688073394495413, 'r1_f1': 0.5081967213114753, 'pegasus_entailment': 0.43634097650647163, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4857142857142857, 'r1_recall': 0.38636363636363635, 'r1_f1': 0.4303797468354431, 'pegasus_entailment': 0.4423443426688512, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4329896907216495, 'r1_recall': 0.28, 'r1_f1': 0.3400809716599191, 'pegasus_entailment': 0.8374154766400655, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6413043478260869, 'r1_recall': 0.42142857142857143, 'r1_f1': 0.5086206896551724, 'pegasus_entailment': 0.44008978456258774, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4838709677419355, 'r1_recall': 0.30201342281879195, 'r1_f1': 0.371900826446281, 'pegasus_entailment': 0.5835882425308228, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36419753086419754, 'r1_recall': 0.6483516483516484, 'r1_f1': 0.466403162055336, 'pegasus_entailment': 0.5586524829268456, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 34, 'pegasus_smog': 23}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4777777777777778, 'r1_recall': 0.5584415584415584, 'r1_f1': 0.5149700598802396, 'pegasus_entailment': 0.6988606452941895, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 20}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3813559322033898, 'r1_recall': 0.6164383561643836, 'r1_f1': 0.4712041884816754, 'pegasus_entailment': 0.15215827524662018, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7619047619047619, 'r1_recall': 0.21739130434782608, 'r1_f1': 0.3382663847780127, 'pegasus_entailment': 0.5998794659972191, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4728682170542636, 'r1_recall': 0.5545454545454546, 'r1_f1': 0.5104602510460251, 'pegasus_entailment': 0.9847099930047989, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.5080645161290323, 'r1_f1': 0.5228215767634854, 'pegasus_entailment': 0.7425786852836609, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.575, 'r1_f1': 0.5348837209302325, 'pegasus_entailment': 0.7064514259497324, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8409090909090909, 'r1_recall': 0.4723404255319149, 'r1_f1': 0.6049046321525886, 'pegasus_entailment': 0.7182165384292603, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4634146341463415, 'r1_recall': 0.5, 'r1_f1': 0.48101265822784817, 'pegasus_entailment': 0.24924166819878987, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3584905660377358, 'r1_recall': 0.6627906976744186, 'r1_f1': 0.46530612244897956, 'pegasus_entailment': 0.6303460150957108, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3482142857142857, 'r1_recall': 0.52, 'r1_f1': 0.41711229946524064, 'pegasus_entailment': 0.6733416467905045, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3790322580645161, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.4392523364485982, 'pegasus_entailment': 0.7799076914787293, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.61, 'r1_recall': 0.3719512195121951, 'r1_f1': 0.46212121212121215, 'pegasus_entailment': 0.7724236994981766, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8160919540229885, 'r1_recall': 0.24738675958188153, 'r1_f1': 0.37967914438502676, 'pegasus_entailment': 0.33340180665254593, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.75, 'r1_recall': 0.3016759776536313, 'r1_f1': 0.4302788844621514, 'pegasus_entailment': 0.5884541471799215, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.553030303030303, 'r1_recall': 0.6403508771929824, 'r1_f1': 0.5934959349593496, 'pegasus_entailment': 0.46639395505189896, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6831683168316832, 'r1_recall': 0.5307692307692308, 'r1_f1': 0.5974025974025974, 'pegasus_entailment': 0.7821817398071289, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 23}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4222222222222222, 'r1_recall': 0.5480769230769231, 'r1_f1': 0.47698744769874474, 'pegasus_entailment': 0.5591401606798172, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.43589743589743596, 'pegasus_entailment': 0.9362344443798065, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6238532110091743, 'r1_recall': 0.41975308641975306, 'r1_f1': 0.5018450184501845, 'pegasus_entailment': 0.6119451001286507, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.59375, 'r1_recall': 0.7402597402597403, 'r1_f1': 0.6589595375722545, 'pegasus_entailment': 0.394996730145067, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5511811023622047, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.5166051660516606, 'pegasus_entailment': 0.5549194812774658, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.56, 'r1_f1': 0.5793103448275861, 'pegasus_entailment': 0.5558383961518606, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.461038961038961, 'r1_recall': 0.5867768595041323, 'r1_f1': 0.5163636363636364, 'pegasus_entailment': 0.7766616642475128, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6909090909090909, 'r1_recall': 0.6846846846846847, 'r1_f1': 0.6877828054298641, 'pegasus_entailment': 0.49826850928366184, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6019417475728155, 'r1_recall': 0.3803680981595092, 'r1_f1': 0.4661654135338346, 'pegasus_entailment': 0.2871922155221303, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 24}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6017699115044248, 'r1_recall': 0.38636363636363635, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.3412942737340927, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48091603053435117, 'r1_recall': 0.7875, 'r1_f1': 0.5971563981042654, 'pegasus_entailment': 0.7002632273361087, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23846153846153847, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.3263157894736842, 'pegasus_entailment': 0.5839461833238602, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3163265306122449, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.3924050632911393, 'pegasus_entailment': 0.6598343253135681, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43434343434343436, 'r1_recall': 0.4387755102040816, 'r1_f1': 0.43654822335025373, 'pegasus_entailment': 0.2504466399550438, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6016260162601627, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.5849802371541502, 'pegasus_entailment': 0.5908371917903423, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.6304347826086957, 'r1_f1': 0.35802469135802467, 'pegasus_entailment': 0.7378079114714637, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5537190082644629, 'r1_recall': 0.5877192982456141, 'r1_f1': 0.570212765957447, 'pegasus_entailment': 0.512027632445097, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45255474452554745, 'r1_recall': 0.5585585585585585, 'r1_f1': 0.5, 'pegasus_entailment': 0.455177690833807, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7117117117117117, 'r1_recall': 0.3607305936073059, 'r1_f1': 0.47878787878787876, 'pegasus_entailment': 0.5257260343059897, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.6829268292682927, 'r1_f1': 0.6021505376344086, 'pegasus_entailment': 0.6214940252248198, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42063492063492064, 'r1_recall': 0.6022727272727273, 'r1_f1': 0.4953271028037383, 'pegasus_entailment': 0.7691210955381393, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5619834710743802, 'r1_recall': 0.6732673267326733, 'r1_f1': 0.6126126126126127, 'pegasus_entailment': 0.17698776088654994, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4806201550387597, 'r1_recall': 0.5740740740740741, 'r1_f1': 0.5232067510548524, 'pegasus_entailment': 0.20117624141275883, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26666666666666666, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.3660130718954248, 'pegasus_entailment': 0.40602368526160715, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.59375, 'r1_recall': 0.5757575757575758, 'r1_f1': 0.5846153846153846, 'pegasus_entailment': 0.5592094540596009, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5289256198347108, 'r1_recall': 0.4050632911392405, 'r1_f1': 0.45878136200716846, 'pegasus_entailment': 0.2981831009189288, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6434782608695652, 'r1_recall': 0.46835443037974683, 'r1_f1': 0.5421245421245422, 'pegasus_entailment': 0.40037916228175163, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.616822429906542, 'r1_recall': 0.34196891191709844, 'r1_f1': 0.44, 'pegasus_entailment': 0.4143464267253876, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5806451612903226, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.6761938532193502, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5877192982456141, 'r1_recall': 0.536, 'r1_f1': 0.5606694560669457, 'pegasus_entailment': 0.5375417947769165, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.36538461538461536, 'r1_f1': 0.42222222222222217, 'pegasus_entailment': 0.8884657422701517, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29347826086956524, 'r1_recall': 0.4426229508196721, 'r1_f1': 0.35294117647058826, 'pegasus_entailment': 0.4234404496382922, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4375, 'r1_recall': 0.5645161290322581, 'r1_f1': 0.4929577464788733, 'pegasus_entailment': 0.8833660880724589, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3229166666666667, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.4000000000000001, 'pegasus_entailment': 0.4319556523114443, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.425, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.4358974358974359, 'pegasus_entailment': 0.48498602708180744, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36633663366336633, 'r1_recall': 0.37373737373737376, 'r1_f1': 0.37, 'pegasus_entailment': 0.5175601877272129, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2653061224489796, 'r1_recall': 0.65, 'r1_f1': 0.3768115942028986, 'pegasus_entailment': 0.8688450455665588, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 24}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42574257425742573, 'r1_recall': 0.49710982658959535, 'r1_f1': 0.4586666666666666, 'pegasus_entailment': 0.3921014042571187, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4140625, 'r1_recall': 0.6625, 'r1_f1': 0.5096153846153846, 'pegasus_entailment': 0.35660714904467267, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5689655172413793, 'r1_recall': 0.3707865168539326, 'r1_f1': 0.4489795918367347, 'pegasus_entailment': 0.6437714397907257, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7111111111111111, 'r1_recall': 0.39751552795031053, 'r1_f1': 0.5099601593625498, 'pegasus_entailment': 0.13664319925010204, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5445544554455446, 'r1_recall': 0.41044776119402987, 'r1_f1': 0.4680851063829788, 'pegasus_entailment': 0.25547654344700277, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6728971962616822, 'r1_recall': 0.2962962962962963, 'r1_f1': 0.41142857142857137, 'pegasus_entailment': 0.4688647612929344, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45098039215686275, 'r1_recall': 0.5609756097560976, 'r1_f1': 0.5, 'pegasus_entailment': 0.6030058066050211, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6707317073170732, 'r1_recall': 0.3618421052631579, 'r1_f1': 0.47008547008547014, 'pegasus_entailment': 0.40091420570388436, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30327868852459017, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.38144329896907214, 'pegasus_entailment': 0.6669193897396326, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.691358024691358, 'r1_recall': 0.25112107623318386, 'r1_f1': 0.3684210526315789, 'pegasus_entailment': 0.4722487762570381, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28205128205128205, 'r1_recall': 0.2920353982300885, 'r1_f1': 0.28695652173913044, 'pegasus_entailment': 0.2996280584484339, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32967032967032966, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.43795620437956206, 'pegasus_entailment': 0.13584206998348236, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6129032258064516, 'r1_recall': 0.4198895027624309, 'r1_f1': 0.49836065573770494, 'pegasus_entailment': 0.41323973536491393, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5833333333333334, 'r1_recall': 0.3559322033898305, 'r1_f1': 0.4421052631578947, 'pegasus_entailment': 0.3798638373613358, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2955665024630542, 'r1_recall': 0.625, 'r1_f1': 0.4013377926421405, 'pegasus_entailment': 0.7679224191233516, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6333333333333333, 'r1_recall': 0.5241379310344828, 'r1_f1': 0.5735849056603772, 'pegasus_entailment': 0.8378613233566284, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.14736842105263157, 'r1_recall': 0.5, 'r1_f1': 0.2276422764227642, 'pegasus_entailment': 0.33038490563631057, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1870967741935484, 'r1_recall': 0.5, 'r1_f1': 0.27230046948356806, 'pegasus_entailment': 0.675854966044426, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6451612903225806, 'r1_recall': 0.5042016806722689, 'r1_f1': 0.5660377358490566, 'pegasus_entailment': 0.4385720541079839, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3467741935483871, 'r1_recall': 0.6056338028169014, 'r1_f1': 0.441025641025641, 'pegasus_entailment': 0.7112539887428284, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2882882882882883, 'r1_recall': 0.5818181818181818, 'r1_f1': 0.38554216867469876, 'pegasus_entailment': 0.7781752496957779, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30392156862745096, 'r1_recall': 0.38271604938271603, 'r1_f1': 0.33879781420765026, 'pegasus_entailment': 0.4378936819266528, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.6037735849056604, 'pegasus_entailment': 0.8697647651036581, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.52, 'r1_recall': 0.46987951807228917, 'r1_f1': 0.4936708860759494, 'pegasus_entailment': 0.3338967598974705, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5590551181102362, 'r1_recall': 0.6396396396396397, 'r1_f1': 0.596638655462185, 'pegasus_entailment': 0.29798583360388875, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7086614173228346, 'r1_recall': 0.26785714285714285, 'r1_f1': 0.3887688984881209, 'pegasus_entailment': 0.6117390632629395, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5752212389380531, 'r1_recall': 0.2927927927927928, 'r1_f1': 0.38805970149253727, 'pegasus_entailment': 0.368030721321702, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36752136752136755, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.44102564102564107, 'pegasus_entailment': 0.6475750133395195, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7037037037037037, 'r1_recall': 0.5480769230769231, 'r1_f1': 0.6162162162162163, 'pegasus_entailment': 0.3639751486480236, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2909090909090909, 'r1_recall': 0.4383561643835616, 'r1_f1': 0.34972677595628415, 'pegasus_entailment': 0.5940685371557871, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4024390243902439, 'r1_recall': 0.5076923076923077, 'r1_f1': 0.4489795918367347, 'pegasus_entailment': 0.21311647444963455, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46808510638297873, 'r1_recall': 0.6111111111111112, 'r1_f1': 0.5301204819277109, 'pegasus_entailment': 0.6122121140360832, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5972222222222222, 'r1_recall': 0.5308641975308642, 'r1_f1': 0.5620915032679739, 'pegasus_entailment': 0.6094744255145391, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 14}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4473684210526316, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.4473684210526316, 'pegasus_entailment': 0.9029853641986847, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 15, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5441176470588235, 'r1_recall': 0.44047619047619047, 'r1_f1': 0.4868421052631579, 'pegasus_entailment': 0.30553184309974313, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6396396396396397, 'r1_recall': 0.45222929936305734, 'r1_f1': 0.5298507462686567, 'pegasus_entailment': 0.8343355059623718, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.616822429906542, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.5258964143426293, 'pegasus_entailment': 0.5093335583806038, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38513513513513514, 'r1_recall': 0.6063829787234043, 'r1_f1': 0.4710743801652893, 'pegasus_entailment': 0.4307665386702865, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6047904191616766, 'r1_recall': 0.5287958115183246, 'r1_f1': 0.5642458100558659, 'pegasus_entailment': 0.48816022525231045, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.24, 'r1_recall': 0.7346938775510204, 'r1_f1': 0.36180904522613067, 'pegasus_entailment': 0.8019844591617584, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 23, 'pegasus_ari': 36, 'pegasus_smog': 28}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5542168674698795, 'r1_recall': 0.5542168674698795, 'r1_f1': 0.5542168674698795, 'pegasus_entailment': 0.7802265683809916, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.5, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.6436097901314497, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 12}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5319148936170213, 'r1_recall': 0.6172839506172839, 'r1_f1': 0.5714285714285713, 'pegasus_entailment': 0.3650123305618763, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5467625899280576, 'r1_recall': 0.5547445255474452, 'r1_f1': 0.5507246376811595, 'pegasus_entailment': 0.7822348326444626, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23333333333333334, 'r1_recall': 0.3181818181818182, 'r1_f1': 0.2692307692307693, 'pegasus_entailment': 0.782502144575119, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25210084033613445, 'r1_recall': 0.5084745762711864, 'r1_f1': 0.33707865168539325, 'pegasus_entailment': 0.7963678687810898, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5590551181102362, 'r1_recall': 0.5298507462686567, 'r1_f1': 0.5440613026819924, 'pegasus_entailment': 0.7086443901062012, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5727272727272728, 'r1_recall': 0.40384615384615385, 'r1_f1': 0.47368421052631576, 'pegasus_entailment': 0.22778382450342177, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3695652173913043, 'r1_recall': 0.7846153846153846, 'r1_f1': 0.5024630541871922, 'pegasus_entailment': 0.7307687550783157, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38317757009345793, 'r1_recall': 0.4659090909090909, 'r1_f1': 0.42051282051282046, 'pegasus_entailment': 0.6050817507008711, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5111111111111111, 'r1_recall': 0.5476190476190477, 'r1_f1': 0.5287356321839081, 'pegasus_entailment': 0.5499101082483927, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43478260869565216, 'r1_recall': 0.5194805194805194, 'r1_f1': 0.4733727810650888, 'pegasus_entailment': 0.5417298106476665, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25477707006369427, 'r1_recall': 0.5, 'r1_f1': 0.3375527426160338, 'pegasus_entailment': 0.6517086277405421, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5375722543352601, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.5653495440729484, 'pegasus_entailment': 0.7541218996047974, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3389830508474576, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.41237113402061853, 'pegasus_entailment': 0.3670961752533913, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25225225225225223, 'r1_recall': 0.6588235294117647, 'r1_f1': 0.36482084690553745, 'pegasus_entailment': 0.5338184339925647, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6936936936936937, 'r1_recall': 0.5877862595419847, 'r1_f1': 0.6363636363636364, 'pegasus_entailment': 0.34946442674845457, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4329896907216495, 'r1_recall': 0.39622641509433965, 'r1_f1': 0.41379310344827586, 'pegasus_entailment': 0.26269884034991264, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7920792079207921, 'r1_recall': 0.4371584699453552, 'r1_f1': 0.5633802816901409, 'pegasus_entailment': 0.6396435722708702, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.28651685393258425, 'r1_recall': 0.6710526315789473, 'r1_f1': 0.4015748031496063, 'pegasus_entailment': 0.38436618633568287, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5130434782608696, 'r1_recall': 0.6413043478260869, 'r1_f1': 0.5700483091787439, 'pegasus_entailment': 0.36865061335265636, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.668918918918919, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.5439560439560439, 'pegasus_entailment': 0.38600407550111415, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6219512195121951, 'r1_recall': 0.504950495049505, 'r1_f1': 0.5573770491803278, 'pegasus_entailment': 0.022974513296503574, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5392156862745098, 'r1_recall': 0.5612244897959183, 'r1_f1': 0.5499999999999999, 'pegasus_entailment': 0.1047386497957632, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.39805825242718446, 'r1_recall': 0.5857142857142857, 'r1_f1': 0.4739884393063584, 'pegasus_entailment': 0.5630463644241294, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7, 'r1_recall': 0.631578947368421, 'r1_f1': 0.6640316205533596, 'pegasus_entailment': 0.3682808515926202, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5277777777777778, 'r1_recall': 0.4222222222222222, 'r1_f1': 0.46913580246913583, 'pegasus_entailment': 0.40079450607299805, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.55, 'r1_recall': 0.3826086956521739, 'r1_f1': 0.4512820512820513, 'pegasus_entailment': 0.565836121638616, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41904761904761906, 'r1_recall': 0.3963963963963964, 'r1_f1': 0.4074074074074074, 'pegasus_entailment': 0.7410467465718588, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7254901960784313, 'r1_recall': 0.5362318840579711, 'r1_f1': 0.6166666666666667, 'pegasus_entailment': 0.8752594192822775, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.20610687022900764, 'r1_recall': 0.54, 'r1_f1': 0.2983425414364641, 'pegasus_entailment': 0.08160261635202914, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4430379746835443, 'r1_recall': 0.625, 'r1_f1': 0.5185185185185185, 'pegasus_entailment': 0.42599132657051086, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.18947368421052632, 'r1_recall': 0.3829787234042553, 'r1_f1': 0.2535211267605634, 'pegasus_entailment': 0.3560933470726013, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.425, 'r1_recall': 0.4788732394366197, 'r1_f1': 0.45033112582781454, 'pegasus_entailment': 0.4726495295763016, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5194805194805194, 'r1_recall': 0.4371584699453552, 'r1_f1': 0.4747774480712166, 'pegasus_entailment': 0.40221239626407623, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 15, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4714285714285714, 'r1_recall': 0.48175182481751827, 'r1_f1': 0.4765342960288809, 'pegasus_entailment': 0.7827632784843445, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5686274509803921, 'r1_recall': 0.6373626373626373, 'r1_f1': 0.6010362694300517, 'pegasus_entailment': 0.7286163046956062, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4550561797752809, 'r1_recall': 0.6090225563909775, 'r1_f1': 0.5209003215434083, 'pegasus_entailment': 0.38639849703758955, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5369127516778524, 'r1_recall': 0.4878048780487805, 'r1_f1': 0.5111821086261981, 'pegasus_entailment': 0.37238496790329617, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7209302325581395, 'r1_recall': 0.4626865671641791, 'r1_f1': 0.5636363636363636, 'pegasus_entailment': 0.6973941326141357, 'pegasus_flesch_kincaid': 34, 'pegasus_coleman_liau': 19, 'pegasus_ari': 40, 'pegasus_smog': 28}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2992125984251969, 'r1_recall': 0.38, 'r1_f1': 0.33480176211453744, 'pegasus_entailment': 0.4157695956528187, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40594059405940597, 'r1_recall': 0.5125, 'r1_f1': 0.4530386740331492, 'pegasus_entailment': 0.9710010439157486, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5212765957446809, 'r1_recall': 0.5975609756097561, 'r1_f1': 0.5568181818181819, 'pegasus_entailment': 0.32674658643857885, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1896551724137931, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.2682926829268293, 'pegasus_entailment': 0.4422093816101551, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 12, 'pegasus_ari': 10, 'pegasus_smog': 15}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24817518248175183, 'r1_recall': 0.5396825396825397, 'r1_f1': 0.33999999999999997, 'pegasus_entailment': 0.7034736010245979, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21176470588235294, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.3025210084033613, 'pegasus_entailment': 0.2671034703031182, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2815533980582524, 'r1_recall': 0.3815789473684211, 'r1_f1': 0.324022346368715, 'pegasus_entailment': 0.705104187130928, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.2608695652173913, 'r1_f1': 0.366412213740458, 'pegasus_entailment': 0.4779355712234974, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30612244897959184, 'r1_recall': 0.44776119402985076, 'r1_f1': 0.36363636363636365, 'pegasus_entailment': 0.315474105377992, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5483870967741935, 'r1_recall': 0.40476190476190477, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.34459428787231444, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5666666666666667, 'r1_recall': 0.5151515151515151, 'r1_f1': 0.5396825396825397, 'pegasus_entailment': 0.31540120641390484, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6697247706422018, 'r1_recall': 0.4620253164556962, 'r1_f1': 0.5468164794007491, 'pegasus_entailment': 0.7457675933837891, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6764705882352942, 'r1_recall': 0.23310810810810811, 'r1_f1': 0.34673366834170855, 'pegasus_entailment': 0.665856346487999, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3023255813953488, 'r1_recall': 0.7090909090909091, 'r1_f1': 0.42391304347826086, 'pegasus_entailment': 0.6208240643143654, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7311827956989247, 'r1_recall': 0.34517766497461927, 'r1_f1': 0.46896551724137936, 'pegasus_entailment': 0.21182203888893128, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.375, 'r1_recall': 0.55, 'r1_f1': 0.44594594594594594, 'pegasus_entailment': 0.389722208182017, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5648148148148148, 'r1_recall': 0.4959349593495935, 'r1_f1': 0.5281385281385281, 'pegasus_entailment': 0.691787526011467, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.58, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5658536585365854, 'pegasus_entailment': 0.7287337382634481, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7128712871287128, 'r1_recall': 0.549618320610687, 'r1_f1': 0.6206896551724138, 'pegasus_entailment': 0.2824291264017423, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3364485981308411, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.41379310344827586, 'pegasus_entailment': 0.5525418917338053, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26277372262773724, 'r1_recall': 0.631578947368421, 'r1_f1': 0.3711340206185567, 'pegasus_entailment': 0.47880323231220245, 'pegasus_flesch_kincaid': 36, 'pegasus_coleman_liau': 20, 'pegasus_ari': 43, 'pegasus_smog': 27}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22981366459627328, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.3394495412844037, 'pegasus_entailment': 0.6982872039079666, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.546875, 'r1_recall': 0.546875, 'r1_f1': 0.546875, 'pegasus_entailment': 0.3892614357173443, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6012658227848101, 'r1_recall': 0.5337078651685393, 'r1_f1': 0.5654761904761905, 'pegasus_entailment': 0.41736343236906187, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6330935251798561, 'r1_recall': 0.5398773006134969, 'r1_f1': 0.5827814569536423, 'pegasus_entailment': 0.6985654830932617, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.624, 'r1_recall': 0.40414507772020725, 'r1_f1': 0.490566037735849, 'pegasus_entailment': 0.7027577459812164, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42276422764227645, 'r1_recall': 0.5148514851485149, 'r1_f1': 0.4642857142857143, 'pegasus_entailment': 0.8138550668954849, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37037037037037035, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.45662100456621, 'pegasus_entailment': 0.43804182165435385, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.415929203539823, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.4630541871921182, 'pegasus_entailment': 0.6481020243838429, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2857142857142857, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.3661971830985915, 'pegasus_entailment': 0.09943162401517232, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6164383561643836, 'r1_recall': 0.6081081081081081, 'r1_f1': 0.6122448979591837, 'pegasus_entailment': 0.5928626706202825, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5981308411214953, 'r1_recall': 0.48854961832061067, 'r1_f1': 0.5378151260504201, 'pegasus_entailment': 0.5036757367663085, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7230769230769231, 'r1_recall': 0.3983050847457627, 'r1_f1': 0.5136612021857924, 'pegasus_entailment': 0.9645333886146545, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7181818181818181, 'r1_recall': 0.6076923076923076, 'r1_f1': 0.6583333333333333, 'pegasus_entailment': 0.6812905271848043, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.51, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.46575342465753417, 'pegasus_entailment': 0.3687994755455293, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6637931034482759, 'r1_recall': 0.5347222222222222, 'r1_f1': 0.5923076923076923, 'pegasus_entailment': 0.6600017994642258, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5641025641025641, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.5238095238095238, 'pegasus_entailment': 0.41945621371269226, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.59, 'r1_recall': 0.44360902255639095, 'r1_f1': 0.5064377682403433, 'pegasus_entailment': 0.8845803141593933, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6695652173913044, 'r1_recall': 0.3632075471698113, 'r1_f1': 0.47094801223241584, 'pegasus_entailment': 0.6501234322786331, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.34594594594594597, 'pegasus_entailment': 0.30402669799514115, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5670103092783505, 'r1_recall': 0.4296875, 'r1_f1': 0.4888888888888889, 'pegasus_entailment': 0.2779076211154461, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3392857142857143, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.44970414201183434, 'pegasus_entailment': 0.5265488564968109, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6277372262773723, 'r1_recall': 0.450261780104712, 'r1_f1': 0.524390243902439, 'pegasus_entailment': 0.5352659732103348, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44502617801047123, 'r1_recall': 0.5782312925170068, 'r1_f1': 0.5029585798816568, 'pegasus_entailment': 0.37357812374830246, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5086206896551724, 'r1_recall': 0.38311688311688313, 'r1_f1': 0.437037037037037, 'pegasus_entailment': 0.8457697033882141, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43410852713178294, 'r1_recall': 0.7466666666666667, 'r1_f1': 0.5490196078431372, 'pegasus_entailment': 0.668788643926382, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43523316062176165, 'r1_recall': 0.7304347826086957, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.7084570154547691, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.568, 'r1_recall': 0.46405228758169936, 'r1_f1': 0.5107913669064749, 'pegasus_entailment': 0.7136535247166952, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5092592592592593, 'r1_recall': 0.5392156862745098, 'r1_f1': 0.5238095238095237, 'pegasus_entailment': 0.26461450904607775, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31313131313131315, 'r1_recall': 0.543859649122807, 'r1_f1': 0.39743589743589747, 'pegasus_entailment': 0.3857461787760258, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4470588235294118, 'r1_recall': 0.59375, 'r1_f1': 0.5100671140939598, 'pegasus_entailment': 0.5820176843553782, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5161290322580645, 'r1_recall': 0.64, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.1763026174157858, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4810126582278481, 'r1_recall': 0.7169811320754716, 'r1_f1': 0.5757575757575758, 'pegasus_entailment': 0.8459522724151611, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.504, 'r1_recall': 0.6774193548387096, 'r1_f1': 0.5779816513761469, 'pegasus_entailment': 0.4886067658662796, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35789473684210527, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.4134679310955107, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6767676767676768, 'r1_recall': 0.6568627450980392, 'r1_f1': 0.6666666666666667, 'pegasus_entailment': 0.5531190969049931, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6161616161616161, 'r1_recall': 0.3860759493670886, 'r1_f1': 0.47470817120622566, 'pegasus_entailment': 0.6424889434129, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31, 'r1_recall': 0.543859649122807, 'r1_f1': 0.39490445859872614, 'pegasus_entailment': 0.40479302080348134, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6638655462184874, 'r1_recall': 0.5302013422818792, 'r1_f1': 0.5895522388059702, 'pegasus_entailment': 0.6046799421310425, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5217391304347826, 'r1_recall': 0.35036496350364965, 'r1_f1': 0.4192139737991266, 'pegasus_entailment': 0.6719161868095398, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5421686746987951, 'r1_recall': 0.6818181818181818, 'r1_f1': 0.6040268456375839, 'pegasus_entailment': 0.07457954878918827, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5568181818181818, 'r1_recall': 0.44144144144144143, 'r1_f1': 0.4924623115577889, 'pegasus_entailment': 0.6947434743245443, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3058823529411765, 'r1_recall': 0.65, 'r1_f1': 0.41600000000000004, 'pegasus_entailment': 0.6195839315652847, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5054945054945055, 'r1_recall': 0.36220472440944884, 'r1_f1': 0.4220183486238532, 'pegasus_entailment': 0.6029576162497202, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.644927536231884, 'r1_recall': 0.4517766497461929, 'r1_f1': 0.5313432835820896, 'pegasus_entailment': 0.3369411788880825, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7105263157894737, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.453781512605042, 'pegasus_entailment': 0.3816449474543333, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6576576576576577, 'r1_recall': 0.5251798561151079, 'r1_f1': 0.584, 'pegasus_entailment': 0.5647763879969716, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.14124293785310735, 'r1_recall': 0.3424657534246575, 'r1_f1': 0.2, 'pegasus_entailment': 0.002422826752687494, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3375, 'r1_recall': 0.4426229508196721, 'r1_f1': 0.3829787234042554, 'pegasus_entailment': 0.2427261816803366, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5959595959595959, 'r1_recall': 0.686046511627907, 'r1_f1': 0.6378378378378378, 'pegasus_entailment': 0.5694848671555519, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43617021276595747, 'r1_recall': 0.5540540540540541, 'r1_f1': 0.4880952380952381, 'pegasus_entailment': 0.24456173181533813, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.532967032967033, 'r1_recall': 0.5574712643678161, 'r1_f1': 0.5449438202247192, 'pegasus_entailment': 0.6229161381721496, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4098360655737705, 'r1_recall': 0.3472222222222222, 'r1_f1': 0.3759398496240602, 'pegasus_entailment': 0.35598167264834046, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6268656716417911, 'r1_recall': 0.4307692307692308, 'r1_f1': 0.5106382978723405, 'pegasus_entailment': 0.7973864525556564, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5512820512820513, 'r1_recall': 0.589041095890411, 'r1_f1': 0.5695364238410597, 'pegasus_entailment': 0.5172711908817291, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4636363636363636, 'r1_recall': 0.68, 'r1_f1': 0.5513513513513514, 'pegasus_entailment': 0.45809801295399666, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46923076923076923, 'r1_recall': 0.5350877192982456, 'r1_f1': 0.5, 'pegasus_entailment': 0.7889416019121805, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.639344262295082, 'r1_recall': 0.2074468085106383, 'r1_f1': 0.3132530120481928, 'pegasus_entailment': 0.6339450120925904, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3113207547169811, 'r1_recall': 0.559322033898305, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.5176110044121742, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7159090909090909, 'r1_recall': 0.375, 'r1_f1': 0.49218750000000006, 'pegasus_entailment': 0.5895891090234121, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.441340782122905, 'r1_recall': 0.6124031007751938, 'r1_f1': 0.512987012987013, 'pegasus_entailment': 0.6584297776222229, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5824175824175825, 'r1_recall': 0.35570469798657717, 'r1_f1': 0.4416666666666667, 'pegasus_entailment': 0.8418052991231283, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6377952755905512, 'r1_recall': 0.47928994082840237, 'r1_f1': 0.5472972972972974, 'pegasus_entailment': 0.40092804096639156, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6513761467889908, 'r1_recall': 0.5419847328244275, 'r1_f1': 0.5916666666666667, 'pegasus_entailment': 0.6452926496664683, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4470588235294118, 'r1_recall': 0.3064516129032258, 'r1_f1': 0.3636363636363637, 'pegasus_entailment': 0.5972260038057963, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40145985401459855, 'r1_recall': 0.6626506024096386, 'r1_f1': 0.5, 'pegasus_entailment': 0.4320931853726506, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2604166666666667, 'r1_recall': 0.6410256410256411, 'r1_f1': 0.3703703703703704, 'pegasus_entailment': 0.4436323530972004, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45454545454545453, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.4838709677419355, 'pegasus_entailment': 0.360270057618618, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6730769230769231, 'r1_recall': 0.3783783783783784, 'r1_f1': 0.48442906574394473, 'pegasus_entailment': 0.4126456279773265, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7068965517241379, 'r1_recall': 0.4270833333333333, 'r1_f1': 0.5324675324675324, 'pegasus_entailment': 0.9654142260551453, 'pegasus_flesch_kincaid': 33, 'pegasus_coleman_liau': 22, 'pegasus_ari': 39, 'pegasus_smog': 29}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7262569832402235, 'r1_recall': 0.33766233766233766, 'r1_f1': 0.4609929078014184, 'pegasus_entailment': 0.4424214256661279, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7611940298507462, 'r1_recall': 0.3541666666666667, 'r1_f1': 0.4834123222748815, 'pegasus_entailment': 0.6143056899309158, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25903614457831325, 'r1_recall': 0.6615384615384615, 'r1_f1': 0.3722943722943723, 'pegasus_entailment': 0.4355976700782776, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32061068702290074, 'r1_recall': 0.7, 'r1_f1': 0.43979057591623033, 'pegasus_entailment': 0.38663254380226136, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38, 'r1_recall': 0.4691358024691358, 'r1_f1': 0.4198895027624309, 'pegasus_entailment': 0.3341523340592782, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43157894736842106, 'r1_recall': 0.3942307692307692, 'r1_f1': 0.4120603015075377, 'pegasus_entailment': 0.7125851035118103, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2619047619047619, 'r1_recall': 0.38372093023255816, 'r1_f1': 0.3113207547169812, 'pegasus_entailment': 0.5495309568941593, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4, 'r1_recall': 0.5256410256410257, 'r1_f1': 0.4542936288088643, 'pegasus_entailment': 0.6471688866615295, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 14, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6120689655172413, 'r1_recall': 0.4303030303030303, 'r1_f1': 0.5053380782918149, 'pegasus_entailment': 0.7227631449699402, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.5901639344262295, 'r1_f1': 0.496551724137931, 'pegasus_entailment': 0.7331307819113135, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5294117647058824, 'r1_recall': 0.54, 'r1_f1': 0.5346534653465347, 'pegasus_entailment': 0.6270806448800224, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5161290322580646, 'pegasus_entailment': 0.33051775582134724, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6341463414634146, 'r1_recall': 0.3969465648854962, 'r1_f1': 0.4882629107981221, 'pegasus_entailment': 0.41792208701372147, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45217391304347826, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5048543689320388, 'pegasus_entailment': 0.5840363681316376, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44155844155844154, 'r1_recall': 0.6476190476190476, 'r1_f1': 0.525096525096525, 'pegasus_entailment': 0.4465103766747883, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.40625, 'r1_recall': 0.7123287671232876, 'r1_f1': 0.5174129353233831, 'pegasus_entailment': 0.46607450023293495, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42105263157894735, 'r1_recall': 0.32, 'r1_f1': 0.3636363636363636, 'pegasus_entailment': 0.2524565467610955, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5573770491803278, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.576271186440678, 'pegasus_entailment': 0.3694284028315451, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4057971014492754, 'r1_recall': 0.6292134831460674, 'r1_f1': 0.49339207048458156, 'pegasus_entailment': 0.31593561843037604, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.6744186046511628, 'r1_f1': 0.4461538461538461, 'pegasus_entailment': 0.3775640436215326, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.48868778280542985, 'r1_f1': 0.5639686684073106, 'pegasus_entailment': 0.4729231645663579, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6509433962264151, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6301369863013699, 'pegasus_entailment': 0.9620340764522552, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 22}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.313953488372093, 'r1_recall': 0.7297297297297297, 'r1_f1': 0.43902439024390244, 'pegasus_entailment': 0.5478938271601995, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4, 'r1_recall': 0.6341463414634146, 'r1_f1': 0.49056603773584906, 'pegasus_entailment': 0.808735579252243, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 13}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3422459893048128, 'r1_recall': 0.5981308411214953, 'r1_f1': 0.435374149659864, 'pegasus_entailment': 0.49664678672949475, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.41379310344827586, 'pegasus_entailment': 0.7014288306236267, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4117647058823529, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.5, 'pegasus_entailment': 0.6784124141559005, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45544554455445546, 'r1_recall': 0.5168539325842697, 'r1_f1': 0.4842105263157895, 'pegasus_entailment': 0.3659364618360996, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3, 'r1_recall': 0.711864406779661, 'r1_f1': 0.4221105527638191, 'pegasus_entailment': 0.41956439820933156, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5684210526315789, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5567010309278351, 'pegasus_entailment': 0.574154682457447, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4811320754716981, 'r1_recall': 0.53125, 'r1_f1': 0.504950495049505, 'pegasus_entailment': 0.8681904474894205, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4117647058823529, 'r1_recall': 0.5212765957446809, 'r1_f1': 0.460093896713615, 'pegasus_entailment': 0.8770277500152588, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8904109589041096, 'r1_recall': 0.24904214559386972, 'r1_f1': 0.38922155688622756, 'pegasus_entailment': 0.689355785648028, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5503875968992248, 'r1_recall': 0.355, 'r1_f1': 0.4316109422492401, 'pegasus_entailment': 0.6950813929239908, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23846153846153847, 'r1_recall': 0.3974358974358974, 'r1_f1': 0.29807692307692313, 'pegasus_entailment': 0.12507748816694533, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6338028169014085, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.5113636363636364, 'pegasus_entailment': 0.5415166139602661, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 18, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.68, 'r1_recall': 0.5, 'r1_f1': 0.576271186440678, 'pegasus_entailment': 0.3638786420226097, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.35678391959798994, 'r1_recall': 0.6283185840707964, 'r1_f1': 0.4551282051282051, 'pegasus_entailment': 0.7952338457107544, 'pegasus_flesch_kincaid': 34, 'pegasus_coleman_liau': 20, 'pegasus_ari': 42, 'pegasus_smog': 26}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5569620253164557, 'r1_recall': 0.5176470588235295, 'r1_f1': 0.5365853658536586, 'pegasus_entailment': 0.4831910679737727, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34615384615384615, 'r1_recall': 0.4090909090909091, 'r1_f1': 0.37500000000000006, 'pegasus_entailment': 0.26772380620241165, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 30, 'pegasus_smog': 20}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.4891304347826087, 'r1_f1': 0.5202312138728324, 'pegasus_entailment': 0.49933280423283577, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3482142857142857, 'r1_recall': 0.46987951807228917, 'r1_f1': 0.4, 'pegasus_entailment': 0.4733418520539999, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6559139784946236, 'r1_recall': 0.48412698412698413, 'r1_f1': 0.5570776255707762, 'pegasus_entailment': 0.5643767982721328, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5317460317460317, 'r1_recall': 0.6568627450980392, 'r1_f1': 0.5877192982456141, 'pegasus_entailment': 0.5240236613899469, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6214285714285714, 'r1_recall': 0.5403726708074534, 'r1_f1': 0.5780730897009967, 'pegasus_entailment': 0.5938585519790649, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3563218390804598, 'r1_recall': 0.543859649122807, 'r1_f1': 0.4305555555555556, 'pegasus_entailment': 0.5774400420486927, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7461538461538462, 'r1_recall': 0.42920353982300885, 'r1_f1': 0.5449438202247191, 'pegasus_entailment': 0.6602593461672465, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 20}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32894736842105265, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.3676470588235294, 'pegasus_entailment': 0.44736649592717487, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5825242718446602, 'r1_recall': 0.594059405940594, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.597746416926384, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3076923076923077, 'r1_recall': 0.7346938775510204, 'r1_f1': 0.43373493975903615, 'pegasus_entailment': 0.6235589114949107, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.16083916083916083, 'r1_recall': 0.5, 'r1_f1': 0.24338624338624337, 'pegasus_entailment': 0.686783391237259, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6, 'r1_recall': 0.5342465753424658, 'r1_f1': 0.5652173913043479, 'pegasus_entailment': 0.8961665829022726, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7083333333333334, 'r1_recall': 0.53125, 'r1_f1': 0.6071428571428571, 'pegasus_entailment': 0.5914654657244682, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4819277108433735, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.5095541401273885, 'pegasus_entailment': 0.42958517900357646, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4205607476635514, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.4368932038834951, 'pegasus_entailment': 0.46648714939753216, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 23, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5857142857142857, 'r1_recall': 0.4939759036144578, 'r1_f1': 0.5359477124183006, 'pegasus_entailment': 0.3466459661722183, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32919254658385094, 'r1_recall': 0.7464788732394366, 'r1_f1': 0.45689655172413796, 'pegasus_entailment': 0.31645672135055064, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.445859872611465, 'r1_recall': 0.6086956521739131, 'r1_f1': 0.5147058823529412, 'pegasus_entailment': 0.47586985528469083, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5620915032679739, 'r1_recall': 0.5119047619047619, 'r1_f1': 0.5358255451713396, 'pegasus_entailment': 0.5100622326135635, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2076923076923077, 'r1_recall': 0.5094339622641509, 'r1_f1': 0.29508196721311475, 'pegasus_entailment': 0.6849335134029388, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4857142857142857, 'r1_recall': 0.4722222222222222, 'r1_f1': 0.47887323943661975, 'pegasus_entailment': 0.7352795700232188, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4426229508196721, 'r1_recall': 0.4778761061946903, 'r1_f1': 0.4595744680851064, 'pegasus_entailment': 0.7532083690166473, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35, 'r1_recall': 0.5915492957746479, 'r1_f1': 0.43979057591623033, 'pegasus_entailment': 0.4487797051668167, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5359116022099447, 'r1_recall': 0.4429223744292237, 'r1_f1': 0.485, 'pegasus_entailment': 0.5004650130867958, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 31, 'pegasus_smog': 26}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1702127659574468, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.24806201550387597, 'pegasus_entailment': 0.7626012936234474, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5876288659793815, 'r1_recall': 0.6867469879518072, 'r1_f1': 0.6333333333333333, 'pegasus_entailment': 0.8178334385156631, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25274725274725274, 'r1_recall': 0.46938775510204084, 'r1_f1': 0.32857142857142857, 'pegasus_entailment': 0.3798382884512345, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5822784810126582, 'r1_recall': 0.5411764705882353, 'r1_f1': 0.5609756097560976, 'pegasus_entailment': 0.6456417888402939, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 14, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5915492957746479, 'r1_recall': 0.6511627906976745, 'r1_f1': 0.6199261992619927, 'pegasus_entailment': 0.6886632412672042, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5420560747663551, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5979381443298968, 'pegasus_entailment': 0.5807883948087692, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4621212121212121, 'r1_recall': 0.45864661654135336, 'r1_f1': 0.460377358490566, 'pegasus_entailment': 0.597563099116087, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47019867549668876, 'r1_recall': 0.6396396396396397, 'r1_f1': 0.5419847328244275, 'pegasus_entailment': 0.2665090948343277, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5164835164835165, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.5026737967914437, 'pegasus_entailment': 0.3958970159292221, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.608, 'r1_recall': 0.5428571428571428, 'r1_f1': 0.5735849056603773, 'pegasus_entailment': 0.8386620879173279, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5346534653465347, 'r1_recall': 0.375, 'r1_f1': 0.44081632653061226, 'pegasus_entailment': 0.5966607987880707, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6373626373626373, 'r1_recall': 0.6304347826086957, 'r1_f1': 0.633879781420765, 'pegasus_entailment': 0.7103262096643448, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6025641025641025, 'r1_recall': 0.4563106796116505, 'r1_f1': 0.5193370165745858, 'pegasus_entailment': 0.4203059909244378, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3972602739726027, 'r1_recall': 0.43283582089552236, 'r1_f1': 0.4142857142857143, 'pegasus_entailment': 0.4793517142534256, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38636363636363635, 'r1_recall': 0.5604395604395604, 'r1_f1': 0.45739910313901344, 'pegasus_entailment': 0.9407247543334961, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6565656565656566, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.5371900826446281, 'pegasus_entailment': 0.7116402983665466, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6333333333333333, 'r1_recall': 0.4672131147540984, 'r1_f1': 0.5377358490566038, 'pegasus_entailment': 0.49619363248348236, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6186440677966102, 'r1_recall': 0.4397590361445783, 'r1_f1': 0.5140845070422535, 'pegasus_entailment': 0.33389566242694857, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5068493150684932, 'r1_recall': 0.6727272727272727, 'r1_f1': 0.578125, 'pegasus_entailment': 0.2585871632521351, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4819277108433735, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.5095541401273885, 'pegasus_entailment': 0.5989743340760469, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6176470588235294, 'r1_recall': 0.4117647058823529, 'r1_f1': 0.4941176470588236, 'pegasus_entailment': 0.9081464290618897, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7142857142857143, 'r1_recall': 0.2777777777777778, 'r1_f1': 0.4, 'pegasus_entailment': 0.17842229083180428, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 22}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4462809917355372, 'r1_recall': 0.4462809917355372, 'r1_f1': 0.4462809917355372, 'pegasus_entailment': 0.38466294258832934, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6240601503759399, 'r1_recall': 0.5804195804195804, 'r1_f1': 0.6014492753623188, 'pegasus_entailment': 0.2679301844909787, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5632183908045977, 'r1_f1': 0.5297297297297298, 'pegasus_entailment': 0.9017541408538818, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4025157232704403, 'r1_recall': 0.7032967032967034, 'r1_f1': 0.512, 'pegasus_entailment': 0.7340094149112701, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.424, 'r1_recall': 0.5196078431372549, 'r1_f1': 0.46696035242290745, 'pegasus_entailment': 0.2617284548468888, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5301204819277109, 'r1_recall': 0.38596491228070173, 'r1_f1': 0.4467005076142132, 'pegasus_entailment': 0.173368559529384, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4230769230769231, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4334975369458128, 'pegasus_entailment': 0.21802279073745012, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34951456310679613, 'r1_recall': 0.4044943820224719, 'r1_f1': 0.375, 'pegasus_entailment': 0.5614780634641647, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7232142857142857, 'r1_recall': 0.49693251533742333, 'r1_f1': 0.589090909090909, 'pegasus_entailment': 0.32371363043785095, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.1978021978021978, 'r1_f1': 0.29032258064516125, 'pegasus_entailment': 0.7202626268068949, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7340425531914894, 'r1_recall': 0.2509090909090909, 'r1_f1': 0.37398373983739835, 'pegasus_entailment': 0.13107179198414087, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5221238938053098, 'r1_recall': 0.5412844036697247, 'r1_f1': 0.5315315315315315, 'pegasus_entailment': 0.5043993443250656, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.14705882352941177, 'r1_recall': 0.3448275862068966, 'r1_f1': 0.20618556701030927, 'pegasus_entailment': 0.7611465871334075, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 13, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6388888888888888, 'r1_recall': 0.2541436464088398, 'r1_f1': 0.36363636363636365, 'pegasus_entailment': 0.7412648598353068, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38333333333333336, 'r1_recall': 0.5974025974025974, 'r1_f1': 0.46700507614213205, 'pegasus_entailment': 0.45729513963063556, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3532934131736527, 'r1_recall': 0.7375, 'r1_f1': 0.4777327935222673, 'pegasus_entailment': 0.5097744427621365, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6333333333333333, 'r1_recall': 0.6129032258064516, 'r1_f1': 0.6229508196721313, 'pegasus_entailment': 0.8256654217839241, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3695652173913043, 'r1_recall': 0.6296296296296297, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.36737420766924817, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34074074074074073, 'r1_recall': 0.5111111111111111, 'r1_f1': 0.40888888888888886, 'pegasus_entailment': 0.22086656318667033, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29411764705882354, 'r1_recall': 0.5072463768115942, 'r1_f1': 0.3723404255319149, 'pegasus_entailment': 0.6648022555746138, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4375, 'r1_recall': 0.65625, 'r1_f1': 0.525, 'pegasus_entailment': 0.4189812032771962, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38317757009345793, 'r1_recall': 0.640625, 'r1_f1': 0.4795321637426901, 'pegasus_entailment': 0.24816097575239837, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32075471698113206, 'r1_recall': 0.5604395604395604, 'r1_f1': 0.40800000000000003, 'pegasus_entailment': 0.6485990583896637, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.6590909090909091, 'r1_f1': 0.5686274509803921, 'pegasus_entailment': 0.5647896478573481, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4032258064516129, 'r1_recall': 0.8064516129032258, 'r1_f1': 0.5376344086021505, 'pegasus_entailment': 0.6525989755988121, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4233128834355828, 'r1_recall': 0.6448598130841121, 'r1_f1': 0.5111111111111112, 'pegasus_entailment': 0.8227545022964478, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 19, 'pegasus_ari': 35, 'pegasus_smog': 26}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35802469135802467, 'r1_recall': 0.4603174603174603, 'r1_f1': 0.4027777777777778, 'pegasus_entailment': 0.5013342751190066, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7843137254901961, 'r1_recall': 0.3018867924528302, 'r1_f1': 0.435967302452316, 'pegasus_entailment': 0.40854107961058617, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37606837606837606, 'r1_recall': 0.6875, 'r1_f1': 0.4861878453038673, 'pegasus_entailment': 0.4723321497440338, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44047619047619047, 'r1_recall': 0.40217391304347827, 'r1_f1': 0.4204545454545454, 'pegasus_entailment': 0.6690264567732811, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4492753623188406, 'r1_recall': 0.62, 'r1_f1': 0.5210084033613446, 'pegasus_entailment': 0.6055862506230673, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5051546391752577, 'r1_recall': 0.35, 'r1_f1': 0.41350210970464135, 'pegasus_entailment': 0.5605651717633009, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5841584158415841, 'r1_recall': 0.6276595744680851, 'r1_f1': 0.6051282051282051, 'pegasus_entailment': 0.37430555671453475, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38095238095238093, 'r1_recall': 0.5039370078740157, 'r1_f1': 0.43389830508474575, 'pegasus_entailment': 0.7205760938425859, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3364485981308411, 'r1_recall': 0.5070422535211268, 'r1_f1': 0.40449438202247184, 'pegasus_entailment': 0.9426589757204056, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33505154639175255, 'r1_recall': 0.6914893617021277, 'r1_f1': 0.45138888888888884, 'pegasus_entailment': 0.4268002316355705, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3617021276595745, 'r1_recall': 0.40476190476190477, 'r1_f1': 0.3820224719101123, 'pegasus_entailment': 0.3946496956050396, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4339622641509434, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.5111111111111112, 'pegasus_entailment': 0.28816146217286587, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4246575342465753, 'r1_recall': 0.4626865671641791, 'r1_f1': 0.44285714285714284, 'pegasus_entailment': 0.8424924810727438, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29411764705882354, 'r1_recall': 0.546875, 'r1_f1': 0.3825136612021858, 'pegasus_entailment': 0.5009281237920126, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4206896551724138, 'r1_recall': 0.35260115606936415, 'r1_f1': 0.38364779874213834, 'pegasus_entailment': 0.6884706701551165, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5460526315789473, 'r1_recall': 0.503030303030303, 'r1_f1': 0.5236593059936909, 'pegasus_entailment': 0.4308182641863823, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.6530612244897959, 'r1_f1': 0.6095238095238094, 'pegasus_entailment': 0.7304733274504542, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4861111111111111, 'r1_recall': 0.37433155080213903, 'r1_f1': 0.42296072507552873, 'pegasus_entailment': 0.41132546961307526, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5053763440860215, 'r1_recall': 0.49473684210526314, 'r1_f1': 0.5, 'pegasus_entailment': 0.17137603129958734, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43157894736842106, 'r1_recall': 0.5694444444444444, 'r1_f1': 0.49101796407185627, 'pegasus_entailment': 0.5554590649902821, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1782178217821782, 'r1_recall': 0.32727272727272727, 'r1_f1': 0.23076923076923075, 'pegasus_entailment': 0.6031137928366661, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1885245901639344, 'r1_recall': 0.5476190476190477, 'r1_f1': 0.28048780487804875, 'pegasus_entailment': 0.4284013081341982, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.5113636363636364, 'pegasus_entailment': 0.8923010379076004, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27419354838709675, 'r1_recall': 0.6538461538461539, 'r1_f1': 0.38636363636363635, 'pegasus_entailment': 0.48869218677282333, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4262295081967213, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4351464435146443, 'pegasus_entailment': 0.43069869341949624, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6293103448275862, 'r1_recall': 0.5572519083969466, 'r1_f1': 0.5910931174089069, 'pegasus_entailment': 0.44796405732631683, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45121951219512196, 'r1_recall': 0.44047619047619047, 'r1_f1': 0.44578313253012053, 'pegasus_entailment': 0.5210512725170702, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 12}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5645161290322581, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.4605263157894737, 'pegasus_entailment': 0.5613986611366272, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5346534653465347, 'r1_recall': 0.5934065934065934, 'r1_f1': 0.5625, 'pegasus_entailment': 0.42794475704431534, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4318181818181818, 'r1_recall': 0.5181818181818182, 'r1_f1': 0.4710743801652893, 'pegasus_entailment': 0.6293681301176548, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30434782608695654, 'r1_recall': 0.6086956521739131, 'r1_f1': 0.4057971014492754, 'pegasus_entailment': 0.6748266637325286, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45045045045045046, 'r1_recall': 0.5, 'r1_f1': 0.4739336492890995, 'pegasus_entailment': 0.7677317361036936, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.308411214953271, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.37499999999999994, 'pegasus_entailment': 0.8831396102905273, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 18, 'pegasus_ari': 34, 'pegasus_smog': 24}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.52, 'r1_recall': 0.5977011494252874, 'r1_f1': 0.5561497326203209, 'pegasus_entailment': 0.8541878312826157, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.52, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.5148514851485149, 'pegasus_entailment': 0.8826821645100912, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32727272727272727, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.43373493975903615, 'pegasus_entailment': 0.6689807027578354, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23232323232323232, 'r1_recall': 0.4423076923076923, 'r1_f1': 0.304635761589404, 'pegasus_entailment': 0.3970381213972966, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5095541401273885, 'r1_recall': 0.5594405594405595, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.7796700298786163, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4492753623188406, 'r1_recall': 0.7126436781609196, 'r1_f1': 0.5511111111111111, 'pegasus_entailment': 0.39139899611473083, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3717948717948718, 'r1_recall': 0.5370370370370371, 'r1_f1': 0.43939393939393945, 'pegasus_entailment': 0.7252814471721649, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.53125, 'r1_recall': 0.4214876033057851, 'r1_f1': 0.4700460829493088, 'pegasus_entailment': 0.6994909346103668, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4305555555555556, 'r1_recall': 0.2980769230769231, 'r1_f1': 0.3522727272727273, 'pegasus_entailment': 0.25040580960921943, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.5294117647058824, 'pegasus_entailment': 0.7207957282662392, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3826086956521739, 'r1_recall': 0.6111111111111112, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.9317698627710342, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3900709219858156, 'r1_recall': 0.6179775280898876, 'r1_f1': 0.4782608695652174, 'pegasus_entailment': 0.5099079748615623, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19718309859154928, 'r1_recall': 0.3111111111111111, 'r1_f1': 0.2413793103448276, 'pegasus_entailment': 0.5412535984069109, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3314917127071823, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.42253521126760557, 'pegasus_entailment': 0.4457071080803871, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.11029411764705882, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.17543859649122806, 'pegasus_entailment': 0.6393171946207682, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28440366972477066, 'r1_recall': 0.6888888888888889, 'r1_f1': 0.40259740259740256, 'pegasus_entailment': 0.5428184867778327, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2777777777777778, 'r1_recall': 0.7692307692307693, 'r1_f1': 0.40816326530612246, 'pegasus_entailment': 0.8962098956108093, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5376344086021505, 'r1_recall': 0.33783783783783783, 'r1_f1': 0.4149377593360996, 'pegasus_entailment': 0.20058237512906393, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48026315789473684, 'r1_recall': 0.6347826086956522, 'r1_f1': 0.5468164794007491, 'pegasus_entailment': 0.8848073333501816, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3780487804878049, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.47692307692307695, 'pegasus_entailment': 0.3950699456036091, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4304635761589404, 'r1_recall': 0.5963302752293578, 'r1_f1': 0.5, 'pegasus_entailment': 0.47415022055308026, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7127659574468085, 'r1_recall': 0.4855072463768116, 'r1_f1': 0.5775862068965516, 'pegasus_entailment': 0.5173121131956577, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.875, 'r1_recall': 0.21875, 'r1_f1': 0.35, 'pegasus_entailment': 0.6140953763388097, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4094488188976378, 'r1_recall': 0.46846846846846846, 'r1_f1': 0.43697478991596633, 'pegasus_entailment': 0.7503554821014404, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5925925925925926, 'r1_recall': 0.3221476510067114, 'r1_f1': 0.41739130434782606, 'pegasus_entailment': 0.5835655828317007, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.746268656716418, 'r1_recall': 0.33557046979865773, 'r1_f1': 0.46296296296296297, 'pegasus_entailment': 0.6607837080955505, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 16}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25217391304347825, 'r1_recall': 0.5918367346938775, 'r1_f1': 0.35365853658536583, 'pegasus_entailment': 0.6299770817160606, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.425, 'r1_recall': 0.7083333333333334, 'r1_f1': 0.53125, 'pegasus_entailment': 0.5361908872922262, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.34532374100719426, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.43636363636363634, 'pegasus_entailment': 0.45333522707223894, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8666666666666667, 'r1_recall': 0.52, 'r1_f1': 0.65, 'pegasus_entailment': 0.509337991476059, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.25925925925925924, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.3465346534653465, 'pegasus_entailment': 0.5047692414373159, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.526829268292683, 'r1_recall': 0.627906976744186, 'r1_f1': 0.572944297082228, 'pegasus_entailment': 0.9166067242622375, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 18}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40476190476190477, 'r1_recall': 0.6891891891891891, 'r1_f1': 0.51, 'pegasus_entailment': 0.7564972192049026, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3897058823529412, 'r1_recall': 0.654320987654321, 'r1_f1': 0.4884792626728111, 'pegasus_entailment': 0.5750885549932718, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49206349206349204, 'r1_recall': 0.4397163120567376, 'r1_f1': 0.4644194756554307, 'pegasus_entailment': 0.5888237562030554, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36257309941520466, 'r1_recall': 0.4732824427480916, 'r1_f1': 0.4105960264900662, 'pegasus_entailment': 0.6308868378400803, 'pegasus_flesch_kincaid': 31, 'pegasus_coleman_liau': 21, 'pegasus_ari': 38, 'pegasus_smog': 26}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6302521008403361, 'r1_recall': 0.352112676056338, 'r1_f1': 0.45180722891566266, 'pegasus_entailment': 0.4726468125979106, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 24}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6056338028169014, 'r1_recall': 0.4777777777777778, 'r1_f1': 0.5341614906832298, 'pegasus_entailment': 0.4736934155225754, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34065934065934067, 'r1_recall': 0.543859649122807, 'r1_f1': 0.41891891891891897, 'pegasus_entailment': 0.5928656955560049, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5867768595041323, 'r1_recall': 0.37566137566137564, 'r1_f1': 0.45806451612903226, 'pegasus_entailment': 0.5044777169823647, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6423841059602649, 'r1_recall': 0.3190789473684211, 'r1_f1': 0.4263736263736264, 'pegasus_entailment': 0.6255021020770073, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.15492957746478872, 'r1_recall': 0.3492063492063492, 'r1_f1': 0.21463414634146338, 'pegasus_entailment': 0.6453132480382919, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.6631578947368421, 'r1_f1': 0.5206611570247933, 'pegasus_entailment': 0.403402116894722, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6836734693877551, 'r1_recall': 0.4240506329113924, 'r1_f1': 0.5234374999999999, 'pegasus_entailment': 0.462316888384521, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.325, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.3768115942028986, 'pegasus_entailment': 0.4004717245697975, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5344827586206896, 'r1_recall': 0.3425414364640884, 'r1_f1': 0.4175084175084175, 'pegasus_entailment': 0.5696811825037003, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5915492957746479, 'r1_recall': 0.29577464788732394, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.931306779384613, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4772727272727273, 'r1_recall': 0.4421052631578947, 'r1_f1': 0.45901639344262296, 'pegasus_entailment': 0.3210659953765571, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5630252100840336, 'r1_recall': 0.38953488372093026, 'r1_f1': 0.4604810996563574, 'pegasus_entailment': 0.7342121362686157, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3898305084745763, 'r1_recall': 0.647887323943662, 'r1_f1': 0.48677248677248675, 'pegasus_entailment': 0.4943094372749329, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6486486486486487, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.5393258426966292, 'pegasus_entailment': 0.5958486437797547, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39869281045751637, 'r1_recall': 0.6559139784946236, 'r1_f1': 0.4959349593495935, 'pegasus_entailment': 0.7683200240135193, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.29333333333333333, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.39111111111111113, 'pegasus_entailment': 0.6867952644824982, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.44954128440366975, 'r1_recall': 0.6901408450704225, 'r1_f1': 0.5444444444444445, 'pegasus_entailment': 0.3819605705793947, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.49504950495049505, 'r1_f1': 0.5235602094240838, 'pegasus_entailment': 0.2650079026352614, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.620253164556962, 'r1_recall': 0.47342995169082125, 'r1_f1': 0.5369863013698629, 'pegasus_entailment': 0.6833783745765686, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.390625, 'r1_recall': 0.49019607843137253, 'r1_f1': 0.4347826086956521, 'pegasus_entailment': 0.6366895238558451, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3, 'r1_recall': 0.35, 'r1_f1': 0.3230769230769231, 'pegasus_entailment': 0.39698904752731323, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6576576576576577, 'r1_recall': 0.4101123595505618, 'r1_f1': 0.5051903114186851, 'pegasus_entailment': 0.7920957008997599, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5145631067961165, 'r1_recall': 0.726027397260274, 'r1_f1': 0.6022727272727273, 'pegasus_entailment': 0.44147954881191254, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40298507462686567, 'r1_recall': 0.7105263157894737, 'r1_f1': 0.5142857142857143, 'pegasus_entailment': 0.3388755025807768, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6071428571428571, 'r1_recall': 0.5604395604395604, 'r1_f1': 0.5828571428571429, 'pegasus_entailment': 0.460161825021108, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5588235294117647, 'r1_recall': 0.6333333333333333, 'r1_f1': 0.59375, 'pegasus_entailment': 0.7583140105009079, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7704918032786885, 'r1_recall': 0.13333333333333333, 'r1_f1': 0.22732769044740025, 'pegasus_entailment': 0.824417769908905, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5029940119760479, 'r1_recall': 0.5915492957746479, 'r1_f1': 0.5436893203883495, 'pegasus_entailment': 0.6133005678653717, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8207547169811321, 'r1_recall': 0.47540983606557374, 'r1_f1': 0.6020761245674741, 'pegasus_entailment': 0.4052615687251091, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.375, 'r1_recall': 0.5161290322580645, 'r1_f1': 0.4343891402714932, 'pegasus_entailment': 0.3793397694826126, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.625, 'r1_recall': 0.5603448275862069, 'r1_f1': 0.5909090909090908, 'pegasus_entailment': 0.5804723761975765, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41284403669724773, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.5172413793103449, 'pegasus_entailment': 0.2385821733623743, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5636363636363636, 'r1_recall': 0.39490445859872614, 'r1_f1': 0.46441947565543074, 'pegasus_entailment': 0.3807106213644147, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19047619047619047, 'r1_recall': 0.5, 'r1_f1': 0.27586206896551724, 'pegasus_entailment': 0.6568746045231819, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5319148936170213, 'r1_recall': 0.5154639175257731, 'r1_f1': 0.5235602094240838, 'pegasus_entailment': 0.9578053653240204, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.11965811965811966, 'r1_recall': 0.4, 'r1_f1': 0.18421052631578946, 'pegasus_entailment': 0.6441221088171005, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5773195876288659, 'r1_recall': 0.5773195876288659, 'r1_f1': 0.5773195876288659, 'pegasus_entailment': 0.693779855966568, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.5575221238938053, 'r1_f1': 0.5478260869565217, 'pegasus_entailment': 0.5145249565442404, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6504854368932039, 'r1_recall': 0.4962962962962963, 'r1_f1': 0.5630252100840336, 'pegasus_entailment': 0.36047184467315674, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23711340206185566, 'r1_recall': 0.42592592592592593, 'r1_f1': 0.304635761589404, 'pegasus_entailment': 0.43698221296072004, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4387755102040816, 'r1_recall': 0.43, 'r1_f1': 0.4343434343434343, 'pegasus_entailment': 0.5563248097896576, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
** Analysing column: malformed_chain



malformed_chain
Length after nones removed
616
MIN
0
MEAN
0
MAX
1
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.11029411764705882
MEAN
0.48141931500862234
MAX
0.8904109589041096
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.13333333333333333
MEAN
0.51285806291861
MAX
0.8405797101449275
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.17543859649122806
MEAN
0.4726727885910914
MAX
0.6880000000000001
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.002422826752687494
MEAN
0.5587482053890708
MAX
0.9918626844882965
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
11
MEAN
18
MAX
36
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
12
MEAN
17
MAX
23
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
10
MEAN
21
MAX
43
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
12
MEAN
19
MAX
29
{}
Entered file!
Imports done!
*** RUN *** 
eval_5d
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 14:29:26.400097: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 14:29:26.942714: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/5d_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4807692307692308, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.4672897196261683, 'pegasus_entailment': 0.6061936747282743, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5225225225225225, 'r1_recall': 0.3352601156069364, 'r1_f1': 0.4084507042253521, 'pegasus_entailment': 0.5769172310829163, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32608695652173914, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.4, 'pegasus_entailment': 0.6014851152896881, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.5116279069767442, 'r1_f1': 0.528, 'pegasus_entailment': 0.7040461540222168, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7684210526315789, 'r1_recall': 0.41954022988505746, 'r1_f1': 0.5427509293680297, 'pegasus_entailment': 0.7793105443318685, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46875, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.46511627906976744, 'pegasus_entailment': 0.5304626058787107, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1574074074074074, 'r1_recall': 0.53125, 'r1_f1': 0.24285714285714285, 'pegasus_entailment': 0.6913942148288091, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.13043478260869565, 'r1_recall': 0.4838709677419355, 'r1_f1': 0.2054794520547945, 'pegasus_entailment': 0.7671996504068375, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4888888888888889, 'r1_recall': 0.4429530201342282, 'r1_f1': 0.4647887323943662, 'pegasus_entailment': 0.3000497557222843, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6041666666666666, 'r1_recall': 0.42028985507246375, 'r1_f1': 0.4957264957264957, 'pegasus_entailment': 0.44016016460955143, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5794392523364486, 'r1_recall': 0.41333333333333333, 'r1_f1': 0.4824902723735408, 'pegasus_entailment': 0.611014187335968, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.335, 'r1_recall': 0.5630252100840336, 'r1_f1': 0.420062695924765, 'pegasus_entailment': 0.6735939681529999, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 23}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5138888888888888, 'r1_recall': 0.34579439252336447, 'r1_f1': 0.4134078212290503, 'pegasus_entailment': 0.40662093460559845, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3424657534246575, 'r1_recall': 0.5681818181818182, 'r1_f1': 0.4273504273504274, 'pegasus_entailment': 0.7258063554763794, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5657894736842105, 'r1_recall': 0.22395833333333334, 'r1_f1': 0.3208955223880597, 'pegasus_entailment': 0.4622803367674351, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1984732824427481, 'r1_recall': 0.4406779661016949, 'r1_f1': 0.27368421052631575, 'pegasus_entailment': 0.5831920504570007, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2670807453416149, 'r1_recall': 0.43434343434343436, 'r1_f1': 0.33076923076923076, 'pegasus_entailment': 0.712011706829071, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7142857142857143, 'r1_recall': 0.20134228187919462, 'r1_f1': 0.31413612565445026, 'pegasus_entailment': 0.5971342126528422, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6521739130434783, 'r1_recall': 0.2795031055900621, 'r1_f1': 0.3913043478260869, 'pegasus_entailment': 0.10512941951553027, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4634146341463415, 'r1_recall': 0.4367816091954023, 'r1_f1': 0.4497041420118343, 'pegasus_entailment': 0.6434887088835239, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 12}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6526315789473685, 'r1_recall': 0.34065934065934067, 'r1_f1': 0.4476534296028881, 'pegasus_entailment': 0.6636417433619499, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6632653061224489, 'r1_recall': 0.43333333333333335, 'r1_f1': 0.5241935483870968, 'pegasus_entailment': 0.4211210757493973, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.4225352112676056, 'pegasus_entailment': 0.7821543961763382, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4391891891891892, 'r1_recall': 0.47794117647058826, 'r1_f1': 0.45774647887323944, 'pegasus_entailment': 0.47493942081928253, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32, 'r1_recall': 0.48, 'r1_f1': 0.38399999999999995, 'pegasus_entailment': 0.441650765016675, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8921568627450981, 'r1_recall': 0.48148148148148145, 'r1_f1': 0.6254295532646048, 'pegasus_entailment': 0.8613804578781128, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 34, 'pegasus_smog': 21}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5523809523809524, 'r1_recall': 0.4233576642335766, 'r1_f1': 0.4793388429752066, 'pegasus_entailment': 0.49784310907125473, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6057692307692307, 'r1_recall': 0.23507462686567165, 'r1_f1': 0.3387096774193548, 'pegasus_entailment': 0.36103848554193974, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35294117647058826, 'r1_recall': 0.5526315789473685, 'r1_f1': 0.43076923076923085, 'pegasus_entailment': 0.498461219171683, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3013698630136986, 'r1_recall': 0.3893805309734513, 'r1_f1': 0.3397683397683397, 'pegasus_entailment': 0.8868874192237854, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27071823204419887, 'r1_recall': 0.5632183908045977, 'r1_f1': 0.3656716417910447, 'pegasus_entailment': 0.5123159842831748, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5542168674698795, 'r1_recall': 0.22885572139303484, 'r1_f1': 0.32394366197183094, 'pegasus_entailment': 0.3657136633992195, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2554347826086957, 'r1_recall': 0.4563106796116505, 'r1_f1': 0.3275261324041812, 'pegasus_entailment': 0.8142919063568115, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4639175257731959, 'r1_f1': 0.4812834224598931, 'pegasus_entailment': 0.5278027486056089, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3669724770642202, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.4145077720207254, 'pegasus_entailment': 0.4326439518481493, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5411764705882353, 'r1_recall': 0.39655172413793105, 'r1_f1': 0.4577114427860696, 'pegasus_entailment': 0.42469828203320503, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45714285714285713, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.7737667858600616, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 27}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31543624161073824, 'r1_recall': 0.6911764705882353, 'r1_f1': 0.43317972350230405, 'pegasus_entailment': 0.5261788163334131, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.14736842105263157, 'r1_recall': 0.6222222222222222, 'r1_f1': 0.2382978723404255, 'pegasus_entailment': 0.5684567362070083, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.56, 'r1_recall': 0.42168674698795183, 'r1_f1': 0.4810996563573884, 'pegasus_entailment': 0.6744902610778809, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5433070866141733, 'r1_recall': 0.43125, 'r1_f1': 0.4808362369337979, 'pegasus_entailment': 0.5746024679392576, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3262411347517731, 'r1_recall': 0.5974025974025974, 'r1_f1': 0.42201834862385323, 'pegasus_entailment': 0.40669519174844027, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3673469387755102, 'r1_recall': 0.4931506849315068, 'r1_f1': 0.4210526315789474, 'pegasus_entailment': 0.4558989037759602, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4523809523809524, 'r1_recall': 0.4634146341463415, 'r1_f1': 0.4578313253012048, 'pegasus_entailment': 0.40219673328101635, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 23, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3017241379310345, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.36082474226804123, 'pegasus_entailment': 0.8659622222185135, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5242718446601942, 'r1_recall': 0.36, 'r1_f1': 0.42687747035573126, 'pegasus_entailment': 0.6334747597575188, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42483660130718953, 'r1_recall': 0.5508474576271186, 'r1_f1': 0.4797047970479705, 'pegasus_entailment': 0.4598232999444008, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4, 'r1_recall': 0.5585585585585585, 'r1_f1': 0.46616541353383456, 'pegasus_entailment': 0.6286517143249511, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.569620253164557, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.5521472392638036, 'pegasus_entailment': 0.5372192561626434, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4152542372881356, 'r1_recall': 0.47115384615384615, 'r1_f1': 0.44144144144144143, 'pegasus_entailment': 0.5549449423948923, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24102564102564103, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.34944237918215615, 'pegasus_entailment': 0.5933695375919342, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20108695652173914, 'r1_recall': 0.7254901960784313, 'r1_f1': 0.3148936170212766, 'pegasus_entailment': 0.684203777462244, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21717171717171718, 'r1_recall': 0.581081081081081, 'r1_f1': 0.3161764705882352, 'pegasus_entailment': 0.5952265610297521, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 23, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4380165289256198, 'r1_recall': 0.2994350282485876, 'r1_f1': 0.3557046979865772, 'pegasus_entailment': 0.22475423912207285, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 20}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43478260869565216, 'r1_recall': 0.5056179775280899, 'r1_f1': 0.46753246753246747, 'pegasus_entailment': 0.5294864922761917, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 23}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2616279069767442, 'r1_recall': 0.625, 'r1_f1': 0.36885245901639346, 'pegasus_entailment': 0.5470004498958587, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45528455284552843, 'r1_recall': 0.22310756972111553, 'r1_f1': 0.2994652406417112, 'pegasus_entailment': 0.7725601345300674, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29245283018867924, 'r1_recall': 0.484375, 'r1_f1': 0.36470588235294116, 'pegasus_entailment': 0.5712818741798401, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48484848484848486, 'r1_recall': 0.5289256198347108, 'r1_f1': 0.5059288537549408, 'pegasus_entailment': 0.6791524827480316, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3652173913043478, 'r1_recall': 0.4, 'r1_f1': 0.38181818181818183, 'pegasus_entailment': 0.7017617374658585, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3805970149253731, 'r1_recall': 0.5795454545454546, 'r1_f1': 0.45945945945945943, 'pegasus_entailment': 0.8739844163258871, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 32, 'pegasus_smog': 22}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29545454545454547, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.38235294117647056, 'pegasus_entailment': 0.45465700700879097, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.55, 'r1_recall': 0.3273809523809524, 'r1_f1': 0.4104477611940299, 'pegasus_entailment': 0.25759636610746384, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36774193548387096, 'r1_recall': 0.5876288659793815, 'r1_f1': 0.4523809523809524, 'pegasus_entailment': 0.593419899897916, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.19186046511627908, 'r1_recall': 0.6875, 'r1_f1': 0.30000000000000004, 'pegasus_entailment': 0.689475824435552, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.608, 'r1_recall': 0.5984251968503937, 'r1_f1': 0.6031746031746033, 'pegasus_entailment': 0.6953065693378448, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5473684210526316, 'r1_recall': 0.49056603773584906, 'r1_f1': 0.5174129353233831, 'pegasus_entailment': 0.665473461151123, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.35365853658536583, 'r1_recall': 0.6041666666666666, 'r1_f1': 0.4461538461538462, 'pegasus_entailment': 0.5691035588582357, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4144144144144144, 'r1_recall': 0.4, 'r1_f1': 0.40707964601769914, 'pegasus_entailment': 0.7009852044284344, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6222222222222222, 'r1_recall': 0.5490196078431373, 'r1_f1': 0.5833333333333334, 'pegasus_entailment': 0.5957823842763901, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6176470588235294, 'r1_recall': 0.3795180722891566, 'r1_f1': 0.47014925373134325, 'pegasus_entailment': 0.8898946195840836, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.336283185840708, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.4198895027624309, 'pegasus_entailment': 0.607048612833023, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3904761904761905, 'r1_recall': 0.6212121212121212, 'r1_f1': 0.47953216374269003, 'pegasus_entailment': 0.5311410546302795, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5234899328859061, 'r1_recall': 0.4105263157894737, 'r1_f1': 0.46017699115044247, 'pegasus_entailment': 0.5891169189874615, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.192, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.2436548223350254, 'pegasus_entailment': 0.6286360174417496, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5465116279069767, 'r1_recall': 0.5529411764705883, 'r1_f1': 0.5497076023391814, 'pegasus_entailment': 0.6917590498924255, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32061068702290074, 'r1_recall': 0.65625, 'r1_f1': 0.43076923076923074, 'pegasus_entailment': 0.35636561257498606, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33695652173913043, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.4305555555555555, 'pegasus_entailment': 0.35084428265690804, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30405405405405406, 'r1_recall': 0.5232558139534884, 'r1_f1': 0.38461538461538464, 'pegasus_entailment': 0.7085159942507744, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 25}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3305785123966942, 'r1_recall': 0.5970149253731343, 'r1_f1': 0.425531914893617, 'pegasus_entailment': 0.7462942004203796, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43902439024390244, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.45, 'pegasus_entailment': 0.40923261642456055, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5423728813559322, 'r1_recall': 0.3106796116504854, 'r1_f1': 0.3950617283950617, 'pegasus_entailment': 0.4467827280362447, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.313953488372093, 'r1_recall': 0.4153846153846154, 'r1_f1': 0.35761589403973515, 'pegasus_entailment': 0.5060287266969681, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34074074074074073, 'r1_recall': 0.5287356321839081, 'r1_f1': 0.4144144144144144, 'pegasus_entailment': 0.6741704444090525, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 22}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4782608695652174, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.4782608695652174, 'pegasus_entailment': 0.6953611373901367, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2932330827067669, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.35454545454545455, 'pegasus_entailment': 0.5854028180241585, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.19090909090909092, 'r1_recall': 0.2692307692307692, 'r1_f1': 0.22340425531914893, 'pegasus_entailment': 0.7246140688657761, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.21830985915492956, 'r1_recall': 0.6888888888888889, 'r1_f1': 0.3315508021390375, 'pegasus_entailment': 0.8109391450881958, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6126126126126126, 'r1_recall': 0.3269230769230769, 'r1_f1': 0.426332288401254, 'pegasus_entailment': 0.5193627652770374, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3465346534653465, 'r1_recall': 0.5, 'r1_f1': 0.4093567251461988, 'pegasus_entailment': 0.6273508250713349, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.620253164556962, 'r1_recall': 0.5104166666666666, 'r1_f1': 0.5599999999999999, 'pegasus_entailment': 0.4087044566869736, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 28}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4523809523809524, 'r1_recall': 0.4253731343283582, 'r1_f1': 0.43846153846153846, 'pegasus_entailment': 0.6338676959276199, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46017699115044247, 'r1_recall': 0.7123287671232876, 'r1_f1': 0.5591397849462365, 'pegasus_entailment': 0.50166996717453, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5510204081632653, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.5023255813953488, 'pegasus_entailment': 0.18973366916179657, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.24675324675324675, 'r1_recall': 0.3917525773195876, 'r1_f1': 0.3027888446215139, 'pegasus_entailment': 0.5593556731939315, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44525547445255476, 'r1_recall': 0.3446327683615819, 'r1_f1': 0.3885350318471337, 'pegasus_entailment': 0.5302359163761139, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3475609756097561, 'r1_recall': 0.5876288659793815, 'r1_f1': 0.4367816091954023, 'pegasus_entailment': 0.47341954428702593, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4523809523809524, 'r1_f1': 0.47500000000000003, 'pegasus_entailment': 0.7161554247140884, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29357798165137616, 'r1_recall': 0.49230769230769234, 'r1_f1': 0.367816091954023, 'pegasus_entailment': 0.5469801962375641, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4107142857142857, 'r1_recall': 0.4107142857142857, 'r1_f1': 0.4107142857142857, 'pegasus_entailment': 0.5768040103837848, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1896551724137931, 'r1_recall': 0.5409836065573771, 'r1_f1': 0.28085106382978725, 'pegasus_entailment': 0.6054768775190625, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37168141592920356, 'r1_recall': 0.44680851063829785, 'r1_f1': 0.4057971014492754, 'pegasus_entailment': 0.6231986731290817, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5537190082644629, 'r1_recall': 0.5826086956521739, 'r1_f1': 0.5677966101694916, 'pegasus_entailment': 0.8110992908477783, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48148148148148145, 'r1_recall': 0.5803571428571429, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.6248864009976387, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32098765432098764, 'r1_recall': 0.65, 'r1_f1': 0.4297520661157025, 'pegasus_entailment': 0.5820901036262512, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5032679738562091, 'r1_recall': 0.5968992248062015, 'r1_f1': 0.5460992907801417, 'pegasus_entailment': 0.6208245679736137, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.39634146341463417, 'r1_recall': 0.6310679611650486, 'r1_f1': 0.4868913857677903, 'pegasus_entailment': 0.3256160318851471, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.57, 'r1_recall': 0.35625, 'r1_f1': 0.4384615384615384, 'pegasus_entailment': 0.37061620006958645, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32592592592592595, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.41904761904761906, 'pegasus_entailment': 0.30759496092796323, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31521739130434784, 'r1_recall': 0.48333333333333334, 'r1_f1': 0.381578947368421, 'pegasus_entailment': 0.6477004587650299, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.30246913580246915, 'r1_recall': 0.7101449275362319, 'r1_f1': 0.42424242424242425, 'pegasus_entailment': 0.7178580363591512, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 21, 'pegasus_ari': 37, 'pegasus_smog': 27}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47058823529411764, 'r1_recall': 0.48120300751879697, 'r1_f1': 0.4758364312267658, 'pegasus_entailment': 0.8503869970639547, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 26}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33093525179856115, 'r1_recall': 0.5822784810126582, 'r1_f1': 0.42201834862385323, 'pegasus_entailment': 0.7277692556381226, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4782608695652174, 'r1_recall': 0.6179775280898876, 'r1_f1': 0.5392156862745098, 'pegasus_entailment': 0.45928732454776766, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47619047619047616, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.46875, 'pegasus_entailment': 0.5112383477389812, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4807692307692308, 'r1_recall': 0.42134831460674155, 'r1_f1': 0.4491017964071856, 'pegasus_entailment': 0.7479603528976441, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7070707070707071, 'r1_recall': 0.3977272727272727, 'r1_f1': 0.509090909090909, 'pegasus_entailment': 0.605744351943334, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5181818181818182, 'r1_recall': 0.4253731343283582, 'r1_f1': 0.4672131147540984, 'pegasus_entailment': 0.539197564125061, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40404040404040403, 'r1_recall': 0.425531914893617, 'r1_f1': 0.4145077720207254, 'pegasus_entailment': 0.48456484638154507, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6629213483146067, 'r1_recall': 0.4645669291338583, 'r1_f1': 0.5462962962962963, 'pegasus_entailment': 0.5431169345974922, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36363636363636365, 'r1_recall': 0.5909090909090909, 'r1_f1': 0.45021645021645024, 'pegasus_entailment': 0.7652554937771389, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5473684210526316, 'r1_recall': 0.45217391304347826, 'r1_f1': 0.4952380952380953, 'pegasus_entailment': 0.34382139643033344, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29850746268656714, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.3809523809523809, 'pegasus_entailment': 0.6432536666591963, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23636363636363636, 'r1_recall': 0.6046511627906976, 'r1_f1': 0.3398692810457516, 'pegasus_entailment': 0.5628548661867777, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.375, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.44117647058823534, 'pegasus_entailment': 0.7278532981872559, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5588235294117647, 'r1_recall': 0.5801526717557252, 'r1_f1': 0.5692883895131087, 'pegasus_entailment': 0.45559594929218294, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3092105263157895, 'r1_recall': 0.5875, 'r1_f1': 0.4051724137931034, 'pegasus_entailment': 0.5779117405414581, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5478260869565217, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5431034482758621, 'pegasus_entailment': 0.7062305688858033, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4262295081967213, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.43697478991596633, 'pegasus_entailment': 0.7646611630916595, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2, 'r1_recall': 0.4915254237288136, 'r1_f1': 0.2843137254901961, 'pegasus_entailment': 0.5690219730138779, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5539568345323741, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.46951219512195125, 'pegasus_entailment': 0.45688296854496, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5658914728682171, 'r1_recall': 0.6033057851239669, 'r1_f1': 0.584, 'pegasus_entailment': 0.8806750893592834, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6923076923076923, 'r1_recall': 0.4064516129032258, 'r1_f1': 0.5121951219512194, 'pegasus_entailment': 0.7770241498947144, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 16, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46629213483146065, 'r1_recall': 0.50920245398773, 'r1_f1': 0.48680351906158353, 'pegasus_entailment': 0.4077759776264429, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 21, 'pegasus_ari': 32, 'pegasus_smog': 27}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3076923076923077, 'r1_recall': 0.43564356435643564, 'r1_f1': 0.3606557377049181, 'pegasus_entailment': 0.5882220305502415, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47183098591549294, 'r1_recall': 0.5537190082644629, 'r1_f1': 0.5095057034220533, 'pegasus_entailment': 0.45496090590022503, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.39263803680981596, 'r1_recall': 0.6881720430107527, 'r1_f1': 0.5, 'pegasus_entailment': 0.5417215116322041, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5652173913043478, 'r1_recall': 0.48872180451127817, 'r1_f1': 0.5241935483870968, 'pegasus_entailment': 0.786485473314921, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 25}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5945945945945946, 'r1_recall': 0.23783783783783785, 'r1_f1': 0.3397683397683398, 'pegasus_entailment': 0.2141242567449808, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3048780487804878, 'r1_recall': 0.43103448275862066, 'r1_f1': 0.3571428571428572, 'pegasus_entailment': 0.6926559060811996, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3707865168539326, 'r1_recall': 0.375, 'r1_f1': 0.3728813559322034, 'pegasus_entailment': 0.6507864445447922, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4205607476635514, 'r1_recall': 0.4838709677419355, 'r1_f1': 0.45000000000000007, 'pegasus_entailment': 0.726100780069828, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4625, 'r1_recall': 0.3274336283185841, 'r1_f1': 0.383419689119171, 'pegasus_entailment': 0.28827847695599, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36363636363636365, 'r1_recall': 0.5, 'r1_f1': 0.4210526315789474, 'pegasus_entailment': 0.5087898522615433, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5647058823529412, 'r1_recall': 0.4752475247524752, 'r1_f1': 0.5161290322580645, 'pegasus_entailment': 0.28839157335460186, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6528925619834711, 'r1_recall': 0.37799043062200954, 'r1_f1': 0.4787878787878788, 'pegasus_entailment': 0.6269687235355377, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5970149253731343, 'r1_recall': 0.4419889502762431, 'r1_f1': 0.5079365079365079, 'pegasus_entailment': 0.6851037070155144, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23008849557522124, 'r1_recall': 0.4406779661016949, 'r1_f1': 0.3023255813953488, 'pegasus_entailment': 0.714817225933075, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7974683544303798, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.5228215767634855, 'pegasus_entailment': 0.22331437468528748, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5308641975308642, 'r1_recall': 0.524390243902439, 'r1_f1': 0.5276073619631901, 'pegasus_entailment': 0.23929626494646072, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36923076923076925, 'r1_recall': 0.5, 'r1_f1': 0.4247787610619469, 'pegasus_entailment': 0.5237914342433214, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43820224719101125, 'r1_recall': 0.42391304347826086, 'r1_f1': 0.430939226519337, 'pegasus_entailment': 0.4932982847094536, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5126050420168067, 'r1_recall': 0.31443298969072164, 'r1_f1': 0.389776357827476, 'pegasus_entailment': 0.650522917509079, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5824175824175825, 'r1_recall': 0.3192771084337349, 'r1_f1': 0.41245136186770426, 'pegasus_entailment': 0.5414619743824005, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41237113402061853, 'r1_recall': 0.6779661016949152, 'r1_f1': 0.5128205128205129, 'pegasus_entailment': 0.54670300334692, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5100671140939598, 'r1_recall': 0.4393063583815029, 'r1_f1': 0.4720496894409938, 'pegasus_entailment': 0.38791665124396485, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5054945054945055, 'r1_recall': 0.5679012345679012, 'r1_f1': 0.5348837209302326, 'pegasus_entailment': 0.6250551044940948, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.580952380952381, 'r1_recall': 0.40939597315436244, 'r1_f1': 0.48031496062992124, 'pegasus_entailment': 0.7794924080371857, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4125874125874126, 'r1_recall': 0.6344086021505376, 'r1_f1': 0.5, 'pegasus_entailment': 0.6863332167267799, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5277777777777778, 'r1_recall': 0.35403726708074534, 'r1_f1': 0.42379182156133827, 'pegasus_entailment': 0.6412726690371832, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2076923076923077, 'r1_recall': 0.7105263157894737, 'r1_f1': 0.32142857142857145, 'pegasus_entailment': 0.8782619833946228, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 23, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5089285714285714, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.5181818181818181, 'pegasus_entailment': 0.784200981259346, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3522012578616352, 'r1_recall': 0.5436893203883495, 'r1_f1': 0.42748091603053434, 'pegasus_entailment': 0.8510902166366577, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5252525252525253, 'r1_recall': 0.31901840490797545, 'r1_f1': 0.3969465648854962, 'pegasus_entailment': 0.700761690735817, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36, 'r1_recall': 0.3302752293577982, 'r1_f1': 0.34449760765550236, 'pegasus_entailment': 0.6623746951421102, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47, 'r1_recall': 0.26704545454545453, 'r1_f1': 0.3405797101449275, 'pegasus_entailment': 0.7608767549196879, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4230769230769231, 'r1_recall': 0.36666666666666664, 'r1_f1': 0.3928571428571428, 'pegasus_entailment': 0.34971419125795367, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6304347826086957, 'r1_recall': 0.4142857142857143, 'r1_f1': 0.5000000000000001, 'pegasus_entailment': 0.583979457616806, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5327868852459017, 'r1_recall': 0.436241610738255, 'r1_f1': 0.47970479704797053, 'pegasus_entailment': 0.7096672058105469, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.34782608695652173, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.511111680418253, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3974358974358974, 'r1_recall': 0.4025974025974026, 'r1_f1': 0.4, 'pegasus_entailment': 0.5906080268323421, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38016528925619836, 'r1_recall': 0.6301369863013698, 'r1_f1': 0.4742268041237114, 'pegasus_entailment': 0.39901166160901386, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.69375, 'r1_recall': 0.3016304347826087, 'r1_f1': 0.4204545454545454, 'pegasus_entailment': 0.6358775943517685, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3821656050955414, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.449438202247191, 'pegasus_entailment': 0.7519879996776581, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45555555555555555, 'r1_recall': 0.33064516129032256, 'r1_f1': 0.38317757009345793, 'pegasus_entailment': 0.44212671120961505, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5445544554455446, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.497737556561086, 'pegasus_entailment': 0.6427619258562723, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4609375, 'r1_recall': 0.251063829787234, 'r1_f1': 0.32506887052341593, 'pegasus_entailment': 0.6472327917814255, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45161290322580644, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.40579710144927533, 'pegasus_entailment': 0.6884088615576426, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34959349593495936, 'r1_recall': 0.5, 'r1_f1': 0.4114832535885168, 'pegasus_entailment': 0.725614495575428, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2905405405405405, 'r1_recall': 0.5733333333333334, 'r1_f1': 0.38565022421524664, 'pegasus_entailment': 0.7113091833889484, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3978494623655914, 'r1_recall': 0.4111111111111111, 'r1_f1': 0.4043715846994535, 'pegasus_entailment': 0.5380986928939819, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6410256410256411, 'r1_recall': 0.3048780487804878, 'r1_f1': 0.4132231404958678, 'pegasus_entailment': 0.6188163906335831, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.538961038961039, 'r1_recall': 0.289198606271777, 'r1_f1': 0.3764172335600907, 'pegasus_entailment': 0.7310842871665955, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6764705882352942, 'r1_recall': 0.3854748603351955, 'r1_f1': 0.491103202846975, 'pegasus_entailment': 0.5622080802917481, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5729166666666666, 'r1_recall': 0.4824561403508772, 'r1_f1': 0.5238095238095237, 'pegasus_entailment': 0.5449555004015565, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5957446808510638, 'r1_recall': 0.4307692307692308, 'r1_f1': 0.5, 'pegasus_entailment': 0.3767072608073552, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3125, 'r1_recall': 0.4326923076923077, 'r1_f1': 0.36290322580645157, 'pegasus_entailment': 0.637198680639267, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5925925925925927, 'pegasus_entailment': 0.6175741851329803, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6979166666666666, 'r1_recall': 0.41358024691358025, 'r1_f1': 0.5193798449612403, 'pegasus_entailment': 0.6556429316600164, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3853211009174312, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.4516129032258065, 'pegasus_entailment': 0.5356809973716736, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6222222222222222, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.47863247863247865, 'pegasus_entailment': 0.45995077583938837, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4631578947368421, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.5176470588235295, 'pegasus_entailment': 0.31254976987838745, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6060606060606061, 'r1_recall': 0.49586776859504134, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.7107737958431244, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.50625, 'r1_recall': 0.7297297297297297, 'r1_f1': 0.5977859778597786, 'pegasus_entailment': 0.9430170655250549, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.38650306748466257, 'r1_f1': 0.4064516129032258, 'pegasus_entailment': 0.559891015291214, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6739130434782609, 'r1_recall': 0.3522727272727273, 'r1_f1': 0.4626865671641791, 'pegasus_entailment': 0.5151577033102512, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.44761904761904764, 'r1_recall': 0.5875, 'r1_f1': 0.508108108108108, 'pegasus_entailment': 0.180817817337811, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2807017543859649, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.367816091954023, 'pegasus_entailment': 0.6749836107095083, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.358695652173913, 'r1_recall': 0.55, 'r1_f1': 0.43421052631578944, 'pegasus_entailment': 0.5687406609455744, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3313953488372093, 'r1_recall': 0.5816326530612245, 'r1_f1': 0.42222222222222217, 'pegasus_entailment': 0.805627167224884, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4727272727272727, 'r1_recall': 0.6, 'r1_f1': 0.5288135593220339, 'pegasus_entailment': 0.7699420948823293, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2, 'r1_recall': 0.5869565217391305, 'r1_f1': 0.2983425414364641, 'pegasus_entailment': 0.5586757759253184, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5783132530120482, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.4873096446700507, 'pegasus_entailment': 0.36968140428264934, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3072289156626506, 'r1_recall': 0.4594594594594595, 'r1_f1': 0.36823104693140796, 'pegasus_entailment': 0.7162537813186646, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49171270718232046, 'r1_recall': 0.4063926940639269, 'r1_f1': 0.44499999999999995, 'pegasus_entailment': 0.3894967958331108, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38016528925619836, 'r1_recall': 0.5609756097560976, 'r1_f1': 0.45320197044334976, 'pegasus_entailment': 0.5400186777114868, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36486486486486486, 'r1_recall': 0.6136363636363636, 'r1_f1': 0.4576271186440678, 'pegasus_entailment': 0.84592205286026, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 26}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45614035087719296, 'r1_recall': 0.5148514851485149, 'r1_f1': 0.48372093023255813, 'pegasus_entailment': 0.4711506560444832, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4485981308411215, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.44651162790697674, 'pegasus_entailment': 0.49944359064102173, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.19463087248322147, 'r1_recall': 0.6041666666666666, 'r1_f1': 0.29441624365482233, 'pegasus_entailment': 0.6150482725352049, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48360655737704916, 'r1_recall': 0.5959595959595959, 'r1_f1': 0.5339366515837105, 'pegasus_entailment': 0.5471995696425438, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5076923076923077, 'r1_recall': 0.4177215189873418, 'r1_f1': 0.4583333333333333, 'pegasus_entailment': 0.5173988282680512, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4794520547945205, 'r1_recall': 0.4430379746835443, 'r1_f1': 0.4605263157894737, 'pegasus_entailment': 0.5931429445743561, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5283018867924528, 'r1_recall': 0.29015544041450775, 'r1_f1': 0.374581939799331, 'pegasus_entailment': 0.5359451125065485, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47674418604651164, 'r1_recall': 0.3904761904761905, 'r1_f1': 0.42931937172774864, 'pegasus_entailment': 0.26587127335369587, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4507042253521127, 'r1_recall': 0.512, 'r1_f1': 0.47940074906367036, 'pegasus_entailment': 0.34964287281036377, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.256198347107438, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.3583815028901734, 'pegasus_entailment': 0.455258896946907, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30327868852459017, 'r1_recall': 0.6065573770491803, 'r1_f1': 0.40437158469945356, 'pegasus_entailment': 0.4369491636753082, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2413793103448276, 'r1_recall': 0.5645161290322581, 'r1_f1': 0.33816425120772947, 'pegasus_entailment': 0.5973040983080864, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20168067226890757, 'r1_recall': 0.4067796610169492, 'r1_f1': 0.26966292134831465, 'pegasus_entailment': 0.3916467227973044, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32061068702290074, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.34285714285714286, 'pegasus_entailment': 0.48695890605449677, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3764705882352941, 'r1_recall': 0.32323232323232326, 'r1_f1': 0.34782608695652173, 'pegasus_entailment': 0.44986334443092346, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1554054054054054, 'r1_recall': 0.575, 'r1_f1': 0.24468085106382978, 'pegasus_entailment': 0.5436434984207154, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5113636363636364, 'r1_recall': 0.5202312138728323, 'r1_f1': 0.5157593123209169, 'pegasus_entailment': 0.7246810921600887, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3973509933774834, 'r1_recall': 0.75, 'r1_f1': 0.5194805194805194, 'pegasus_entailment': 0.2950376346707344, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5803571428571429, 'r1_recall': 0.3651685393258427, 'r1_f1': 0.4482758620689655, 'pegasus_entailment': 0.518213264644146, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6699029126213593, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.5227272727272727, 'pegasus_entailment': 0.7734996825456619, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6022727272727273, 'r1_recall': 0.39552238805970147, 'r1_f1': 0.47747747747747754, 'pegasus_entailment': 0.5494626412789027, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6220472440944882, 'r1_recall': 0.32510288065843623, 'r1_f1': 0.4270270270270271, 'pegasus_entailment': 0.3951172133286794, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.5121951219512195, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.5043034106492996, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5663716814159292, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.4830188679245283, 'pegasus_entailment': 0.8521494269371033, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3163265306122449, 'r1_recall': 0.4305555555555556, 'r1_f1': 0.36470588235294116, 'pegasus_entailment': 0.5001791622489691, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4573643410852713, 'r1_recall': 0.2645739910313901, 'r1_f1': 0.33522727272727265, 'pegasus_entailment': 0.7078423164784908, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.23893805309734514, 'r1_f1': 0.24434389140271492, 'pegasus_entailment': 0.28933173324912786, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2761904761904762, 'r1_recall': 0.6304347826086957, 'r1_f1': 0.3841059602649007, 'pegasus_entailment': 0.7395773082971573, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7205882352941176, 'r1_recall': 0.27071823204419887, 'r1_f1': 0.393574297188755, 'pegasus_entailment': 0.23660973211129507, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6551724137931034, 'r1_recall': 0.3220338983050847, 'r1_f1': 0.43181818181818177, 'pegasus_entailment': 0.45231930539011955, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4180327868852459, 'r1_recall': 0.53125, 'r1_f1': 0.46788990825688076, 'pegasus_entailment': 0.5685647577047348, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4811320754716981, 'r1_recall': 0.35172413793103446, 'r1_f1': 0.40637450199203184, 'pegasus_entailment': 0.28552109996477765, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1619047619047619, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.25563909774436094, 'pegasus_entailment': 0.48122889176011086, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2125984251968504, 'r1_recall': 0.46551724137931033, 'r1_f1': 0.2918918918918919, 'pegasus_entailment': 0.6199465356767178, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5510204081632653, 'r1_recall': 0.453781512605042, 'r1_f1': 0.4976958525345622, 'pegasus_entailment': 0.3209143769927323, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2553191489361702, 'r1_recall': 0.5070422535211268, 'r1_f1': 0.33962264150943394, 'pegasus_entailment': 0.5752660421033701, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2872340425531915, 'r1_recall': 0.4909090909090909, 'r1_f1': 0.36241610738255037, 'pegasus_entailment': 0.3235432207584381, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22695035460992907, 'r1_recall': 0.3950617283950617, 'r1_f1': 0.2882882882882883, 'pegasus_entailment': 0.7003447668892997, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5670103092783505, 'r1_recall': 0.6790123456790124, 'r1_f1': 0.6179775280898876, 'pegasus_entailment': 0.30941975452005865, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4673913043478261, 'r1_recall': 0.5180722891566265, 'r1_f1': 0.49142857142857144, 'pegasus_entailment': 0.6951143443584442, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.4431818181818182, 'pegasus_entailment': 0.1998412317285935, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6861313868613139, 'r1_recall': 0.27976190476190477, 'r1_f1': 0.3974630021141649, 'pegasus_entailment': 0.47067420308788616, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5112781954887218, 'r1_recall': 0.3063063063063063, 'r1_f1': 0.38309859154929576, 'pegasus_entailment': 0.5463467910885811, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2388888888888889, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.33333333333333337, 'pegasus_entailment': 0.7461278694016593, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.4347826086956522, 'pegasus_entailment': 0.10219312086701393, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 14}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3670886075949367, 'r1_recall': 0.3972602739726027, 'r1_f1': 0.381578947368421, 'pegasus_entailment': 0.5168981440365314, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36065573770491804, 'r1_recall': 0.3384615384615385, 'r1_f1': 0.3492063492063492, 'pegasus_entailment': 0.3955930769443512, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4880952380952381, 'r1_recall': 0.5694444444444444, 'r1_f1': 0.5256410256410257, 'pegasus_entailment': 0.5162832299247384, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44537815126050423, 'r1_recall': 0.654320987654321, 'r1_f1': 0.53, 'pegasus_entailment': 0.5648987839619318, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26256983240223464, 'r1_recall': 0.618421052631579, 'r1_f1': 0.3686274509803922, 'pegasus_entailment': 0.6562719941139221, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38738738738738737, 'r1_recall': 0.5119047619047619, 'r1_f1': 0.44102564102564096, 'pegasus_entailment': 0.70540751516819, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6320754716981132, 'r1_recall': 0.4267515923566879, 'r1_f1': 0.5095057034220533, 'pegasus_entailment': 0.6148289777338505, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6973684210526315, 'r1_recall': 0.3680555555555556, 'r1_f1': 0.4818181818181818, 'pegasus_entailment': 0.18334195390343666, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.34591194968553457, 'r1_recall': 0.5851063829787234, 'r1_f1': 0.4347826086956521, 'pegasus_entailment': 0.8113715529441834, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5596330275229358, 'r1_recall': 0.3193717277486911, 'r1_f1': 0.4066666666666667, 'pegasus_entailment': 0.3506631801525752, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.21428571428571427, 'r1_recall': 0.7959183673469388, 'r1_f1': 0.33766233766233766, 'pegasus_entailment': 0.6591095149517059, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3968253968253968, 'r1_recall': 0.6024096385542169, 'r1_f1': 0.4784688995215311, 'pegasus_entailment': 0.6555001497268677, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.1794871794871795, 'r1_f1': 0.2641509433962264, 'pegasus_entailment': 0.15375247597694397, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 12}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.28823529411764703, 'r1_recall': 0.6049382716049383, 'r1_f1': 0.3904382470119522, 'pegasus_entailment': 0.5304449565708638, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7375, 'r1_recall': 0.4306569343065693, 'r1_f1': 0.543778801843318, 'pegasus_entailment': 0.565331868827343, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19101123595505617, 'r1_recall': 0.38636363636363635, 'r1_f1': 0.2556390977443609, 'pegasus_entailment': 0.6052051136891047, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20634920634920634, 'r1_recall': 0.4406779661016949, 'r1_f1': 0.28108108108108104, 'pegasus_entailment': 0.5364930970328194, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5847457627118644, 'r1_recall': 0.5149253731343284, 'r1_f1': 0.5476190476190477, 'pegasus_entailment': 0.7454538583755493, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5727272727272728, 'r1_recall': 0.40384615384615385, 'r1_f1': 0.47368421052631576, 'pegasus_entailment': 0.3039652034640312, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3305084745762712, 'r1_recall': 0.6, 'r1_f1': 0.42622950819672134, 'pegasus_entailment': 0.49008926190435886, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2857142857142857, 'r1_recall': 0.22727272727272727, 'r1_f1': 0.2531645569620253, 'pegasus_entailment': 0.717892225831747, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3644859813084112, 'r1_recall': 0.4642857142857143, 'r1_f1': 0.4083769633507853, 'pegasus_entailment': 0.43806077539920807, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4148936170212766, 'r1_recall': 0.5064935064935064, 'r1_f1': 0.45614035087719296, 'pegasus_entailment': 0.5195192955434322, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3490566037735849, 'r1_recall': 0.4625, 'r1_f1': 0.39784946236559143, 'pegasus_entailment': 0.5315413117408753, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5267175572519084, 'r1_recall': 0.4423076923076923, 'r1_f1': 0.4808362369337979, 'pegasus_entailment': 0.43647917608420056, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3904761904761905, 'r1_recall': 0.5394736842105263, 'r1_f1': 0.4530386740331492, 'pegasus_entailment': 0.3162037402391434, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5157894736842106, 'r1_recall': 0.5764705882352941, 'r1_f1': 0.5444444444444444, 'pegasus_entailment': 0.507021447022756, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43333333333333335, 'r1_recall': 0.4961832061068702, 'r1_f1': 0.4626334519572954, 'pegasus_entailment': 0.6211773703495661, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38235294117647056, 'r1_recall': 0.36792452830188677, 'r1_f1': 0.37499999999999994, 'pegasus_entailment': 0.31227694638073444, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5625, 'r1_recall': 0.29508196721311475, 'r1_f1': 0.3870967741935484, 'pegasus_entailment': 0.4782224651426077, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34710743801652894, 'r1_recall': 0.5526315789473685, 'r1_f1': 0.4263959390862944, 'pegasus_entailment': 0.7367551386356354, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4174757281553398, 'r1_recall': 0.4673913043478261, 'r1_f1': 0.44102564102564107, 'pegasus_entailment': 0.43868642672896385, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6062992125984252, 'r1_recall': 0.35648148148148145, 'r1_f1': 0.44897959183673475, 'pegasus_entailment': 0.840421998500824, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36036036036036034, 'r1_recall': 0.39603960396039606, 'r1_f1': 0.37735849056603776, 'pegasus_entailment': 0.5804626168683171, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5595238095238095, 'r1_recall': 0.47959183673469385, 'r1_f1': 0.5164835164835165, 'pegasus_entailment': 0.27904067635536195, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36885245901639346, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.46875000000000006, 'pegasus_entailment': 0.5093378752470017, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6307692307692307, 'r1_recall': 0.6165413533834586, 'r1_f1': 0.6235741444866919, 'pegasus_entailment': 0.5458590565249324, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3984375, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.4678899082568807, 'pegasus_entailment': 0.5468027591705322, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46464646464646464, 'r1_recall': 0.4, 'r1_f1': 0.42990654205607476, 'pegasus_entailment': 0.7951567023992538, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2926829268292683, 'r1_recall': 0.43243243243243246, 'r1_f1': 0.34909090909090906, 'pegasus_entailment': 0.4098633289337158, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.39855072463768115, 'r1_f1': 0.4641350210970464, 'pegasus_entailment': 0.7004193961620331, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.24761904761904763, 'r1_recall': 0.52, 'r1_f1': 0.33548387096774196, 'pegasus_entailment': 0.37392913301785785, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23841059602649006, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.34782608695652173, 'pegasus_entailment': 0.5293931216001511, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.06565656565656566, 'r1_recall': 0.2765957446808511, 'r1_f1': 0.10612244897959185, 'pegasus_entailment': 0.5900009820858637, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43243243243243246, 'r1_recall': 0.4507042253521127, 'r1_f1': 0.4413793103448276, 'pegasus_entailment': 0.5425503551959991, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5267175572519084, 'r1_recall': 0.3770491803278688, 'r1_f1': 0.4394904458598726, 'pegasus_entailment': 0.6643447528282801, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3511111111111111, 'r1_recall': 0.5766423357664233, 'r1_f1': 0.43646408839779005, 'pegasus_entailment': 0.5651663482189179, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.4347826086956522, 'pegasus_entailment': 0.8025433570146561, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41044776119402987, 'r1_recall': 0.41353383458646614, 'r1_f1': 0.41198501872659177, 'pegasus_entailment': 0.4447967167943716, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6692307692307692, 'r1_recall': 0.5304878048780488, 'r1_f1': 0.5918367346938774, 'pegasus_entailment': 0.6500454768538475, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.5970149253731343, 'r1_f1': 0.6299212598425197, 'pegasus_entailment': 0.6866801142692566, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36283185840707965, 'r1_recall': 0.41, 'r1_f1': 0.3849765258215962, 'pegasus_entailment': 0.6154325604438782, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5375, 'r1_f1': 0.5180722891566264, 'pegasus_entailment': 0.5274884601434072, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46153846153846156, 'r1_recall': 0.5121951219512195, 'r1_f1': 0.48554913294797686, 'pegasus_entailment': 0.4141770079731941, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1732283464566929, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.25142857142857145, 'pegasus_entailment': 0.8527734577655792, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34177215189873417, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.38028169014084506, 'pegasus_entailment': 0.6490167776743571, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19642857142857142, 'r1_recall': 0.6470588235294118, 'r1_f1': 0.3013698630136986, 'pegasus_entailment': 0.6397860292345285, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.24806201550387597, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.31219512195121946, 'pegasus_entailment': 0.13688364438712597, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 13, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.5382262996941897, 'pegasus_entailment': 0.757965658392225, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.26666666666666666, 'r1_recall': 0.5970149253731343, 'r1_f1': 0.3686635944700461, 'pegasus_entailment': 0.73250070640019, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6310679611650486, 'r1_recall': 0.3869047619047619, 'r1_f1': 0.4797047970479705, 'pegasus_entailment': 0.45886141434311867, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.494949494949495, 'r1_recall': 0.3712121212121212, 'r1_f1': 0.42424242424242425, 'pegasus_entailment': 0.7517046853899956, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5909090909090909, 'r1_recall': 0.41139240506329117, 'r1_f1': 0.48507462686567165, 'pegasus_entailment': 0.4985836606938392, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7159090909090909, 'r1_recall': 0.21283783783783783, 'r1_f1': 0.328125, 'pegasus_entailment': 0.5789746522903443, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4875, 'r1_recall': 0.7090909090909091, 'r1_f1': 0.5777777777777778, 'pegasus_entailment': 0.5472841262817383, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5851063829787234, 'r1_recall': 0.27918781725888325, 'r1_f1': 0.37800687285223367, 'pegasus_entailment': 0.454472412665685, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.272108843537415, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.38647342995169087, 'pegasus_entailment': 0.637869131565094, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4246575342465753, 'r1_recall': 0.5040650406504065, 'r1_f1': 0.4609665427509293, 'pegasus_entailment': 0.7467504382133484, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5428571428571428, 'r1_f1': 0.5205479452054795, 'pegasus_entailment': 0.5552616156637669, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4946236559139785, 'r1_recall': 0.3511450381679389, 'r1_f1': 0.41071428571428575, 'pegasus_entailment': 0.36510165259242056, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2, 'r1_recall': 0.4925373134328358, 'r1_f1': 0.28448275862068967, 'pegasus_entailment': 0.6023604646325111, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2229299363057325, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.3271028037383178, 'pegasus_entailment': 0.736391568183899, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3804347826086957, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.46979865771812085, 'pegasus_entailment': 0.6733104089895884, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4, 'r1_recall': 0.046875, 'r1_f1': 0.08391608391608392, 'pegasus_entailment': 0.6853658556938171, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 21, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5811965811965812, 'r1_recall': 0.38202247191011235, 'r1_f1': 0.46101694915254243, 'pegasus_entailment': 0.3971633702516556, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4602272727272727, 'r1_recall': 0.49693251533742333, 'r1_f1': 0.4778761061946903, 'pegasus_entailment': 0.6408997351924578, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6695652173913044, 'r1_recall': 0.39896373056994816, 'r1_f1': 0.5, 'pegasus_entailment': 0.4829877093434334, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4426229508196721, 'r1_recall': 0.5346534653465347, 'r1_f1': 0.484304932735426, 'pegasus_entailment': 0.4604223929345608, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31333333333333335, 'r1_recall': 0.5595238095238095, 'r1_f1': 0.4017094017094018, 'pegasus_entailment': 0.4406252294778824, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25925925925925924, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.3111111111111111, 'pegasus_entailment': 0.6251264452934265, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.24752475247524752, 'r1_recall': 0.49019607843137253, 'r1_f1': 0.3289473684210526, 'pegasus_entailment': 0.6211587674915791, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7391304347826086, 'r1_recall': 0.34459459459459457, 'r1_f1': 0.4700460829493088, 'pegasus_entailment': 0.3077746282021205, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5084745762711864, 'r1_recall': 0.4580152671755725, 'r1_f1': 0.48192771084337344, 'pegasus_entailment': 0.44308145865798, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5865384615384616, 'r1_recall': 0.5169491525423728, 'r1_f1': 0.5495495495495495, 'pegasus_entailment': 0.509399933119615, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5957446808510638, 'pegasus_entailment': 0.3307445286773145, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45384615384615384, 'r1_recall': 0.4957983193277311, 'r1_f1': 0.4738955823293173, 'pegasus_entailment': 0.32369680679403245, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7096774193548387, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.5569620253164557, 'pegasus_entailment': 0.6554336026310921, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5053763440860215, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.5136612021857925, 'pegasus_entailment': 0.4266278874129057, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41333333333333333, 'r1_recall': 0.23308270676691728, 'r1_f1': 0.2980769230769231, 'pegasus_entailment': 0.4209802548090617, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.2688679245283019, 'r1_f1': 0.3496932515337423, 'pegasus_entailment': 0.6404547989368439, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2692307692307692, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.37433155080213903, 'pegasus_entailment': 0.5236635009447733, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4431818181818182, 'r1_recall': 0.3046875, 'r1_f1': 0.36111111111111116, 'pegasus_entailment': 0.4292819444090128, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3076923076923077, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.35555555555555557, 'pegasus_entailment': 0.5153508633375168, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5503355704697986, 'r1_recall': 0.4293193717277487, 'r1_f1': 0.48235294117647054, 'pegasus_entailment': 0.5679532766342164, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.32653061224489793, 'r1_f1': 0.37065637065637064, 'pegasus_entailment': 0.4720195621872942, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4305555555555556, 'r1_recall': 0.4025974025974026, 'r1_f1': 0.4161073825503356, 'pegasus_entailment': 0.6211423973242441, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4666666666666667, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.48794253170490265, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38095238095238093, 'r1_recall': 0.5565217391304348, 'r1_f1': 0.45229681978798586, 'pegasus_entailment': 0.5854311159678868, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.660377358490566, 'r1_recall': 0.45751633986928103, 'r1_f1': 0.5405405405405405, 'pegasus_entailment': 0.4958761900663376, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5569620253164557, 'r1_recall': 0.43137254901960786, 'r1_f1': 0.4861878453038674, 'pegasus_entailment': 0.49316277354955673, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.38518518518518513, 'pegasus_entailment': 0.39493512734770775, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3763440860215054, 'r1_recall': 0.546875, 'r1_f1': 0.445859872611465, 'pegasus_entailment': 0.51272152364254, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2558139534883721, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.35627530364372473, 'pegasus_entailment': 0.5789102196693421, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42105263157894735, 'r1_recall': 0.6037735849056604, 'r1_f1': 0.496124031007752, 'pegasus_entailment': 0.5196697612603506, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4725274725274725, 'r1_recall': 0.46236559139784944, 'r1_f1': 0.4673913043478261, 'pegasus_entailment': 0.8100472291310629, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.7068965517241379, 'r1_f1': 0.5857142857142857, 'pegasus_entailment': 0.659855180978775, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5729166666666666, 'r1_recall': 0.5392156862745098, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.5075122807174921, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5144927536231884, 'r1_recall': 0.44936708860759494, 'r1_f1': 0.47972972972972966, 'pegasus_entailment': 0.4702572929007666, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3263157894736842, 'r1_recall': 0.543859649122807, 'r1_f1': 0.40789473684210525, 'pegasus_entailment': 0.7405003756284714, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4489795918367347, 'r1_recall': 0.4429530201342282, 'r1_f1': 0.44594594594594594, 'pegasus_entailment': 0.5073156928022703, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5955056179775281, 'r1_recall': 0.38686131386861317, 'r1_f1': 0.46902654867256643, 'pegasus_entailment': 0.47327234875410795, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22459893048128343, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.3320158102766798, 'pegasus_entailment': 0.678175171216329, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5050505050505051, 'r1_recall': 0.45045045045045046, 'r1_f1': 0.4761904761904763, 'pegasus_entailment': 0.48303837329149246, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3356164383561644, 'r1_recall': 0.6125, 'r1_f1': 0.4336283185840708, 'pegasus_entailment': 0.7407533675432205, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5038759689922481, 'r1_recall': 0.5118110236220472, 'r1_f1': 0.5078125, 'pegasus_entailment': 0.43393387347459794, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7053571428571429, 'r1_recall': 0.4010152284263959, 'r1_f1': 0.511326860841424, 'pegasus_entailment': 0.6836732998490334, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6078431372549019, 'r1_recall': 0.38271604938271603, 'r1_f1': 0.46969696969696967, 'pegasus_entailment': 0.6796249945958456, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44171779141104295, 'r1_recall': 0.5179856115107914, 'r1_f1': 0.4768211920529802, 'pegasus_entailment': 0.503495047489802, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.18840579710144928, 'r1_recall': 0.3561643835616438, 'r1_f1': 0.24644549763033172, 'pegasus_entailment': 0.008146524429321289, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.19594594594594594, 'r1_recall': 0.47540983606557374, 'r1_f1': 0.27751196172248804, 'pegasus_entailment': 0.7850621789693832, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.376, 'r1_recall': 0.5465116279069767, 'r1_f1': 0.44549763033175355, 'pegasus_entailment': 0.3999204896390438, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38461538461538464, 'r1_recall': 0.33783783783783783, 'r1_f1': 0.3597122302158273, 'pegasus_entailment': 0.5604795878753066, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5140845070422535, 'r1_recall': 0.41954022988505746, 'r1_f1': 0.46202531645569617, 'pegasus_entailment': 0.7364693284034729, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5327868852459017, 'r1_recall': 0.4513888888888889, 'r1_f1': 0.4887218045112783, 'pegasus_entailment': 0.3835796736180782, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5957446808510638, 'r1_recall': 0.28717948717948716, 'r1_f1': 0.38754325259515565, 'pegasus_entailment': 0.5379377156496048, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37209302325581395, 'r1_recall': 0.6575342465753424, 'r1_f1': 0.4752475247524752, 'pegasus_entailment': 0.12461639791727067, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5119047619047619, 'r1_recall': 0.5733333333333334, 'r1_f1': 0.5408805031446541, 'pegasus_entailment': 0.8295864164829254, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.41228070175438597, 'r1_f1': 0.4519230769230769, 'pegasus_entailment': 0.5710835158824921, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5988023952095808, 'r1_recall': 0.26595744680851063, 'r1_f1': 0.3683241252302025, 'pegasus_entailment': 0.6298316046595573, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3968253968253968, 'r1_recall': 0.423728813559322, 'r1_f1': 0.4098360655737705, 'pegasus_entailment': 0.7755922377109528, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.58, 'r1_recall': 0.34523809523809523, 'r1_f1': 0.43283582089552236, 'pegasus_entailment': 0.5480874687433243, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49166666666666664, 'r1_recall': 0.4573643410852713, 'r1_f1': 0.4738955823293173, 'pegasus_entailment': 0.5223602592945099, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5112781954887218, 'r1_recall': 0.4563758389261745, 'r1_f1': 0.48226950354609927, 'pegasus_entailment': 0.7251373132069906, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4853801169590643, 'r1_recall': 0.4911242603550296, 'r1_f1': 0.48823529411764705, 'pegasus_entailment': 0.5305381119251251, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.417910447761194, 'r1_recall': 0.42748091603053434, 'r1_f1': 0.4226415094339623, 'pegasus_entailment': 0.32250625523738563, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4423076923076923, 'r1_recall': 0.3709677419354839, 'r1_f1': 0.4035087719298246, 'pegasus_entailment': 0.6410467028617859, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37037037037037035, 'r1_recall': 0.4819277108433735, 'r1_f1': 0.418848167539267, 'pegasus_entailment': 0.4422425106167793, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2345679012345679, 'r1_recall': 0.48717948717948717, 'r1_f1': 0.31666666666666665, 'pegasus_entailment': 0.670861005783081, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5217391304347826, 'r1_recall': 0.41379310344827586, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.4567435532808304, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.3027027027027027, 'r1_f1': 0.4057971014492754, 'pegasus_entailment': 0.4070693651835124, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47115384615384615, 'r1_recall': 0.5104166666666666, 'r1_f1': 0.48999999999999994, 'pegasus_entailment': 0.4167166668921709, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.16103896103896104, 'r1_f1': 0.2594142259414226, 'pegasus_entailment': 0.5773627273738384, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5357142857142857, 'r1_recall': 0.3125, 'r1_f1': 0.39473684210526316, 'pegasus_entailment': 0.536488672097524, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2595419847328244, 'r1_recall': 0.5230769230769231, 'r1_f1': 0.346938775510204, 'pegasus_entailment': 0.3701957881450653, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3106060606060606, 'r1_recall': 0.6833333333333333, 'r1_f1': 0.4270833333333333, 'pegasus_entailment': 0.5348840594291687, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.16363636363636364, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.23920265780730898, 'pegasus_entailment': 0.725737476348877, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5131578947368421, 'r1_recall': 0.375, 'r1_f1': 0.4333333333333334, 'pegasus_entailment': 0.6183109482129415, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27722772277227725, 'r1_recall': 0.32558139534883723, 'r1_f1': 0.29946524064171126, 'pegasus_entailment': 0.3178334728969882, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5309734513274337, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.44609665427509293, 'pegasus_entailment': 0.623664602637291, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5952380952380952, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.5154639175257733, 'pegasus_entailment': 0.7664195895195007, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2857142857142857, 'r1_recall': 0.5573770491803278, 'r1_f1': 0.37777777777777777, 'pegasus_entailment': 0.852149772644043, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6565656565656566, 'r1_recall': 0.43333333333333335, 'r1_f1': 0.5220883534136547, 'pegasus_entailment': 0.600547707080841, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.4175824175824176, 'r1_f1': 0.37073170731707317, 'pegasus_entailment': 0.21274494752287865, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44776119402985076, 'r1_recall': 0.4580152671755725, 'r1_f1': 0.4528301886792453, 'pegasus_entailment': 0.5651363581418991, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2648401826484018, 'r1_recall': 0.6373626373626373, 'r1_f1': 0.3741935483870968, 'pegasus_entailment': 0.5383391496207979, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47101449275362317, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.5349794238683129, 'pegasus_entailment': 0.5152353346347809, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3904761904761905, 'r1_recall': 0.5616438356164384, 'r1_f1': 0.4606741573033708, 'pegasus_entailment': 0.6063434635289013, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3790322580645161, 'r1_recall': 0.376, 'r1_f1': 0.3775100401606426, 'pegasus_entailment': 0.4022956922650337, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.456, 'r1_recall': 0.5, 'r1_f1': 0.4769874476987448, 'pegasus_entailment': 0.5062990759809812, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39669421487603307, 'r1_recall': 0.5393258426966292, 'r1_f1': 0.45714285714285713, 'pegasus_entailment': 0.4149792045354843, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24096385542168675, 'r1_recall': 0.46511627906976744, 'r1_f1': 0.31746031746031744, 'pegasus_entailment': 0.2751763919368386, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5149253731343284, 'r1_recall': 0.31221719457013575, 'r1_f1': 0.38873239436619716, 'pegasus_entailment': 0.43842457126205164, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4014084507042254, 'r1_recall': 0.504424778761062, 'r1_f1': 0.4470588235294118, 'pegasus_entailment': 0.403769763186574, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.11428571428571428, 'r1_recall': 0.6486486486486487, 'r1_f1': 0.194331983805668, 'pegasus_entailment': 0.7180651511464801, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3358208955223881, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.41666666666666674, 'pegasus_entailment': 0.5259642750024796, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37254901960784315, 'r1_recall': 0.5327102803738317, 'r1_f1': 0.43846153846153846, 'pegasus_entailment': 0.5726163131850106, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.24882629107981222, 'r1_recall': 0.7361111111111112, 'r1_f1': 0.3719298245614035, 'pegasus_entailment': 0.9258979048047747, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3935483870967742, 'r1_recall': 0.6931818181818182, 'r1_f1': 0.5020576131687242, 'pegasus_entailment': 0.6016869772225618, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5507246376811594, 'r1_recall': 0.42696629213483145, 'r1_f1': 0.4810126582278481, 'pegasus_entailment': 0.33470892161130905, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32653061224489793, 'r1_recall': 0.5423728813559322, 'r1_f1': 0.4076433121019108, 'pegasus_entailment': 0.431425005197525, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5102040816326531, 'r1_recall': 0.5050505050505051, 'r1_f1': 0.5076142131979695, 'pegasus_entailment': 0.427072498947382, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3467741935483871, 'r1_recall': 0.4479166666666667, 'r1_f1': 0.39090909090909093, 'pegasus_entailment': 0.8434368729591369, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5164835164835165, 'r1_recall': 0.5, 'r1_f1': 0.5081081081081081, 'pegasus_entailment': 0.6664147973060608, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7196969696969697, 'r1_recall': 0.18199233716475097, 'r1_f1': 0.29051987767584103, 'pegasus_entailment': 0.6897960975766182, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.55, 'r1_recall': 0.385, 'r1_f1': 0.45294117647058824, 'pegasus_entailment': 0.5580452034870783, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3655913978494624, 'r1_recall': 0.4358974358974359, 'r1_f1': 0.39766081871345027, 'pegasus_entailment': 0.331150484085083, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45689655172413796, 'r1_recall': 0.5047619047619047, 'r1_f1': 0.47963800904977383, 'pegasus_entailment': 0.7374683171510696, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6375, 'r1_recall': 0.375, 'r1_f1': 0.4722222222222222, 'pegasus_entailment': 0.8162467330694199, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.358695652173913, 'r1_recall': 0.584070796460177, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.45850696521145956, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2692307692307692, 'r1_recall': 0.32941176470588235, 'r1_f1': 0.2962962962962963, 'pegasus_entailment': 0.650185190141201, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2875816993464052, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.4018264840182648, 'pegasus_entailment': 0.8067248463630676, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3854166666666667, 'r1_recall': 0.40217391304347827, 'r1_f1': 0.39361702127659576, 'pegasus_entailment': 0.3087816536426544, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.43373493975903615, 'r1_f1': 0.4390243902439024, 'pegasus_entailment': 0.6881212592124939, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.46825396825396826, 'r1_f1': 0.48360655737704916, 'pegasus_entailment': 0.4537313371896744, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5522388059701493, 'r1_recall': 0.3627450980392157, 'r1_f1': 0.43786982248520706, 'pegasus_entailment': 0.2887360262684524, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5531914893617021, 'r1_recall': 0.32298136645962733, 'r1_f1': 0.4078431372549019, 'pegasus_entailment': 0.4594513773918152, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2980769230769231, 'r1_recall': 0.543859649122807, 'r1_f1': 0.3850931677018634, 'pegasus_entailment': 0.21449230859676996, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.34513274336283184, 'r1_f1': 0.4083769633507853, 'pegasus_entailment': 0.5058797597885132, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32727272727272727, 'r1_recall': 0.6, 'r1_f1': 0.4235294117647059, 'pegasus_entailment': 0.5363341748714447, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.367816091954023, 'r1_recall': 0.31683168316831684, 'r1_f1': 0.3404255319148936, 'pegasus_entailment': 0.6918413281440735, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22818791946308725, 'r1_recall': 0.6938775510204082, 'r1_f1': 0.3434343434343434, 'pegasus_entailment': 0.5261788163334131, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.15217391304347827, 'r1_recall': 0.45652173913043476, 'r1_f1': 0.22826086956521738, 'pegasus_entailment': 0.7456067562103271, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46629213483146065, 'r1_recall': 0.5684931506849316, 'r1_f1': 0.5123456790123457, 'pegasus_entailment': 0.5972099204858144, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5238095238095238, 'r1_recall': 0.4010416666666667, 'r1_f1': 0.4542772861356933, 'pegasus_entailment': 0.6453950703144073, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2463768115942029, 'r1_recall': 0.4594594594594595, 'r1_f1': 0.32075471698113206, 'pegasus_entailment': 0.620006400346756, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43137254901960786, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.43781094527363185, 'pegasus_entailment': 0.422179455558459, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.46987951807228917, 'r1_f1': 0.48447204968944096, 'pegasus_entailment': 0.518974781036377, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 15, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.647887323943662, 'r1_f1': 0.5644171779141104, 'pegasus_entailment': 0.49239127337932587, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3987341772151899, 'r1_recall': 0.5478260869565217, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.4287123799324036, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5408805031446541, 'r1_recall': 0.5119047619047619, 'r1_f1': 0.525993883792049, 'pegasus_entailment': 0.32682589143514634, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18699186991869918, 'r1_recall': 0.4339622641509434, 'r1_f1': 0.26136363636363635, 'pegasus_entailment': 0.61772820353508, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.5462962962962963, 'r1_f1': 0.41403508771929826, 'pegasus_entailment': 0.5290350653231144, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6530612244897959, 'r1_recall': 0.2831858407079646, 'r1_f1': 0.3950617283950617, 'pegasus_entailment': 0.274017023970373, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.6056338028169014, 'r1_f1': 0.35390946502057613, 'pegasus_entailment': 0.5818848056452615, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.553030303030303, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.41595441595441596, 'pegasus_entailment': 0.6638744711875916, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.08035714285714286, 'r1_recall': 0.2571428571428571, 'r1_f1': 0.12244897959183673, 'pegasus_entailment': 0.4615617170929909, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5053763440860215, 'r1_recall': 0.5662650602409639, 'r1_f1': 0.5340909090909092, 'pegasus_entailment': 0.47867069840431214, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25961538461538464, 'r1_recall': 0.5510204081632653, 'r1_f1': 0.3529411764705883, 'pegasus_entailment': 0.4793246280401945, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6422764227642277, 'r1_recall': 0.4647058823529412, 'r1_f1': 0.5392491467576793, 'pegasus_entailment': 0.5980433467775583, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5585585585585585, 'r1_recall': 0.4806201550387597, 'r1_f1': 0.5166666666666666, 'pegasus_entailment': 0.8507004380226135, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3355263157894737, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.42677824267782427, 'pegasus_entailment': 0.8745689541101456, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.35119047619047616, 'r1_recall': 0.44360902255639095, 'r1_f1': 0.39202657807308966, 'pegasus_entailment': 0.35521857142448426, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5043478260869565, 'r1_recall': 0.5225225225225225, 'r1_f1': 0.5132743362831858, 'pegasus_entailment': 0.36469743866473436, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35454545454545455, 'r1_recall': 0.40625, 'r1_f1': 0.3786407766990292, 'pegasus_entailment': 0.38772158324718475, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5208333333333334, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.528169014084507, 'pegasus_entailment': 0.6494958400726318, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43103448275862066, 'r1_recall': 0.3472222222222222, 'r1_f1': 0.3846153846153846, 'pegasus_entailment': 0.5693309381604195, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3048780487804878, 'r1_recall': 0.2717391304347826, 'r1_f1': 0.28735632183908044, 'pegasus_entailment': 0.872107982635498, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39705882352941174, 'r1_recall': 0.5242718446601942, 'r1_f1': 0.45188284518828453, 'pegasus_entailment': 0.5865766331553459, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3473684210526316, 'r1_recall': 0.4925373134328358, 'r1_f1': 0.4074074074074074, 'pegasus_entailment': 0.506642809137702, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.375886524822695, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.45689655172413796, 'pegasus_entailment': 0.5310108177363873, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 14, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6086956521739131, 'r1_recall': 0.3916083916083916, 'r1_f1': 0.4765957446808511, 'pegasus_entailment': 0.3946740850806236, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5106382978723404, 'r1_recall': 0.39344262295081966, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.29278837591409684, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5772357723577236, 'r1_recall': 0.42771084337349397, 'r1_f1': 0.4913494809688582, 'pegasus_entailment': 0.5892571806907654, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2987012987012987, 'r1_recall': 0.41818181818181815, 'r1_f1': 0.34848484848484845, 'pegasus_entailment': 0.4304780475795269, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.20710059171597633, 'r1_recall': 0.47297297297297297, 'r1_f1': 0.28806584362139914, 'pegasus_entailment': 0.5468541319881167, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5967741935483871, 'r1_recall': 0.3627450980392157, 'r1_f1': 0.451219512195122, 'pegasus_entailment': 0.5120287574827671, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47706422018348627, 'r1_recall': 0.24074074074074073, 'r1_f1': 0.32, 'pegasus_entailment': 0.39055462181568146, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 20, 'pegasus_ari': 36, 'pegasus_smog': 26}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48148148148148145, 'r1_recall': 0.4297520661157025, 'r1_f1': 0.4541484716157205, 'pegasus_entailment': 0.6088345572352409, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4420289855072464, 'r1_recall': 0.42657342657342656, 'r1_f1': 0.43416370106761565, 'pegasus_entailment': 0.34384915232658386, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32515337423312884, 'r1_recall': 0.6091954022988506, 'r1_f1': 0.42400000000000004, 'pegasus_entailment': 0.5619591403752565, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.26422764227642276, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.3857566765578635, 'pegasus_entailment': 0.6142450613634927, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47706422018348627, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.4928909952606635, 'pegasus_entailment': 0.5118298064917326, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4528301886792453, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.43636363636363634, 'pegasus_entailment': 0.5624456107616425, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46153846153846156, 'r1_recall': 0.48484848484848486, 'r1_f1': 0.47290640394088673, 'pegasus_entailment': 0.4927874654531479, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2764227642276423, 'r1_recall': 0.38202247191011235, 'r1_f1': 0.32075471698113206, 'pegasus_entailment': 0.46065793046727777, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6237623762376238, 'r1_recall': 0.38650306748466257, 'r1_f1': 0.4772727272727272, 'pegasus_entailment': 0.40575117990374565, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5486725663716814, 'r1_recall': 0.34065934065934067, 'r1_f1': 0.42033898305084744, 'pegasus_entailment': 0.49941310584545134, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5906040268456376, 'r1_recall': 0.32, 'r1_f1': 0.41509433962264153, 'pegasus_entailment': 0.5340407621115446, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5353535353535354, 'r1_recall': 0.48623853211009177, 'r1_f1': 0.5096153846153846, 'pegasus_entailment': 0.7960594892501831, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.13793103448275862, 'r1_recall': 0.27586206896551724, 'r1_f1': 0.1839080459770115, 'pegasus_entailment': 0.20339038968086243, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.544, 'r1_recall': 0.3756906077348066, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.4174641460180283, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3838383838383838, 'r1_recall': 0.4935064935064935, 'r1_f1': 0.43181818181818177, 'pegasus_entailment': 0.30814593099057674, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3443708609271523, 'r1_recall': 0.65, 'r1_f1': 0.4502164502164502, 'pegasus_entailment': 0.6005312085151673, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45098039215686275, 'r1_recall': 0.4946236559139785, 'r1_f1': 0.47179487179487184, 'pegasus_entailment': 0.24514445811510086, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3710691823899371, 'r1_recall': 0.7283950617283951, 'r1_f1': 0.4916666666666666, 'pegasus_entailment': 0.5150026295866285, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4563106796116505, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.4870466321243524, 'pegasus_entailment': 0.36044493736699224, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3246753246753247, 'r1_recall': 0.36231884057971014, 'r1_f1': 0.3424657534246575, 'pegasus_entailment': 0.5039962381124496, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3197278911564626, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.38683127572016457, 'pegasus_entailment': 0.5358067651589712, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.19791666666666666, 'r1_recall': 0.59375, 'r1_f1': 0.296875, 'pegasus_entailment': 0.6909829434007406, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2824074074074074, 'r1_recall': 0.6703296703296703, 'r1_f1': 0.3973941368078176, 'pegasus_entailment': 0.6707986891269684, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 31, 'pegasus_smog': 25}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44329896907216493, 'r1_recall': 0.48863636363636365, 'r1_f1': 0.46486486486486484, 'pegasus_entailment': 0.71526850014925, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 22}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2894736842105263, 'r1_recall': 0.7096774193548387, 'r1_f1': 0.4112149532710281, 'pegasus_entailment': 0.36828048604850966, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6106194690265486, 'r1_recall': 0.6448598130841121, 'r1_f1': 0.6272727272727272, 'pegasus_entailment': 0.6242966949939728, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2571428571428571, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.35467980295566504, 'pegasus_entailment': 0.3999118313193321, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.664, 'r1_recall': 0.3132075471698113, 'r1_f1': 0.42564102564102557, 'pegasus_entailment': 0.6433999463915825, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4, 'r1_recall': 0.59375, 'r1_f1': 0.4779874213836478, 'pegasus_entailment': 0.5948800314217806, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44680851063829785, 'r1_recall': 0.45652173913043476, 'r1_f1': 0.45161290322580644, 'pegasus_entailment': 0.6003676541149616, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5416666666666666, 'r1_recall': 0.52, 'r1_f1': 0.5306122448979592, 'pegasus_entailment': 0.8397439479827881, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5142857142857142, 'r1_recall': 0.38571428571428573, 'r1_f1': 0.44081632653061226, 'pegasus_entailment': 0.9395105838775635, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4628099173553719, 'r1_recall': 0.5957446808510638, 'r1_f1': 0.5209302325581395, 'pegasus_entailment': 0.45337354112416506, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5609756097560976, 'r1_recall': 0.5433070866141733, 'r1_f1': 0.552, 'pegasus_entailment': 0.43698753975331783, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3305785123966942, 'r1_recall': 0.5633802816901409, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.6601342409849167, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4155844155844156, 'r1_recall': 0.3404255319148936, 'r1_f1': 0.37426900584795325, 'pegasus_entailment': 0.6171248536556959, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3162393162393162, 'r1_recall': 0.44047619047619047, 'r1_f1': 0.3681592039800995, 'pegasus_entailment': 0.6703666523098946, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5409836065573771, 'r1_recall': 0.44594594594594594, 'r1_f1': 0.48888888888888893, 'pegasus_entailment': 0.4127548784017563, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4125, 'r1_recall': 0.4925373134328358, 'r1_f1': 0.44897959183673464, 'pegasus_entailment': 0.41299952318271, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3181818181818182, 'r1_recall': 0.546875, 'r1_f1': 0.4022988505747127, 'pegasus_entailment': 0.33349159080535173, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3416149068322981, 'r1_recall': 0.3179190751445087, 'r1_f1': 0.32934131736526945, 'pegasus_entailment': 0.3265839163213968, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49606299212598426, 'r1_recall': 0.38181818181818183, 'r1_f1': 0.43150684931506855, 'pegasus_entailment': 0.6505275875329971, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5072463768115942, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.5932203389830508, 'pegasus_entailment': 0.39179553017020224, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5777777777777777, 'r1_recall': 0.27807486631016043, 'r1_f1': 0.37545126353790614, 'pegasus_entailment': 0.7021807283163071, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4, 'r1_recall': 0.4631578947368421, 'r1_f1': 0.4292682926829268, 'pegasus_entailment': 0.26670326143503187, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2396694214876033, 'r1_recall': 0.4027777777777778, 'r1_f1': 0.3005181347150259, 'pegasus_entailment': 0.7335114479064941, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 25}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3218390804597701, 'r1_recall': 0.509090909090909, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.8294081489245096, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.16666666666666666, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.25806451612903225, 'pegasus_entailment': 0.5349697371323904, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 21, 'pegasus_ari': 34, 'pegasus_smog': 25}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27439024390243905, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.3829787234042553, 'pegasus_entailment': 0.630658820271492, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.264, 'r1_recall': 0.6346153846153846, 'r1_f1': 0.3728813559322034, 'pegasus_entailment': 0.2598458528518677, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43157894736842106, 'r1_recall': 0.3504273504273504, 'r1_f1': 0.3867924528301887, 'pegasus_entailment': 0.5924401916563511, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5225225225225225, 'r1_recall': 0.44274809160305345, 'r1_f1': 0.47933884297520657, 'pegasus_entailment': 0.7035919626553854, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42045454545454547, 'r1_recall': 0.44047619047619047, 'r1_f1': 0.4302325581395349, 'pegasus_entailment': 0.3855854898691177, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.4, 'r1_f1': 0.4210526315789474, 'pegasus_entailment': 0.5930556108554205, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3096774193548387, 'r1_recall': 0.5274725274725275, 'r1_f1': 0.3902439024390244, 'pegasus_entailment': 0.7593178391456604, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3548387096774194, 'r1_recall': 0.5, 'r1_f1': 0.41509433962264153, 'pegasus_entailment': 0.8733084201812744, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42424242424242425, 'r1_recall': 0.45652173913043476, 'r1_f1': 0.43979057591623033, 'pegasus_entailment': 0.3050461545586586, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.48, 'r1_f1': 0.4528301886792452, 'pegasus_entailment': 0.8113365372021993, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 25}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2857142857142857, 'r1_recall': 0.4927536231884058, 'r1_f1': 0.36170212765957444, 'pegasus_entailment': 0.6662427708506584, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5392156862745098, 'r1_recall': 0.632183908045977, 'r1_f1': 0.5820105820105821, 'pegasus_entailment': 0.538392499089241, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3116883116883117, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.37499999999999994, 'pegasus_entailment': 0.5169730452554566, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3482142857142857, 'r1_recall': 0.4642857142857143, 'r1_f1': 0.3979591836734694, 'pegasus_entailment': 0.6994415181688964, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1497005988023952, 'r1_recall': 0.4807692307692308, 'r1_f1': 0.228310502283105, 'pegasus_entailment': 0.7034288167953491, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.573170731707317, 'r1_recall': 0.32867132867132864, 'r1_f1': 0.41777777777777775, 'pegasus_entailment': 0.4559853672981262, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 22, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4424778761061947, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.5, 'pegasus_entailment': 0.6237548689047495, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2923076923076923, 'r1_recall': 0.7037037037037037, 'r1_f1': 0.41304347826086957, 'pegasus_entailment': 0.5440660665432612, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5294117647058824, 'r1_recall': 0.5206611570247934, 'r1_f1': 0.525, 'pegasus_entailment': 0.5937141925096512, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33043478260869563, 'r1_recall': 0.36538461538461536, 'r1_f1': 0.34703196347031967, 'pegasus_entailment': 0.44446170578400296, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2, 'r1_recall': 0.5857142857142857, 'r1_f1': 0.2981818181818182, 'pegasus_entailment': 0.6607240974903107, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2736842105263158, 'r1_recall': 0.3611111111111111, 'r1_f1': 0.31137724550898205, 'pegasus_entailment': 0.5289449592431387, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2647058823529412, 'r1_recall': 0.4044943820224719, 'r1_f1': 0.31999999999999995, 'pegasus_entailment': 0.5545865346988043, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.17204301075268819, 'r1_recall': 0.35555555555555557, 'r1_f1': 0.2318840579710145, 'pegasus_entailment': 0.43469118792563677, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5268817204301075, 'r1_recall': 0.47572815533980584, 'r1_f1': 0.5, 'pegasus_entailment': 0.4837253801524639, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.11214953271028037, 'r1_recall': 0.34285714285714286, 'r1_f1': 0.16901408450704225, 'pegasus_entailment': 0.6254249095916748, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.22377622377622378, 'r1_recall': 0.7111111111111111, 'r1_f1': 0.3404255319148936, 'pegasus_entailment': 0.4990060428157449, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.35114503816793896, 'pegasus_entailment': 0.6521236995855967, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.375, 'r1_recall': 0.32432432432432434, 'r1_f1': 0.34782608695652173, 'pegasus_entailment': 0.5420826710760593, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 14}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5689655172413793, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.5711456847687563, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4044943820224719, 'r1_recall': 0.375, 'r1_f1': 0.38918918918918916, 'pegasus_entailment': 0.6505370624363422, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40131578947368424, 'r1_recall': 0.5596330275229358, 'r1_f1': 0.4674329501915709, 'pegasus_entailment': 0.36577524691820146, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6265060240963856, 'r1_recall': 0.37681159420289856, 'r1_f1': 0.4705882352941176, 'pegasus_entailment': 0.4688603952527046, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7941176470588235, 'r1_recall': 0.23011363636363635, 'r1_f1': 0.35682819383259906, 'pegasus_entailment': 0.6535736080259085, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3068181818181818, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.37630662020905925, 'pegasus_entailment': 0.4798415079712868, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46534653465346537, 'r1_recall': 0.31543624161073824, 'r1_f1': 0.37599999999999995, 'pegasus_entailment': 0.7534673064947128, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5151515151515151, 'r1_recall': 0.3422818791946309, 'r1_f1': 0.41129032258064513, 'pegasus_entailment': 0.6090420285860697, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.24468085106382978, 'r1_recall': 0.46938775510204084, 'r1_f1': 0.32167832167832167, 'pegasus_entailment': 0.48604170279577374, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3821138211382114, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.48205128205128206, 'pegasus_entailment': 0.7101364334424337, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4, 'r1_recall': 0.5679012345679012, 'r1_f1': 0.46938775510204084, 'pegasus_entailment': 0.8222473502159119, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7452830188679245, 'r1_recall': 0.5266666666666666, 'r1_f1': 0.6171875, 'pegasus_entailment': 0.7065692643324534, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4177215189873418, 'r1_recall': 0.4925373134328358, 'r1_f1': 0.4520547945205479, 'pegasus_entailment': 0.5345698539167643, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6176470588235294, 'r1_recall': 0.4883720930232558, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.3380311994502942, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2978723404255319, 'r1_recall': 0.5675675675675675, 'r1_f1': 0.3906976744186046, 'pegasus_entailment': 0.3252023970708251, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31297709923664124, 'r1_recall': 0.5061728395061729, 'r1_f1': 0.38679245283018876, 'pegasus_entailment': 0.7566186130046845, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6133333333333333, 'r1_recall': 0.3262411347517731, 'r1_f1': 0.42592592592592593, 'pegasus_entailment': 0.4258557092398405, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43703703703703706, 'r1_recall': 0.45038167938931295, 'r1_f1': 0.44360902255639095, 'pegasus_entailment': 0.6719631135463715, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5867768595041323, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.4251497005988024, 'pegasus_entailment': 0.6794128119945526, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46551724137931033, 'r1_recall': 0.6, 'r1_f1': 0.5242718446601942, 'pegasus_entailment': 0.577658511698246, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3368421052631579, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.4210526315789474, 'pegasus_entailment': 0.3745007496327162, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5789473684210527, 'r1_recall': 0.4656084656084656, 'r1_f1': 0.5161290322580645, 'pegasus_entailment': 0.6227197104266712, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5563380281690141, 'r1_recall': 0.2598684210526316, 'r1_f1': 0.3542600896860987, 'pegasus_entailment': 0.45868617482483387, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19298245614035087, 'r1_recall': 0.3492063492063492, 'r1_f1': 0.2485875706214689, 'pegasus_entailment': 0.4238451151177287, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40816326530612246, 'r1_recall': 0.631578947368421, 'r1_f1': 0.4958677685950414, 'pegasus_entailment': 0.6194432497024536, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.50920245398773, 'r1_recall': 0.5253164556962026, 'r1_f1': 0.5171339563862928, 'pegasus_entailment': 0.5883450905481974, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 19, 'pegasus_ari': 35, 'pegasus_smog': 26}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.32098765432098764, 'pegasus_entailment': 0.6698156793912252, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5172413793103449, 'r1_recall': 0.3314917127071823, 'r1_f1': 0.4040404040404041, 'pegasus_entailment': 0.6847927838563919, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4566929133858268, 'r1_recall': 0.4084507042253521, 'r1_f1': 0.4312267657992565, 'pegasus_entailment': 0.5306251832516864, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3723404255319149, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.37037037037037035, 'pegasus_entailment': 0.6402019280940294, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48507462686567165, 'r1_recall': 0.37790697674418605, 'r1_f1': 0.4248366013071896, 'pegasus_entailment': 0.5119323544204235, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23870967741935484, 'r1_recall': 0.5211267605633803, 'r1_f1': 0.327433628318584, 'pegasus_entailment': 0.6028133767346541, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6619718309859155, 'r1_recall': 0.4519230769230769, 'r1_f1': 0.5371428571428571, 'pegasus_entailment': 0.5351366822918256, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3173076923076923, 'r1_recall': 0.3548387096774194, 'r1_f1': 0.3350253807106599, 'pegasus_entailment': 0.8586556017398834, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2603550295857988, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.36065573770491804, 'pegasus_entailment': 0.8755922317504883, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4835164835164835, 'r1_recall': 0.6197183098591549, 'r1_f1': 0.5432098765432098, 'pegasus_entailment': 0.44836376011371615, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3466666666666667, 'r1_recall': 0.5148514851485149, 'r1_f1': 0.41434262948207173, 'pegasus_entailment': 0.6751068234443665, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8, 'r1_recall': 0.3671497584541063, 'r1_f1': 0.5033112582781457, 'pegasus_entailment': 0.6543982297182083, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48598130841121495, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.4976076555023923, 'pegasus_entailment': 0.6118854433298111, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31343283582089554, 'r1_recall': 0.35, 'r1_f1': 0.3307086614173228, 'pegasus_entailment': 0.5609736641248068, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5471698113207547, 'r1_recall': 0.4887640449438202, 'r1_f1': 0.5163204747774481, 'pegasus_entailment': 0.601470448076725, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40404040404040403, 'r1_recall': 0.547945205479452, 'r1_f1': 0.46511627906976744, 'pegasus_entailment': 0.40344197303056717, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3120567375886525, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.4055299539170507, 'pegasus_entailment': 0.5962445810437202, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48, 'r1_recall': 0.5274725274725275, 'r1_f1': 0.5026178010471205, 'pegasus_entailment': 0.609003871679306, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42276422764227645, 'r1_recall': 0.43333333333333335, 'r1_f1': 0.4279835390946502, 'pegasus_entailment': 0.7501323342323303, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.777027027027027, 'r1_recall': 0.16312056737588654, 'r1_f1': 0.2696365767878077, 'pegasus_entailment': 0.6337008299306035, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45652173913043476, 'r1_recall': 0.44366197183098594, 'r1_f1': 0.45, 'pegasus_entailment': 0.6290945907433828, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43870967741935485, 'r1_recall': 0.37158469945355194, 'r1_f1': 0.4023668639053255, 'pegasus_entailment': 0.7545958310365677, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 22}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47191011235955055, 'r1_recall': 0.45161290322580644, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.5027007162570953, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43795620437956206, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.47430830039525695, 'pegasus_entailment': 0.5266673743724823, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2222222222222222, 'r1_recall': 0.49230769230769234, 'r1_f1': 0.3062200956937799, 'pegasus_entailment': 0.7643145442008972, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.4140127388535032, 'r1_f1': 0.4529616724738676, 'pegasus_entailment': 0.5389671742916107, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24210526315789474, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.32167832167832167, 'pegasus_entailment': 0.5254494473338127, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37168141592920356, 'r1_recall': 0.4329896907216495, 'r1_f1': 0.4, 'pegasus_entailment': 0.6905397921800613, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 23, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.14049586776859505, 'r1_recall': 0.4857142857142857, 'r1_f1': 0.21794871794871795, 'pegasus_entailment': 0.36407698690891266, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.4536082474226804, 'r1_f1': 0.4489795918367347, 'pegasus_entailment': 0.843474288781484, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 23, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.41237113402061853, 'r1_recall': 0.35398230088495575, 'r1_f1': 0.38095238095238093, 'pegasus_entailment': 0.3834375712322071, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6923076923076923, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.5575221238938054, 'pegasus_entailment': 0.21915176510810852, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2631578947368421, 'r1_recall': 0.37037037037037035, 'r1_f1': 0.30769230769230765, 'pegasus_entailment': 0.49733196943998337, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4392523364485981, 'r1_recall': 0.47, 'r1_f1': 0.45410628019323673, 'pegasus_entailment': 0.725895631313324, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
** Analysing column: malformed_chain



malformed_chain
Length after nones removed
616
MIN
0
MEAN
0
MAX
1
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.06565656565656566
MEAN
0.4306829584161161
MAX
0.8921568627450981
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.046875
MEAN
0.47030746106239063
MAX
0.7959183673469388
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.08391608391608392
MEAN
0.42424046367928564
MAX
0.6299212598425197
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.008146524429321289
MEAN
0.5577617164136058
MAX
0.9430170655250549
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
18
MAX
30
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
13
MEAN
18
MAX
23
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
12
MEAN
21
MAX
37
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
12
MEAN
18
MAX
28
{}
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37333333333333335, 'r1_recall': 0.509090909090909, 'r1_f1': 0.4307692307692308, 'pegasus_entailment': 0.6115750014781952, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5494505494505495, 'r1_recall': 0.28901734104046245, 'r1_f1': 0.3787878787878789, 'pegasus_entailment': 0.7598638733228048, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3561643835616438, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.3969465648854962, 'pegasus_entailment': 0.6127078235149384, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5403225806451613, 'r1_recall': 0.5193798449612403, 'r1_f1': 0.5296442687747036, 'pegasus_entailment': 0.5842858355026692, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6956521739130435, 'r1_recall': 0.367816091954023, 'r1_f1': 0.48120300751879697, 'pegasus_entailment': 0.46148580461740496, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4573643410852713, 'r1_recall': 0.45384615384615384, 'r1_f1': 0.4555984555984556, 'pegasus_entailment': 0.3236233085393906, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.17346938775510204, 'r1_recall': 0.53125, 'r1_f1': 0.26153846153846155, 'pegasus_entailment': 0.45756004254023236, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27472527472527475, 'r1_recall': 0.8064516129032258, 'r1_f1': 0.40983606557377045, 'pegasus_entailment': 0.5884719689687093, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7209302325581395, 'r1_recall': 0.4161073825503356, 'r1_f1': 0.5276595744680851, 'pegasus_entailment': 0.6538144946098328, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6528925619834711, 'r1_recall': 0.572463768115942, 'r1_f1': 0.61003861003861, 'pegasus_entailment': 0.5872775216897329, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7222222222222222, 'r1_recall': 0.3466666666666667, 'r1_f1': 0.4684684684684684, 'pegasus_entailment': 0.41406606137752533, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5338983050847458, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.5316455696202531, 'pegasus_entailment': 0.6612891554832458, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6710526315789473, 'r1_recall': 0.4766355140186916, 'r1_f1': 0.5573770491803279, 'pegasus_entailment': 0.8185312151908875, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5942028985507246, 'r1_recall': 0.4659090909090909, 'r1_f1': 0.5222929936305732, 'pegasus_entailment': 0.5763680767267942, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7590361445783133, 'r1_recall': 0.328125, 'r1_f1': 0.45818181818181813, 'pegasus_entailment': 0.7202640175819397, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1875, 'r1_recall': 0.2033898305084746, 'r1_f1': 0.1951219512195122, 'pegasus_entailment': 0.6483420232931772, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36879432624113473, 'r1_recall': 0.5252525252525253, 'r1_f1': 0.4333333333333333, 'pegasus_entailment': 0.6831628620624542, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7878787878787878, 'r1_recall': 0.26174496644295303, 'r1_f1': 0.39294710327455923, 'pegasus_entailment': 0.23410137929022312, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5882352941176471, 'r1_recall': 0.37267080745341613, 'r1_f1': 0.45627376425855515, 'pegasus_entailment': 0.3040904601414998, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35714285714285715, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.44052863436123346, 'pegasus_entailment': 0.5093731778208166, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5483870967741935, 'r1_recall': 0.37362637362637363, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.3937962104876836, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5084745762711864, 'r1_recall': 0.4, 'r1_f1': 0.44776119402985076, 'pegasus_entailment': 0.4773606862872839, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42424242424242425, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.5689589500427246, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6395348837209303, 'r1_recall': 0.40441176470588236, 'r1_f1': 0.49549549549549543, 'pegasus_entailment': 0.5195132493972778, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44, 'r1_recall': 0.66, 'r1_f1': 0.5279999999999999, 'pegasus_entailment': 0.5545938275754452, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7083333333333334, 'r1_recall': 0.5396825396825397, 'r1_f1': 0.6126126126126126, 'pegasus_entailment': 0.46406122744083406, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6037735849056604, 'r1_recall': 0.46715328467153283, 'r1_f1': 0.5267489711934156, 'pegasus_entailment': 0.510853773355484, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7701149425287356, 'r1_recall': 0.25, 'r1_f1': 0.3774647887323944, 'pegasus_entailment': 0.6124545216560364, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47619047619047616, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.4316546762589928, 'pegasus_entailment': 0.2718936949968338, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4065934065934066, 'r1_recall': 0.3274336283185841, 'r1_f1': 0.36274509803921573, 'pegasus_entailment': 0.5351805587609609, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3630573248407643, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.4672131147540984, 'pegasus_entailment': 0.594984894990921, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6065573770491803, 'r1_recall': 0.5522388059701493, 'r1_f1': 0.578125, 'pegasus_entailment': 0.7917952736218771, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24358974358974358, 'r1_recall': 0.36893203883495146, 'r1_f1': 0.29343629343629346, 'pegasus_entailment': 0.7097152695059776, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4507042253521127, 'r1_recall': 0.32989690721649484, 'r1_f1': 0.38095238095238093, 'pegasus_entailment': 0.6168331149965525, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3, 'r1_recall': 0.5, 'r1_f1': 0.37499999999999994, 'pegasus_entailment': 0.4612551884104808, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6049382716049383, 'r1_recall': 0.4224137931034483, 'r1_f1': 0.4974619289340101, 'pegasus_entailment': 0.267160464823246, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.39072847682119205, 'r1_recall': 0.855072463768116, 'r1_f1': 0.5363636363636364, 'pegasus_entailment': 0.6791648983955383, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36082474226804123, 'r1_recall': 0.5147058823529411, 'r1_f1': 0.4242424242424242, 'pegasus_entailment': 0.639914090745151, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23076923076923078, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.3510638297872341, 'pegasus_entailment': 0.6637586280703545, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5405405405405406, 'r1_recall': 0.3614457831325301, 'r1_f1': 0.4332129963898917, 'pegasus_entailment': 0.9094644039869308, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5923566878980892, 'r1_recall': 0.58125, 'r1_f1': 0.5867507886435332, 'pegasus_entailment': 0.5770272649824619, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45569620253164556, 'r1_recall': 0.4675324675324675, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.43265604053158313, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40217391304347827, 'r1_recall': 0.5068493150684932, 'r1_f1': 0.44848484848484854, 'pegasus_entailment': 0.40266725483040017, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.75, 'r1_recall': 0.5121951219512195, 'r1_f1': 0.6086956521739131, 'pegasus_entailment': 0.5605195723474026, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23529411764705882, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.31168831168831174, 'pegasus_entailment': 0.6530719958245754, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 22}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44660194174757284, 'r1_recall': 0.30666666666666664, 'r1_f1': 0.36363636363636365, 'pegasus_entailment': 0.790607213973999, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 34, 'pegasus_smog': 22}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5096774193548387, 'r1_recall': 0.6694915254237288, 'r1_f1': 0.5787545787545787, 'pegasus_entailment': 0.32184758215832215, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5350877192982456, 'r1_recall': 0.5495495495495496, 'r1_f1': 0.5422222222222223, 'pegasus_entailment': 0.6928569316864014, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4351145038167939, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.530232558139535, 'pegasus_entailment': 0.40493958480656145, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3105590062111801, 'r1_recall': 0.4807692307692308, 'r1_f1': 0.3773584905660377, 'pegasus_entailment': 0.3591605991125107, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40869565217391307, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.4973544973544973, 'pegasus_entailment': 0.5905499830842018, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2052980132450331, 'r1_recall': 0.6078431372549019, 'r1_f1': 0.30693069306930687, 'pegasus_entailment': 0.5455556383563412, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2878787878787879, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.36893203883495146, 'pegasus_entailment': 0.5743681430816651, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6351351351351351, 'r1_recall': 0.2655367231638418, 'r1_f1': 0.37450199203187245, 'pegasus_entailment': 0.19932902604341507, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6206896551724138, 'r1_recall': 0.5056179775280899, 'r1_f1': 0.5572755417956656, 'pegasus_entailment': 0.3728234335780144, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.28169014084507044, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.37383177570093457, 'pegasus_entailment': 0.5175390928983689, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5923566878980892, 'r1_recall': 0.3705179282868526, 'r1_f1': 0.4558823529411765, 'pegasus_entailment': 0.6096627749502659, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46835443037974683, 'r1_recall': 0.578125, 'r1_f1': 0.5174825174825174, 'pegasus_entailment': 0.47513427833716076, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7053571428571429, 'r1_recall': 0.6528925619834711, 'r1_f1': 0.6781115879828326, 'pegasus_entailment': 0.42969915581246215, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3626373626373626, 'r1_recall': 0.6285714285714286, 'r1_f1': 0.4599303135888501, 'pegasus_entailment': 0.5934453904628754, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3923076923076923, 'r1_recall': 0.5795454545454546, 'r1_f1': 0.46788990825688076, 'pegasus_entailment': 0.8431368768215179, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.336283185840708, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.41081081081081083, 'pegasus_entailment': 0.30770368268713355, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5242718446601942, 'r1_recall': 0.32142857142857145, 'r1_f1': 0.39852398523985244, 'pegasus_entailment': 0.730649933218956, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32666666666666666, 'r1_recall': 0.5051546391752577, 'r1_f1': 0.3967611336032389, 'pegasus_entailment': 0.8106765126188596, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4246575342465753, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.512396694214876, 'pegasus_entailment': 0.43964346249898273, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6607142857142857, 'r1_recall': 0.5826771653543307, 'r1_f1': 0.6192468619246861, 'pegasus_entailment': 0.6236967816948891, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47107438016528924, 'r1_recall': 0.5377358490566038, 'r1_f1': 0.5022026431718062, 'pegasus_entailment': 0.7626731693744659, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4411764705882353, 'r1_recall': 0.46875, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.4856181234121323, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.48695652173913045, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.3347058688911299, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6481481481481481, 'r1_recall': 0.3431372549019608, 'r1_f1': 0.4487179487179487, 'pegasus_entailment': 0.6928176482518514, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4625, 'r1_recall': 0.4457831325301205, 'r1_f1': 0.4539877300613497, 'pegasus_entailment': 0.6386201530694962, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4017857142857143, 'r1_recall': 0.6617647058823529, 'r1_f1': 0.5, 'pegasus_entailment': 0.31922749678293866, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3142857142857143, 'r1_recall': 0.5, 'r1_f1': 0.38596491228070173, 'pegasus_entailment': 0.9011369496583939, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6857142857142857, 'r1_recall': 0.5052631578947369, 'r1_f1': 0.5818181818181819, 'pegasus_entailment': 0.6504602611064911, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3130434782608696, 'r1_recall': 0.5, 'r1_f1': 0.3850267379679145, 'pegasus_entailment': 0.3926175255328417, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44339622641509435, 'r1_recall': 0.5529411764705883, 'r1_f1': 0.49214659685863876, 'pegasus_entailment': 0.3343339338898659, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2746478873239437, 'r1_recall': 0.609375, 'r1_f1': 0.3786407766990291, 'pegasus_entailment': 0.9376637101173401, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4032258064516129, 'r1_recall': 0.4807692307692308, 'r1_f1': 0.43859649122807015, 'pegasus_entailment': 0.17239447496831417, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4084507042253521, 'r1_recall': 0.6744186046511628, 'r1_f1': 0.5087719298245613, 'pegasus_entailment': 0.6240362301468849, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33695652173913043, 'r1_recall': 0.4626865671641791, 'r1_f1': 0.389937106918239, 'pegasus_entailment': 0.8138797879219055, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5056179775280899, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.5389221556886228, 'pegasus_entailment': 0.3819707930088043, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.594059405940594, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.2352050936431624, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33980582524271846, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.4166666666666667, 'pegasus_entailment': 0.5525264746199051, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4260869565217391, 'r1_recall': 0.5632183908045977, 'r1_f1': 0.48514851485148514, 'pegasus_entailment': 0.44734661118127406, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.17391304347826086, 'r1_f1': 0.25806451612903225, 'pegasus_entailment': 0.42332305014133453, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21022727272727273, 'r1_recall': 0.42528735632183906, 'r1_f1': 0.28136882129277563, 'pegasus_entailment': 0.6014472889713943, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2558139534883721, 'r1_recall': 0.28205128205128205, 'r1_f1': 0.2682926829268293, 'pegasus_entailment': 0.5616256212815642, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2988505747126437, 'r1_recall': 0.5777777777777777, 'r1_f1': 0.393939393939394, 'pegasus_entailment': 0.9378903309504191, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7115384615384616, 'r1_recall': 0.3557692307692308, 'r1_f1': 0.4743589743589744, 'pegasus_entailment': 0.4119340628385544, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31666666666666665, 'r1_recall': 0.5428571428571428, 'r1_f1': 0.4, 'pegasus_entailment': 0.4996903100516647, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5193370165745856, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.5040214477211796, 'pegasus_entailment': 0.6807783246040344, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49264705882352944, 'r1_recall': 0.5, 'r1_f1': 0.4962962962962963, 'pegasus_entailment': 0.44281920914848644, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4365079365079365, 'r1_recall': 0.7534246575342466, 'r1_f1': 0.5527638190954773, 'pegasus_entailment': 0.6258925667498261, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45774647887323944, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.5019305019305019, 'pegasus_entailment': 0.6389762843027711, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32727272727272727, 'r1_recall': 0.18556701030927836, 'r1_f1': 0.2368421052631579, 'pegasus_entailment': 0.9904266893863678, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.632183908045977, 'r1_recall': 0.3107344632768362, 'r1_f1': 0.4166666666666667, 'pegasus_entailment': 0.5850710868835449, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45794392523364486, 'r1_recall': 0.5051546391752577, 'r1_f1': 0.4803921568627451, 'pegasus_entailment': 0.5705479085445404, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4392523364485981, 'r1_recall': 0.373015873015873, 'r1_f1': 0.4034334763948498, 'pegasus_entailment': 0.5360481753945351, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.31932773109243695, 'r1_recall': 0.5846153846153846, 'r1_f1': 0.41304347826086957, 'pegasus_entailment': 0.6351787775754929, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5212765957446809, 'r1_recall': 0.4375, 'r1_f1': 0.47572815533980584, 'pegasus_entailment': 0.7391711473464966, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38271604938271603, 'r1_recall': 0.5081967213114754, 'r1_f1': 0.43661971830985913, 'pegasus_entailment': 0.659699410200119, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4567901234567901, 'r1_recall': 0.39361702127659576, 'r1_f1': 0.4228571428571428, 'pegasus_entailment': 0.6629329267889261, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4166666666666667, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.5084745762711865, 'pegasus_entailment': 0.7541697442531585, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.504, 'r1_recall': 0.5625, 'r1_f1': 0.5316455696202531, 'pegasus_entailment': 0.5619356594979763, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33125, 'r1_recall': 0.6625, 'r1_f1': 0.4416666666666667, 'pegasus_entailment': 0.7544201612472534, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5504587155963303, 'r1_recall': 0.46511627906976744, 'r1_f1': 0.5042016806722689, 'pegasus_entailment': 0.4064277149736881, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5514018691588785, 'r1_recall': 0.5728155339805825, 'r1_f1': 0.5619047619047619, 'pegasus_entailment': 0.6405346803367138, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5161290322580645, 'r1_recall': 0.4, 'r1_f1': 0.4507042253521127, 'pegasus_entailment': 0.5911065662900606, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31496062992125984, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.39603960396039606, 'pegasus_entailment': 0.4786293514383336, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.25806451612903225, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.34782608695652173, 'pegasus_entailment': 0.4076640826339523, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43478260869565216, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.8914365321397781, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48344370860927155, 'r1_recall': 0.5488721804511278, 'r1_f1': 0.5140845070422535, 'pegasus_entailment': 0.69965960085392, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6875, 'r1_recall': 0.5569620253164557, 'r1_f1': 0.6153846153846154, 'pegasus_entailment': 0.46899417811073363, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.452991452991453, 'r1_recall': 0.5955056179775281, 'r1_f1': 0.5145631067961165, 'pegasus_entailment': 0.5912953093647957, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3544973544973545, 'r1_recall': 0.5153846153846153, 'r1_f1': 0.4200626959247649, 'pegasus_entailment': 0.590422896357874, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6829268292682927, 'r1_recall': 0.47191011235955055, 'r1_f1': 0.558139534883721, 'pegasus_entailment': 0.574665492773056, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7016129032258065, 'r1_recall': 0.4943181818181818, 'r1_f1': 0.58, 'pegasus_entailment': 0.5156022720038891, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4794520547945205, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.5, 'pegasus_entailment': 0.4145296171385174, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4563106796116505, 'r1_recall': 0.5, 'r1_f1': 0.47715736040609136, 'pegasus_entailment': 0.39416818154859357, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6885245901639344, 'r1_recall': 0.33070866141732286, 'r1_f1': 0.4468085106382979, 'pegasus_entailment': 0.7529306213061014, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.625, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.72182996571064, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5132743362831859, 'r1_recall': 0.5043478260869565, 'r1_f1': 0.5087719298245613, 'pegasus_entailment': 0.584490954875946, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 18}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3560606060606061, 'r1_recall': 0.618421052631579, 'r1_f1': 0.4519230769230769, 'pegasus_entailment': 0.5855731278657913, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22123893805309736, 'r1_recall': 0.5813953488372093, 'r1_f1': 0.32051282051282054, 'pegasus_entailment': 0.5946978032588959, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5526315789473685, 'r1_recall': 0.75, 'r1_f1': 0.6363636363636364, 'pegasus_entailment': 0.3427880802191794, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5683453237410072, 'r1_recall': 0.6030534351145038, 'r1_f1': 0.5851851851851851, 'pegasus_entailment': 0.5427781209349632, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.275, 'r1_f1': 0.3548387096774194, 'pegasus_entailment': 0.3287636488676071, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 13, 'pegasus_ari': 11, 'pegasus_smog': 15}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.631578947368421, 'r1_recall': 0.5128205128205128, 'r1_f1': 0.5660377358490566, 'pegasus_entailment': 0.6385106053203344, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5619834710743802, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.5738396624472574, 'pegasus_entailment': 0.7065477768580118, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36538461538461536, 'r1_recall': 0.6440677966101694, 'r1_f1': 0.4662576687116564, 'pegasus_entailment': 0.37436588257551195, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.5436893203883495, 'pegasus_entailment': 0.07398531849806507, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7448979591836735, 'r1_recall': 0.6033057851239669, 'r1_f1': 0.6666666666666667, 'pegasus_entailment': 0.6957511813379824, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6138613861386139, 'r1_recall': 0.4, 'r1_f1': 0.484375, 'pegasus_entailment': 0.8626004457473755, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5572519083969466, 'r1_recall': 0.44785276073619634, 'r1_f1': 0.49659863945578236, 'pegasus_entailment': 0.6372936125844717, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5813953488372093, 'r1_recall': 0.49504950495049505, 'r1_f1': 0.53475935828877, 'pegasus_entailment': 0.4154680445790291, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4566929133858268, 'r1_recall': 0.4793388429752066, 'r1_f1': 0.467741935483871, 'pegasus_entailment': 0.7909341752529144, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2863636363636364, 'r1_recall': 0.6774193548387096, 'r1_f1': 0.40255591054313095, 'pegasus_entailment': 0.6394667824109396, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6694214876033058, 'r1_recall': 0.6090225563909775, 'r1_f1': 0.6377952755905512, 'pegasus_entailment': 0.7989461794495583, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7040816326530612, 'r1_recall': 0.372972972972973, 'r1_f1': 0.48763250883392223, 'pegasus_entailment': 0.6150806546211243, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4367816091954023, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.5241379310344828, 'pegasus_entailment': 0.457336263731122, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4666666666666667, 'r1_recall': 0.4772727272727273, 'r1_f1': 0.4719101123595506, 'pegasus_entailment': 0.4841199778020382, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4270833333333333, 'r1_recall': 0.44086021505376344, 'r1_f1': 0.43386243386243384, 'pegasus_entailment': 0.6988864243030548, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5360824742268041, 'r1_recall': 0.46017699115044247, 'r1_f1': 0.49523809523809526, 'pegasus_entailment': 0.6969681531190872, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5922330097087378, 'r1_recall': 0.7625, 'r1_f1': 0.6666666666666666, 'pegasus_entailment': 0.5300065279006958, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5789473684210527, 'r1_recall': 0.43564356435643564, 'r1_f1': 0.4971751412429379, 'pegasus_entailment': 0.6400363504886627, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5988372093023255, 'r1_recall': 0.49282296650717705, 'r1_f1': 0.5406824146981627, 'pegasus_entailment': 0.7619868874549866, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5474452554744526, 'r1_recall': 0.4143646408839779, 'r1_f1': 0.4716981132075471, 'pegasus_entailment': 0.5701313143596053, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36666666666666664, 'r1_recall': 0.559322033898305, 'r1_f1': 0.44295302013422816, 'pegasus_entailment': 0.6752041904255748, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7435897435897436, 'r1_recall': 0.35802469135802467, 'r1_f1': 0.4833333333333333, 'pegasus_entailment': 0.1738992885996898, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3951612903225806, 'r1_recall': 0.5975609756097561, 'r1_f1': 0.47572815533980584, 'pegasus_entailment': 0.4716818481683731, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46788990825688076, 'r1_recall': 0.53125, 'r1_f1': 0.4975609756097561, 'pegasus_entailment': 0.6125685513019562, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4634146341463415, 'r1_recall': 0.6195652173913043, 'r1_f1': 0.5302325581395348, 'pegasus_entailment': 0.503111606836319, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6904761904761905, 'r1_recall': 0.29896907216494845, 'r1_f1': 0.41726618705035967, 'pegasus_entailment': 0.6224924027919769, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5228758169934641, 'r1_recall': 0.4819277108433735, 'r1_f1': 0.5015673981191222, 'pegasus_entailment': 0.5370026901364326, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.36771300448430494, 'pegasus_entailment': 0.689915681630373, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.66, 'r1_recall': 0.3815028901734104, 'r1_f1': 0.48351648351648346, 'pegasus_entailment': 0.35417877286672594, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.37037037037037035, 'r1_f1': 0.425531914893617, 'pegasus_entailment': 0.8843394219875336, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48951048951048953, 'r1_recall': 0.4697986577181208, 'r1_f1': 0.4794520547945205, 'pegasus_entailment': 0.5588666588068009, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3873239436619718, 'r1_recall': 0.5913978494623656, 'r1_f1': 0.4680851063829787, 'pegasus_entailment': 0.577768656037127, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6067415730337079, 'r1_recall': 0.33540372670807456, 'r1_f1': 0.432, 'pegasus_entailment': 0.4702848394711812, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1724137931034483, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.24000000000000002, 'pegasus_entailment': 0.33109155483543873, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5564516129032258, 'r1_recall': 0.6388888888888888, 'r1_f1': 0.5948275862068966, 'pegasus_entailment': 0.8446146696805954, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46875, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.5194805194805194, 'pegasus_entailment': 0.6521521757046381, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.515625, 'r1_recall': 0.4049079754601227, 'r1_f1': 0.4536082474226804, 'pegasus_entailment': 0.7303230881690979, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.415929203539823, 'r1_recall': 0.43119266055045874, 'r1_f1': 0.4234234234234234, 'pegasus_entailment': 0.5351912714540958, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.475177304964539, 'r1_recall': 0.3806818181818182, 'r1_f1': 0.4227129337539432, 'pegasus_entailment': 0.3378958112249772, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5256410256410257, 'r1_recall': 0.2733333333333333, 'r1_f1': 0.3596491228070175, 'pegasus_entailment': 0.38880448959146935, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.44508670520231214, 'r1_recall': 0.55, 'r1_f1': 0.49201277955271566, 'pegasus_entailment': 0.6828626564570835, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4594594594594595, 'r1_recall': 0.4563758389261745, 'r1_f1': 0.45791245791245794, 'pegasus_entailment': 0.57964528799057, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3716216216216216, 'r1_recall': 0.6043956043956044, 'r1_f1': 0.4602510460251046, 'pegasus_entailment': 0.7237293362617493, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38461538461538464, 'r1_recall': 0.6493506493506493, 'r1_f1': 0.48309178743961356, 'pegasus_entailment': 0.6809957772493362, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.41904761904761906, 'r1_recall': 0.6027397260273972, 'r1_f1': 0.49438202247191004, 'pegasus_entailment': 0.31243613362312317, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 21, 'pegasus_ari': 36, 'pegasus_smog': 26}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6261682242990654, 'r1_recall': 0.18206521739130435, 'r1_f1': 0.28210526315789475, 'pegasus_entailment': 0.7047715112566948, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43703703703703706, 'r1_recall': 0.5363636363636364, 'r1_f1': 0.4816326530612245, 'pegasus_entailment': 0.6595925252884627, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4369747899159664, 'r1_recall': 0.41935483870967744, 'r1_f1': 0.4279835390946502, 'pegasus_entailment': 0.485667304135859, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4576271186440678, 'r1_recall': 0.675, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.5994711170593897, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7450980392156863, 'r1_recall': 0.4851063829787234, 'r1_f1': 0.5876288659793814, 'pegasus_entailment': 0.6878353238105774, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4695121951219512, 'r1_recall': 0.506578947368421, 'r1_f1': 0.4873417721518987, 'pegasus_entailment': 0.25355737863315475, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44166666666666665, 'r1_recall': 0.6162790697674418, 'r1_f1': 0.5145631067961165, 'pegasus_entailment': 0.7961849719285965, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3898305084745763, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.47668393782383417, 'pegasus_entailment': 0.4612613581120968, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.39166666666666666, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.4476190476190476, 'pegasus_entailment': 0.7934860825538635, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5877192982456141, 'r1_recall': 0.40853658536585363, 'r1_f1': 0.48201438848920863, 'pegasus_entailment': 0.6623623775584357, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8068181818181818, 'r1_recall': 0.24738675958188153, 'r1_f1': 0.3786666666666666, 'pegasus_entailment': 0.3600131571292877, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.746268656716418, 'r1_recall': 0.27932960893854747, 'r1_f1': 0.4065040650406504, 'pegasus_entailment': 0.5106915831565857, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46408839779005523, 'r1_recall': 0.7368421052631579, 'r1_f1': 0.5694915254237288, 'pegasus_entailment': 0.5532552599906921, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3888888888888889, 'r1_recall': 0.1076923076923077, 'r1_f1': 0.16867469879518074, 'pegasus_entailment': 0.8878397941589355, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 12, 'pegasus_smog': 14}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.44881889763779526, 'r1_recall': 0.5480769230769231, 'r1_f1': 0.4935064935064935, 'pegasus_entailment': 0.5506481498479843, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38095238095238093, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.4848484848484849, 'pegasus_entailment': 0.9456979393959045, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7195121951219512, 'r1_recall': 0.36419753086419754, 'r1_f1': 0.4836065573770492, 'pegasus_entailment': 0.5298856943845749, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47572815533980584, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.5444444444444444, 'pegasus_entailment': 0.1477975668385625, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5955882352941176, 'r1_recall': 0.5625, 'r1_f1': 0.5785714285714285, 'pegasus_entailment': 0.6124342978000641, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6615384615384615, 'r1_recall': 0.5733333333333334, 'r1_f1': 0.6142857142857143, 'pegasus_entailment': 0.6401668985684713, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41530054644808745, 'r1_recall': 0.628099173553719, 'r1_f1': 0.5, 'pegasus_entailment': 0.6704418361186981, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7, 'r1_recall': 0.6936936936936937, 'r1_f1': 0.6968325791855203, 'pegasus_entailment': 0.46756625501438975, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6103896103896104, 'r1_recall': 0.2883435582822086, 'r1_f1': 0.39166666666666666, 'pegasus_entailment': 0.2952444441616535, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5625, 'r1_recall': 0.35795454545454547, 'r1_f1': 0.43750000000000006, 'pegasus_entailment': 0.5786575153470039, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5425531914893617, 'r1_recall': 0.6375, 'r1_f1': 0.5862068965517241, 'pegasus_entailment': 0.6644155830144882, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.248, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.33513513513513515, 'pegasus_entailment': 0.566954318434, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33695652173913043, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.40789473684210525, 'pegasus_entailment': 0.5751105348269144, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43137254901960786, 'r1_recall': 0.4489795918367347, 'r1_f1': 0.43999999999999995, 'pegasus_entailment': 0.18999333307147026, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.592, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.580392156862745, 'pegasus_entailment': 0.7095234245061874, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23577235772357724, 'r1_recall': 0.6304347826086957, 'r1_f1': 0.3431952662721894, 'pegasus_entailment': 0.7447598045691848, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48026315789473684, 'r1_recall': 0.6403508771929824, 'r1_f1': 0.548872180451128, 'pegasus_entailment': 0.776798677444458, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5151515151515151, 'r1_recall': 0.6126126126126126, 'r1_f1': 0.5596707818930041, 'pegasus_entailment': 0.4386916854127776, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7062937062937062, 'r1_recall': 0.4611872146118721, 'r1_f1': 0.5580110497237569, 'pegasus_entailment': 0.5671888500452041, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48333333333333334, 'r1_recall': 0.7073170731707317, 'r1_f1': 0.5742574257425742, 'pegasus_entailment': 0.5572447897866368, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39361702127659576, 'r1_recall': 0.42045454545454547, 'r1_f1': 0.40659340659340665, 'pegasus_entailment': 0.692373052239418, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.456, 'r1_recall': 0.5643564356435643, 'r1_f1': 0.504424778761062, 'pegasus_entailment': 0.17935621365904808, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.504424778761062, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.5158371040723982, 'pegasus_entailment': 0.21517833843827247, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19444444444444445, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.2916666666666667, 'pegasus_entailment': 0.11458897916600108, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4732142857142857, 'r1_recall': 0.5353535353535354, 'r1_f1': 0.5023696682464455, 'pegasus_entailment': 0.5017418891191483, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5070422535211268, 'r1_recall': 0.45569620253164556, 'r1_f1': 0.48, 'pegasus_entailment': 0.5070431530475616, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45614035087719296, 'r1_recall': 0.4936708860759494, 'r1_f1': 0.47416413373860183, 'pegasus_entailment': 0.5382806211709976, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6619718309859155, 'r1_recall': 0.24352331606217617, 'r1_f1': 0.3560606060606061, 'pegasus_entailment': 0.42946272529661655, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 18}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7291666666666666, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6965174129353233, 'pegasus_entailment': 0.7926880419254303, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 21, 'pegasus_ari': 33, 'pegasus_smog': 24}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5206611570247934, 'r1_recall': 0.504, 'r1_f1': 0.5121951219512195, 'pegasus_entailment': 0.5965649400438581, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42028985507246375, 'r1_recall': 0.5576923076923077, 'r1_f1': 0.4793388429752066, 'pegasus_entailment': 0.4182561408961192, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29292929292929293, 'r1_recall': 0.47540983606557374, 'r1_f1': 0.3625, 'pegasus_entailment': 0.3458342436157788, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4722222222222222, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.5074626865671641, 'pegasus_entailment': 0.3038710809778422, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23770491803278687, 'r1_recall': 0.4915254237288136, 'r1_f1': 0.32044198895027626, 'pegasus_entailment': 0.4039854362607002, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4953271028037383, 'r1_recall': 0.4649122807017544, 'r1_f1': 0.4796380090497737, 'pegasus_entailment': 0.5044006109237671, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 24}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3619047619047619, 'r1_recall': 0.3838383838383838, 'r1_f1': 0.37254901960784315, 'pegasus_entailment': 0.49799228087067604, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22429906542056074, 'r1_recall': 0.6, 'r1_f1': 0.326530612244898, 'pegasus_entailment': 0.45862102322280407, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42790697674418604, 'r1_recall': 0.5317919075144508, 'r1_f1': 0.47422680412371127, 'pegasus_entailment': 0.4120323657989502, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3783783783783784, 'r1_recall': 0.35, 'r1_f1': 0.36363636363636365, 'pegasus_entailment': 0.39197395741939545, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 17}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5892857142857143, 'r1_recall': 0.3707865168539326, 'r1_f1': 0.45517241379310347, 'pegasus_entailment': 0.5739059065069471, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 21, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6972477064220184, 'r1_recall': 0.4720496894409938, 'r1_f1': 0.5629629629629629, 'pegasus_entailment': 0.19764588524897894, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.3805970149253731, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.1177477256860584, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7160493827160493, 'r1_recall': 0.23868312757201646, 'r1_f1': 0.35802469135802467, 'pegasus_entailment': 0.4794957935810089, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4380952380952381, 'r1_recall': 0.5609756097560976, 'r1_f1': 0.4919786096256685, 'pegasus_entailment': 0.8052410185337067, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 22}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5072463768115942, 'r1_recall': 0.23026315789473684, 'r1_f1': 0.3167420814479638, 'pegasus_entailment': 0.5510073501616717, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23684210526315788, 'r1_recall': 0.5, 'r1_f1': 0.32142857142857145, 'pegasus_entailment': 0.6270971042769296, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5287356321839081, 'r1_recall': 0.2062780269058296, 'r1_f1': 0.2967741935483871, 'pegasus_entailment': 0.7126134485006332, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32894736842105265, 'r1_recall': 0.22123893805309736, 'r1_f1': 0.2645502645502646, 'pegasus_entailment': 0.3731187549419701, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2357142857142857, 'r1_recall': 0.717391304347826, 'r1_f1': 0.3548387096774194, 'pegasus_entailment': 0.9543441087007523, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6434782608695652, 'r1_recall': 0.4088397790055249, 'r1_f1': 0.5, 'pegasus_entailment': 0.21187995250026384, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.3389830508474576, 'r1_f1': 0.4332129963898917, 'pegasus_entailment': 0.3950333041138947, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28078817733990147, 'r1_recall': 0.59375, 'r1_f1': 0.38127090301003347, 'pegasus_entailment': 0.8955531120300293, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6129032258064516, 'r1_recall': 0.5241379310344828, 'r1_f1': 0.5650557620817844, 'pegasus_entailment': 0.8116526703039805, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.14285714285714285, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.23129251700680267, 'pegasus_entailment': 0.26450393348932266, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19594594594594594, 'r1_recall': 0.5, 'r1_f1': 0.2815533980582524, 'pegasus_entailment': 0.628827636440595, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5494505494505495, 'r1_recall': 0.42016806722689076, 'r1_f1': 0.4761904761904762, 'pegasus_entailment': 0.5255946666002274, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3761467889908257, 'r1_recall': 0.5774647887323944, 'r1_f1': 0.45555555555555555, 'pegasus_entailment': 0.86918123960495, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23728813559322035, 'r1_recall': 0.509090909090909, 'r1_f1': 0.3236994219653179, 'pegasus_entailment': 0.5989515036344528, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27884615384615385, 'r1_recall': 0.35802469135802467, 'r1_f1': 0.31351351351351353, 'pegasus_entailment': 0.3789836831856519, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4297520661157025, 'r1_recall': 0.6419753086419753, 'r1_f1': 0.5148514851485149, 'pegasus_entailment': 0.8600623905658722, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40594059405940597, 'r1_recall': 0.4939759036144578, 'r1_f1': 0.44565217391304346, 'pegasus_entailment': 0.2767308389302343, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5040650406504065, 'r1_recall': 0.5585585585585585, 'r1_f1': 0.5299145299145298, 'pegasus_entailment': 0.4020487293601036, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6842105263157895, 'r1_recall': 0.2708333333333333, 'r1_f1': 0.38805970149253727, 'pegasus_entailment': 0.6247775256633759, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6, 'r1_recall': 0.3108108108108108, 'r1_f1': 0.40949554896142426, 'pegasus_entailment': 0.42367191053926945, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36936936936936937, 'r1_recall': 0.5256410256410257, 'r1_f1': 0.4338624338624339, 'pegasus_entailment': 0.7589334189891815, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.575, 'r1_recall': 0.6634615384615384, 'r1_f1': 0.6160714285714285, 'pegasus_entailment': 0.6404471658170223, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2361111111111111, 'r1_recall': 0.4657534246575342, 'r1_f1': 0.3133640552995392, 'pegasus_entailment': 0.44919398687779905, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26126126126126126, 'r1_recall': 0.4461538461538462, 'r1_f1': 0.3295454545454546, 'pegasus_entailment': 0.43605308681726457, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.425531914893617, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.48192771084337355, 'pegasus_entailment': 0.615190714597702, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4864864864864865, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5625, 'pegasus_entailment': 0.5566440778784454, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3783783783783784, 'r1_recall': 0.5526315789473685, 'r1_f1': 0.44919786096256686, 'pegasus_entailment': 0.8852891623973846, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.5468614461521307, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5862068965517241, 'r1_recall': 0.43312101910828027, 'r1_f1': 0.49816849816849823, 'pegasus_entailment': 0.7778378625710806, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6635514018691588, 'r1_recall': 0.4930555555555556, 'r1_f1': 0.5657370517928286, 'pegasus_entailment': 0.5037613213062286, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36054421768707484, 'r1_recall': 0.5638297872340425, 'r1_f1': 0.4398340248962656, 'pegasus_entailment': 0.2841750959632918, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6114649681528662, 'r1_recall': 0.5026178010471204, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.3521799381290163, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3490566037735849, 'r1_recall': 0.7551020408163265, 'r1_f1': 0.4774193548387097, 'pegasus_entailment': 0.7049704948440194, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46534653465346537, 'r1_recall': 0.5662650602409639, 'r1_f1': 0.5108695652173914, 'pegasus_entailment': 0.7626789808273315, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45054945054945056, 'r1_recall': 0.5256410256410257, 'r1_f1': 0.48520710059171596, 'pegasus_entailment': 0.5019234049832448, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4435483870967742, 'r1_recall': 0.6790123456790124, 'r1_f1': 0.5365853658536586, 'pegasus_entailment': 0.47635123282670977, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5811965811965812, 'r1_recall': 0.49635036496350365, 'r1_f1': 0.5354330708661418, 'pegasus_entailment': 0.7871238142251968, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26666666666666666, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.30769230769230765, 'pegasus_entailment': 0.3866307120770216, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25742574257425743, 'r1_recall': 0.4406779661016949, 'r1_f1': 0.32500000000000007, 'pegasus_entailment': 0.712619386613369, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 23, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.4701492537313433, 'r1_f1': 0.5271966527196653, 'pegasus_entailment': 0.6558682322502136, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 17, 'pegasus_ari': 33, 'pegasus_smog': 21}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.4230769230769231, 'r1_f1': 0.4765342960288808, 'pegasus_entailment': 0.4606052227318287, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3779527559055118, 'r1_recall': 0.7384615384615385, 'r1_f1': 0.5, 'pegasus_entailment': 0.6966434828937054, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5194805194805194, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.4848484848484848, 'pegasus_entailment': 0.5747135616838932, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.475, 'r1_recall': 0.4523809523809524, 'r1_f1': 0.46341463414634143, 'pegasus_entailment': 0.7249991099039713, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5070422535211268, 'r1_recall': 0.4675324675324675, 'r1_f1': 0.48648648648648646, 'pegasus_entailment': 0.4068881389684975, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2796610169491525, 'r1_recall': 0.4125, 'r1_f1': 0.33333333333333326, 'pegasus_entailment': 0.6281787923404148, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.564935064935065, 'r1_recall': 0.5576923076923077, 'r1_f1': 0.5612903225806453, 'pegasus_entailment': 0.56850276225143, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4025974025974026, 'r1_recall': 0.40789473684210525, 'r1_f1': 0.40522875816993464, 'pegasus_entailment': 0.25048715248703957, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.381294964028777, 'r1_recall': 0.6235294117647059, 'r1_f1': 0.4732142857142857, 'pegasus_entailment': 0.4727176781743765, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5655737704918032, 'r1_recall': 0.5267175572519084, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.43474692925810815, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3841059602649007, 'r1_recall': 0.5471698113207547, 'r1_f1': 0.45136186770428016, 'pegasus_entailment': 0.7236073732376098, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6296296296296297, 'r1_recall': 0.5573770491803278, 'r1_f1': 0.591304347826087, 'pegasus_entailment': 0.6117092285837445, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4230769230769231, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.4888888888888889, 'pegasus_entailment': 0.6428432166576385, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47619047619047616, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.4545454545454545, 'pegasus_entailment': 0.31691196002066135, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7850467289719626, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.5201238390092878, 'pegasus_entailment': 0.23927418179810048, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48514851485148514, 'r1_recall': 0.48514851485148514, 'r1_f1': 0.48514851485148514, 'pegasus_entailment': 0.24329654399771244, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5483870967741935, 'r1_recall': 0.3469387755102041, 'r1_f1': 0.425, 'pegasus_entailment': 0.10360656911507249, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4155844155844156, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.43537414965986393, 'pegasus_entailment': 0.665198489325121, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.631578947368421, 'r1_f1': 0.6339622641509434, 'pegasus_entailment': 0.5346378795802593, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6428571428571429, 'r1_recall': 0.5, 'r1_f1': 0.5625000000000001, 'pegasus_entailment': 0.3144248326619466, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5371900826446281, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.5508474576271186, 'pegasus_entailment': 0.5611620664596557, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42592592592592593, 'r1_recall': 0.4144144144144144, 'r1_f1': 0.4200913242009132, 'pegasus_entailment': 0.6601887866854668, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6904761904761905, 'r1_recall': 0.42028985507246375, 'r1_f1': 0.5225225225225225, 'pegasus_entailment': 0.9570502638816833, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.21551724137931033, 'r1_recall': 0.5, 'r1_f1': 0.30120481927710846, 'pegasus_entailment': 0.25056929199490696, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43529411764705883, 'r1_recall': 0.6607142857142857, 'r1_f1': 0.5248226950354609, 'pegasus_entailment': 0.48020654916763306, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 25}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.07627118644067797, 'r1_recall': 0.3829787234042553, 'r1_f1': 0.12720848056537104, 'pegasus_entailment': 0.6155631201607841, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3253968253968254, 'r1_recall': 0.5774647887323944, 'r1_f1': 0.41624365482233505, 'pegasus_entailment': 0.9272867143154144, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6375, 'r1_recall': 0.2786885245901639, 'r1_f1': 0.38783269961977185, 'pegasus_entailment': 0.38469995309909183, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.44954128440366975, 'r1_recall': 0.35766423357664234, 'r1_f1': 0.3983739837398374, 'pegasus_entailment': 0.7425954739252726, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4777777777777778, 'r1_recall': 0.4725274725274725, 'r1_f1': 0.47513812154696133, 'pegasus_entailment': 0.7772535234689713, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46629213483146065, 'r1_recall': 0.6240601503759399, 'r1_f1': 0.5337620578778135, 'pegasus_entailment': 0.3943489821006854, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5436241610738255, 'r1_recall': 0.49390243902439024, 'r1_f1': 0.5175718849840256, 'pegasus_entailment': 0.4417526572942734, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7777777777777778, 'r1_recall': 0.38308457711442784, 'r1_f1': 0.5133333333333333, 'pegasus_entailment': 0.6500471830368042, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2956521739130435, 'r1_recall': 0.34, 'r1_f1': 0.3162790697674419, 'pegasus_entailment': 0.376177246371905, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3826086956521739, 'r1_recall': 0.55, 'r1_f1': 0.4512820512820513, 'pegasus_entailment': 0.5134493904188275, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37349397590361444, 'r1_recall': 0.3780487804878049, 'r1_f1': 0.37575757575757573, 'pegasus_entailment': 0.003579447162337601, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 26}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23076923076923078, 'r1_recall': 0.4375, 'r1_f1': 0.3021582733812949, 'pegasus_entailment': 0.2858038867513339, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 13, 'pegasus_ari': 12, 'pegasus_smog': 16}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3063063063063063, 'r1_recall': 0.5396825396825397, 'r1_f1': 0.3908045977011494, 'pegasus_entailment': 0.6931428405456245, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1810344827586207, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.28, 'pegasus_entailment': 0.6097655692137778, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3564356435643564, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.4067796610169491, 'pegasus_entailment': 0.36813971896966297, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6376811594202898, 'r1_recall': 0.2391304347826087, 'r1_f1': 0.3478260869565218, 'pegasus_entailment': 0.6871088941891988, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3392857142857143, 'r1_recall': 0.2835820895522388, 'r1_f1': 0.30894308943089427, 'pegasus_entailment': 0.21125494688749313, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5918367346938775, 'r1_recall': 0.34523809523809523, 'r1_f1': 0.43609022556390975, 'pegasus_entailment': 0.2675054273568094, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5748031496062992, 'r1_recall': 0.553030303030303, 'r1_f1': 0.5637065637065636, 'pegasus_entailment': 0.2904787864536047, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6578947368421053, 'r1_recall': 0.47468354430379744, 'r1_f1': 0.5514705882352942, 'pegasus_entailment': 0.5455460796753565, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6831683168316832, 'r1_recall': 0.23310810810810811, 'r1_f1': 0.34760705289672544, 'pegasus_entailment': 0.6422588229179382, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4794520547945205, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.546875, 'pegasus_entailment': 0.7314231775235385, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6408450704225352, 'r1_recall': 0.4619289340101523, 'r1_f1': 0.536873156342183, 'pegasus_entailment': 0.11720823496580124, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 33, 'pegasus_smog': 23}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3595505617977528, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.42953020134228187, 'pegasus_entailment': 0.5454985598723093, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3954802259887006, 'r1_recall': 0.5691056910569106, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.8493285179138184, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4473684210526316, 'r1_recall': 0.4857142857142857, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.6202397346496582, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6111111111111112, 'r1_recall': 0.4198473282442748, 'r1_f1': 0.497737556561086, 'pegasus_entailment': 0.6164925843477249, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33043478260869563, 'r1_recall': 0.5671641791044776, 'r1_f1': 0.41758241758241754, 'pegasus_entailment': 0.503422985970974, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3404255319148936, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.42384105960264895, 'pegasus_entailment': 0.22722693035999933, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 23, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2422360248447205, 'r1_recall': 0.6842105263157895, 'r1_f1': 0.35779816513761464, 'pegasus_entailment': 0.712080442905426, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5841584158415841, 'r1_recall': 0.4609375, 'r1_f1': 0.5152838427947598, 'pegasus_entailment': 0.32914358377456665, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6197183098591549, 'r1_recall': 0.4943820224719101, 'r1_f1': 0.55, 'pegasus_entailment': 0.6960833444900345, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5785714285714286, 'r1_recall': 0.49693251533742333, 'r1_f1': 0.5346534653465347, 'pegasus_entailment': 0.6110453282793363, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6290322580645161, 'r1_recall': 0.40414507772020725, 'r1_f1': 0.4921135646687697, 'pegasus_entailment': 0.7918730020523072, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40869565217391307, 'r1_recall': 0.46534653465346537, 'r1_f1': 0.4351851851851852, 'pegasus_entailment': 0.834866464138031, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34965034965034963, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.44052863436123346, 'pegasus_entailment': 0.38839084814701763, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28776978417266186, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.3493449781659389, 'pegasus_entailment': 0.5086874453616994, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43037974683544306, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5230769230769231, 'pegasus_entailment': 0.23569690932830176, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6037735849056604, 'r1_recall': 0.43243243243243246, 'r1_f1': 0.5039370078740159, 'pegasus_entailment': 0.30738315135240557, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5370370370370371, 'r1_recall': 0.44274809160305345, 'r1_f1': 0.48535564853556495, 'pegasus_entailment': 0.36607431032462046, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5681818181818182, 'r1_recall': 0.423728813559322, 'r1_f1': 0.4854368932038835, 'pegasus_entailment': 0.8753639310598373, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7307692307692307, 'r1_recall': 0.5846153846153846, 'r1_f1': 0.6495726495726495, 'pegasus_entailment': 0.8557998239994049, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 20, 'pegasus_ari': 34, 'pegasus_smog': 24}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5086206896551724, 'r1_recall': 0.4957983193277311, 'r1_f1': 0.502127659574468, 'pegasus_entailment': 0.3263038681470789, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.43243243243243246, 'pegasus_entailment': 0.08699997887015343, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4927536231884058, 'r1_recall': 0.37777777777777777, 'r1_f1': 0.4276729559748428, 'pegasus_entailment': 0.33858174085617065, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6020408163265306, 'r1_recall': 0.44360902255639095, 'r1_f1': 0.5108225108225107, 'pegasus_entailment': 0.6789278462529182, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5132743362831859, 'r1_recall': 0.27358490566037735, 'r1_f1': 0.35692307692307695, 'pegasus_entailment': 0.7693875233332316, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2564102564102564, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.3448275862068965, 'pegasus_entailment': 0.3032138113464628, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6477272727272727, 'r1_recall': 0.4453125, 'r1_f1': 0.5277777777777778, 'pegasus_entailment': 0.5988938035443425, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2595419847328244, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.36170212765957444, 'pegasus_entailment': 0.5426520794630051, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7321428571428571, 'r1_recall': 0.4293193717277487, 'r1_f1': 0.5412541254125413, 'pegasus_entailment': 0.5431368748346964, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5398230088495575, 'r1_recall': 0.41496598639455784, 'r1_f1': 0.46923076923076923, 'pegasus_entailment': 0.2705789875239134, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4868421052631579, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.48366013071895425, 'pegasus_entailment': 0.8668896913528442, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.37583892617449666, 'r1_recall': 0.7466666666666667, 'r1_f1': 0.5, 'pegasus_entailment': 0.8690317571163177, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5615384615384615, 'r1_recall': 0.6347826086956522, 'r1_f1': 0.5959183673469388, 'pegasus_entailment': 0.5083232820034027, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5916666666666667, 'r1_recall': 0.46405228758169936, 'r1_f1': 0.5201465201465202, 'pegasus_entailment': 0.7152962684631348, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 17, 'pegasus_ari': 36, 'pegasus_smog': 20}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4411764705882353, 'r1_f1': 0.46875, 'pegasus_entailment': 0.28538992744870484, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3563218390804598, 'r1_recall': 0.543859649122807, 'r1_f1': 0.4305555555555556, 'pegasus_entailment': 0.36593693867325783, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4857142857142857, 'r1_recall': 0.53125, 'r1_f1': 0.5074626865671641, 'pegasus_entailment': 0.5445028026588261, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4326923076923077, 'r1_recall': 0.6, 'r1_f1': 0.5027932960893856, 'pegasus_entailment': 0.18412560725118965, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4605263157894737, 'r1_recall': 0.660377358490566, 'r1_f1': 0.5426356589147286, 'pegasus_entailment': 0.8229853808879852, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5632183908045977, 'r1_recall': 0.5268817204301075, 'r1_f1': 0.5444444444444445, 'pegasus_entailment': 0.482737772166729, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.5344827586206896, 'r1_f1': 0.41059602649006616, 'pegasus_entailment': 0.25174007564783096, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8055555555555556, 'r1_recall': 0.5686274509803921, 'r1_f1': 0.6666666666666667, 'pegasus_entailment': 0.6487989127635956, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.55, 'r1_recall': 0.4873417721518987, 'r1_f1': 0.516778523489933, 'pegasus_entailment': 0.6786064008871714, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23776223776223776, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.33999999999999997, 'pegasus_entailment': 0.5239853598177433, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6140350877192983, 'r1_recall': 0.4697986577181208, 'r1_f1': 0.532319391634981, 'pegasus_entailment': 0.6619677742322286, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5975609756097561, 'r1_recall': 0.35766423357664234, 'r1_f1': 0.4474885844748858, 'pegasus_entailment': 0.6101442476113638, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5227272727272727, 'r1_recall': 0.696969696969697, 'r1_f1': 0.5974025974025974, 'pegasus_entailment': 0.33049069593350094, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4491525423728814, 'r1_recall': 0.4774774774774775, 'r1_f1': 0.462882096069869, 'pegasus_entailment': 0.6504695981740951, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38095238095238093, 'r1_recall': 0.6, 'r1_f1': 0.4660194174757281, 'pegasus_entailment': 0.6688690930604935, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4878048780487805, 'r1_recall': 0.31496062992125984, 'r1_f1': 0.3827751196172248, 'pegasus_entailment': 0.605635792016983, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6635514018691588, 'r1_recall': 0.3604060913705584, 'r1_f1': 0.4671052631578947, 'pegasus_entailment': 0.41865632124245167, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6578947368421053, 'r1_recall': 0.30864197530864196, 'r1_f1': 0.42016806722689076, 'pegasus_entailment': 0.3827493451535702, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5971223021582733, 'r1_recall': 0.5971223021582733, 'r1_f1': 0.5971223021582733, 'pegasus_entailment': 0.6072940879190961, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1810344827586207, 'r1_recall': 0.2876712328767123, 'r1_f1': 0.22222222222222218, 'pegasus_entailment': 0.002808688976801932, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2948717948717949, 'r1_recall': 0.3770491803278688, 'r1_f1': 0.3309352517985611, 'pegasus_entailment': 0.13589763144652048, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 11, 'pegasus_ari': 10, 'pegasus_smog': 12}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38345864661654133, 'r1_recall': 0.5930232558139535, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.5011975395027548, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4020618556701031, 'r1_recall': 0.527027027027027, 'r1_f1': 0.45614035087719296, 'pegasus_entailment': 0.21694189112167805, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5524475524475524, 'r1_recall': 0.4540229885057471, 'r1_f1': 0.498422712933754, 'pegasus_entailment': 0.509243827845369, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4868421052631579, 'r1_recall': 0.2569444444444444, 'r1_f1': 0.33636363636363636, 'pegasus_entailment': 0.24163465108722448, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.632, 'r1_recall': 0.40512820512820513, 'r1_f1': 0.49375, 'pegasus_entailment': 0.7862944155931473, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4639175257731959, 'r1_recall': 0.6164383561643836, 'r1_f1': 0.5294117647058824, 'pegasus_entailment': 0.7270911733309428, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5113636363636364, 'r1_recall': 0.6, 'r1_f1': 0.5521472392638037, 'pegasus_entailment': 0.44531241431832314, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47058823529411764, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.5119999999999999, 'pegasus_entailment': 0.7830026894807816, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7176470588235294, 'r1_recall': 0.1622340425531915, 'r1_f1': 0.2646420824295011, 'pegasus_entailment': 0.6967212557792664, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28346456692913385, 'r1_recall': 0.6101694915254238, 'r1_f1': 0.3870967741935483, 'pegasus_entailment': 0.5863045036792756, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5576923076923077, 'r1_recall': 0.34523809523809523, 'r1_f1': 0.42647058823529416, 'pegasus_entailment': 0.6488556116819382, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.4418604651162791, 'r1_f1': 0.46913580246913583, 'pegasus_entailment': 0.5425734147429466, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5842696629213483, 'r1_recall': 0.348993288590604, 'r1_f1': 0.43697478991596633, 'pegasus_entailment': 0.7986474633216858, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 22}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5686274509803921, 'r1_recall': 0.514792899408284, 'r1_f1': 0.5403726708074533, 'pegasus_entailment': 0.6178972318768501, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5179856115107914, 'r1_recall': 0.549618320610687, 'r1_f1': 0.5333333333333334, 'pegasus_entailment': 0.6224713996052742, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4878048780487805, 'r1_recall': 0.3225806451612903, 'r1_f1': 0.3883495145631068, 'pegasus_entailment': 0.544108010828495, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4322033898305085, 'r1_recall': 0.6144578313253012, 'r1_f1': 0.5074626865671641, 'pegasus_entailment': 0.4355950327590108, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2727272727272727, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.3620689655172414, 'pegasus_entailment': 0.43927573785185814, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5212765957446809, 'r1_recall': 0.4224137931034483, 'r1_f1': 0.46666666666666673, 'pegasus_entailment': 0.40116557478904724, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6190476190476191, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.4482758620689656, 'pegasus_entailment': 0.6429335236549377, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.68, 'r1_recall': 0.53125, 'r1_f1': 0.5964912280701754, 'pegasus_entailment': 0.8371017575263977, 'pegasus_flesch_kincaid': 38, 'pegasus_coleman_liau': 18, 'pegasus_ari': 45, 'pegasus_smog': 30}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7027027027027027, 'r1_recall': 0.33766233766233766, 'r1_f1': 0.45614035087719296, 'pegasus_entailment': 0.6270179940121514, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6805555555555556, 'r1_recall': 0.3402777777777778, 'r1_f1': 0.45370370370370366, 'pegasus_entailment': 0.5769786387681961, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.291044776119403, 'r1_recall': 0.6, 'r1_f1': 0.3919597989949749, 'pegasus_entailment': 0.6416426688432694, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20987654320987653, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.3063063063063063, 'pegasus_entailment': 0.5571252048015595, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.359375, 'r1_recall': 0.2839506172839506, 'r1_f1': 0.31724137931034485, 'pegasus_entailment': 0.9903484980265299, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 22, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44660194174757284, 'r1_recall': 0.4423076923076923, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.7712495923042297, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3203125, 'r1_recall': 0.47674418604651164, 'r1_f1': 0.383177570093458, 'pegasus_entailment': 0.8189804553985596, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4972375690607735, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.5341246290801186, 'pegasus_entailment': 0.5022698268294334, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.576, 'r1_recall': 0.43636363636363634, 'r1_f1': 0.496551724137931, 'pegasus_entailment': 0.7126408219337463, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33962264150943394, 'r1_recall': 0.5901639344262295, 'r1_f1': 0.4311377245508982, 'pegasus_entailment': 0.1280921249805639, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5298013245033113, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.53156146179402, 'pegasus_entailment': 0.6571421573559443, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35714285714285715, 'r1_recall': 0.4945054945054945, 'r1_f1': 0.4147465437788018, 'pegasus_entailment': 0.34409371558576823, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5504587155963303, 'r1_recall': 0.4580152671755725, 'r1_f1': 0.5, 'pegasus_entailment': 0.382532333334287, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5089285714285714, 'r1_recall': 0.6263736263736264, 'r1_f1': 0.5615763546798029, 'pegasus_entailment': 0.5788039922714233, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5299145299145299, 'r1_recall': 0.5904761904761905, 'r1_f1': 0.5585585585585586, 'pegasus_entailment': 0.4480772688984871, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4396551724137931, 'r1_recall': 0.6986301369863014, 'r1_f1': 0.5396825396825397, 'pegasus_entailment': 0.46496032923460007, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36538461538461536, 'r1_recall': 0.304, 'r1_f1': 0.3318777292576419, 'pegasus_entailment': 0.5087353454437107, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4647887323943662, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.515625, 'pegasus_entailment': 0.553895252943039, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.41379310344827586, 'r1_recall': 0.5393258426966292, 'r1_f1': 0.4682926829268293, 'pegasus_entailment': 0.3988733470439911, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2818181818181818, 'r1_recall': 0.7209302325581395, 'r1_f1': 0.40522875816993464, 'pegasus_entailment': 0.45947661623358727, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6866666666666666, 'r1_recall': 0.4660633484162896, 'r1_f1': 0.555256064690027, 'pegasus_entailment': 0.455425711614745, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6509433962264151, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6301369863013699, 'pegasus_entailment': 0.9620340764522552, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 22}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29213483146067415, 'r1_recall': 0.7027027027027027, 'r1_f1': 0.4126984126984127, 'pegasus_entailment': 0.5063235660394033, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3188405797101449, 'r1_recall': 0.5365853658536586, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.5452102601528168, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 13}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37423312883435583, 'r1_recall': 0.5700934579439252, 'r1_f1': 0.4518518518518518, 'pegasus_entailment': 0.6300334384044012, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3202614379084967, 'r1_recall': 0.6805555555555556, 'r1_f1': 0.43555555555555553, 'pegasus_entailment': 0.5788802603880564, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3877551020408163, 'r1_recall': 0.4318181818181818, 'r1_f1': 0.4086021505376344, 'pegasus_entailment': 0.9048068722089132, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.42696629213483145, 'r1_f1': 0.5205479452054794, 'pegasus_entailment': 0.4836004674434662, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3014705882352941, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.4205128205128205, 'pegasus_entailment': 0.36199762317119166, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6190476190476191, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.48148148148148145, 'pegasus_entailment': 0.47472940882047016, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.55, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.5, 'pegasus_entailment': 0.8423315087954203, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4236111111111111, 'r1_recall': 0.648936170212766, 'r1_f1': 0.5126050420168068, 'pegasus_entailment': 0.7120996475219726, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.916030534351145, 'r1_recall': 0.22988505747126436, 'r1_f1': 0.3675344563552833, 'pegasus_entailment': 0.6340669755424772, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6423841059602649, 'r1_recall': 0.485, 'r1_f1': 0.5527065527065527, 'pegasus_entailment': 0.5015932034168925, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3106796116504854, 'r1_recall': 0.41025641025641024, 'r1_f1': 0.3535911602209944, 'pegasus_entailment': 0.10466119647026062, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6341463414634146, 'r1_recall': 0.49523809523809526, 'r1_f1': 0.5561497326203207, 'pegasus_entailment': 0.5754261016845703, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.5, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.41244319304823873, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38613861386138615, 'r1_recall': 0.6902654867256637, 'r1_f1': 0.49523809523809526, 'pegasus_entailment': 0.8384492248296738, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 34, 'pegasus_smog': 25}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4948453608247423, 'r1_recall': 0.5647058823529412, 'r1_f1': 0.5274725274725275, 'pegasus_entailment': 0.28618573894103366, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43209876543209874, 'r1_recall': 0.5303030303030303, 'r1_f1': 0.4761904761904762, 'pegasus_entailment': 0.48499984480440617, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 22, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5238095238095238, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.5, 'pegasus_entailment': 0.4468916406234105, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41333333333333333, 'r1_recall': 0.37349397590361444, 'r1_f1': 0.3924050632911392, 'pegasus_entailment': 0.3297278508543968, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7692307692307693, 'r1_recall': 0.3968253968253968, 'r1_f1': 0.5235602094240838, 'pegasus_entailment': 0.752319723367691, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5588235294117647, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.5588235294117647, 'pegasus_entailment': 0.4529508911073208, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5138121546961326, 'r1_recall': 0.577639751552795, 'r1_f1': 0.543859649122807, 'pegasus_entailment': 0.5365153231791088, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.4076433121019108, 'pegasus_entailment': 0.9824907332658768, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7163120567375887, 'r1_recall': 0.4469026548672566, 'r1_f1': 0.5504087193460491, 'pegasus_entailment': 0.4232473528633515, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.25396825396825395, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.3440860215053763, 'pegasus_entailment': 0.10384100954979658, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5391304347826087, 'r1_recall': 0.6138613861386139, 'r1_f1': 0.5740740740740741, 'pegasus_entailment': 0.617369718849659, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2589928057553957, 'r1_recall': 0.7346938775510204, 'r1_f1': 0.3829787234042553, 'pegasus_entailment': 0.4046226553618908, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.22123893805309736, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.3144654088050315, 'pegasus_entailment': 0.5525568403303623, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5954198473282443, 'r1_recall': 0.5342465753424658, 'r1_f1': 0.5631768953068592, 'pegasus_entailment': 0.8968883752822876, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5668789808917197, 'r1_recall': 0.4635416666666667, 'r1_f1': 0.510028653295129, 'pegasus_entailment': 0.653382882475853, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41509433962264153, 'r1_recall': 0.2972972972972973, 'r1_f1': 0.3464566929133859, 'pegasus_entailment': 0.7124414145946503, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4470588235294118, 'r1_recall': 0.3838383838383838, 'r1_f1': 0.4130434782608695, 'pegasus_entailment': 0.29509086068719625, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47, 'r1_recall': 0.5662650602409639, 'r1_f1': 0.5136612021857923, 'pegasus_entailment': 0.30115858018398284, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3888888888888889, 'r1_recall': 0.6901408450704225, 'r1_f1': 0.49746192893401014, 'pegasus_entailment': 0.3903261336187522, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5272727272727272, 'r1_recall': 0.5043478260869565, 'r1_f1': 0.5155555555555555, 'pegasus_entailment': 0.33550648515423137, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5981308411214953, 'r1_recall': 0.38095238095238093, 'r1_f1': 0.4654545454545454, 'pegasus_entailment': 0.4510543942451477, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24509803921568626, 'r1_recall': 0.4716981132075472, 'r1_f1': 0.3225806451612903, 'pegasus_entailment': 0.3823559229495004, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6056338028169014, 'r1_recall': 0.39814814814814814, 'r1_f1': 0.4804469273743017, 'pegasus_entailment': 0.5565374245246252, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.616822429906542, 'r1_recall': 0.584070796460177, 'r1_f1': 0.6000000000000001, 'pegasus_entailment': 0.7904253154993057, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4065934065934066, 'r1_recall': 0.5211267605633803, 'r1_f1': 0.45679012345679015, 'pegasus_entailment': 0.5382085293531418, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5370370370370371, 'r1_recall': 0.3972602739726027, 'r1_f1': 0.4566929133858268, 'pegasus_entailment': 0.5039723794907331, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.16666666666666666, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.2442748091603053, 'pegasus_entailment': 0.7618318125605583, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.484375, 'r1_recall': 0.7469879518072289, 'r1_f1': 0.5876777251184835, 'pegasus_entailment': 0.5491658300161362, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24509803921568626, 'r1_recall': 0.5102040816326531, 'r1_f1': 0.3311258278145695, 'pegasus_entailment': 0.37585719923178357, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6964285714285714, 'r1_recall': 0.4588235294117647, 'r1_f1': 0.5531914893617021, 'pegasus_entailment': 0.851566880941391, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7029702970297029, 'r1_recall': 0.5503875968992248, 'r1_f1': 0.6173913043478262, 'pegasus_entailment': 0.7885714570681254, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4247787610619469, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.48, 'pegasus_entailment': 0.7379960894584656, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5161290322580645, 'r1_recall': 0.48120300751879697, 'r1_f1': 0.4980544747081712, 'pegasus_entailment': 0.812883049249649, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5084745762711864, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.5240174672489083, 'pegasus_entailment': 0.3098113551735878, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.49504950495049505, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.5076142131979695, 'pegasus_entailment': 0.2909077728788058, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.5571428571428572, 'r1_f1': 0.6070038910505836, 'pegasus_entailment': 0.5498151313513517, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40131578947368424, 'r1_recall': 0.4236111111111111, 'r1_f1': 0.41216216216216217, 'pegasus_entailment': 0.6965013146400452, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.33695652173913043, 'r1_f1': 0.4025974025974026, 'pegasus_entailment': 0.7652113735675812, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5540540540540541, 'r1_recall': 0.39805825242718446, 'r1_f1': 0.4632768361581921, 'pegasus_entailment': 0.2741798684000969, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33653846153846156, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.4093567251461988, 'pegasus_entailment': 0.36780557843546074, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47368421052631576, 'r1_recall': 0.5934065934065934, 'r1_f1': 0.5268292682926828, 'pegasus_entailment': 0.91678287088871, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5185185185185186, 'pegasus_entailment': 0.7451376616954803, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6222222222222222, 'r1_recall': 0.45901639344262296, 'r1_f1': 0.5283018867924528, 'pegasus_entailment': 0.5114264264702797, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5877192982456141, 'r1_recall': 0.4036144578313253, 'r1_f1': 0.4785714285714286, 'pegasus_entailment': 0.4982694983482361, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49333333333333335, 'r1_recall': 0.6727272727272727, 'r1_f1': 0.5692307692307692, 'pegasus_entailment': 0.19399202056229115, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4368932038834951, 'r1_recall': 0.6081081081081081, 'r1_f1': 0.5084745762711864, 'pegasus_entailment': 0.5375480502843857, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6272189349112426, 'r1_recall': 0.5196078431372549, 'r1_f1': 0.5683646112600537, 'pegasus_entailment': 0.880976402759552, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.2958672471344471, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.550561797752809, 'r1_recall': 0.4049586776859504, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.40148257308950025, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6384615384615384, 'r1_recall': 0.5804195804195804, 'r1_f1': 0.6080586080586081, 'pegasus_entailment': 0.23527948341021934, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40707964601769914, 'r1_recall': 0.5287356321839081, 'r1_f1': 0.4600000000000001, 'pegasus_entailment': 0.7563952393829823, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.34210526315789475, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.4626334519572954, 'pegasus_entailment': 0.8166858553886414, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4166666666666667, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.48780487804878053, 'pegasus_entailment': 0.40517624219258624, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.56, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.16859595477581024, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48717948717948717, 'r1_recall': 0.3838383838383838, 'r1_f1': 0.4293785310734463, 'pegasus_entailment': 0.39586299657821655, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36363636363636365, 'r1_recall': 0.4044943820224719, 'r1_f1': 0.3829787234042553, 'pegasus_entailment': 0.5684722438454628, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.4601226993865031, 'r1_f1': 0.5208333333333334, 'pegasus_entailment': 0.4219630179660661, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5765765765765766, 'r1_recall': 0.3516483516483517, 'r1_f1': 0.4368600682593857, 'pegasus_entailment': 0.5218934714794159, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6509433962264151, 'r1_recall': 0.2509090909090909, 'r1_f1': 0.3622047244094488, 'pegasus_entailment': 0.17052941117435694, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5392156862745098, 'r1_recall': 0.5045871559633027, 'r1_f1': 0.5213270142180094, 'pegasus_entailment': 0.5669700503349304, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18691588785046728, 'r1_recall': 0.3448275862068966, 'r1_f1': 0.24242424242424243, 'pegasus_entailment': 0.5561590590514243, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.26519337016574585, 'r1_f1': 0.367816091954023, 'pegasus_entailment': 0.5246260911226273, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22566371681415928, 'r1_recall': 0.6623376623376623, 'r1_f1': 0.33663366336633666, 'pegasus_entailment': 0.48526134424739414, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.35714285714285715, 'r1_recall': 0.6875, 'r1_f1': 0.4700854700854701, 'pegasus_entailment': 0.534579174593091, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5894736842105263, 'r1_recall': 0.6021505376344086, 'r1_f1': 0.5957446808510638, 'pegasus_entailment': 0.8105862319469452, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.408, 'r1_recall': 0.6296296296296297, 'r1_f1': 0.49514563106796117, 'pegasus_entailment': 0.40632144520059227, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2727272727272727, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.3442622950819672, 'pegasus_entailment': 0.3060409836471081, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2857142857142857, 'r1_recall': 0.5507246376811594, 'r1_f1': 0.37623762376237624, 'pegasus_entailment': 0.6213514979928731, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4766355140186916, 'r1_recall': 0.53125, 'r1_f1': 0.5024630541871922, 'pegasus_entailment': 0.546993114054203, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29365079365079366, 'r1_recall': 0.578125, 'r1_f1': 0.3894736842105263, 'pegasus_entailment': 0.5377764612436294, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36551724137931035, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.4491525423728814, 'pegasus_entailment': 0.7073058784008026, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35135135135135137, 'r1_recall': 0.5909090909090909, 'r1_f1': 0.4406779661016949, 'pegasus_entailment': 0.5720545394080025, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38524590163934425, 'r1_recall': 0.7580645161290323, 'r1_f1': 0.5108695652173914, 'pegasus_entailment': 0.6629846400581301, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27346938775510204, 'r1_recall': 0.6261682242990654, 'r1_f1': 0.38068181818181823, 'pegasus_entailment': 0.5404697738587856, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39080459770114945, 'r1_recall': 0.5396825396825397, 'r1_f1': 0.4533333333333333, 'pegasus_entailment': 0.32564527541399, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6724137931034483, 'r1_recall': 0.44150943396226416, 'r1_f1': 0.5330296127562643, 'pegasus_entailment': 0.4931558022896449, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3611111111111111, 'r1_recall': 0.609375, 'r1_f1': 0.45348837209302323, 'pegasus_entailment': 0.4511070449370891, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44086021505376344, 'r1_recall': 0.44565217391304346, 'r1_f1': 0.4432432432432432, 'pegasus_entailment': 0.48342615067958833, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5833333333333334, 'r1_recall': 0.49, 'r1_f1': 0.532608695652174, 'pegasus_entailment': 0.5629258155822754, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49019607843137253, 'r1_recall': 0.35714285714285715, 'r1_f1': 0.4132231404958677, 'pegasus_entailment': 0.5390736442059278, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5974025974025974, 'r1_recall': 0.48936170212765956, 'r1_f1': 0.5380116959064328, 'pegasus_entailment': 0.35910879299044607, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46540880503144655, 'r1_recall': 0.5826771653543307, 'r1_f1': 0.5174825174825175, 'pegasus_entailment': 0.5447708779829554, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3125, 'r1_recall': 0.5633802816901409, 'r1_f1': 0.4020100502512563, 'pegasus_entailment': 0.930869460105896, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46956521739130436, 'r1_recall': 0.574468085106383, 'r1_f1': 0.5167464114832536, 'pegasus_entailment': 0.31779349986463784, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40625, 'r1_recall': 0.4642857142857143, 'r1_f1': 0.4333333333333333, 'pegasus_entailment': 0.6798059148713946, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38613861386138615, 'r1_recall': 0.527027027027027, 'r1_f1': 0.44571428571428573, 'pegasus_entailment': 0.3453181395307183, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43478260869565216, 'r1_recall': 0.29850746268656714, 'r1_f1': 0.35398230088495575, 'pegasus_entailment': 0.6713614761829376, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34579439252336447, 'r1_recall': 0.578125, 'r1_f1': 0.43274853801169594, 'pegasus_entailment': 0.4938108205795288, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4556213017751479, 'r1_recall': 0.44508670520231214, 'r1_f1': 0.4502923976608187, 'pegasus_entailment': 0.7556751668453217, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6074766355140186, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.47794117647058826, 'pegasus_entailment': 0.44774083197116854, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5394736842105263, 'r1_recall': 0.41836734693877553, 'r1_f1': 0.471264367816092, 'pegasus_entailment': 0.9154935598373413, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4055299539170507, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.43564356435643564, 'pegasus_entailment': 0.43134811396400136, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5303030303030303, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.4347826086956521, 'pegasus_entailment': 0.1857348136836663, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4065934065934066, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.4539877300613497, 'pegasus_entailment': 0.5106549546122551, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1782178217821782, 'r1_recall': 0.32727272727272727, 'r1_f1': 0.23076923076923075, 'pegasus_entailment': 0.6091945394873619, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19801980198019803, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.2797202797202797, 'pegasus_entailment': 0.44672188628464937, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3953488372093023, 'r1_recall': 0.4788732394366197, 'r1_f1': 0.43312101910828027, 'pegasus_entailment': 0.6293026904265085, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29245283018867924, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.3924050632911393, 'pegasus_entailment': 0.3618337884545326, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3680555555555556, 'r1_recall': 0.452991452991453, 'r1_f1': 0.40613026819923376, 'pegasus_entailment': 0.4915002251509577, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6633663366336634, 'r1_recall': 0.5114503816793893, 'r1_f1': 0.5775862068965517, 'pegasus_entailment': 0.5077106013894082, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4606741573033708, 'r1_recall': 0.4880952380952381, 'r1_f1': 0.47398843930635837, 'pegasus_entailment': 0.8679467737674713, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5212765957446809, 'r1_recall': 0.2722222222222222, 'r1_f1': 0.3576642335766423, 'pegasus_entailment': 0.5578264832496643, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3125, 'r1_recall': 0.6593406593406593, 'r1_f1': 0.4240282685512367, 'pegasus_entailment': 0.34755926579236984, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.33532934131736525, 'r1_recall': 0.509090909090909, 'r1_f1': 0.4043321299638989, 'pegasus_entailment': 0.6084096804261208, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3609022556390977, 'r1_recall': 0.5217391304347826, 'r1_f1': 0.42666666666666664, 'pegasus_entailment': 0.5313996771971384, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2621951219512195, 'r1_recall': 0.43, 'r1_f1': 0.3257575757575758, 'pegasus_entailment': 0.5714825640122095, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.308411214953271, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.37499999999999994, 'pegasus_entailment': 0.8831396102905273, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 18, 'pegasus_ari': 34, 'pegasus_smog': 24}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46835443037974683, 'r1_recall': 0.42528735632183906, 'r1_f1': 0.4457831325301205, 'pegasus_entailment': 0.6483666738495231, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5185185185185185, 'r1_recall': 0.5490196078431373, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.5923212934285402, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2904761904761905, 'r1_recall': 0.7261904761904762, 'r1_f1': 0.4149659863945579, 'pegasus_entailment': 0.6053175528844198, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20987654320987653, 'r1_recall': 0.6538461538461539, 'r1_f1': 0.31775700934579443, 'pegasus_entailment': 0.6151959504932165, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5307692307692308, 'r1_recall': 0.4825174825174825, 'r1_f1': 0.5054945054945056, 'pegasus_entailment': 0.6582466550171375, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4375, 'r1_recall': 0.5632183908045977, 'r1_f1': 0.492462311557789, 'pegasus_entailment': 0.30583605617284776, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4492753623188406, 'r1_recall': 0.5740740740740741, 'r1_f1': 0.5040650406504064, 'pegasus_entailment': 0.6288177020226916, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46308724832214765, 'r1_recall': 0.5702479338842975, 'r1_f1': 0.5111111111111111, 'pegasus_entailment': 0.49817947298288345, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4024390243902439, 'r1_recall': 0.3173076923076923, 'r1_f1': 0.3548387096774194, 'pegasus_entailment': 0.31730947401374576, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.4776119402985075, 'pegasus_entailment': 0.5245779156684875, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3275862068965517, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.40425531914893614, 'pegasus_entailment': 0.8849328756332397, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5154639175257731, 'r1_recall': 0.5617977528089888, 'r1_f1': 0.5376344086021505, 'pegasus_entailment': 0.273670163936913, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.15126050420168066, 'r1_recall': 0.4, 'r1_f1': 0.2195121951219512, 'pegasus_entailment': 0.5188833732778827, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4846153846153846, 'r1_recall': 0.6116504854368932, 'r1_f1': 0.5407725321888412, 'pegasus_entailment': 0.5611127585172653, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.11224489795918367, 'r1_recall': 0.3142857142857143, 'r1_f1': 0.16541353383458646, 'pegasus_entailment': 0.3538768794387579, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.37333333333333335, 'r1_recall': 0.6222222222222222, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.30590831325389445, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.22137404580152673, 'r1_recall': 0.7435897435897436, 'r1_f1': 0.3411764705882353, 'pegasus_entailment': 0.7269619941711426, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4161849710982659, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.44859813084112155, 'pegasus_entailment': 0.3020217094038214, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5520833333333334, 'r1_recall': 0.4608695652173913, 'r1_f1': 0.5023696682464455, 'pegasus_entailment': 0.9518148899078369, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.37349397590361444, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.47328244274809167, 'pegasus_entailment': 0.4574371464550495, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44, 'r1_recall': 0.6055045871559633, 'r1_f1': 0.5096525096525096, 'pegasus_entailment': 0.46616795446191517, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49230769230769234, 'r1_recall': 0.463768115942029, 'r1_f1': 0.47761194029850745, 'pegasus_entailment': 0.4364282488822937, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.872093023255814, 'r1_recall': 0.21306818181818182, 'r1_f1': 0.3424657534246575, 'pegasus_entailment': 0.5768330409191549, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4594594594594595, 'r1_f1': 0.47887323943661975, 'pegasus_entailment': 0.710747230052948, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41739130434782606, 'r1_recall': 0.3221476510067114, 'r1_f1': 0.3636363636363636, 'pegasus_entailment': 0.6980856895446778, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 22, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7692307692307693, 'r1_recall': 0.33557046979865773, 'r1_f1': 0.4672897196261682, 'pegasus_entailment': 0.7706096768379211, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1694915254237288, 'r1_recall': 0.6122448979591837, 'r1_f1': 0.2654867256637168, 'pegasus_entailment': 0.6167119592428207, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 16, 'pegasus_ari': 28, 'pegasus_smog': 19}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4098360655737705, 'r1_recall': 0.6944444444444444, 'r1_f1': 0.5154639175257733, 'pegasus_entailment': 0.49586227536201477, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.34615384615384615, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.4265402843601896, 'pegasus_entailment': 0.4284016951918602, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7087378640776699, 'r1_recall': 0.4866666666666667, 'r1_f1': 0.5770750988142292, 'pegasus_entailment': 0.3297549734512965, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.20422535211267606, 'r1_recall': 0.43283582089552236, 'r1_f1': 0.27751196172248804, 'pegasus_entailment': 0.9677087324006217, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6283783783783784, 'r1_recall': 0.5406976744186046, 'r1_f1': 0.58125, 'pegasus_entailment': 0.6961405754089356, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4108527131782946, 'r1_recall': 0.7162162162162162, 'r1_f1': 0.522167487684729, 'pegasus_entailment': 0.7278061032295227, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37398373983739835, 'r1_recall': 0.5679012345679012, 'r1_f1': 0.45098039215686275, 'pegasus_entailment': 0.5806121349334716, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46788990825688076, 'r1_recall': 0.3617021276595745, 'r1_f1': 0.40800000000000003, 'pegasus_entailment': 0.5722023546695709, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3532110091743119, 'r1_recall': 0.5877862595419847, 'r1_f1': 0.4412607449856733, 'pegasus_entailment': 0.6080492053713117, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6201550387596899, 'r1_recall': 0.3755868544600939, 'r1_f1': 0.4678362573099415, 'pegasus_entailment': 0.36353057995438576, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5571428571428572, 'r1_recall': 0.43333333333333335, 'r1_f1': 0.4875, 'pegasus_entailment': 0.9574130177497864, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4383561643835616, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.49230769230769234, 'pegasus_entailment': 0.4347357327739398, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.31746031746031744, 'r1_f1': 0.43010752688172044, 'pegasus_entailment': 0.573101669549942, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6346153846153846, 'r1_recall': 0.3256578947368421, 'r1_f1': 0.43043478260869567, 'pegasus_entailment': 0.6101715080440044, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3157894736842105, 'r1_recall': 0.38095238095238093, 'r1_f1': 0.34532374100719426, 'pegasus_entailment': 0.4849691241979599, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.425531914893617, 'r1_recall': 0.631578947368421, 'r1_f1': 0.5084745762711865, 'pegasus_entailment': 0.5544402420520782, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.5569620253164557, 'r1_f1': 0.564102564102564, 'pegasus_entailment': 0.6308579295873642, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.359375, 'r1_recall': 0.39655172413793105, 'r1_f1': 0.3770491803278689, 'pegasus_entailment': 0.5839318633079529, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6071428571428571, 'r1_recall': 0.4696132596685083, 'r1_f1': 0.5295950155763239, 'pegasus_entailment': 0.4508640706539154, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5405405405405406, 'r1_recall': 0.28169014084507044, 'r1_f1': 0.37037037037037035, 'pegasus_entailment': 0.9222656091054281, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4, 'r1_recall': 0.4, 'r1_f1': 0.4000000000000001, 'pegasus_entailment': 0.3035786197520792, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5871559633027523, 'r1_recall': 0.37209302325581395, 'r1_f1': 0.4555160142348755, 'pegasus_entailment': 0.6581119149923325, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4810126582278481, 'r1_recall': 0.5352112676056338, 'r1_f1': 0.5066666666666666, 'pegasus_entailment': 0.45923240259289744, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.696, 'r1_recall': 0.4182692307692308, 'r1_f1': 0.5225225225225225, 'pegasus_entailment': 0.6933180928230286, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39325842696629215, 'r1_recall': 0.3763440860215054, 'r1_f1': 0.38461538461538464, 'pegasus_entailment': 0.6757038235664368, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2709677419354839, 'r1_recall': 0.56, 'r1_f1': 0.3652173913043478, 'pegasus_entailment': 0.6905631065368653, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3769230769230769, 'r1_recall': 0.6901408450704225, 'r1_f1': 0.4875621890547263, 'pegasus_entailment': 0.5668604344129562, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.569620253164557, 'r1_recall': 0.44554455445544555, 'r1_f1': 0.5, 'pegasus_entailment': 0.3716442833344142, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7368421052631579, 'r1_recall': 0.4057971014492754, 'r1_f1': 0.5233644859813084, 'pegasus_entailment': 0.6208369731903076, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4339622641509434, 'r1_recall': 0.45098039215686275, 'r1_f1': 0.4423076923076923, 'pegasus_entailment': 0.7211384296417236, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29411764705882354, 'r1_recall': 0.5, 'r1_f1': 0.37037037037037035, 'pegasus_entailment': 0.3564862171187997, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6826923076923077, 'r1_recall': 0.398876404494382, 'r1_f1': 0.5035460992907802, 'pegasus_entailment': 0.7748512923717499, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.375, 'r1_recall': 0.6575342465753424, 'r1_f1': 0.47761194029850745, 'pegasus_entailment': 0.5249224901199341, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43103448275862066, 'r1_recall': 0.6578947368421053, 'r1_f1': 0.5208333333333334, 'pegasus_entailment': 0.35838659703731535, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2905405405405405, 'r1_recall': 0.4725274725274725, 'r1_f1': 0.3598326359832636, 'pegasus_entailment': 0.562924205015103, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.6, 'r1_f1': 0.6075949367088608, 'pegasus_entailment': 0.7190227769315243, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7582417582417582, 'r1_recall': 0.09787234042553192, 'r1_f1': 0.17336683417085427, 'pegasus_entailment': 0.8651510179042816, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5625, 'r1_recall': 0.5704225352112676, 'r1_f1': 0.5664335664335666, 'pegasus_entailment': 0.6151691873868307, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7582417582417582, 'r1_recall': 0.3770491803278688, 'r1_f1': 0.5036496350364964, 'pegasus_entailment': 0.36252453178167343, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42990654205607476, 'r1_recall': 0.4946236559139785, 'r1_f1': 0.45999999999999996, 'pegasus_entailment': 0.300208592414856, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6020408163265306, 'r1_recall': 0.5086206896551724, 'r1_f1': 0.5514018691588785, 'pegasus_entailment': 0.6325386269949377, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.410958904109589, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.6341108456254005, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4370860927152318, 'r1_recall': 0.42038216560509556, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.44502071402966975, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.16901408450704225, 'r1_recall': 0.5, 'r1_f1': 0.25263157894736843, 'pegasus_entailment': 0.6629133075475693, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4519230769230769, 'r1_recall': 0.4845360824742268, 'r1_f1': 0.46766169154228854, 'pegasus_entailment': 0.9833232462406158, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 21, 'pegasus_ari': 35, 'pegasus_smog': 27}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18095238095238095, 'r1_recall': 0.5428571428571428, 'r1_f1': 0.2714285714285714, 'pegasus_entailment': 0.5110729851294309, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6129032258064516, 'r1_recall': 0.5876288659793815, 'r1_f1': 0.6, 'pegasus_entailment': 0.5715239215642214, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4357142857142857, 'r1_recall': 0.5398230088495575, 'r1_f1': 0.48221343873517786, 'pegasus_entailment': 0.6321286675520241, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.56, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.5384615384615384, 'pegasus_entailment': 0.523535019531846, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1901840490797546, 'r1_recall': 0.5740740740740741, 'r1_f1': 0.28571428571428575, 'pegasus_entailment': 0.5619571581482887, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5294117647058824, 'r1_recall': 0.36, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.6510004971253996, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 12, 'pegasus_smog': 14}
** Analysing column: malformed_chain



malformed_chain
Length after nones removed
616
MIN
0
MEAN
0
MAX
1
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.07627118644067797
MEAN
0.47257168190287435
MAX
0.916030534351145
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.09787234042553192
MEAN
0.49503420273827936
MAX
0.855072463768116
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.12720848056537104
MEAN
0.45860469375956603
MAX
0.6968325791855203
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.002808688976801932
MEAN
0.5492142083866678
MAX
0.9904266893863678
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
17
MAX
38
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
11
MEAN
17
MAX
23
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
10
MEAN
21
MAX
45
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
12
MEAN
18
MAX
30
{}
Entered file!
Imports done!
*** RUN *** 
eval_1d2
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 14:37:07.697160: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 14:37:08.243053: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/1d2_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4084507042253521, 'r1_recall': 0.5272727272727272, 'r1_f1': 0.46031746031746035, 'pegasus_entailment': 0.7724915146827698, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6593406593406593, 'r1_recall': 0.3468208092485549, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.6576289087533951, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.4724409448818897, 'pegasus_entailment': 0.5390811171382666, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7349397590361446, 'r1_recall': 0.4728682170542636, 'r1_f1': 0.5754716981132076, 'pegasus_entailment': 0.4870912486997743, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7029702970297029, 'r1_recall': 0.40804597701149425, 'r1_f1': 0.5163636363636364, 'pegasus_entailment': 0.4424409940838814, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4178082191780822, 'r1_recall': 0.46923076923076923, 'r1_f1': 0.4420289855072464, 'pegasus_entailment': 0.3408838614821434, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16666666666666666, 'r1_recall': 0.375, 'r1_f1': 0.23076923076923078, 'pegasus_entailment': 0.28631126740947366, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22772277227722773, 'r1_recall': 0.7419354838709677, 'r1_f1': 0.3484848484848485, 'pegasus_entailment': 0.5533858048729599, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7415730337078652, 'r1_recall': 0.4429530201342282, 'r1_f1': 0.5546218487394958, 'pegasus_entailment': 0.47559825237840414, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6428571428571429, 'r1_recall': 0.5869565217391305, 'r1_f1': 0.6136363636363638, 'pegasus_entailment': 0.6252761855721474, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7027027027027027, 'r1_recall': 0.3466666666666667, 'r1_f1': 0.46428571428571436, 'pegasus_entailment': 0.516546007245779, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5892857142857143, 'r1_recall': 0.5546218487394958, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.889235277970632, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7887323943661971, 'r1_recall': 0.5233644859813084, 'r1_f1': 0.6292134831460674, 'pegasus_entailment': 0.7453572247177362, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5873015873015873, 'r1_recall': 0.42045454545454547, 'r1_f1': 0.4900662251655629, 'pegasus_entailment': 0.7580639521280924, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8701298701298701, 'r1_recall': 0.3489583333333333, 'r1_f1': 0.4981412639405205, 'pegasus_entailment': 0.655083179473877, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21052631578947367, 'r1_recall': 0.2033898305084746, 'r1_f1': 0.20689655172413796, 'pegasus_entailment': 0.6182583371798197, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4722222222222222, 'r1_recall': 0.3434343434343434, 'r1_f1': 0.39766081871345027, 'pegasus_entailment': 0.6825147171815237, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7951807228915663, 'r1_recall': 0.2214765100671141, 'r1_f1': 0.3464566929133859, 'pegasus_entailment': 0.38432972878217697, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6639344262295082, 'r1_recall': 0.5031055900621118, 'r1_f1': 0.5724381625441696, 'pegasus_entailment': 0.42666998878121376, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5494505494505495, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.5617977528089888, 'pegasus_entailment': 0.5804827511310577, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6194690265486725, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.47457627118644063, 'pegasus_entailment': 0.4292094074189663, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5693430656934306, 'r1_recall': 0.52, 'r1_f1': 0.5435540069686411, 'pegasus_entailment': 0.6179236595829328, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3963963963963964, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.4018264840182648, 'pegasus_entailment': 0.69203253587087, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 26}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6810344827586207, 'r1_recall': 0.5808823529411765, 'r1_f1': 0.626984126984127, 'pegasus_entailment': 0.5345117092132569, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3723404255319149, 'r1_recall': 0.7, 'r1_f1': 0.48611111111111105, 'pegasus_entailment': 0.6895427651082476, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6201117318435754, 'r1_recall': 0.5873015873015873, 'r1_f1': 0.6032608695652174, 'pegasus_entailment': 0.482532124966383, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5811965811965812, 'r1_recall': 0.49635036496350365, 'r1_f1': 0.5354330708661418, 'pegasus_entailment': 0.5321875838562846, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8620689655172413, 'r1_recall': 0.2798507462686567, 'r1_f1': 0.4225352112676056, 'pegasus_entailment': 0.6074931671222051, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42592592592592593, 'r1_recall': 0.3026315789473684, 'r1_f1': 0.3538461538461538, 'pegasus_entailment': 0.8554395437240601, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 12, 'pegasus_ari': 12, 'pegasus_smog': 11}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40404040404040403, 'r1_recall': 0.35398230088495575, 'r1_f1': 0.3773584905660377, 'pegasus_entailment': 0.5586630403995514, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 15, 'pegasus_ari': 30, 'pegasus_smog': 19}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4818181818181818, 'r1_recall': 0.6091954022988506, 'r1_f1': 0.5380710659898478, 'pegasus_entailment': 0.7331172972917557, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5688073394495413, 'r1_recall': 0.30845771144278605, 'r1_f1': 0.4, 'pegasus_entailment': 0.5389385223388672, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2708333333333333, 'r1_recall': 0.3786407766990291, 'r1_f1': 0.3157894736842105, 'pegasus_entailment': 0.6817261576652527, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6268656716417911, 'r1_recall': 0.4329896907216495, 'r1_f1': 0.5121951219512195, 'pegasus_entailment': 0.4571133553981781, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42016806722689076, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.49261083743842365, 'pegasus_entailment': 0.24310313016176224, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44, 'r1_recall': 0.5689655172413793, 'r1_f1': 0.49624060150375937, 'pegasus_entailment': 0.5995419124762217, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 16, 'pegasus_ari': 31, 'pegasus_smog': 22}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4824561403508772, 'r1_recall': 0.7971014492753623, 'r1_f1': 0.6010928961748634, 'pegasus_entailment': 0.3558418992906809, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3392857142857143, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.4222222222222223, 'pegasus_entailment': 0.7086844330769964, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2158273381294964, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.32608695652173914, 'pegasus_entailment': 0.5585499167442322, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5027027027027027, 'r1_recall': 0.5602409638554217, 'r1_f1': 0.5299145299145298, 'pegasus_entailment': 0.5907276675105095, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7029702970297029, 'r1_recall': 0.44375, 'r1_f1': 0.5440613026819924, 'pegasus_entailment': 0.6363784652203321, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5967741935483871, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.5323741007194245, 'pegasus_entailment': 0.6368355502684911, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5733333333333334, 'r1_recall': 0.589041095890411, 'r1_f1': 0.5810810810810811, 'pegasus_entailment': 0.4572935209920009, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8, 'r1_recall': 0.5203252032520326, 'r1_f1': 0.6305418719211824, 'pegasus_entailment': 0.8583741585413615, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3684210526315789, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.4046242774566474, 'pegasus_entailment': 0.6639065742492676, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4692737430167598, 'r1_recall': 0.56, 'r1_f1': 0.5106382978723405, 'pegasus_entailment': 0.47598588466644287, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.61, 'r1_recall': 0.5169491525423728, 'r1_f1': 0.5596330275229358, 'pegasus_entailment': 0.5543049506377429, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.7027027027027027, 'r1_f1': 0.5098039215686274, 'pegasus_entailment': 0.7242395494665418, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3708609271523179, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.47659574468085103, 'pegasus_entailment': 0.554472331268092, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3983739837398374, 'r1_recall': 0.47115384615384615, 'r1_f1': 0.4317180616740089, 'pegasus_entailment': 0.49961447566747663, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3082706766917293, 'r1_recall': 0.5540540540540541, 'r1_f1': 0.3961352657004831, 'pegasus_entailment': 0.5740776658058167, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24427480916030533, 'r1_recall': 0.6274509803921569, 'r1_f1': 0.3516483516483516, 'pegasus_entailment': 0.6189645236978928, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35537190082644626, 'r1_recall': 0.581081081081081, 'r1_f1': 0.441025641025641, 'pegasus_entailment': 0.4952914547175169, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.3107344632768362, 'r1_f1': 0.4119850187265918, 'pegasus_entailment': 0.2732164611419042, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6642857142857143, 'r1_recall': 0.5224719101123596, 'r1_f1': 0.5849056603773586, 'pegasus_entailment': 0.3126731589436531, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42727272727272725, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.5164835164835165, 'pegasus_entailment': 0.5515370219945908, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6196319018404908, 'r1_recall': 0.40239043824701193, 'r1_f1': 0.48792270531400955, 'pegasus_entailment': 0.5853856280446053, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39090909090909093, 'r1_recall': 0.671875, 'r1_f1': 0.4942528735632184, 'pegasus_entailment': 0.5879095159471035, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.6115702479338843, 'r1_f1': 0.6379310344827586, 'pegasus_entailment': 0.44853512570261955, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5918367346938775, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.30873304853836697, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42391304347826086, 'r1_recall': 0.4431818181818182, 'r1_f1': 0.4333333333333333, 'pegasus_entailment': 0.8287956515947977, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4358974358974359, 'r1_recall': 0.4722222222222222, 'r1_f1': 0.45333333333333337, 'pegasus_entailment': 0.3628084361553192, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5268817204301075, 'r1_recall': 0.2916666666666667, 'r1_f1': 0.3754789272030651, 'pegasus_entailment': 0.6636510118842125, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3894736842105263, 'r1_recall': 0.38144329896907214, 'r1_f1': 0.38541666666666663, 'pegasus_entailment': 0.6726335237423579, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30526315789473685, 'r1_recall': 0.6041666666666666, 'r1_f1': 0.4055944055944056, 'pegasus_entailment': 0.26413025458653766, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7254901960784313, 'r1_recall': 0.5826771653543307, 'r1_f1': 0.6462882096069869, 'pegasus_entailment': 0.5024576857686043, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31794871794871793, 'r1_recall': 0.5849056603773585, 'r1_f1': 0.4119601328903654, 'pegasus_entailment': 0.9247671961784363, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 24}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4097222222222222, 'r1_recall': 0.6145833333333334, 'r1_f1': 0.49166666666666664, 'pegasus_entailment': 0.3526182036846876, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6082474226804123, 'r1_recall': 0.5130434782608696, 'r1_f1': 0.5566037735849056, 'pegasus_entailment': 0.2738933617947623, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7230769230769231, 'r1_recall': 0.46078431372549017, 'r1_f1': 0.562874251497006, 'pegasus_entailment': 0.6452730645736059, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4327485380116959, 'r1_recall': 0.4457831325301205, 'r1_f1': 0.4391691394658754, 'pegasus_entailment': 0.6009947001934052, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2971014492753623, 'r1_recall': 0.6029411764705882, 'r1_f1': 0.3980582524271844, 'pegasus_entailment': 0.4221682965755463, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2972972972972973, 'r1_recall': 0.5, 'r1_f1': 0.3728813559322034, 'pegasus_entailment': 0.2889961926266551, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6638655462184874, 'r1_recall': 0.41578947368421054, 'r1_f1': 0.511326860841424, 'pegasus_entailment': 0.6325911656022072, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25280898876404495, 'r1_recall': 0.625, 'r1_f1': 0.36, 'pegasus_entailment': 0.24065336678177118, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.379746835443038, 'r1_recall': 0.7058823529411765, 'r1_f1': 0.49382716049382724, 'pegasus_entailment': 0.3533804578972714, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29357798165137616, 'r1_recall': 0.5, 'r1_f1': 0.36994219653179194, 'pegasus_entailment': 0.9561551511287689, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5818181818181818, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5981308411214953, 'pegasus_entailment': 0.49981139476100606, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5181818181818182, 'r1_recall': 0.6627906976744186, 'r1_f1': 0.5816326530612245, 'pegasus_entailment': 0.5459788478910923, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5223880597014925, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.5223880597014925, 'pegasus_entailment': 0.8432019501924515, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5180722891566265, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.5341614906832298, 'pegasus_entailment': 0.29760339111089706, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.71, 'r1_recall': 0.6893203883495146, 'r1_f1': 0.6995073891625615, 'pegasus_entailment': 0.3805353989203771, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.43243243243243246, 'pegasus_entailment': 0.44439053535461426, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.527027027027027, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.48447204968944096, 'pegasus_entailment': 0.9556332528591156, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5309734513274337, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.5853658536585366, 'pegasus_entailment': 0.4753687207897504, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3619047619047619, 'r1_recall': 0.4367816091954023, 'r1_f1': 0.39583333333333337, 'pegasus_entailment': 0.7331586927175522, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2716049382716049, 'r1_recall': 0.28205128205128205, 'r1_f1': 0.27672955974842767, 'pegasus_entailment': 0.42119892438252765, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2719298245614035, 'r1_recall': 0.6888888888888889, 'r1_f1': 0.389937106918239, 'pegasus_entailment': 0.8661567717790604, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7634408602150538, 'r1_recall': 0.34134615384615385, 'r1_f1': 0.4717607973421926, 'pegasus_entailment': 0.4846502721309662, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47191011235955055, 'r1_recall': 0.6, 'r1_f1': 0.5283018867924529, 'pegasus_entailment': 0.22750169615028426, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.5729166666666666, 'r1_f1': 0.5641025641025641, 'pegasus_entailment': 0.8042283654212952, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 33, 'pegasus_smog': 27}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425, 'r1_recall': 0.3805970149253731, 'r1_f1': 0.4015748031496063, 'pegasus_entailment': 0.42347376700490713, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 13}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.31343283582089554, 'r1_recall': 0.5753424657534246, 'r1_f1': 0.4057971014492754, 'pegasus_entailment': 0.4569806487299502, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5094339622641509, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.484304932735426, 'pegasus_entailment': 0.44477460446069017, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.15463917525773196, 'r1_f1': 0.2307692307692308, 'pegasus_entailment': 0.9775312542915344, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4424778761061947, 'r1_recall': 0.5649717514124294, 'r1_f1': 0.4962779156327544, 'pegasus_entailment': 0.6841746978461742, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47572815533980584, 'r1_recall': 0.5051546391752577, 'r1_f1': 0.49, 'pegasus_entailment': 0.4672451963027318, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5306122448979592, 'r1_recall': 0.4126984126984127, 'r1_f1': 0.4642857142857143, 'pegasus_entailment': 0.7804876963297526, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3490566037735849, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.4327485380116959, 'pegasus_entailment': 0.6252047084271908, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3867924528301887, 'r1_recall': 0.36607142857142855, 'r1_f1': 0.37614678899082565, 'pegasus_entailment': 0.5853602214095494, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37681159420289856, 'r1_recall': 0.4262295081967213, 'r1_f1': 0.4, 'pegasus_entailment': 0.22727882644782463, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4639175257731959, 'r1_recall': 0.4787234042553192, 'r1_f1': 0.47120418848167545, 'pegasus_entailment': 0.7710384353995323, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5233644859813084, 'r1_recall': 0.48695652173913045, 'r1_f1': 0.5045045045045046, 'pegasus_entailment': 0.8629238605499268, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.547945205479452, 'r1_recall': 0.35714285714285715, 'r1_f1': 0.4324324324324324, 'pegasus_entailment': 0.7307569682598114, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3505747126436782, 'r1_recall': 0.7625, 'r1_f1': 0.4803149606299212, 'pegasus_entailment': 0.6758878976106644, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6710526315789473, 'r1_recall': 0.3953488372093023, 'r1_f1': 0.49756097560975604, 'pegasus_entailment': 0.44810023307800295, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49166666666666664, 'r1_recall': 0.5728155339805825, 'r1_f1': 0.5291479820627802, 'pegasus_entailment': 0.7231589108705521, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6979166666666666, 'r1_recall': 0.41875, 'r1_f1': 0.5234375, 'pegasus_entailment': 0.45678095519542694, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3790322580645161, 'r1_recall': 0.6266666666666667, 'r1_f1': 0.4723618090452261, 'pegasus_entailment': 0.6298145682667382, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34375, 'r1_recall': 0.55, 'r1_f1': 0.42307692307692313, 'pegasus_entailment': 0.6714966495831808, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.6040268456375839, 'pegasus_entailment': 0.927316352725029, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6020408163265306, 'r1_recall': 0.44360902255639095, 'r1_f1': 0.5108225108225107, 'pegasus_entailment': 0.22826587967574596, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7213114754098361, 'r1_recall': 0.5569620253164557, 'r1_f1': 0.6285714285714286, 'pegasus_entailment': 0.4885687637142837, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46956521739130436, 'r1_recall': 0.6067415730337079, 'r1_f1': 0.5294117647058824, 'pegasus_entailment': 0.6052300110459328, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.46923076923076923, 'r1_f1': 0.48412698412698413, 'pegasus_entailment': 0.6423696019919589, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851851851851851, 'r1_recall': 0.4438202247191011, 'r1_f1': 0.5047923322683706, 'pegasus_entailment': 0.6357724666595459, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7575757575757576, 'r1_recall': 0.42613636363636365, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.7660873532295227, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 19, 'pegasus_ari': 33, 'pegasus_smog': 23}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5841584158415841, 'r1_recall': 0.44029850746268656, 'r1_f1': 0.502127659574468, 'pegasus_entailment': 0.4436695694923401, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5092592592592593, 'r1_recall': 0.5851063829787234, 'r1_f1': 0.5445544554455446, 'pegasus_entailment': 0.5841448467690498, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6923076923076923, 'r1_recall': 0.3543307086614173, 'r1_f1': 0.46874999999999994, 'pegasus_entailment': 0.8002045949300131, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4766355140186916, 'r1_recall': 0.5795454545454546, 'r1_f1': 0.5230769230769231, 'pegasus_entailment': 0.7382049262523651, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5365853658536586, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.5546218487394958, 'pegasus_entailment': 0.7433254917462667, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 19}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39814814814814814, 'r1_recall': 0.5657894736842105, 'r1_f1': 0.46739130434782605, 'pegasus_entailment': 0.6243456929922104, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23232323232323232, 'r1_recall': 0.5348837209302325, 'r1_f1': 0.32394366197183094, 'pegasus_entailment': 0.45122377946972847, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7555555555555555, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.6732673267326731, 'pegasus_entailment': 0.9478484193483988, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5419847328244275, 'r1_recall': 0.5419847328244275, 'r1_f1': 0.5419847328244275, 'pegasus_entailment': 0.4712727442383766, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26, 'r1_recall': 0.65, 'r1_f1': 0.37142857142857144, 'pegasus_entailment': 0.47108266362920403, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.552, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.5702479338842975, 'pegasus_entailment': 0.9169735511144003, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 15, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5035460992907801, 'r1_recall': 0.6120689655172413, 'r1_f1': 0.5525291828793774, 'pegasus_entailment': 0.5796971842646599, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5256410256410257, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.5985401459854015, 'pegasus_entailment': 0.5310210337241491, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6834532374100719, 'r1_recall': 0.5026455026455027, 'r1_f1': 0.5792682926829269, 'pegasus_entailment': 0.1277024628361687, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.5950413223140496, 'r1_f1': 0.5255474452554746, 'pegasus_entailment': 0.9823962251345316, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 25}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.578125, 'r1_recall': 0.4774193548387097, 'r1_f1': 0.5229681978798586, 'pegasus_entailment': 0.8744952082633972, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6583333333333333, 'r1_recall': 0.48466257668711654, 'r1_f1': 0.5583038869257951, 'pegasus_entailment': 0.6053387373685837, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.475, 'r1_recall': 0.5643564356435643, 'r1_f1': 0.5158371040723981, 'pegasus_entailment': 0.5533628523349762, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4198895027624309, 'r1_recall': 0.628099173553719, 'r1_f1': 0.5033112582781457, 'pegasus_entailment': 0.7204168289899826, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5510204081632653, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.5654450261780105, 'pegasus_entailment': 0.6203324645757675, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6530612244897959, 'r1_recall': 0.48120300751879697, 'r1_f1': 0.5541125541125541, 'pegasus_entailment': 0.7693269610404968, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7019230769230769, 'r1_recall': 0.3945945945945946, 'r1_f1': 0.5051903114186851, 'pegasus_entailment': 0.6054031848907471, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3644859813084112, 'r1_recall': 0.6724137931034483, 'r1_f1': 0.4727272727272727, 'pegasus_entailment': 0.5255739882588386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39473684210526316, 'r1_recall': 0.5113636363636364, 'r1_f1': 0.44554455445544555, 'pegasus_entailment': 0.46424571610987186, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4782608695652174, 'r1_recall': 0.4731182795698925, 'r1_f1': 0.4756756756756757, 'pegasus_entailment': 0.3810370812813441, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.53, 'r1_recall': 0.4690265486725664, 'r1_f1': 0.4976525821596244, 'pegasus_entailment': 0.7582129836082458, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5098039215686274, 'r1_recall': 0.65, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.6757595837116241, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5333333333333333, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.5436893203883496, 'pegasus_entailment': 0.5713955760002136, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6201550387596899, 'r1_recall': 0.3827751196172249, 'r1_f1': 0.47337278106508873, 'pegasus_entailment': 0.6067440658807755, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.660377358490566, 'r1_recall': 0.3867403314917127, 'r1_f1': 0.48780487804878053, 'pegasus_entailment': 0.44900578757127124, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3717948717948718, 'r1_recall': 0.4915254237288136, 'r1_f1': 0.4233576642335766, 'pegasus_entailment': 0.813797652721405, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7981651376146789, 'r1_recall': 0.5370370370370371, 'r1_f1': 0.6420664206642067, 'pegasus_entailment': 0.4584514629095793, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3923076923076923, 'r1_recall': 0.6219512195121951, 'r1_f1': 0.48113207547169806, 'pegasus_entailment': 0.37593673914670944, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43037974683544306, 'r1_recall': 0.3541666666666667, 'r1_f1': 0.3885714285714286, 'pegasus_entailment': 0.5583342090249062, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44881889763779526, 'r1_recall': 0.6195652173913043, 'r1_f1': 0.5205479452054794, 'pegasus_entailment': 0.4178726593963802, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7766990291262136, 'r1_recall': 0.41237113402061853, 'r1_f1': 0.5387205387205387, 'pegasus_entailment': 0.45479800179600716, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5370370370370371, 'r1_recall': 0.3493975903614458, 'r1_f1': 0.4233576642335767, 'pegasus_entailment': 0.41829054057598114, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33064516129032256, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.44808743169398907, 'pegasus_entailment': 0.7514328161875407, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6271186440677966, 'r1_recall': 0.4277456647398844, 'r1_f1': 0.5085910652920962, 'pegasus_entailment': 0.4022599846124649, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4626865671641791, 'r1_recall': 0.38271604938271603, 'r1_f1': 0.41891891891891897, 'pegasus_entailment': 0.6580566229919592, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5034965034965035, 'r1_recall': 0.48322147651006714, 'r1_f1': 0.49315068493150693, 'pegasus_entailment': 0.8055967092514038, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5747126436781609, 'r1_recall': 0.5376344086021505, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.27868172415765, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.33540372670807456, 'r1_f1': 0.4202334630350195, 'pegasus_entailment': 0.2320029828697443, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21739130434782608, 'r1_recall': 0.2631578947368421, 'r1_f1': 0.23809523809523808, 'pegasus_entailment': 0.9635570049285889, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 24, 'pegasus_ari': 35, 'pegasus_smog': 28}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5728155339805825, 'r1_recall': 0.5462962962962963, 'r1_f1': 0.5592417061611374, 'pegasus_entailment': 0.7289799526333809, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37572254335260113, 'r1_recall': 0.6310679611650486, 'r1_f1': 0.47101449275362317, 'pegasus_entailment': 0.869426429271698, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.654320987654321, 'r1_recall': 0.32515337423312884, 'r1_f1': 0.43442622950819676, 'pegasus_entailment': 0.6885570958256721, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5742574257425742, 'r1_recall': 0.5321100917431193, 'r1_f1': 0.5523809523809524, 'pegasus_entailment': 0.5509080678224564, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48863636363636365, 'r1_recall': 0.48863636363636365, 'r1_f1': 0.48863636363636365, 'pegasus_entailment': 0.4277232617139816, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43010752688172044, 'r1_recall': 0.26666666666666666, 'r1_f1': 0.3292181069958848, 'pegasus_entailment': 0.8380877176920573, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5089820359281437, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.5537459283387622, 'pegasus_entailment': 0.5460172792275747, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5080645161290323, 'r1_recall': 0.4228187919463087, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.6134821996092796, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48598130841121495, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5252525252525252, 'pegasus_entailment': 0.5923701326052347, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3805970149253731, 'r1_recall': 0.6623376623376623, 'r1_f1': 0.4834123222748815, 'pegasus_entailment': 0.5072733014822006, 'pegasus_flesch_kincaid': 33, 'pegasus_coleman_liau': 19, 'pegasus_ari': 41, 'pegasus_smog': 25}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39166666666666666, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.48704663212435234, 'pegasus_entailment': 0.620512424968183, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6896551724137931, 'r1_recall': 0.16304347826086957, 'r1_f1': 0.26373626373626374, 'pegasus_entailment': 0.5534291565418243, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.4909090909090909, 'r1_f1': 0.5167464114832535, 'pegasus_entailment': 0.6389245775838693, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5402298850574713, 'r1_recall': 0.3790322580645161, 'r1_f1': 0.44549763033175355, 'pegasus_entailment': 0.6536457240581512, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47468354430379744, 'r1_recall': 0.625, 'r1_f1': 0.539568345323741, 'pegasus_entailment': 0.5750852167606354, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7865168539325843, 'r1_recall': 0.2978723404255319, 'r1_f1': 0.4320987654320988, 'pegasus_entailment': 0.6572804339230061, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5100671140939598, 'r1_recall': 0.5, 'r1_f1': 0.5049833887043189, 'pegasus_entailment': 0.27998129092156887, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3089887640449438, 'r1_recall': 0.6395348837209303, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.528675944233934, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34408602150537637, 'r1_recall': 0.4266666666666667, 'r1_f1': 0.38095238095238104, 'pegasus_entailment': 0.6376828327775002, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41904761904761906, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.4512820512820513, 'pegasus_entailment': 0.9024880528450012, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6708860759493671, 'r1_recall': 0.3231707317073171, 'r1_f1': 0.43621399176954734, 'pegasus_entailment': 0.7083357274532318, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7829457364341085, 'r1_recall': 0.3519163763066202, 'r1_f1': 0.4855769230769231, 'pegasus_entailment': 0.41632277199200224, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6847826086956522, 'r1_recall': 0.35195530726256985, 'r1_f1': 0.46494464944649444, 'pegasus_entailment': 0.49718244187533855, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5752212389380531, 'r1_recall': 0.5701754385964912, 'r1_f1': 0.5726872246696035, 'pegasus_entailment': 0.6546744108200073, 'pegasus_flesch_kincaid': 52, 'pegasus_coleman_liau': 19, 'pegasus_ari': 64, 'pegasus_smog': 34}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6707317073170732, 'r1_recall': 0.4230769230769231, 'r1_f1': 0.5188679245283019, 'pegasus_entailment': 0.6752978463967642, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4661016949152542, 'r1_recall': 0.5288461538461539, 'r1_f1': 0.4954954954954955, 'pegasus_entailment': 0.3866795152425766, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3221476510067114, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.41201716738197425, 'pegasus_entailment': 0.9566343665122986, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6759259259259259, 'r1_recall': 0.4506172839506173, 'r1_f1': 0.5407407407407409, 'pegasus_entailment': 0.7148935596148173, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5897435897435898, 'r1_recall': 0.5974025974025974, 'r1_f1': 0.5935483870967742, 'pegasus_entailment': 0.4566979742376134, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.552, 'pegasus_entailment': 0.42761924816295505, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6133333333333333, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.6133333333333333, 'pegasus_entailment': 0.4594133794307709, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5688073394495413, 'r1_recall': 0.512396694214876, 'r1_f1': 0.5391304347826087, 'pegasus_entailment': 0.7448178589344024, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8082191780821918, 'r1_recall': 0.5315315315315315, 'r1_f1': 0.641304347826087, 'pegasus_entailment': 0.5455225699891647, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851063829787234, 'r1_recall': 0.3374233128834356, 'r1_f1': 0.42801556420233466, 'pegasus_entailment': 0.18151729305585226, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5779816513761468, 'r1_recall': 0.35795454545454547, 'r1_f1': 0.4421052631578947, 'pegasus_entailment': 0.3454425409436226, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5588235294117647, 'r1_recall': 0.7125, 'r1_f1': 0.6263736263736264, 'pegasus_entailment': 0.7891814609368643, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2636363636363636, 'r1_recall': 0.48333333333333334, 'r1_f1': 0.34117647058823525, 'pegasus_entailment': 0.6165966217716535, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 26}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4375, 'pegasus_entailment': 0.4352775923907757, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4426229508196721, 'r1_recall': 0.5510204081632653, 'r1_f1': 0.49090909090909085, 'pegasus_entailment': 0.33541417121887207, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5531914893617021, 'r1_recall': 0.6, 'r1_f1': 0.5756457564575646, 'pegasus_entailment': 0.617013406008482, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3047619047619048, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.42384105960264906, 'pegasus_entailment': 0.9890740911165873, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.675, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.5567010309278351, 'pegasus_entailment': 0.8306477467219034, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4672131147540984, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.4892703862660944, 'pegasus_entailment': 0.5148066524416208, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6938775510204082, 'r1_recall': 0.4657534246575342, 'r1_f1': 0.5573770491803278, 'pegasus_entailment': 0.4899275004863739, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.611764705882353, 'r1_recall': 0.6341463414634146, 'r1_f1': 0.6227544910179641, 'pegasus_entailment': 0.6797349055608114, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4621212121212121, 'r1_recall': 0.6931818181818182, 'r1_f1': 0.5545454545454546, 'pegasus_entailment': 0.7526635527610779, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5446428571428571, 'r1_recall': 0.6039603960396039, 'r1_f1': 0.5727699530516431, 'pegasus_entailment': 0.17453824058175088, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.472, 'r1_recall': 0.5462962962962963, 'r1_f1': 0.5064377682403434, 'pegasus_entailment': 0.2525451338539521, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2840909090909091, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.36764705882352944, 'pegasus_entailment': 0.27770412736572325, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5280898876404494, 'r1_recall': 0.47474747474747475, 'r1_f1': 0.5, 'pegasus_entailment': 0.584257165590922, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.56, 'r1_recall': 0.35443037974683544, 'r1_f1': 0.434108527131783, 'pegasus_entailment': 0.47310803333918255, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5140845070422535, 'r1_recall': 0.4620253164556962, 'r1_f1': 0.4866666666666667, 'pegasus_entailment': 0.48535676300525665, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5680473372781065, 'r1_recall': 0.49740932642487046, 'r1_f1': 0.5303867403314917, 'pegasus_entailment': 0.31199143330256146, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6885245901639344, 'r1_recall': 0.4, 'r1_f1': 0.5060240963855422, 'pegasus_entailment': 0.6027634143829346, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45569620253164556, 'r1_recall': 0.576, 'r1_f1': 0.5088339222614842, 'pegasus_entailment': 0.6013013064861298, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3409090909090909, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.3208227555733174, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3153153153153153, 'r1_recall': 0.5737704918032787, 'r1_f1': 0.40697674418604646, 'pegasus_entailment': 0.2494944843929261, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4657534246575342, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.5037037037037037, 'pegasus_entailment': 0.9451161424318949, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2702702702702703, 'r1_recall': 0.5084745762711864, 'r1_f1': 0.3529411764705882, 'pegasus_entailment': 0.2992536723613739, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4358974358974359, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.44155844155844154, 'pegasus_entailment': 0.3517903983592987, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4431818181818182, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.41711229946524064, 'pegasus_entailment': 0.6101228147745132, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2815533980582524, 'r1_recall': 0.725, 'r1_f1': 0.40559440559440557, 'pegasus_entailment': 0.6760659019152323, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4371584699453552, 'r1_recall': 0.4624277456647399, 'r1_f1': 0.44943820224719094, 'pegasus_entailment': 0.5536630700031916, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 25}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4351851851851852, 'r1_recall': 0.5875, 'r1_f1': 0.5, 'pegasus_entailment': 0.5107136726379394, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6224489795918368, 'r1_recall': 0.34269662921348315, 'r1_f1': 0.44202898550724645, 'pegasus_entailment': 0.5645067654550076, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7228915662650602, 'r1_recall': 0.37267080745341613, 'r1_f1': 0.49180327868852464, 'pegasus_entailment': 0.28952719643712044, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6076923076923076, 'r1_recall': 0.5895522388059702, 'r1_f1': 0.5984848484848485, 'pegasus_entailment': 0.20588585610191026, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 31, 'pegasus_smog': 26}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6875, 'r1_recall': 0.22633744855967078, 'r1_f1': 0.3405572755417957, 'pegasus_entailment': 0.5585938592751821, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4326923076923077, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.4838709677419355, 'pegasus_entailment': 0.6324315816164017, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 16, 'pegasus_ari': 31, 'pegasus_smog': 20}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49523809523809526, 'r1_recall': 0.34210526315789475, 'r1_f1': 0.4046692607003891, 'pegasus_entailment': 0.48075965978205204, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3211009174311927, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.3867403314917127, 'pegasus_entailment': 0.666877289613088, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5877862595419847, 'r1_recall': 0.3452914798206278, 'r1_f1': 0.4350282485875706, 'pegasus_entailment': 0.5783930346369743, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35714285714285715, 'r1_recall': 0.30973451327433627, 'r1_f1': 0.33175355450236965, 'pegasus_entailment': 0.316874402264754, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3402061855670103, 'r1_recall': 0.717391304347826, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.40247253281995654, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7555555555555555, 'r1_recall': 0.3756906077348066, 'r1_f1': 0.5018450184501846, 'pegasus_entailment': 0.330894747748971, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.686046511627907, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.4486692015209125, 'pegasus_entailment': 0.3104033973067999, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4236111111111111, 'r1_recall': 0.6354166666666666, 'r1_f1': 0.5083333333333334, 'pegasus_entailment': 0.6399297515551249, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6176470588235294, 'r1_recall': 0.43448275862068964, 'r1_f1': 0.5101214574898786, 'pegasus_entailment': 0.8030675768852233, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1450381679389313, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.23899371069182387, 'pegasus_entailment': 0.17203863114118575, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19310344827586207, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.27586206896551724, 'pegasus_entailment': 0.6303148925304413, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.68, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.6210045662100457, 'pegasus_entailment': 0.39496460537581396, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30952380952380953, 'r1_recall': 0.5492957746478874, 'r1_f1': 0.39593908629441626, 'pegasus_entailment': 0.3894849956035614, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.248, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.34444444444444444, 'pegasus_entailment': 0.7146193504333496, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3617021276595745, 'r1_recall': 0.41975308641975306, 'r1_f1': 0.38857142857142857, 'pegasus_entailment': 0.3070040214806795, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.611764705882353, 'r1_recall': 0.6419753086419753, 'r1_f1': 0.6265060240963856, 'pegasus_entailment': 0.8770049413045248, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5063291139240507, 'r1_recall': 0.4819277108433735, 'r1_f1': 0.49382716049382713, 'pegasus_entailment': 0.259297750541009, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5652173913043478, 'r1_recall': 0.46846846846846846, 'r1_f1': 0.5123152709359605, 'pegasus_entailment': 0.3363981540314853, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7961165048543689, 'r1_recall': 0.24404761904761904, 'r1_f1': 0.3735763097949886, 'pegasus_entailment': 0.5112008690834046, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.3108108108108108, 'r1_f1': 0.4207317073170732, 'pegasus_entailment': 0.4609153997153044, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47674418604651164, 'r1_recall': 0.5256410256410257, 'r1_f1': 0.5, 'pegasus_entailment': 0.5324264243245125, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5523809523809524, 'r1_recall': 0.5576923076923077, 'r1_f1': 0.5550239234449761, 'pegasus_entailment': 0.43314006303747493, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21965317919075145, 'r1_recall': 0.5205479452054794, 'r1_f1': 0.30894308943089427, 'pegasus_entailment': 0.5216895192861557, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3228346456692913, 'r1_recall': 0.6307692307692307, 'r1_f1': 0.4270833333333333, 'pegasus_entailment': 0.2945159201820691, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5921052631578947, 'r1_recall': 0.625, 'r1_f1': 0.6081081081081081, 'pegasus_entailment': 0.5674796203772227, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5487804878048781, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.5521472392638037, 'pegasus_entailment': 0.8695265799760818, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4375, 'r1_recall': 0.5526315789473685, 'r1_f1': 0.4883720930232558, 'pegasus_entailment': 0.8834349115689596, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42718446601941745, 'r1_recall': 0.5238095238095238, 'r1_f1': 0.4705882352941177, 'pegasus_entailment': 0.2228782958118245, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7254901960784313, 'r1_recall': 0.4713375796178344, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.7784717231988907, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6886792452830188, 'r1_recall': 0.5069444444444444, 'r1_f1': 0.584, 'pegasus_entailment': 0.5282692015171051, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3411764705882353, 'r1_recall': 0.30851063829787234, 'r1_f1': 0.32402234636871513, 'pegasus_entailment': 0.6005418747663498, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6483516483516484, 'r1_recall': 0.6178010471204188, 'r1_f1': 0.6327077747989276, 'pegasus_entailment': 0.4432292928298314, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3465346534653465, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.9816618164380392, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4492753623188406, 'r1_recall': 0.37349397590361444, 'r1_f1': 0.40789473684210525, 'pegasus_entailment': 0.9005027562379837, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7166666666666667, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.6231884057971016, 'pegasus_entailment': 0.6865303814411163, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 8}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44696969696969696, 'r1_recall': 0.7283950617283951, 'r1_f1': 0.5539906103286385, 'pegasus_entailment': 0.4352083284407854, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5310344827586206, 'r1_recall': 0.5620437956204379, 'r1_f1': 0.5460992907801417, 'pegasus_entailment': 0.7303782254457474, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3076923076923077, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.33333333333333337, 'pegasus_entailment': 0.6575305623312792, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32051282051282054, 'r1_recall': 0.423728813559322, 'r1_f1': 0.3649635036496351, 'pegasus_entailment': 0.46847159415483475, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.4701492537313433, 'r1_f1': 0.4980237154150198, 'pegasus_entailment': 0.5008024135604501, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.358974358974359, 'r1_f1': 0.4534412955465587, 'pegasus_entailment': 0.2949881562963128, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43119266055045874, 'r1_recall': 0.7230769230769231, 'r1_f1': 0.5402298850574713, 'pegasus_entailment': 0.7357929050922394, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4326923076923077, 'r1_recall': 0.5113636363636364, 'r1_f1': 0.46875, 'pegasus_entailment': 0.5529967024922371, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4946236559139785, 'r1_recall': 0.5476190476190477, 'r1_f1': 0.5197740112994351, 'pegasus_entailment': 0.6758133098483086, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3977272727272727, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.4242424242424242, 'pegasus_entailment': 0.5415948955342174, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33858267716535434, 'r1_recall': 0.5375, 'r1_f1': 0.41545893719806765, 'pegasus_entailment': 0.4993847645819187, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5035971223021583, 'r1_recall': 0.44871794871794873, 'r1_f1': 0.4745762711864407, 'pegasus_entailment': 0.45366304895530146, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5063291139240507, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.5161290322580646, 'pegasus_entailment': 0.25480619817972183, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3708609271523179, 'r1_recall': 0.6588235294117647, 'r1_f1': 0.47457627118644063, 'pegasus_entailment': 0.46662308648228645, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6730769230769231, 'r1_recall': 0.5343511450381679, 'r1_f1': 0.5957446808510639, 'pegasus_entailment': 0.45500591211020947, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4642857142857143, 'r1_recall': 0.36792452830188677, 'r1_f1': 0.4105263157894737, 'pegasus_entailment': 0.2987853630911559, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5939849624060151, 'r1_recall': 0.43169398907103823, 'r1_f1': 0.5, 'pegasus_entailment': 0.8131778538227081, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4880952380952381, 'r1_recall': 0.5394736842105263, 'r1_f1': 0.5125, 'pegasus_entailment': 0.34397818757376325, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5121951219512195, 'r1_recall': 0.45652173913043476, 'r1_f1': 0.48275862068965514, 'pegasus_entailment': 0.4509930331259966, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7520661157024794, 'r1_recall': 0.4212962962962963, 'r1_f1': 0.5400593471810089, 'pegasus_entailment': 0.2496687311679125, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5949367088607594, 'r1_recall': 0.46534653465346537, 'r1_f1': 0.5222222222222221, 'pegasus_entailment': 0.06338276776174705, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5119047619047619, 'r1_recall': 0.4387755102040816, 'r1_f1': 0.4725274725274725, 'pegasus_entailment': 0.18773385975509882, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5161290322580646, 'pegasus_entailment': 0.6153527131925026, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6990291262135923, 'r1_recall': 0.5413533834586466, 'r1_f1': 0.6101694915254237, 'pegasus_entailment': 0.2906938042433467, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.4, 'r1_f1': 0.4675324675324675, 'pegasus_entailment': 0.2651624729235967, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.3652173913043478, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.49146442785859107, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44329896907216493, 'r1_recall': 0.38738738738738737, 'r1_f1': 0.41346153846153844, 'pegasus_entailment': 0.696148137251536, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7528089887640449, 'r1_recall': 0.4855072463768116, 'r1_f1': 0.5903083700440528, 'pegasus_entailment': 0.6719439923763275, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21782178217821782, 'r1_recall': 0.44, 'r1_f1': 0.2913907284768212, 'pegasus_entailment': 0.32551082223653793, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26573426573426573, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.38190954773869346, 'pegasus_entailment': 0.25152797531336546, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22580645161290322, 'r1_recall': 0.2978723404255319, 'r1_f1': 0.2568807339449541, 'pegasus_entailment': 0.284672349691391, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4411764705882353, 'r1_recall': 0.4225352112676056, 'r1_f1': 0.43165467625899284, 'pegasus_entailment': 0.5144440829753876, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.3005464480874317, 'r1_f1': 0.40293040293040294, 'pegasus_entailment': 0.2458620723336935, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.514018691588785, 'r1_recall': 0.40145985401459855, 'r1_f1': 0.4508196721311475, 'pegasus_entailment': 0.8132250209649404, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 17}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6022727272727273, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.5921787709497207, 'pegasus_entailment': 0.7983407527208328, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5210084033613446, 'r1_recall': 0.46616541353383456, 'r1_f1': 0.49206349206349204, 'pegasus_entailment': 0.3848346810787916, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48333333333333334, 'r1_recall': 0.5304878048780488, 'r1_f1': 0.5058139534883721, 'pegasus_entailment': 0.2958300940692425, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6846153846153846, 'r1_recall': 0.4427860696517413, 'r1_f1': 0.5377643504531721, 'pegasus_entailment': 0.4883404541760683, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.3, 'r1_f1': 0.34285714285714286, 'pegasus_entailment': 0.5599430501461029, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.5625, 'r1_f1': 0.5590062111801242, 'pegasus_entailment': 0.5671789787709713, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33663366336633666, 'r1_recall': 0.4146341463414634, 'r1_f1': 0.37158469945355194, 'pegasus_entailment': 0.8419028123219808, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26666666666666666, 'r1_recall': 0.5, 'r1_f1': 0.3478260869565218, 'pegasus_entailment': 0.28081218898296356, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2857142857142857, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.3571428571428571, 'pegasus_entailment': 0.6898664496839046, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19607843137254902, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.29411764705882354, 'pegasus_entailment': 0.43534406144171955, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.375, 'r1_recall': 0.4342105263157895, 'r1_f1': 0.4024390243902439, 'pegasus_entailment': 0.5767182894051075, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6451612903225806, 'r1_recall': 0.32608695652173914, 'r1_f1': 0.4332129963898917, 'pegasus_entailment': 0.8045540452003479, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3402061855670103, 'r1_recall': 0.4925373134328358, 'r1_f1': 0.4024390243902439, 'pegasus_entailment': 0.34251442179083824, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6888888888888889, 'r1_recall': 0.36904761904761907, 'r1_f1': 0.4806201550387597, 'pegasus_entailment': 0.4161246486008167, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6320754716981132, 'r1_recall': 0.5075757575757576, 'r1_f1': 0.5630252100840336, 'pegasus_entailment': 0.32203347608447075, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7844827586206896, 'r1_recall': 0.5759493670886076, 'r1_f1': 0.6642335766423357, 'pegasus_entailment': 0.5782024264335632, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7647058823529411, 'r1_recall': 0.2195945945945946, 'r1_f1': 0.3412073490813648, 'pegasus_entailment': 0.43408970534801483, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.7272727272727273, 'r1_f1': 0.54421768707483, 'pegasus_entailment': 0.4875956103205681, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6481481481481481, 'r1_recall': 0.3553299492385787, 'r1_f1': 0.459016393442623, 'pegasus_entailment': 0.1930928498506546, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45588235294117646, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.484375, 'pegasus_entailment': 0.6408371962606907, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4961832061068702, 'r1_recall': 0.5284552845528455, 'r1_f1': 0.5118110236220472, 'pegasus_entailment': 0.7989411801099777, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5523809523809524, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5523809523809524, 'pegasus_entailment': 0.5678386330604553, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.775, 'r1_recall': 0.4732824427480916, 'r1_f1': 0.5876777251184834, 'pegasus_entailment': 0.4727054998278618, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3140495867768595, 'r1_recall': 0.5671641791044776, 'r1_f1': 0.4042553191489362, 'pegasus_entailment': 0.4419554229825735, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2894736842105263, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.3859649122807018, 'pegasus_entailment': 0.4621002972126007, 'pegasus_flesch_kincaid': 32, 'pegasus_coleman_liau': 21, 'pegasus_ari': 38, 'pegasus_smog': 26}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25806451612903225, 'r1_recall': 0.7017543859649122, 'r1_f1': 0.3773584905660377, 'pegasus_entailment': 0.616279861330986, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.5625, 'r1_f1': 0.5877551020408163, 'pegasus_entailment': 0.3008006915450096, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7818181818181819, 'r1_recall': 0.48314606741573035, 'r1_f1': 0.5972222222222223, 'pegasus_entailment': 0.55433922012647, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6333333333333333, 'r1_recall': 0.4662576687116564, 'r1_f1': 0.5371024734982333, 'pegasus_entailment': 0.726044887304306, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6415094339622641, 'r1_recall': 0.35233160621761656, 'r1_f1': 0.45484949832775917, 'pegasus_entailment': 0.6340672224760056, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4909090909090909, 'r1_recall': 0.5346534653465347, 'r1_f1': 0.5118483412322276, 'pegasus_entailment': 0.4082975375155608, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35947712418300654, 'r1_recall': 0.6547619047619048, 'r1_f1': 0.46413502109704646, 'pegasus_entailment': 0.4123345666698047, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.5, 'r1_f1': 0.4736842105263158, 'pegasus_entailment': 0.6782827149145305, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3380281690140845, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.39344262295081966, 'pegasus_entailment': 0.14754684269428253, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6267605633802817, 'r1_recall': 0.6013513513513513, 'r1_f1': 0.6137931034482759, 'pegasus_entailment': 0.5645301242669424, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.4580152671755725, 'r1_f1': 0.5286343612334802, 'pegasus_entailment': 0.560332209803164, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7121212121212122, 'r1_recall': 0.3983050847457627, 'r1_f1': 0.5108695652173914, 'pegasus_entailment': 0.9548970858256022, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7777777777777778, 'r1_recall': 0.3769230769230769, 'r1_f1': 0.5077720207253886, 'pegasus_entailment': 0.6044277374943098, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5408163265306123, 'r1_recall': 0.44537815126050423, 'r1_f1': 0.4884792626728111, 'pegasus_entailment': 0.4587773655851682, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7346938775510204, 'r1_recall': 0.5, 'r1_f1': 0.5950413223140496, 'pegasus_entailment': 0.7153411044273525, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5957446808510638, 'r1_recall': 0.6222222222222222, 'r1_f1': 0.608695652173913, 'pegasus_entailment': 0.3169755460694432, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45161290322580644, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.43579766536964976, 'pegasus_entailment': 0.3381445140577853, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6589147286821705, 'r1_recall': 0.4009433962264151, 'r1_f1': 0.4985337243401759, 'pegasus_entailment': 0.6678925057252248, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33766233766233766, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.3880597014925373, 'pegasus_entailment': 0.4067276641726494, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46511627906976744, 'r1_recall': 0.46875, 'r1_f1': 0.4669260700389105, 'pegasus_entailment': 0.45340456403791907, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34579439252336447, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.45121951219512196, 'pegasus_entailment': 0.5727633386850357, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7310924369747899, 'r1_recall': 0.45549738219895286, 'r1_f1': 0.5612903225806452, 'pegasus_entailment': 0.6220632692178091, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6333333333333333, 'r1_recall': 0.5170068027210885, 'r1_f1': 0.5692883895131086, 'pegasus_entailment': 0.38553042709827423, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45588235294117646, 'r1_recall': 0.4025974025974026, 'r1_f1': 0.42758620689655175, 'pegasus_entailment': 0.874851793050766, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36875, 'r1_recall': 0.7866666666666666, 'r1_f1': 0.5021276595744681, 'pegasus_entailment': 0.6777335129678249, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5984251968503937, 'r1_recall': 0.6608695652173913, 'r1_f1': 0.628099173553719, 'pegasus_entailment': 0.5237200796604157, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5945945945945946, 'r1_recall': 0.43137254901960786, 'r1_f1': 0.5000000000000001, 'pegasus_entailment': 0.6547691524028778, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5188679245283019, 'r1_recall': 0.5392156862745098, 'r1_f1': 0.5288461538461537, 'pegasus_entailment': 0.06418022233992815, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.445859872611465, 'pegasus_entailment': 0.4173084482550621, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3956043956043956, 'r1_recall': 0.5625, 'r1_f1': 0.4645161290322581, 'pegasus_entailment': 0.3455523768439889, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43, 'r1_recall': 0.5733333333333334, 'r1_f1': 0.49142857142857144, 'pegasus_entailment': 0.27242566586937755, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34513274336283184, 'r1_recall': 0.7358490566037735, 'r1_f1': 0.4698795180722891, 'pegasus_entailment': 0.86143858730793, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5670103092783505, 'r1_recall': 0.5913978494623656, 'r1_f1': 0.5789473684210525, 'pegasus_entailment': 0.6674053966999054, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43902439024390244, 'r1_recall': 0.6206896551724138, 'r1_f1': 0.5142857142857142, 'pegasus_entailment': 0.3770249326868604, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5431034482758621, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.5779816513761469, 'pegasus_entailment': 0.6137364953756332, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6296296296296297, 'r1_recall': 0.43037974683544306, 'r1_f1': 0.5112781954887219, 'pegasus_entailment': 0.5634314373135567, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3466666666666667, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.3939393939393939, 'pegasus_entailment': 0.4825938992823164, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5725190839694656, 'r1_recall': 0.5033557046979866, 'r1_f1': 0.5357142857142857, 'pegasus_entailment': 0.6616428891817728, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5316455696202531, 'r1_recall': 0.30656934306569344, 'r1_f1': 0.3888888888888889, 'pegasus_entailment': 0.6306249111890793, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6176470588235294, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.6268656716417911, 'pegasus_entailment': 0.21700024232268333, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5284552845528455, 'r1_recall': 0.5855855855855856, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.7940180897712708, 'pegasus_flesch_kincaid': 32, 'pegasus_coleman_liau': 20, 'pegasus_ari': 39, 'pegasus_smog': 28}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24285714285714285, 'r1_recall': 0.6375, 'r1_f1': 0.35172413793103446, 'pegasus_entailment': 0.9482558795383998, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.4409448818897638, 'r1_f1': 0.4534412955465587, 'pegasus_entailment': 0.8250105828046799, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7536231884057971, 'r1_recall': 0.5279187817258884, 'r1_f1': 0.6208955223880598, 'pegasus_entailment': 0.48445955770356314, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6890756302521008, 'r1_recall': 0.3374485596707819, 'r1_f1': 0.4530386740331492, 'pegasus_entailment': 0.31519676093012094, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.676056338028169, 'r1_recall': 0.34532374100719426, 'r1_f1': 0.45714285714285713, 'pegasus_entailment': 0.48386128908896353, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.031578947368421054, 'r1_recall': 0.0410958904109589, 'r1_f1': 0.03571428571428571, 'pegasus_entailment': 0.9542099833488464, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 1, 'pegasus_ari': 17, 'pegasus_smog': 8}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2828282828282828, 'r1_recall': 0.45901639344262296, 'r1_f1': 0.35, 'pegasus_entailment': 0.15300726937130094, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6875, 'r1_recall': 0.6395348837209303, 'r1_f1': 0.6626506024096386, 'pegasus_entailment': 0.6324207410216331, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4673913043478261, 'r1_recall': 0.581081081081081, 'r1_f1': 0.5180722891566265, 'pegasus_entailment': 0.2594465515576303, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5885714285714285, 'r1_recall': 0.5919540229885057, 'r1_f1': 0.5902578796561605, 'pegasus_entailment': 0.6316783428192139, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4827586206896552, 'r1_recall': 0.2916666666666667, 'r1_f1': 0.3636363636363637, 'pegasus_entailment': 0.3849963629618287, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7863247863247863, 'r1_recall': 0.4717948717948718, 'r1_f1': 0.5897435897435896, 'pegasus_entailment': 0.6674446687102318, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5531914893617021, 'r1_recall': 0.7123287671232876, 'r1_f1': 0.6227544910179641, 'pegasus_entailment': 0.49371232837438583, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49074074074074076, 'r1_recall': 0.7066666666666667, 'r1_f1': 0.5792349726775956, 'pegasus_entailment': 0.43740286622196434, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4830508474576271, 'r1_recall': 0.5, 'r1_f1': 0.49137931034482757, 'pegasus_entailment': 0.7744606733322144, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7398373983739838, 'r1_recall': 0.24202127659574468, 'r1_f1': 0.3647294589178357, 'pegasus_entailment': 0.580346517264843, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4857142857142857, 'r1_recall': 0.576271186440678, 'r1_f1': 0.5271317829457364, 'pegasus_entailment': 0.7218687931696574, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7397260273972602, 'r1_recall': 0.32142857142857145, 'r1_f1': 0.44813278008298757, 'pegasus_entailment': 0.6580447033047676, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47586206896551725, 'r1_recall': 0.5348837209302325, 'r1_f1': 0.5036496350364963, 'pegasus_entailment': 0.4769918170890638, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5109489051094891, 'r1_recall': 0.4697986577181208, 'r1_f1': 0.4895104895104895, 'pegasus_entailment': 0.7563707530498505, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6106194690265486, 'r1_recall': 0.40828402366863903, 'r1_f1': 0.48936170212765956, 'pegasus_entailment': 0.3965494744479656, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6696428571428571, 'r1_recall': 0.5725190839694656, 'r1_f1': 0.6172839506172839, 'pegasus_entailment': 0.7024544030427933, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4225352112676056, 'r1_recall': 0.24193548387096775, 'r1_f1': 0.3076923076923077, 'pegasus_entailment': 0.5976449449857076, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425531914893617, 'r1_recall': 0.7228915662650602, 'r1_f1': 0.5357142857142857, 'pegasus_entailment': 0.4587004162371159, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26373626373626374, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.36923076923076925, 'pegasus_entailment': 0.4108757358044386, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6756756756756757, 'r1_recall': 0.43103448275862066, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.26026322444279987, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6636363636363637, 'r1_recall': 0.3945945945945946, 'r1_f1': 0.49491525423728816, 'pegasus_entailment': 0.5605097077786922, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6417910447761194, 'r1_recall': 0.4479166666666667, 'r1_f1': 0.5276073619631902, 'pegasus_entailment': 0.9471827149391174, 'pegasus_flesch_kincaid': 37, 'pegasus_coleman_liau': 22, 'pegasus_ari': 44, 'pegasus_smog': 30}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7815126050420168, 'r1_recall': 0.24155844155844156, 'r1_f1': 0.369047619047619, 'pegasus_entailment': 0.329908254245917, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6770833333333334, 'r1_recall': 0.4513888888888889, 'r1_f1': 0.5416666666666666, 'pegasus_entailment': 0.5722659900784492, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2482758620689655, 'r1_recall': 0.5538461538461539, 'r1_f1': 0.34285714285714286, 'pegasus_entailment': 0.3597773537039757, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45555555555555555, 'r1_recall': 0.6833333333333333, 'r1_f1': 0.5466666666666666, 'pegasus_entailment': 0.26742803646872443, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44594594594594594, 'r1_recall': 0.4074074074074074, 'r1_f1': 0.42580645161290326, 'pegasus_entailment': 0.2515876851975918, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5066666666666667, 'r1_recall': 0.36538461538461536, 'r1_f1': 0.4245810055865922, 'pegasus_entailment': 0.6934632062911987, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32558139534883723, 'r1_recall': 0.4883720930232558, 'r1_f1': 0.39069767441860465, 'pegasus_entailment': 0.6529766172170639, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.421875, 'r1_recall': 0.5192307692307693, 'r1_f1': 0.46551724137931033, 'pegasus_entailment': 0.40192589660485584, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5245901639344263, 'r1_recall': 0.3878787878787879, 'r1_f1': 0.445993031358885, 'pegasus_entailment': 0.6856850117444993, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4578313253012048, 'r1_recall': 0.6229508196721312, 'r1_f1': 0.5277777777777778, 'pegasus_entailment': 0.43050251858464134, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5857142857142857, 'r1_recall': 0.5466666666666666, 'r1_f1': 0.5655172413793104, 'pegasus_entailment': 0.5225172005593777, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5319148936170213, 'r1_recall': 0.5494505494505495, 'r1_f1': 0.5405405405405406, 'pegasus_entailment': 0.39293381075064343, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.544, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.53125, 'pegasus_entailment': 0.3526668002208074, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.52, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5445026178010471, 'pegasus_entailment': 0.6401330679655075, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.584070796460177, 'r1_recall': 0.6285714285714286, 'r1_f1': 0.6055045871559633, 'pegasus_entailment': 0.48934214242867063, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4375, 'r1_recall': 0.7671232876712328, 'r1_f1': 0.5572139303482587, 'pegasus_entailment': 0.4795444518327713, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5581395348837209, 'r1_recall': 0.384, 'r1_f1': 0.4549763033175356, 'pegasus_entailment': 0.25187146477401257, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5612244897959183, 'r1_recall': 0.4824561403508772, 'r1_f1': 0.5188679245283019, 'pegasus_entailment': 0.391675066947937, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35542168674698793, 'r1_recall': 0.6629213483146067, 'r1_f1': 0.4627450980392156, 'pegasus_entailment': 0.5033868892739216, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2, 'r1_recall': 0.32558139534883723, 'r1_f1': 0.24778761061946902, 'pegasus_entailment': 0.9248838722705841, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 15}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7075471698113207, 'r1_recall': 0.3393665158371041, 'r1_f1': 0.45871559633027525, 'pegasus_entailment': 0.5199355781078339, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6301369863013699, 'pegasus_entailment': 0.9620340764522552, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 22}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27835051546391754, 'r1_recall': 0.7297297297297297, 'r1_f1': 0.40298507462686567, 'pegasus_entailment': 0.3749085192879041, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 18}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2980132450331126, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.3862660944206009, 'pegasus_entailment': 0.6741462871432304, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47863247863247865, 'r1_recall': 0.5233644859813084, 'r1_f1': 0.5, 'pegasus_entailment': 0.6878381222486496, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2986111111111111, 'r1_recall': 0.5972222222222222, 'r1_f1': 0.39814814814814814, 'pegasus_entailment': 0.6571219086647033, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5638297872340425, 'r1_recall': 0.6022727272727273, 'r1_f1': 0.5824175824175825, 'pegasus_entailment': 0.48688208195380867, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 30, 'pegasus_smog': 20}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7, 'r1_recall': 0.550561797752809, 'r1_f1': 0.6163522012578616, 'pegasus_entailment': 0.41168683767318726, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2692307692307692, 'r1_recall': 0.5932203389830508, 'r1_f1': 0.3703703703703704, 'pegasus_entailment': 0.15530007786583155, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6741573033707865, 'r1_recall': 0.6060606060606061, 'r1_f1': 0.6382978723404256, 'pegasus_entailment': 0.776126429438591, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46551724137931033, 'r1_recall': 0.5625, 'r1_f1': 0.5094339622641509, 'pegasus_entailment': 0.6770926594734192, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41830065359477125, 'r1_recall': 0.6808510638297872, 'r1_f1': 0.5182186234817814, 'pegasus_entailment': 0.5247123266259829, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8616352201257862, 'r1_recall': 0.2624521072796935, 'r1_f1': 0.40234948604992654, 'pegasus_entailment': 0.565445890384061, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6524390243902439, 'r1_recall': 0.535, 'r1_f1': 0.5879120879120879, 'pegasus_entailment': 0.5532713415367263, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30357142857142855, 'r1_recall': 0.4358974358974359, 'r1_f1': 0.35789473684210527, 'pegasus_entailment': 0.11778875514864921, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6236559139784946, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5858585858585859, 'pegasus_entailment': 0.6512515544891357, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.4852941176470588, 'r1_f1': 0.4925373134328358, 'pegasus_entailment': 0.4438908211886883, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6111111111111112, 'r1_recall': 0.48672566371681414, 'r1_f1': 0.5418719211822659, 'pegasus_entailment': 0.511633176356554, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47572815533980584, 'r1_recall': 0.5764705882352941, 'r1_f1': 0.5212765957446808, 'pegasus_entailment': 0.4667632281780243, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4186046511627907, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.47368421052631576, 'pegasus_entailment': 0.48165300861001015, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5555555555555556, 'r1_recall': 0.4891304347826087, 'r1_f1': 0.5202312138728324, 'pegasus_entailment': 0.6083359532058239, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5274725274725275, 'r1_recall': 0.5783132530120482, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.33475450053811073, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6090909090909091, 'r1_recall': 0.5317460317460317, 'r1_f1': 0.5677966101694915, 'pegasus_entailment': 0.5171469151973724, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6206896551724138, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.4214533917605877, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5864661654135338, 'r1_recall': 0.484472049689441, 'r1_f1': 0.5306122448979592, 'pegasus_entailment': 0.5496786117553711, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42028985507246375, 'r1_recall': 0.5087719298245614, 'r1_f1': 0.46031746031746035, 'pegasus_entailment': 0.3604556878951068, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 13}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6204819277108434, 'r1_recall': 0.4557522123893805, 'r1_f1': 0.5255102040816326, 'pegasus_entailment': 0.6254832506179809, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3103448275862069, 'r1_recall': 0.6, 'r1_f1': 0.4090909090909091, 'pegasus_entailment': 0.19837059639394283, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5514018691588785, 'r1_recall': 0.5841584158415841, 'r1_f1': 0.5673076923076923, 'pegasus_entailment': 0.579101045926412, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3595505617977528, 'r1_recall': 0.6530612244897959, 'r1_f1': 0.463768115942029, 'pegasus_entailment': 0.6984294652938843, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.203125, 'r1_recall': 0.2826086956521739, 'r1_f1': 0.23636363636363636, 'pegasus_entailment': 0.8177447517712911, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6218487394957983, 'r1_recall': 0.5068493150684932, 'r1_f1': 0.5584905660377358, 'pegasus_entailment': 0.8368285894393921, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6459627329192547, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.5892351274787535, 'pegasus_entailment': 0.6935430586338043, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5254237288135594, 'r1_recall': 0.4189189189189189, 'r1_f1': 0.46616541353383456, 'pegasus_entailment': 0.34189148258883506, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4017857142857143, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.42654028436018965, 'pegasus_entailment': 0.4437068998813629, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5463917525773195, 'r1_recall': 0.6385542168674698, 'r1_f1': 0.5888888888888889, 'pegasus_entailment': 0.6052955587704977, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35772357723577236, 'r1_recall': 0.6197183098591549, 'r1_f1': 0.4536082474226804, 'pegasus_entailment': 0.4342086136341095, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.512396694214876, 'r1_recall': 0.5391304347826087, 'r1_f1': 0.5254237288135593, 'pegasus_entailment': 0.3408238925039768, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6296296296296297, 'r1_recall': 0.40476190476190477, 'r1_f1': 0.4927536231884058, 'pegasus_entailment': 0.28402944207191466, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29906542056074764, 'r1_recall': 0.6037735849056604, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.7132363468408585, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.42424242424242425, 'pegasus_entailment': 0.8700978010892868, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3923076923076923, 'r1_recall': 0.45132743362831856, 'r1_f1': 0.41975308641975306, 'pegasus_entailment': 0.4894271455705166, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39473684210526316, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.4864864864864865, 'pegasus_entailment': 0.4749680653214455, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5419354838709678, 'r1_recall': 0.3835616438356164, 'r1_f1': 0.4491978609625668, 'pegasus_entailment': 0.48808587789535524, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23076923076923078, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.3185840707964602, 'pegasus_entailment': 0.8682784835497538, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 21}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49019607843137253, 'r1_recall': 0.6024096385542169, 'r1_f1': 0.5405405405405406, 'pegasus_entailment': 0.49508877024054526, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3582089552238806, 'r1_recall': 0.4897959183673469, 'r1_f1': 0.4137931034482758, 'pegasus_entailment': 0.35937045365571973, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6493506493506493, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.6172839506172839, 'pegasus_entailment': 0.6865713596343994, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6379310344827587, 'r1_recall': 0.5736434108527132, 'r1_f1': 0.6040816326530614, 'pegasus_entailment': 0.6006013676524162, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.504950495049505, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.5425531914893617, 'pegasus_entailment': 0.8108405470848083, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6464646464646465, 'r1_recall': 0.48120300751879697, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.5616117380559444, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5945945945945946, 'r1_f1': 0.5432098765432098, 'pegasus_entailment': 0.17247513184944788, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4537037037037037, 'r1_recall': 0.5104166666666666, 'r1_f1': 0.4803921568627451, 'pegasus_entailment': 0.37727495771832764, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7176470588235294, 'r1_recall': 0.4357142857142857, 'r1_f1': 0.5422222222222223, 'pegasus_entailment': 0.8924940427144369, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46703296703296704, 'r1_recall': 0.5902777777777778, 'r1_f1': 0.5214723926380368, 'pegasus_entailment': 0.6907042860984802, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49504950495049505, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.5181347150259067, 'pegasus_entailment': 0.7772064805030823, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5542168674698795, 'r1_recall': 0.44660194174757284, 'r1_f1': 0.49462365591397855, 'pegasus_entailment': 0.712490051984787, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39473684210526316, 'r1_recall': 0.44776119402985076, 'r1_f1': 0.41958041958041953, 'pegasus_entailment': 0.4711893058071534, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4765625, 'r1_recall': 0.6703296703296703, 'r1_f1': 0.5570776255707763, 'pegasus_entailment': 0.7808398976922035, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.624, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5820895522388059, 'pegasus_entailment': 0.6613152585923672, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6739130434782609, 'r1_recall': 0.5081967213114754, 'r1_f1': 0.5794392523364487, 'pegasus_entailment': 0.4218052327632904, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6875, 'r1_recall': 0.463855421686747, 'r1_f1': 0.5539568345323741, 'pegasus_entailment': 0.36346298456192017, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5205479452054794, 'r1_recall': 0.6909090909090909, 'r1_f1': 0.59375, 'pegasus_entailment': 0.20500308523575464, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.6621621621621622, 'r1_f1': 0.547486033519553, 'pegasus_entailment': 0.5421691872179508, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5882352941176471, 'r1_recall': 0.3431372549019608, 'r1_f1': 0.43343653250773995, 'pegasus_entailment': 0.8909037113189697, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7094017094017094, 'r1_recall': 0.38425925925925924, 'r1_f1': 0.4984984984984985, 'pegasus_entailment': 0.38093746701876324, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4909090909090909, 'r1_recall': 0.4462809917355372, 'r1_f1': 0.4675324675324675, 'pegasus_entailment': 0.3786330081522465, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6422018348623854, 'r1_recall': 0.48951048951048953, 'r1_f1': 0.5555555555555556, 'pegasus_entailment': 0.1516966436058283, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42142857142857143, 'r1_recall': 0.6781609195402298, 'r1_f1': 0.5198237885462554, 'pegasus_entailment': 0.839323103427887, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41721854304635764, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.5206611570247935, 'pegasus_entailment': 0.8117801348368326, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3986013986013986, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.4653061224489796, 'pegasus_entailment': 0.3215726986527443, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5753424657534246, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.44919786096256686, 'pegasus_entailment': 0.26089430321007967, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5897435897435898, 'r1_recall': 0.46464646464646464, 'r1_f1': 0.519774011299435, 'pegasus_entailment': 0.21887610480189323, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3220338983050847, 'r1_recall': 0.42696629213483145, 'r1_f1': 0.3671497584541063, 'pegasus_entailment': 0.5952624082565308, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.675, 'r1_recall': 0.49693251533742333, 'r1_f1': 0.5724381625441696, 'pegasus_entailment': 0.3389609344303608, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.64, 'r1_recall': 0.26373626373626374, 'r1_f1': 0.37354085603112835, 'pegasus_entailment': 0.5633938908576965, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6935483870967742, 'r1_recall': 0.31272727272727274, 'r1_f1': 0.431077694235589, 'pegasus_entailment': 0.20300436913967132, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5789473684210527, 'r1_recall': 0.5045871559633027, 'r1_f1': 0.5392156862745099, 'pegasus_entailment': 0.6460630521178246, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26582278481012656, 'r1_recall': 0.3620689655172414, 'r1_f1': 0.3065693430656934, 'pegasus_entailment': 0.9707360565662384, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 17}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5813953488372093, 'r1_recall': 0.27624309392265195, 'r1_f1': 0.3745318352059925, 'pegasus_entailment': 0.688292404015859, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3445378151260504, 'r1_recall': 0.5324675324675324, 'r1_f1': 0.41836734693877553, 'pegasus_entailment': 0.4574697569012642, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32571428571428573, 'r1_recall': 0.7125, 'r1_f1': 0.4470588235294118, 'pegasus_entailment': 0.5455219112336636, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5934065934065934, 'r1_recall': 0.5806451612903226, 'r1_f1': 0.5869565217391305, 'pegasus_entailment': 0.7388964220881462, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5096153846153846, 'r1_recall': 0.654320987654321, 'r1_f1': 0.572972972972973, 'pegasus_entailment': 0.5579134874045849, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5308641975308642, 'r1_recall': 0.4777777777777778, 'r1_f1': 0.5029239766081872, 'pegasus_entailment': 0.6428880492846171, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27956989247311825, 'r1_recall': 0.37681159420289856, 'r1_f1': 0.32098765432098764, 'pegasus_entailment': 0.4505146484589204, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3782051282051282, 'r1_recall': 0.6145833333333334, 'r1_f1': 0.46825396825396826, 'pegasus_entailment': 0.4413776679171456, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38, 'r1_recall': 0.59375, 'r1_f1': 0.46341463414634143, 'pegasus_entailment': 0.3738635601475835, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3968253968253968, 'r1_recall': 0.5494505494505495, 'r1_f1': 0.4608294930875576, 'pegasus_entailment': 0.6062497496604919, 'pegasus_flesch_kincaid': 31, 'pegasus_coleman_liau': 18, 'pegasus_ari': 39, 'pegasus_smog': 24}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44696969696969696, 'r1_recall': 0.6704545454545454, 'r1_f1': 0.5363636363636364, 'pegasus_entailment': 0.6399026811122894, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38524590163934425, 'r1_recall': 0.7580645161290323, 'r1_f1': 0.5108695652173914, 'pegasus_entailment': 0.5259238600730896, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5147058823529411, 'r1_recall': 0.6542056074766355, 'r1_f1': 0.5761316872427984, 'pegasus_entailment': 0.5157240554690361, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38028169014084506, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.40298507462686567, 'pegasus_entailment': 0.3669706713408232, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7920792079207921, 'r1_recall': 0.3018867924528302, 'r1_f1': 0.4371584699453552, 'pegasus_entailment': 0.4796195328235626, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36633663366336633, 'r1_recall': 0.578125, 'r1_f1': 0.4484848484848485, 'pegasus_entailment': 0.4862455949187279, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4148936170212766, 'r1_recall': 0.42391304347826086, 'r1_f1': 0.41935483870967744, 'pegasus_entailment': 0.8469926357269287, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.512396694214876, 'r1_recall': 0.62, 'r1_f1': 0.5610859728506787, 'pegasus_entailment': 0.5371859036386013, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4772727272727273, 'r1_recall': 0.45, 'r1_f1': 0.4632352941176471, 'pegasus_entailment': 0.7819550991058349, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5319148936170213, 'r1_recall': 0.5319148936170213, 'r1_f1': 0.5319148936170213, 'pegasus_entailment': 0.4124035630375147, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5816326530612245, 'r1_recall': 0.44881889763779526, 'r1_f1': 0.5066666666666667, 'pegasus_entailment': 0.7392638102173805, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3918918918918919, 'r1_recall': 0.4084507042253521, 'r1_f1': 0.4, 'pegasus_entailment': 0.59487184882164, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4409448818897638, 'r1_recall': 0.5957446808510638, 'r1_f1': 0.506787330316742, 'pegasus_entailment': 0.34745545871555805, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5263157894736842, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5, 'pegasus_entailment': 0.23872927762567997, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5348837209302325, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.575, 'pegasus_entailment': 0.3030800308721761, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4642857142857143, 'r1_recall': 0.582089552238806, 'r1_f1': 0.5165562913907285, 'pegasus_entailment': 0.6351023316383362, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.358974358974359, 'r1_recall': 0.4375, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.836095929145813, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5287356321839081, 'r1_recall': 0.2658959537572254, 'r1_f1': 0.3538461538461538, 'pegasus_entailment': 0.5277276933193207, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6261682242990654, 'r1_recall': 0.40606060606060607, 'r1_f1': 0.4926470588235294, 'pegasus_entailment': 0.42679300780097645, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6320754716981132, 'r1_recall': 0.6836734693877551, 'r1_f1': 0.6568627450980392, 'pegasus_entailment': 0.6183235887438059, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851063829787234, 'r1_recall': 0.29411764705882354, 'r1_f1': 0.3914590747330961, 'pegasus_entailment': 0.10104828886687756, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44871794871794873, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.4046242774566474, 'pegasus_entailment': 0.44852709472179414, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42424242424242425, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4912280701754386, 'pegasus_entailment': 0.6436878641446432, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40625, 'r1_recall': 0.4727272727272727, 'r1_f1': 0.43697478991596644, 'pegasus_entailment': 0.651074081659317, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22727272727272727, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.3289473684210526, 'pegasus_entailment': 0.37106930650770664, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4144144144144144, 'r1_recall': 0.647887323943662, 'r1_f1': 0.5054945054945055, 'pegasus_entailment': 0.9077486991882324, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32142857142857145, 'r1_recall': 0.5192307692307693, 'r1_f1': 0.39705882352941174, 'pegasus_entailment': 0.3618789967149496, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5072463768115942, 'r1_recall': 0.29914529914529914, 'r1_f1': 0.3763440860215054, 'pegasus_entailment': 0.4053036882542074, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6534653465346535, 'r1_recall': 0.5038167938931297, 'r1_f1': 0.5689655172413793, 'pegasus_entailment': 0.4550515413284302, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5405405405405406, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5063291139240507, 'pegasus_entailment': 0.5093708166386932, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 12}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6037735849056604, 'r1_recall': 0.35555555555555557, 'r1_f1': 0.44755244755244755, 'pegasus_entailment': 0.6055308878421783, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.5934065934065934, 'r1_f1': 0.5118483412322274, 'pegasus_entailment': 0.43761444091796875, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 25}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.51, 'r1_recall': 0.4636363636363636, 'r1_f1': 0.4857142857142857, 'pegasus_entailment': 0.5802631005644798, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 22}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5842696629213483, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.574585635359116, 'pegasus_entailment': 0.5011084030071894, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5058823529411764, 'r1_recall': 0.43, 'r1_f1': 0.46486486486486484, 'pegasus_entailment': 0.6636000603437424, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2708333333333333, 'r1_recall': 0.37681159420289856, 'r1_f1': 0.3151515151515151, 'pegasus_entailment': 0.6837629559449852, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5227272727272727, 'r1_recall': 0.5287356321839081, 'r1_f1': 0.5257142857142857, 'pegasus_entailment': 0.6650414168834686, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6203703703703703, 'r1_recall': 0.6568627450980392, 'r1_f1': 0.638095238095238, 'pegasus_entailment': 0.5822240188717842, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40298507462686567, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.49541284403669733, 'pegasus_entailment': 0.6191720366477966, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23255813953488372, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.2898550724637681, 'pegasus_entailment': 0.4679887555539608, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6237623762376238, 'r1_recall': 0.4405594405594406, 'r1_f1': 0.5163934426229508, 'pegasus_entailment': 0.7031949818134308, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5402298850574713, 'r1_recall': 0.5402298850574713, 'r1_f1': 0.5402298850574713, 'pegasus_entailment': 0.3125515356659889, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.4878048780487805, 'pegasus_entailment': 0.6433320247257749, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.39669421487603307, 'r1_f1': 0.45933014354066987, 'pegasus_entailment': 0.6853058040142059, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41379310344827586, 'r1_recall': 0.34615384615384615, 'r1_f1': 0.37696335078534027, 'pegasus_entailment': 0.3346194537977378, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47368421052631576, 'r1_recall': 0.2571428571428571, 'r1_f1': 0.3333333333333333, 'pegasus_entailment': 0.6736226181189219, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2892561983471074, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.36269430051813467, 'pegasus_entailment': 0.37788626505061984, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48598130841121495, 'r1_recall': 0.5842696629213483, 'r1_f1': 0.5306122448979592, 'pegasus_entailment': 0.29396875699361164, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1826086956521739, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.2625, 'pegasus_entailment': 0.6165829971432686, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45255474452554745, 'r1_recall': 0.6019417475728155, 'r1_f1': 0.5166666666666667, 'pegasus_entailment': 0.45390594253937405, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.13186813186813187, 'r1_recall': 0.34285714285714286, 'r1_f1': 0.1904761904761905, 'pegasus_entailment': 0.44790851697325706, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3472222222222222, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.42735042735042733, 'pegasus_entailment': 0.879147469997406, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22627737226277372, 'r1_recall': 0.7948717948717948, 'r1_f1': 0.3522727272727273, 'pegasus_entailment': 0.9510880907376608, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7647058823529411, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.48148148148148157, 'pegasus_entailment': 0.26776187121868134, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.6, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.8117288649082184, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32450331125827814, 'r1_recall': 0.5104166666666666, 'r1_f1': 0.3967611336032389, 'pegasus_entailment': 0.3928569592535496, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.532258064516129, 'r1_recall': 0.6055045871559633, 'r1_f1': 0.5665236051502146, 'pegasus_entailment': 0.35898205637931824, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.603448275862069, 'r1_recall': 0.5072463768115942, 'r1_f1': 0.5511811023622047, 'pegasus_entailment': 0.3799579789241155, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8791208791208791, 'r1_recall': 0.22727272727272727, 'r1_f1': 0.3611738148984198, 'pegasus_entailment': 0.9009361664454142, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4298245614035088, 'r1_recall': 0.44144144144144143, 'r1_f1': 0.4355555555555556, 'pegasus_entailment': 0.7416481897234917, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5212765957446809, 'r1_recall': 0.3288590604026846, 'r1_f1': 0.4032921810699589, 'pegasus_entailment': 0.6765744984149933, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7325581395348837, 'r1_recall': 0.4228187919463087, 'r1_f1': 0.5361702127659574, 'pegasus_entailment': 0.7686430931091308, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24691358024691357, 'r1_recall': 0.40816326530612246, 'r1_f1': 0.3076923076923077, 'pegasus_entailment': 0.199537156149745, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3884297520661157, 'r1_recall': 0.6527777777777778, 'r1_f1': 0.48704663212435234, 'pegasus_entailment': 0.36349406590064365, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3602941176470588, 'r1_recall': 0.6049382716049383, 'r1_f1': 0.45161290322580644, 'pegasus_entailment': 0.48194907456636427, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8762886597938144, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.6882591093117408, 'pegasus_entailment': 0.5371608038743337, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4117647058823529, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.4605263157894737, 'pegasus_entailment': 0.5246486216783524, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7894736842105263, 'r1_recall': 0.5232558139534884, 'r1_f1': 0.6293706293706294, 'pegasus_entailment': 0.9063218633333842, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34965034965034963, 'r1_recall': 0.6756756756756757, 'r1_f1': 0.4608294930875576, 'pegasus_entailment': 0.7385792210698128, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5223880597014925, 'r1_recall': 0.43209876543209874, 'r1_f1': 0.47297297297297297, 'pegasus_entailment': 0.8222944339116415, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5603448275862069, 'r1_recall': 0.46099290780141844, 'r1_f1': 0.5058365758754862, 'pegasus_entailment': 0.5897003471851349, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3438914027149321, 'r1_recall': 0.5801526717557252, 'r1_f1': 0.4318181818181818, 'pegasus_entailment': 0.6571499332785606, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 20, 'pegasus_ari': 36, 'pegasus_smog': 25}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5975609756097561, 'r1_recall': 0.460093896713615, 'r1_f1': 0.519893899204244, 'pegasus_entailment': 0.5900787532329559, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5529411764705883, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.537142857142857, 'pegasus_entailment': 0.8222491343816122, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36470588235294116, 'r1_recall': 0.543859649122807, 'r1_f1': 0.4366197183098592, 'pegasus_entailment': 0.564756323893865, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.625, 'r1_recall': 0.31746031746031744, 'r1_f1': 0.42105263157894735, 'pegasus_entailment': 0.5144186150282621, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6941176470588235, 'r1_recall': 0.19407894736842105, 'r1_f1': 0.3033419023136247, 'pegasus_entailment': 0.29711681852738064, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.18840579710144928, 'r1_recall': 0.4126984126984127, 'r1_f1': 0.25870646766169153, 'pegasus_entailment': 0.5562828965485096, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40131578947368424, 'r1_recall': 0.6421052631578947, 'r1_f1': 0.4939271255060729, 'pegasus_entailment': 0.6066539287567139, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6782608695652174, 'r1_recall': 0.4936708860759494, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.43907816614955664, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2835820895522388, 'r1_recall': 0.3275862068965517, 'r1_f1': 0.304, 'pegasus_entailment': 0.3528770574678977, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7272727272727273, 'r1_recall': 0.35359116022099446, 'r1_f1': 0.4758364312267657, 'pegasus_entailment': 0.401650071144104, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.569620253164557, 'r1_recall': 0.31690140845070425, 'r1_f1': 0.40723981900452494, 'pegasus_entailment': 0.5625083049138387, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44761904761904764, 'r1_recall': 0.49473684210526314, 'r1_f1': 0.47000000000000003, 'pegasus_entailment': 0.29756504762917757, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5855855855855856, 'r1_recall': 0.37790697674418605, 'r1_f1': 0.45936395759717313, 'pegasus_entailment': 0.6312712550163269, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41509433962264153, 'r1_recall': 0.6197183098591549, 'r1_f1': 0.4971751412429378, 'pegasus_entailment': 0.5009271539747715, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7159090909090909, 'r1_recall': 0.30288461538461536, 'r1_f1': 0.42567567567567566, 'pegasus_entailment': 0.7563634117444357, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36464088397790057, 'r1_recall': 0.7096774193548387, 'r1_f1': 0.48175182481751827, 'pegasus_entailment': 0.6750149726867676, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36507936507936506, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.45771144278606957, 'pegasus_entailment': 0.6137096732854843, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46236559139784944, 'r1_recall': 0.6056338028169014, 'r1_f1': 0.524390243902439, 'pegasus_entailment': 0.3920397361119588, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5148514851485149, 'r1_recall': 0.5148514851485149, 'r1_f1': 0.5148514851485149, 'pegasus_entailment': 0.6513090133666992, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6938775510204082, 'r1_recall': 0.4927536231884058, 'r1_f1': 0.576271186440678, 'pegasus_entailment': 0.7587986886501312, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.4485981308411215, 'pegasus_entailment': 0.7946982562541962, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27058823529411763, 'r1_recall': 0.38333333333333336, 'r1_f1': 0.31724137931034485, 'pegasus_entailment': 0.32220791776974994, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8058252427184466, 'r1_recall': 0.46629213483146065, 'r1_f1': 0.590747330960854, 'pegasus_entailment': 0.7039458863437176, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44339622641509435, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.5251396648044692, 'pegasus_entailment': 0.4095403850078583, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4435483870967742, 'r1_recall': 0.7236842105263158, 'r1_f1': 0.55, 'pegasus_entailment': 0.21511110139545053, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5529411764705883, 'r1_recall': 0.5164835164835165, 'r1_f1': 0.5340909090909091, 'pegasus_entailment': 0.4883999414741993, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6228070175438597, 'r1_recall': 0.5916666666666667, 'r1_f1': 0.6068376068376069, 'pegasus_entailment': 0.565395787358284, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8145161290322581, 'r1_recall': 0.14326241134751774, 'r1_f1': 0.2436670687575392, 'pegasus_entailment': 0.719287283718586, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6363636363636364, 'r1_recall': 0.49295774647887325, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.5859746634960175, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.88, 'r1_recall': 0.4808743169398907, 'r1_f1': 0.6219081272084805, 'pegasus_entailment': 0.4208165916303794, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4015748031496063, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.4636363636363636, 'pegasus_entailment': 0.3654447728767991, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5929203539823009, 'r1_recall': 0.5775862068965517, 'r1_f1': 0.5851528384279475, 'pegasus_entailment': 0.5120957437902689, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4574468085106383, 'r1_recall': 0.6615384615384615, 'r1_f1': 0.540880503144654, 'pegasus_entailment': 0.32931030122563243, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48201438848920863, 'r1_recall': 0.4267515923566879, 'r1_f1': 0.4527027027027027, 'pegasus_entailment': 0.41376807913184166, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.20175438596491227, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.2839506172839506, 'pegasus_entailment': 0.39992243610322475, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4731182795698925, 'r1_recall': 0.4536082474226804, 'r1_f1': 0.46315789473684216, 'pegasus_entailment': 0.9707311391830444, 'pegasus_flesch_kincaid': 45, 'pegasus_coleman_liau': 20, 'pegasus_ari': 55, 'pegasus_smog': 32}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1743119266055046, 'r1_recall': 0.5428571428571428, 'r1_f1': 0.2638888888888889, 'pegasus_entailment': 0.4398182760924101, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43537414965986393, 'r1_recall': 0.6597938144329897, 'r1_f1': 0.5245901639344263, 'pegasus_entailment': 0.5514963768422604, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5178571428571429, 'r1_recall': 0.5132743362831859, 'r1_f1': 0.5155555555555555, 'pegasus_entailment': 0.67866450548172, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6363636363636364, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.5384615384615385, 'pegasus_entailment': 0.45638997317291796, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23232323232323232, 'r1_recall': 0.42592592592592593, 'r1_f1': 0.30065359477124176, 'pegasus_entailment': 0.39395245611667634, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5774647887323944, 'r1_recall': 0.41, 'r1_f1': 0.47953216374269003, 'pegasus_entailment': 0.8469030410051346, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.031578947368421054
MEAN
0.5039881876995551
MAX
0.88
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.0410958904109589
MEAN
0.5021844395657316
MAX
0.7971014492753623
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.03571428571428571
MEAN
0.4796578201394519
MAX
0.6995073891625615
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.06338276776174705
MEAN
0.5457424162566189
MAX
0.9890740911165873
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
17
MAX
52
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
1
MEAN
17
MAX
24
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
12
MEAN
21
MAX
64
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
8
MEAN
18
MAX
34
{}
Entered file!
Imports done!
*** RUN *** 
eval_2d2
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 14:40:38.101935: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 14:40:38.652997: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/2d2_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48623853211009177, 'r1_recall': 0.4818181818181818, 'r1_f1': 0.4840182648401826, 'pegasus_entailment': 0.5776585340499878, 'gold_entailment': 0.4284333050251007, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 13, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6588235294117647, 'r1_recall': 0.3236994219653179, 'r1_f1': 0.434108527131783, 'pegasus_entailment': 0.6350872330367565, 'gold_entailment': 0.5142355050359454, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2644628099173554, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.3575418994413408, 'pegasus_entailment': 0.6218796819448471, 'gold_entailment': 0.5164063846071562, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 14, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7446808510638298, 'r1_recall': 0.5426356589147286, 'r1_f1': 0.6278026905829596, 'pegasus_entailment': 0.7990065813064575, 'gold_entailment': 0.4932037750259042, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 17, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 21, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.672566371681416, 'r1_recall': 0.4367816091954023, 'r1_f1': 0.529616724738676, 'pegasus_entailment': 0.3965887241065502, 'gold_entailment': 0.5065276759366194, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4715447154471545, 'r1_recall': 0.4461538461538462, 'r1_f1': 0.45849802371541504, 'pegasus_entailment': 0.26648516207933426, 'gold_entailment': 0.21131984740495682, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.189873417721519, 'r1_recall': 0.46875, 'r1_f1': 0.2702702702702703, 'pegasus_entailment': 0.3585384860634804, 'gold_entailment': 0.4352297745645046, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 10, 'gold_coleman_liau': 14, 'gold_ari': 11, 'gold_smog': 15}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2876712328767123, 'r1_recall': 0.6774193548387096, 'r1_f1': 0.40384615384615385, 'pegasus_entailment': 0.40709395334124565, 'gold_entailment': 0.06752728670835495, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7169811320754716, 'r1_recall': 0.5100671140939598, 'r1_f1': 0.596078431372549, 'pegasus_entailment': 0.5436099320650101, 'gold_entailment': 0.6372850891202688, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5563380281690141, 'r1_recall': 0.572463768115942, 'r1_f1': 0.5642857142857143, 'pegasus_entailment': 0.5631787776947021, 'gold_entailment': 0.3198578345278899, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 19, 'gold_ari': 31, 'gold_smog': 24}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7777777777777778, 'r1_recall': 0.37333333333333335, 'r1_f1': 0.5045045045045045, 'pegasus_entailment': 0.38459283486008644, 'gold_entailment': 0.41076447665691374, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45161290322580644, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.4609053497942387, 'pegasus_entailment': 0.7864744265874227, 'gold_entailment': 0.4572588294744492, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.726027397260274, 'r1_recall': 0.4953271028037383, 'r1_f1': 0.5888888888888889, 'pegasus_entailment': 0.6612625246246656, 'gold_entailment': 0.3518748050555587, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6470588235294118, 'r1_recall': 0.5, 'r1_f1': 0.5641025641025642, 'pegasus_entailment': 0.7623180945714315, 'gold_entailment': 0.22173562071596584, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8505747126436781, 'r1_recall': 0.3854166666666667, 'r1_f1': 0.5304659498207885, 'pegasus_entailment': 0.6967844168345133, 'gold_entailment': 0.35728325648233294, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25, 'r1_recall': 0.5084745762711864, 'r1_f1': 0.33519553072625696, 'pegasus_entailment': 0.5649176072329283, 'gold_entailment': 0.005505232373252511, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43902439024390244, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.3977900552486187, 'pegasus_entailment': 0.5912778576215109, 'gold_entailment': 0.484069528679053, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7722772277227723, 'r1_recall': 0.26174496644295303, 'r1_f1': 0.3909774436090226, 'pegasus_entailment': 0.28142471238970757, 'gold_entailment': 0.40958941197022797, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6306306306306306, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.5147058823529412, 'pegasus_entailment': 0.34134733453392985, 'gold_entailment': 0.35734020599297117, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.494949494949495, 'r1_recall': 0.5632183908045977, 'r1_f1': 0.5268817204301075, 'pegasus_entailment': 0.6198220352331797, 'gold_entailment': 0.4441959811374545, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6637168141592921, 'r1_recall': 0.41208791208791207, 'r1_f1': 0.5084745762711864, 'pegasus_entailment': 0.46753083169460297, 'gold_entailment': 0.19629437290132046, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 15, 'gold_ari': 28, 'gold_smog': 18}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6014492753623188, 'r1_recall': 0.5533333333333333, 'r1_f1': 0.576388888888889, 'pegasus_entailment': 0.7947301715612411, 'gold_entailment': 0.6185178024073442, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44755244755244755, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.5099601593625498, 'pegasus_entailment': 0.5669271945953369, 'gold_entailment': 0.31062590330839157, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.69, 'r1_recall': 0.5073529411764706, 'r1_f1': 0.5847457627118644, 'pegasus_entailment': 0.37241795659065247, 'gold_entailment': 0.3561852586766084, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35051546391752575, 'r1_recall': 0.68, 'r1_f1': 0.46258503401360546, 'pegasus_entailment': 0.6448382258415222, 'gold_entailment': 0.4778066100552678, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5737704918032787, 'r1_recall': 0.37037037037037035, 'r1_f1': 0.45016077170418, 'pegasus_entailment': 0.3860257716849446, 'gold_entailment': 0.5903877660632133, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 29, 'gold_smog': 22}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5862068965517241, 'r1_recall': 0.49635036496350365, 'r1_f1': 0.5375494071146245, 'pegasus_entailment': 0.5313470080494881, 'gold_entailment': 0.47313677668571474, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7951807228915663, 'r1_recall': 0.2462686567164179, 'r1_f1': 0.37606837606837606, 'pegasus_entailment': 0.6164184510707855, 'gold_entailment': 0.5458775135603818, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5974025974025974, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.6013071895424836, 'pegasus_entailment': 0.538751224676768, 'gold_entailment': 0.28643152366081875, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 16}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3770491803278688, 'r1_recall': 0.40707964601769914, 'r1_f1': 0.39148936170212767, 'pegasus_entailment': 0.6908449649810791, 'gold_entailment': 0.5069271326065063, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 18}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4519230769230769, 'r1_recall': 0.5402298850574713, 'r1_f1': 0.49214659685863876, 'pegasus_entailment': 0.5891800597310066, 'gold_entailment': 0.6574686268965403, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5739130434782609, 'r1_recall': 0.3283582089552239, 'r1_f1': 0.4177215189873418, 'pegasus_entailment': 0.5783639311790466, 'gold_entailment': 0.6649928738673528, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4095238095238095, 'r1_recall': 0.4174757281553398, 'r1_f1': 0.4134615384615385, 'pegasus_entailment': 0.7202720940113068, 'gold_entailment': 0.4112209789454937, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3674698795180723, 'r1_recall': 0.6288659793814433, 'r1_f1': 0.4638783269961977, 'pegasus_entailment': 0.6183017671108246, 'gold_entailment': 0.08859759953338653, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32413793103448274, 'r1_recall': 0.5595238095238095, 'r1_f1': 0.4104803493449782, 'pegasus_entailment': 0.2847154259681702, 'gold_entailment': 0.1680013487736384, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5408163265306123, 'r1_recall': 0.45689655172413796, 'r1_f1': 0.4953271028037384, 'pegasus_entailment': 0.5831048339605331, 'gold_entailment': 0.3026718993981679, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 24}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4296875, 'r1_recall': 0.7971014492753623, 'r1_f1': 0.5583756345177665, 'pegasus_entailment': 0.5608726859092712, 'gold_entailment': 0.6821679373582205, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34234234234234234, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.4245810055865922, 'pegasus_entailment': 0.7213659049011767, 'gold_entailment': 0.40810126019641757, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23577235772357724, 'r1_recall': 0.6444444444444445, 'r1_f1': 0.34523809523809523, 'pegasus_entailment': 0.4655906483530998, 'gold_entailment': 0.6502262055873871, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45901639344262296, 'r1_recall': 0.5060240963855421, 'r1_f1': 0.4813753581661891, 'pegasus_entailment': 0.8382661417126656, 'gold_entailment': 0.029503032914362848, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 23, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7171717171717171, 'r1_recall': 0.44375, 'r1_f1': 0.5482625482625482, 'pegasus_entailment': 0.5706129213795066, 'gold_entailment': 0.5620311737060547, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.5844155844155844, 'r1_f1': 0.5555555555555555, 'pegasus_entailment': 0.40708838154872257, 'gold_entailment': 0.37908293097279966, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3956043956043956, 'r1_recall': 0.4931506849315068, 'r1_f1': 0.43902439024390244, 'pegasus_entailment': 0.4444118719547987, 'gold_entailment': 0.2982013610502084, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7866666666666666, 'r1_recall': 0.4796747967479675, 'r1_f1': 0.5959595959595959, 'pegasus_entailment': 0.8370452523231506, 'gold_entailment': 0.4443937788407008, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 21, 'gold_ari': 30, 'gold_smog': 24}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3305785123966942, 'r1_recall': 0.5128205128205128, 'r1_f1': 0.4020100502512563, 'pegasus_entailment': 0.6187413148581982, 'gold_entailment': 0.22961276955902576, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 21, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 21, 'gold_ari': 29, 'gold_smog': 22}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46846846846846846, 'r1_recall': 0.6933333333333334, 'r1_f1': 0.5591397849462365, 'pegasus_entailment': 0.61427241563797, 'gold_entailment': 0.5292595326900482, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6595744680851063, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.5849056603773585, 'pegasus_entailment': 0.5190710723400116, 'gold_entailment': 0.16219192725839093, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 17}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42771084337349397, 'r1_recall': 0.6396396396396397, 'r1_f1': 0.5126353790613718, 'pegasus_entailment': 0.7405392527580261, 'gold_entailment': 0.554141528904438, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38926174496644295, 'r1_recall': 0.6904761904761905, 'r1_f1': 0.49785407725321895, 'pegasus_entailment': 0.6298483982682228, 'gold_entailment': 0.520937035481135, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41605839416058393, 'r1_recall': 0.5480769230769231, 'r1_f1': 0.47302904564315357, 'pegasus_entailment': 0.548842485062778, 'gold_entailment': 0.37701962391535443, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 21, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3560606060606061, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.4563106796116505, 'pegasus_entailment': 0.607223492860794, 'gold_entailment': 0.6234436432520548, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19900497512437812, 'r1_recall': 0.7843137254901961, 'r1_f1': 0.31746031746031744, 'pegasus_entailment': 0.5023507280275226, 'gold_entailment': 0.20820337533950806, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2893081761006289, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.39484978540772525, 'pegasus_entailment': 0.4229212626814842, 'gold_entailment': 0.2355069617430369, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6162790697674418, 'r1_recall': 0.2994350282485876, 'r1_f1': 0.40304182509505704, 'pegasus_entailment': 0.29961858689785004, 'gold_entailment': 0.27606385946273804, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.64375, 'r1_recall': 0.5786516853932584, 'r1_f1': 0.6094674556213018, 'pegasus_entailment': 0.4902019679546356, 'gold_entailment': 0.3164125746116042, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3617021276595745, 'r1_recall': 0.7083333333333334, 'r1_f1': 0.4788732394366197, 'pegasus_entailment': 0.5795364864170551, 'gold_entailment': 0.43442073464393616, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5911949685534591, 'r1_recall': 0.3745019920318725, 'r1_f1': 0.4585365853658537, 'pegasus_entailment': 0.6000876948237419, 'gold_entailment': 0.3794069561091336, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43157894736842106, 'r1_recall': 0.640625, 'r1_f1': 0.5157232704402516, 'pegasus_entailment': 0.4862620811909437, 'gold_entailment': 0.5141248181462288, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 21}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7345132743362832, 'r1_recall': 0.6859504132231405, 'r1_f1': 0.7094017094017094, 'pegasus_entailment': 0.45319875826438266, 'gold_entailment': 0.47109444066882133, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 19}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5742574257425742, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5631067961165049, 'pegasus_entailment': 0.4824264235794544, 'gold_entailment': 0.46931852400302887, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3591549295774648, 'r1_recall': 0.5795454545454546, 'r1_f1': 0.44347826086956527, 'pegasus_entailment': 0.7086425572633743, 'gold_entailment': 0.7641754150390625, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 22, 'gold_ari': 32, 'gold_smog': 21}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5066666666666667, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.5170068027210885, 'pegasus_entailment': 0.39562320585052174, 'gold_entailment': 0.0772534292191267, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 25, 'gold_smog': 17}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5225225225225225, 'r1_recall': 0.34523809523809523, 'r1_f1': 0.41577060931899645, 'pegasus_entailment': 0.6833944693207741, 'gold_entailment': 0.319033095613122, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 15}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4418604651162791, 'r1_recall': 0.3917525773195876, 'r1_f1': 0.4153005464480874, 'pegasus_entailment': 0.6160088951388994, 'gold_entailment': 0.37677286627391976, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3076923076923077, 'r1_recall': 0.75, 'r1_f1': 0.4363636363636364, 'pegasus_entailment': 0.5475229521592458, 'gold_entailment': 0.7838674187660217, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7549019607843137, 'r1_recall': 0.6062992125984252, 'r1_f1': 0.6724890829694323, 'pegasus_entailment': 0.5831493437290192, 'gold_entailment': 0.4276651442050934, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39473684210526316, 'r1_recall': 0.5660377358490566, 'r1_f1': 0.46511627906976744, 'pegasus_entailment': 0.8760405629873276, 'gold_entailment': 0.3882515400648117, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3563218390804598, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.4592592592592593, 'pegasus_entailment': 0.2959147404347147, 'gold_entailment': 0.34536723867058755, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7325581395348837, 'r1_recall': 0.5478260869565217, 'r1_f1': 0.626865671641791, 'pegasus_entailment': 0.2738794247270562, 'gold_entailment': 0.3109560728383561, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7966101694915254, 'r1_recall': 0.46078431372549017, 'r1_f1': 0.5838509316770185, 'pegasus_entailment': 0.5816609188914299, 'gold_entailment': 0.123036061724027, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.3373493975903614, 'r1_f1': 0.42748091603053434, 'pegasus_entailment': 0.4828009174671024, 'gold_entailment': 0.40880132040807177, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4077669902912621, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.49122807017543857, 'pegasus_entailment': 0.24761976599693297, 'gold_entailment': 0.20190025307238102, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3191489361702128, 'r1_recall': 0.6818181818181818, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.29473609558772296, 'gold_entailment': 0.2246767869219184, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 16, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6923076923076923, 'r1_recall': 0.5210526315789473, 'r1_f1': 0.5945945945945946, 'pegasus_entailment': 0.45553685538470745, 'gold_entailment': 0.3129086513072252, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.4166666666666667, 'pegasus_entailment': 0.35060054808855057, 'gold_entailment': 0.30718058347702026, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 22, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4956521739130435, 'r1_recall': 0.6705882352941176, 'r1_f1': 0.57, 'pegasus_entailment': 0.41699037204186123, 'gold_entailment': 0.4441030502319336, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35714285714285715, 'r1_recall': 0.546875, 'r1_f1': 0.43209876543209874, 'pegasus_entailment': 0.948105588555336, 'gold_entailment': 0.45756909681949764, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5409836065573771, 'r1_recall': 0.6346153846153846, 'r1_f1': 0.5840707964601771, 'pegasus_entailment': 0.4739167960360646, 'gold_entailment': 0.44624231196939945, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5185185185185185, 'r1_recall': 0.6511627906976745, 'r1_f1': 0.577319587628866, 'pegasus_entailment': 0.5669274429480234, 'gold_entailment': 0.4408782348036766, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44680851063829785, 'r1_recall': 0.6268656716417911, 'r1_f1': 0.5217391304347827, 'pegasus_entailment': 0.8823285400867462, 'gold_entailment': 0.47124032210558653, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45045045045045046, 'r1_recall': 0.6410256410256411, 'r1_f1': 0.5291005291005292, 'pegasus_entailment': 0.38218502700328827, 'gold_entailment': 0.3574437350034714, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 13, 'gold_ari': 12, 'gold_smog': 16}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8441558441558441, 'r1_recall': 0.6310679611650486, 'r1_f1': 0.7222222222222222, 'pegasus_entailment': 0.4334053322672844, 'gold_entailment': 0.15951498535772166, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 24}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28695652173913044, 'r1_recall': 0.5076923076923077, 'r1_f1': 0.3666666666666667, 'pegasus_entailment': 0.6322858929634094, 'gold_entailment': 0.3715967920919259, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5735294117647058, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.5032258064516129, 'pegasus_entailment': 0.22037683116892973, 'gold_entailment': 0.2224965455631415, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5887850467289719, 'r1_recall': 0.6847826086956522, 'r1_f1': 0.6331658291457286, 'pegasus_entailment': 0.37061692476272584, 'gold_entailment': 0.4040308119729161, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4642857142857143, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.456140350877193, 'pegasus_entailment': 0.5988945066928864, 'gold_entailment': 0.05708108423277736, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 23, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19298245614035087, 'r1_recall': 0.28205128205128205, 'r1_f1': 0.22916666666666666, 'pegasus_entailment': 0.8832955956459045, 'gold_entailment': 0.35342718847095966, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 20, 'gold_ari': 28, 'gold_smog': 25}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2909090909090909, 'r1_recall': 0.7111111111111111, 'r1_f1': 0.4129032258064516, 'pegasus_entailment': 0.7880307510495186, 'gold_entailment': 0.49168046936392784, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7634408602150538, 'r1_recall': 0.34134615384615385, 'r1_f1': 0.4717607973421926, 'pegasus_entailment': 0.6354798972606659, 'gold_entailment': 0.3413220900628302, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4725274725274725, 'r1_recall': 0.6142857142857143, 'r1_f1': 0.5341614906832297, 'pegasus_entailment': 0.6319387058028951, 'gold_entailment': 0.05042371929933628, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 17}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6453488372093024, 'r1_recall': 0.578125, 'r1_f1': 0.6098901098901099, 'pegasus_entailment': 0.6849488765001297, 'gold_entailment': 0.40099664218723774, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 26, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4358974358974359, 'r1_recall': 0.3805970149253731, 'r1_f1': 0.40637450199203184, 'pegasus_entailment': 0.3515203222632408, 'gold_entailment': 0.5819063544273376, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 13, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 21}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38848920863309355, 'r1_recall': 0.7397260273972602, 'r1_f1': 0.5094339622641509, 'pegasus_entailment': 0.5932557687163353, 'gold_entailment': 0.6098212897777557, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 17, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5679012345679012, 'r1_recall': 0.39316239316239315, 'r1_f1': 0.46464646464646464, 'pegasus_entailment': 0.6279519945383072, 'gold_entailment': 0.4593630730523728, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32727272727272727, 'r1_recall': 0.18556701030927836, 'r1_f1': 0.2368421052631579, 'pegasus_entailment': 0.989773690700531, 'gold_entailment': 0.0008654110206407495, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5642857142857143, 'r1_recall': 0.4463276836158192, 'r1_f1': 0.49842271293375395, 'pegasus_entailment': 0.7387932240962982, 'gold_entailment': 0.5791263182957967, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46788990825688076, 'r1_recall': 0.5257731958762887, 'r1_f1': 0.4951456310679612, 'pegasus_entailment': 0.5820118387540182, 'gold_entailment': 0.4793732911348343, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48695652173913045, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4647302904564315, 'pegasus_entailment': 0.7036953065544367, 'gold_entailment': 0.39366940249289784, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34782608695652173, 'r1_recall': 0.49230769230769234, 'r1_f1': 0.4076433121019108, 'pegasus_entailment': 0.8022560775279999, 'gold_entailment': 0.47808530926704407, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4069767441860465, 'r1_recall': 0.3125, 'r1_f1': 0.35353535353535354, 'pegasus_entailment': 0.7888848632574081, 'gold_entailment': 0.365379623156817, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3972602739726027, 'r1_recall': 0.47540983606557374, 'r1_f1': 0.4328358208955224, 'pegasus_entailment': 0.27943436926580034, 'gold_entailment': 0.6398592856712639, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 12, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44285714285714284, 'r1_recall': 0.32978723404255317, 'r1_f1': 0.3780487804878049, 'pegasus_entailment': 0.7204008623957634, 'gold_entailment': 0.5884177924599499, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 15, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6458333333333334, 'r1_recall': 0.5391304347826087, 'r1_f1': 0.5876777251184834, 'pegasus_entailment': 0.7017158567905426, 'gold_entailment': 0.5055292993783951, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4846153846153846, 'r1_recall': 0.5625, 'r1_f1': 0.5206611570247933, 'pegasus_entailment': 0.6186015401035547, 'gold_entailment': 0.1151046788727399, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 21, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4878048780487805, 'r1_recall': 0.75, 'r1_f1': 0.5911330049261083, 'pegasus_entailment': 0.6906870529055595, 'gold_entailment': 0.6343338117003441, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6493506493506493, 'r1_recall': 0.3875968992248062, 'r1_f1': 0.48543689320388345, 'pegasus_entailment': 0.6729603012402853, 'gold_entailment': 0.28474118933081627, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33879781420765026, 'r1_recall': 0.6019417475728155, 'r1_f1': 0.4335664335664336, 'pegasus_entailment': 0.6354487008518643, 'gold_entailment': 0.5262012198567391, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5563380281690141, 'r1_recall': 0.49375, 'r1_f1': 0.5231788079470199, 'pegasus_entailment': 0.7283593863248825, 'gold_entailment': 0.5833617951720953, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 19}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3418803418803419, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.4166666666666667, 'pegasus_entailment': 0.21197005982200304, 'gold_entailment': 0.014491177396848798, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 15, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29896907216494845, 'r1_recall': 0.48333333333333334, 'r1_f1': 0.36942675159235666, 'pegasus_entailment': 0.6654045879840851, 'gold_entailment': 0.3071797313168645, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 10, 'gold_coleman_liau': 13, 'gold_ari': 11, 'gold_smog': 15}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4888888888888889, 'r1_recall': 0.6376811594202898, 'r1_f1': 0.5534591194968553, 'pegasus_entailment': 0.9367663562297821, 'gold_entailment': 0.3754922126730283, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6746987951807228, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.5185185185185185, 'pegasus_entailment': 0.30863158591091633, 'gold_entailment': 0.5212389174848795, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 22}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4842105263157895, 'r1_recall': 0.5822784810126582, 'r1_f1': 0.5287356321839081, 'pegasus_entailment': 0.25897690607234836, 'gold_entailment': 0.3039111797697842, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 18, 'gold_ari': 27, 'gold_smog': 20}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45454545454545453, 'r1_recall': 0.5617977528089888, 'r1_f1': 0.5025125628140704, 'pegasus_entailment': 0.5754958242177963, 'gold_entailment': 0.3190098814666271, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39375, 'r1_recall': 0.4846153846153846, 'r1_f1': 0.43448275862068964, 'pegasus_entailment': 0.6463600308634341, 'gold_entailment': 0.18746358792607984, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7166666666666667, 'r1_recall': 0.48314606741573035, 'r1_f1': 0.5771812080536913, 'pegasus_entailment': 0.49724017083644867, 'gold_entailment': 0.33722649621112005, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7431192660550459, 'r1_recall': 0.4602272727272727, 'r1_f1': 0.5684210526315789, 'pegasus_entailment': 0.592577901482582, 'gold_entailment': 0.4391362794807979, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5390625, 'r1_recall': 0.5149253731343284, 'r1_f1': 0.5267175572519084, 'pegasus_entailment': 0.46350657168243614, 'gold_entailment': 0.35990245764454204, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.532608695652174, 'r1_recall': 0.5212765957446809, 'r1_f1': 0.5268817204301075, 'pegasus_entailment': 0.5202566684650568, 'gold_entailment': 0.17692635022103786, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 15, 'gold_ari': 20, 'gold_smog': 15}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7352941176470589, 'r1_recall': 0.3937007874015748, 'r1_f1': 0.5128205128205129, 'pegasus_entailment': 0.5885003283619881, 'gold_entailment': 0.4228528306952545, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43089430894308944, 'r1_recall': 0.6022727272727273, 'r1_f1': 0.5023696682464455, 'pegasus_entailment': 0.7550351023674011, 'gold_entailment': 0.39883021265268326, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6041666666666666, 'r1_recall': 0.5043478260869565, 'r1_f1': 0.5497630331753554, 'pegasus_entailment': 0.7457469031214714, 'gold_entailment': 0.5673329055309295, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35555555555555557, 'r1_recall': 0.631578947368421, 'r1_f1': 0.4549763033175355, 'pegasus_entailment': 0.6502661481499672, 'gold_entailment': 0.4879330576707919, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2013888888888889, 'r1_recall': 0.6744186046511628, 'r1_f1': 0.31016042780748665, 'pegasus_entailment': 0.44677775017917154, 'gold_entailment': 0.06445643212646246, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5394736842105263, 'r1_recall': 0.7321428571428571, 'r1_f1': 0.6212121212121212, 'pegasus_entailment': 0.4951264364644885, 'gold_entailment': 0.3352990100781123, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5511811023622047, 'r1_recall': 0.5343511450381679, 'r1_f1': 0.5426356589147286, 'pegasus_entailment': 0.5429381256302198, 'gold_entailment': 0.43681256224711734, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2702702702702703, 'r1_recall': 0.625, 'r1_f1': 0.3773584905660377, 'pegasus_entailment': 0.5427135569708688, 'gold_entailment': 0.4302612642447154, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5069444444444444, 'r1_recall': 0.6239316239316239, 'r1_f1': 0.5593869731800766, 'pegasus_entailment': 0.6278312843292951, 'gold_entailment': 0.33445290227731067, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5409836065573771, 'r1_recall': 0.5689655172413793, 'r1_f1': 0.5546218487394958, 'pegasus_entailment': 0.4938943423330784, 'gold_entailment': 0.4455862045288086, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 15, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 18, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5060240963855421, 'r1_recall': 0.711864406779661, 'r1_f1': 0.5915492957746479, 'pegasus_entailment': 0.261610348476097, 'gold_entailment': 0.15887310914695263, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 18}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7008547008547008, 'r1_recall': 0.43386243386243384, 'r1_f1': 0.5359477124183006, 'pegasus_entailment': 0.053654720385869346, 'gold_entailment': 0.11314713302999735, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6160714285714286, 'r1_recall': 0.5702479338842975, 'r1_f1': 0.5922746781115881, 'pegasus_entailment': 0.6616140076269706, 'gold_entailment': 0.6595242222150167, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 19, 'gold_ari': 28, 'gold_smog': 23}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5865384615384616, 'r1_recall': 0.3935483870967742, 'r1_f1': 0.47104247104247104, 'pegasus_entailment': 0.8311738967895508, 'gold_entailment': 0.6252789007765907, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.660377358490566, 'r1_recall': 0.4294478527607362, 'r1_f1': 0.5204460966542751, 'pegasus_entailment': 0.5586045771837235, 'gold_entailment': 0.41129820172985393, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4222222222222222, 'r1_recall': 0.5643564356435643, 'r1_f1': 0.4830508474576271, 'pegasus_entailment': 0.6839616795380911, 'gold_entailment': 0.4223140552639961, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5206611570247934, 'r1_f1': 0.5101214574898786, 'pegasus_entailment': 0.7361351648966471, 'gold_entailment': 0.4409015402197838, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 22, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3155080213903743, 'r1_recall': 0.6344086021505376, 'r1_f1': 0.4214285714285714, 'pegasus_entailment': 0.5712021868675947, 'gold_entailment': 0.33789269998669624, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6339285714285714, 'r1_recall': 0.5338345864661654, 'r1_f1': 0.5795918367346938, 'pegasus_entailment': 0.9594494104385376, 'gold_entailment': 0.6491177678108215, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7471264367816092, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.4779411764705882, 'pegasus_entailment': 0.6051113456487656, 'gold_entailment': 0.3115256801247597, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.6206896551724138, 'r1_f1': 0.5806451612903226, 'pegasus_entailment': 0.4338909188906352, 'gold_entailment': 0.5717878192663193, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 13, 'gold_smog': 17}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44047619047619047, 'r1_recall': 0.42045454545454547, 'r1_f1': 0.4302325581395349, 'pegasus_entailment': 0.32417843987544376, 'gold_entailment': 0.4749525027970473, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 23, 'gold_ari': 26, 'gold_smog': 25}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40594059405940597, 'r1_recall': 0.44086021505376344, 'r1_f1': 0.422680412371134, 'pegasus_entailment': 0.5831027865409851, 'gold_entailment': 0.37156326075394946, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 26, 'gold_smog': 24}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5813953488372093, 'r1_recall': 0.4424778761061947, 'r1_f1': 0.5025125628140704, 'pegasus_entailment': 0.7518425583839417, 'gold_entailment': 0.4521738390127818, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 22, 'gold_ari': 30, 'gold_smog': 26}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6458333333333334, 'r1_recall': 0.775, 'r1_f1': 0.7045454545454546, 'pegasus_entailment': 0.5264342606067658, 'gold_entailment': 0.586473761498928, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48695652173913045, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.5185185185185186, 'pegasus_entailment': 0.7917368561029434, 'gold_entailment': 0.4214214789015906, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 23}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5870967741935483, 'r1_recall': 0.4354066985645933, 'r1_f1': 0.5, 'pegasus_entailment': 0.8533371835947037, 'gold_entailment': 0.405370357632637, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 24, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 20, 'gold_ari': 29, 'gold_smog': 25}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.635036496350365, 'r1_recall': 0.48066298342541436, 'r1_f1': 0.5471698113207547, 'pegasus_entailment': 0.33208655193448067, 'gold_entailment': 0.32253599129617216, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.576271186440678, 'r1_f1': 0.422360248447205, 'pegasus_entailment': 0.7773483693599701, 'gold_entailment': 0.3588366413023323, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7727272727272727, 'r1_recall': 0.5246913580246914, 'r1_f1': 0.6250000000000001, 'pegasus_entailment': 0.35233226865530015, 'gold_entailment': 0.31061737090349195, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 21}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.410958904109589, 'r1_recall': 0.7317073170731707, 'r1_f1': 0.5263157894736841, 'pegasus_entailment': 0.5804445445537567, 'gold_entailment': 0.4412107566992442, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 24, 'gold_smog': 23}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5353535353535354, 'r1_recall': 0.5520833333333334, 'r1_f1': 0.5435897435897437, 'pegasus_entailment': 0.5641639828681946, 'gold_entailment': 0.3748807840049267, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48148148148148145, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.52, 'pegasus_entailment': 0.6642584651708603, 'gold_entailment': 0.1286857556551695, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 27, 'gold_coleman_liau': 21, 'gold_ari': 33, 'gold_smog': 27}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7735849056603774, 'r1_recall': 0.422680412371134, 'r1_f1': 0.5466666666666666, 'pegasus_entailment': 0.4198438860476017, 'gold_entailment': 0.3943897985986301, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49230769230769234, 'r1_recall': 0.3855421686746988, 'r1_f1': 0.43243243243243246, 'pegasus_entailment': 0.4962998367846012, 'gold_entailment': 0.4200523623398372, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 23, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 22, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41414141414141414, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.5189873417721519, 'pegasus_entailment': 0.9308434327443441, 'gold_entailment': 0.009914936497807503, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7017543859649122, 'r1_recall': 0.4624277456647399, 'r1_f1': 0.5574912891986062, 'pegasus_entailment': 0.5128360688686371, 'gold_entailment': 0.26308468942131313, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4727272727272727, 'r1_recall': 0.32098765432098764, 'r1_f1': 0.3823529411764705, 'pegasus_entailment': 0.7443737586339315, 'gold_entailment': 0.5206293761730194, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 24, 'gold_smog': 23}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5798319327731093, 'r1_recall': 0.46308724832214765, 'r1_f1': 0.5149253731343284, 'pegasus_entailment': 0.5328555116429925, 'gold_entailment': 0.2835363745689392, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40441176470588236, 'r1_recall': 0.5913978494623656, 'r1_f1': 0.48034934497816595, 'pegasus_entailment': 0.22325345177281028, 'gold_entailment': 0.270995682454668, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6666666666666666, 'r1_recall': 0.36024844720496896, 'r1_f1': 0.46774193548387105, 'pegasus_entailment': 0.16193794645369053, 'gold_entailment': 0.2225036503126224, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.14285714285714285, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.2165605095541401, 'pegasus_entailment': 0.7567152604460716, 'gold_entailment': 0.001480974373407662, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7411764705882353, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.6528497409326425, 'pegasus_entailment': 0.6786173780759176, 'gold_entailment': 0.39266572644313175, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 15, 'pegasus_ari': 26, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 19, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47058823529411764, 'r1_recall': 0.5436893203883495, 'r1_f1': 0.5045045045045046, 'pegasus_entailment': 0.7618859827518463, 'gold_entailment': 0.824240580201149, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6262626262626263, 'r1_recall': 0.3803680981595092, 'r1_f1': 0.4732824427480916, 'pegasus_entailment': 0.6872889906167984, 'gold_entailment': 0.6633848945299784, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 17}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.544, 'r1_recall': 0.6238532110091743, 'r1_f1': 0.5811965811965812, 'pegasus_entailment': 0.46053324174135923, 'gold_entailment': 0.5554791738589605, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 15, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4556213017751479, 'r1_recall': 0.4375, 'r1_f1': 0.4463768115942029, 'pegasus_entailment': 0.340929713845253, 'gold_entailment': 0.3536142572760582, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 16, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4329896907216495, 'r1_recall': 0.28, 'r1_f1': 0.3400809716599191, 'pegasus_entailment': 0.8374154766400655, 'gold_entailment': 0.4513792507350445, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5596330275229358, 'r1_recall': 0.4357142857142857, 'r1_f1': 0.4899598393574297, 'pegasus_entailment': 0.5379457697272301, 'gold_entailment': 0.28707756226261455, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5252525252525253, 'r1_recall': 0.348993288590604, 'r1_f1': 0.41935483870967744, 'pegasus_entailment': 0.5695684075355529, 'gold_entailment': 0.5050531670451164, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33507853403141363, 'r1_recall': 0.7032967032967034, 'r1_f1': 0.4539007092198582, 'pegasus_entailment': 0.7458828985691071, 'gold_entailment': 0.5571026653051376, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 18, 'gold_ari': 30, 'gold_smog': 22}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3103448275862069, 'r1_recall': 0.7012987012987013, 'r1_f1': 0.4302788844621514, 'pegasus_entailment': 0.7712846547365189, 'gold_entailment': 0.3698735535144806, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3821138211382114, 'r1_recall': 0.6438356164383562, 'r1_f1': 0.4795918367346939, 'pegasus_entailment': 0.6167517403761545, 'gold_entailment': 0.6255641227665668, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6767676767676768, 'r1_recall': 0.18206521739130435, 'r1_f1': 0.28693790149892934, 'pegasus_entailment': 0.710808277130127, 'gold_entailment': 0.4400969033057873, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48360655737704916, 'r1_recall': 0.5363636363636364, 'r1_f1': 0.5086206896551725, 'pegasus_entailment': 0.9679873585700989, 'gold_entailment': 0.13929199458410343, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 20, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5040650406504065, 'r1_recall': 0.5, 'r1_f1': 0.5020242914979758, 'pegasus_entailment': 0.5671283513307571, 'gold_entailment': 0.4746696650981903, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 34, 'gold_coleman_liau': 23, 'gold_ari': 42, 'gold_smog': 28}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6435643564356436, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.588235294117647, 'pegasus_entailment': 0.5552377477288246, 'gold_entailment': 0.2336856541223824, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8527131782945736, 'r1_recall': 0.46808510638297873, 'r1_f1': 0.6043956043956044, 'pegasus_entailment': 0.7436049729585648, 'gold_entailment': 0.5095073346580777, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4785276073619632, 'r1_recall': 0.5131578947368421, 'r1_f1': 0.49523809523809526, 'pegasus_entailment': 0.2570571191608906, 'gold_entailment': 0.18338259011507035, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34705882352941175, 'r1_recall': 0.686046511627907, 'r1_f1': 0.4609375, 'pegasus_entailment': 0.8001967370510101, 'gold_entailment': 0.3122670240700245, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 24, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37735849056603776, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.44198895027624313, 'pegasus_entailment': 0.613471694290638, 'gold_entailment': 0.42985916261871654, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42592592592592593, 'r1_recall': 0.5111111111111111, 'r1_f1': 0.4646464646464646, 'pegasus_entailment': 0.7761467099189758, 'gold_entailment': 0.7447324991226196, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6262626262626263, 'r1_recall': 0.3780487804878049, 'r1_f1': 0.4714828897338404, 'pegasus_entailment': 0.7720704317092896, 'gold_entailment': 0.6074502430856228, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8067226890756303, 'r1_recall': 0.3344947735191638, 'r1_f1': 0.47290640394088673, 'pegasus_entailment': 0.4899223489420755, 'gold_entailment': 0.4922215590874354, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7444444444444445, 'r1_recall': 0.3743016759776536, 'r1_f1': 0.49814126394052044, 'pegasus_entailment': 0.5254494808614254, 'gold_entailment': 0.16051801775271693, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.635593220338983, 'r1_recall': 0.6578947368421053, 'r1_f1': 0.6465517241379309, 'pegasus_entailment': 0.6169518694281578, 'gold_entailment': 0.34048312678933146, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7157894736842105, 'r1_recall': 0.5230769230769231, 'r1_f1': 0.6044444444444446, 'pegasus_entailment': 0.7436866958936056, 'gold_entailment': 0.5538119859993458, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48598130841121495, 'r1_recall': 0.5, 'r1_f1': 0.4928909952606635, 'pegasus_entailment': 0.5141741335391998, 'gold_entailment': 0.3341562694736889, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32653061224489793, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.41558441558441556, 'pegasus_entailment': 0.9363581299781799, 'gold_entailment': 0.3138007861562073, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7368421052631579, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.6086956521739131, 'pegasus_entailment': 0.6502813398838043, 'gold_entailment': 0.5176722288131714, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5258620689655172, 'r1_recall': 0.7922077922077922, 'r1_f1': 0.6321243523316062, 'pegasus_entailment': 0.23909423465374857, 'gold_entailment': 0.1279887811979279, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 17, 'gold_ari': 26, 'gold_smog': 23}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6166666666666667, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.5606060606060607, 'pegasus_entailment': 0.6333152949810028, 'gold_entailment': 0.3761278599500656, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6375, 'r1_recall': 0.68, 'r1_f1': 0.6580645161290323, 'pegasus_entailment': 0.48674211154381436, 'gold_entailment': 0.4722329992800951, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5826086956521739, 'r1_recall': 0.5537190082644629, 'r1_f1': 0.5677966101694916, 'pegasus_entailment': 0.7686481177806854, 'gold_entailment': 0.25367505609756336, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6293103448275862, 'r1_recall': 0.6576576576576577, 'r1_f1': 0.6431718061674009, 'pegasus_entailment': 0.4856155982706696, 'gold_entailment': 0.5882605759737393, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 23, 'gold_ari': 30, 'gold_smog': 24}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3775933609958506, 'r1_recall': 0.558282208588957, 'r1_f1': 0.4504950495049505, 'pegasus_entailment': 0.5759115325553077, 'gold_entailment': 0.3272162874539693, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5289855072463768, 'r1_recall': 0.4147727272727273, 'r1_f1': 0.46496815286624205, 'pegasus_entailment': 0.4558401834219694, 'gold_entailment': 0.3648712659875552, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 22}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5370370370370371, 'r1_recall': 0.725, 'r1_f1': 0.6170212765957447, 'pegasus_entailment': 0.8477127552032471, 'gold_entailment': 0.3789958581328392, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 19, 'pegasus_ari': 35, 'pegasus_smog': 24, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25984251968503935, 'r1_recall': 0.55, 'r1_f1': 0.3529411764705882, 'pegasus_entailment': 0.3334119077771902, 'gold_entailment': 0.08245798596180975, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 24}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3431372549019608, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4320987654320988, 'pegasus_entailment': 0.636118878920873, 'gold_entailment': 0.41628745570778847, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45098039215686275, 'r1_recall': 0.46938775510204084, 'r1_f1': 0.46, 'pegasus_entailment': 0.27661238946020605, 'gold_entailment': 0.1933226902037859, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5793103448275863, 'r1_recall': 0.6461538461538462, 'r1_f1': 0.6109090909090908, 'pegasus_entailment': 0.5802473098039627, 'gold_entailment': 0.4698334676878793, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.26744186046511625, 'r1_recall': 0.5, 'r1_f1': 0.34848484848484845, 'pegasus_entailment': 0.9689902663230896, 'gold_entailment': 0.6138170380145311, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 10, 'gold_coleman_liau': 13, 'gold_ari': 11, 'gold_smog': 15}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425531914893617, 'r1_recall': 0.7017543859649122, 'r1_f1': 0.5298013245033113, 'pegasus_entailment': 0.7063020638057164, 'gold_entailment': 0.4329674817621708, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4513888888888889, 'r1_recall': 0.5855855855855856, 'r1_f1': 0.5098039215686275, 'pegasus_entailment': 0.37567614763975143, 'gold_entailment': 0.4111532204385315, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7421875, 'r1_recall': 0.4337899543378995, 'r1_f1': 0.547550432276657, 'pegasus_entailment': 0.49755779653787613, 'gold_entailment': 0.31305099874734876, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5238095238095238, 'r1_recall': 0.6707317073170732, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.46703894352540376, 'gold_entailment': 0.6274175808066502, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5217391304347826, 'pegasus_entailment': 0.6698445677757263, 'gold_entailment': 0.43875676579773426, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 22}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5254237288135594, 'r1_recall': 0.6138613861386139, 'r1_f1': 0.5662100456621004, 'pegasus_entailment': 0.2012036107480526, 'gold_entailment': 0.18851906061172485, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 22}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5245901639344263, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.5565217391304348, 'pegasus_entailment': 0.148892781464383, 'gold_entailment': 0.17677475263675055, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 16, 'gold_ari': 13, 'gold_smog': 16}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.30864197530864196, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.3875968992248062, 'pegasus_entailment': 0.24117740616202354, 'gold_entailment': 0.334776830393821, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 24, 'gold_ari': 25, 'gold_smog': 24}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5789473684210527, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.5670103092783506, 'pegasus_entailment': 0.4717847093939781, 'gold_entailment': 0.4454313337802887, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.525, 'r1_recall': 0.6645569620253164, 'r1_f1': 0.5865921787709498, 'pegasus_entailment': 0.4405900090932846, 'gold_entailment': 0.13542329768339792, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 29, 'gold_coleman_liau': 19, 'gold_ari': 34, 'gold_smog': 25}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.45569620253164556, 'r1_f1': 0.5236363636363637, 'pegasus_entailment': 0.49487923085689545, 'gold_entailment': 0.4617698162794113, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 16, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5511363636363636, 'r1_recall': 0.5025906735751295, 'r1_f1': 0.5257452574525745, 'pegasus_entailment': 0.29461762734821867, 'gold_entailment': 0.28134285493029487, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7794117647058824, 'r1_recall': 0.5047619047619047, 'r1_f1': 0.6127167630057804, 'pegasus_entailment': 0.530771791934967, 'gold_entailment': 0.3329100493186464, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6753246753246753, 'r1_recall': 0.416, 'r1_f1': 0.5148514851485149, 'pegasus_entailment': 0.4908769230047862, 'gold_entailment': 0.4178646355867386, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4155844155844156, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.496124031007752, 'pegasus_entailment': 0.3218306914592783, 'gold_entailment': 0.02809669015308221, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2909090909090909, 'r1_recall': 0.5245901639344263, 'r1_f1': 0.3742690058479532, 'pegasus_entailment': 0.4155359868891537, 'gold_entailment': 0.01819443687175711, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 15, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4367816091954023, 'r1_recall': 0.6129032258064516, 'r1_f1': 0.5100671140939598, 'pegasus_entailment': 0.6187162047252059, 'gold_entailment': 0.4372031975071877, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2641509433962264, 'r1_recall': 0.4745762711864407, 'r1_f1': 0.33939393939393936, 'pegasus_entailment': 0.2560764290392399, 'gold_entailment': 0.29232625849545, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 16}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4830508474576271, 'r1_recall': 0.5, 'r1_f1': 0.49137931034482757, 'pegasus_entailment': 0.4594385226567586, 'gold_entailment': 0.2787841906150182, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35, 'r1_recall': 0.42424242424242425, 'r1_f1': 0.3835616438356164, 'pegasus_entailment': 0.5493820816278457, 'gold_entailment': 0.5097059905529022, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2641509433962264, 'r1_recall': 0.7, 'r1_f1': 0.3835616438356165, 'pegasus_entailment': 0.6479672193527222, 'gold_entailment': 0.44551197066903114, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 19}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43005181347150256, 'r1_recall': 0.4797687861271676, 'r1_f1': 0.453551912568306, 'pegasus_entailment': 0.37083046417683363, 'gold_entailment': 0.19915243238210678, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3828125, 'r1_recall': 0.6125, 'r1_f1': 0.4711538461538462, 'pegasus_entailment': 0.46769316991170246, 'gold_entailment': 0.3847366461995989, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 21, 'gold_ari': 20, 'gold_smog': 21}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5634920634920635, 'r1_recall': 0.398876404494382, 'r1_f1': 0.4671052631578947, 'pegasus_entailment': 0.6208313554525375, 'gold_entailment': 0.542765611410141, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6847826086956522, 'r1_recall': 0.391304347826087, 'r1_f1': 0.4980237154150197, 'pegasus_entailment': 0.30738015174865724, 'gold_entailment': 0.3746371205363955, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5031847133757962, 'r1_recall': 0.5895522388059702, 'r1_f1': 0.5429553264604812, 'pegasus_entailment': 0.46713510900735855, 'gold_entailment': 0.4230722486972809, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 24, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6442307692307693, 'r1_recall': 0.2757201646090535, 'r1_f1': 0.3861671469740634, 'pegasus_entailment': 0.42853888869285583, 'gold_entailment': 0.2520585760474205, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 29, 'gold_coleman_liau': 21, 'gold_ari': 34, 'gold_smog': 26}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5057471264367817, 'r1_recall': 0.5365853658536586, 'r1_f1': 0.5207100591715976, 'pegasus_entailment': 0.5051126380761465, 'gold_entailment': 0.5012525618076324, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6302521008403361, 'r1_recall': 0.4934210526315789, 'r1_f1': 0.5535055350553505, 'pegasus_entailment': 0.4768214076757431, 'gold_entailment': 0.3908864427357912, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 20}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2890625, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.36999999999999994, 'pegasus_entailment': 0.5657569055911154, 'gold_entailment': 0.4048581190407276, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 19}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.592, 'r1_recall': 0.33183856502242154, 'r1_f1': 0.4252873563218391, 'pegasus_entailment': 0.5065988171845675, 'gold_entailment': 0.3815760002894835, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24074074074074073, 'r1_recall': 0.23008849557522124, 'r1_f1': 0.23529411764705882, 'pegasus_entailment': 0.6262917995452881, 'gold_entailment': 0.170063110999763, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.25, 'r1_recall': 0.7391304347826086, 'r1_f1': 0.37362637362637363, 'pegasus_entailment': 0.753582701086998, 'gold_entailment': 0.5207799133689454, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 15}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6396396396396397, 'r1_recall': 0.39226519337016574, 'r1_f1': 0.4863013698630136, 'pegasus_entailment': 0.4896550714969635, 'gold_entailment': 0.3061299573164433, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6571428571428571, 'r1_recall': 0.3898305084745763, 'r1_f1': 0.4893617021276596, 'pegasus_entailment': 0.441116276755929, 'gold_entailment': 0.16910113543272018, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 24}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2975609756097561, 'r1_recall': 0.6354166666666666, 'r1_f1': 0.4053156146179402, 'pegasus_entailment': 0.8695572879579332, 'gold_entailment': 0.6246634252369404, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6126126126126126, 'r1_recall': 0.4689655172413793, 'r1_f1': 0.53125, 'pegasus_entailment': 0.8037609954675039, 'gold_entailment': 0.7510646070752826, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16470588235294117, 'r1_recall': 0.5, 'r1_f1': 0.24778761061946902, 'pegasus_entailment': 0.22543554659932852, 'gold_entailment': 0.07805763185024261, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 10, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 14}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1870967741935484, 'r1_recall': 0.5, 'r1_f1': 0.27230046948356806, 'pegasus_entailment': 0.6422848502794901, 'gold_entailment': 0.38828088715672493, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16, 'gold_flesch_kincaid': 11, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6896551724137931, 'r1_recall': 0.5042016806722689, 'r1_f1': 0.5825242718446602, 'pegasus_entailment': 0.5374885350465775, 'gold_entailment': 0.46125562706341344, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3697478991596639, 'r1_recall': 0.6197183098591549, 'r1_f1': 0.4631578947368421, 'pegasus_entailment': 0.6605775579810143, 'gold_entailment': 0.8766826788584391, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 21}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28440366972477066, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.3780487804878049, 'pegasus_entailment': 0.7092878520488739, 'gold_entailment': 0.3501824140548706, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23931623931623933, 'r1_recall': 0.345679012345679, 'r1_f1': 0.2828282828282828, 'pegasus_entailment': 0.382490579970181, 'gold_entailment': 0.43237057514488697, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7619047619047619, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.6666666666666666, 'pegasus_entailment': 0.7166617214679718, 'gold_entailment': 0.2777901791851036, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47126436781609193, 'r1_recall': 0.4939759036144578, 'r1_f1': 0.4823529411764706, 'pegasus_entailment': 0.2583414101973176, 'gold_entailment': 0.32960542136182386, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 17}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4888888888888889, 'r1_recall': 0.5945945945945946, 'r1_f1': 0.5365853658536586, 'pegasus_entailment': 0.4606471937149763, 'gold_entailment': 0.4020276218652725, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.82, 'r1_recall': 0.24404761904761904, 'r1_f1': 0.3761467889908257, 'pegasus_entailment': 0.5294976606965065, 'gold_entailment': 0.5425531376491893, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6153846153846154, 'r1_recall': 0.25225225225225223, 'r1_f1': 0.35782747603833864, 'pegasus_entailment': 0.4455788880586624, 'gold_entailment': 0.4044804833829403, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3389830508474576, 'r1_recall': 0.5128205128205128, 'r1_f1': 0.4081632653061224, 'pegasus_entailment': 0.7300939373672009, 'gold_entailment': 0.15819273640712103, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17, 'gold_flesch_kincaid': 9, 'gold_coleman_liau': 13, 'gold_ari': 11, 'gold_smog': 13}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6271186440677966, 'r1_recall': 0.7115384615384616, 'r1_f1': 0.6666666666666666, 'pegasus_entailment': 0.5504718772135675, 'gold_entailment': 0.4064350239932537, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 16}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2331288343558282, 'r1_recall': 0.5205479452054794, 'r1_f1': 0.3220338983050847, 'pegasus_entailment': 0.5639211755866805, 'gold_entailment': 0.37724727333988994, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42168674698795183, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.47297297297297297, 'pegasus_entailment': 0.08702689819037915, 'gold_entailment': 0.14111190289258957, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6081081081081081, 'r1_recall': 0.625, 'r1_f1': 0.6164383561643835, 'pegasus_entailment': 0.6027447432279587, 'gold_entailment': 0.5571541090806326, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.6049382716049383, 'r1_f1': 0.5939393939393939, 'pegasus_entailment': 0.8534751087427139, 'gold_entailment': 0.5054758107289672, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33043478260869563, 'r1_recall': 0.5, 'r1_f1': 0.39790575916230364, 'pegasus_entailment': 0.8699091871579488, 'gold_entailment': 0.6454972103238106, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 15}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.5487804878048781, 'pegasus_entailment': 0.5013197595253587, 'gold_entailment': 0.4206629067659378, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 17, 'gold_ari': 14, 'gold_smog': 15}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.62, 'r1_recall': 0.39490445859872614, 'r1_f1': 0.4824902723735409, 'pegasus_entailment': 0.7633824944496155, 'gold_entailment': 0.6291903725692204, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7475728155339806, 'r1_recall': 0.5347222222222222, 'r1_f1': 0.6234817813765182, 'pegasus_entailment': 0.4943821653723717, 'gold_entailment': 0.6122700199484825, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41836734693877553, 'r1_recall': 0.43617021276595747, 'r1_f1': 0.42708333333333337, 'pegasus_entailment': 0.35166961851064116, 'gold_entailment': 0.01185196750642111, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 17}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.59, 'r1_recall': 0.6178010471204188, 'r1_f1': 0.6035805626598465, 'pegasus_entailment': 0.4914821854659489, 'gold_entailment': 0.23785632736980916, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2692307692307692, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.3910614525139664, 'pegasus_entailment': 0.9808341562747955, 'gold_entailment': 0.01936294138431549, 'pegasus_flesch_kincaid': 35, 'pegasus_coleman_liau': 22, 'pegasus_ari': 43, 'pegasus_smog': 29, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5733333333333334, 'r1_recall': 0.5180722891566265, 'r1_f1': 0.5443037974683543, 'pegasus_entailment': 0.561043782858178, 'gold_entailment': 0.5234314799308777, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4672897196261682, 'r1_recall': 0.6410256410256411, 'r1_f1': 0.5405405405405406, 'pegasus_entailment': 0.6239297837018967, 'gold_entailment': 0.37708954969421027, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 15, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 17, 'gold_ari': 15, 'gold_smog': 13}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5045871559633027, 'r1_recall': 0.6790123456790124, 'r1_f1': 0.5789473684210527, 'pegasus_entailment': 0.5367444299161435, 'gold_entailment': 0.44693438708782196, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5165562913907285, 'r1_recall': 0.5693430656934306, 'r1_f1': 0.5416666666666666, 'pegasus_entailment': 0.7777893662452697, 'gold_entailment': 0.46349689960479734, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24324324324324326, 'r1_recall': 0.4090909090909091, 'r1_f1': 0.3050847457627119, 'pegasus_entailment': 0.5335994704316059, 'gold_entailment': 0.07506494969129562, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 28, 'gold_coleman_liau': 25, 'gold_ari': 35, 'gold_smog': 30}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2631578947368421, 'r1_recall': 0.5084745762711864, 'r1_f1': 0.3468208092485549, 'pegasus_entailment': 0.8066587895154953, 'gold_entailment': 0.2890716725960374, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5384615384615384, 'r1_recall': 0.5746268656716418, 'r1_f1': 0.555956678700361, 'pegasus_entailment': 0.5288810759782792, 'gold_entailment': 0.5306823054949442, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6597938144329897, 'r1_recall': 0.41025641025641024, 'r1_f1': 0.5059288537549407, 'pegasus_entailment': 0.43965157369772595, 'gold_entailment': 0.16293240152299404, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38333333333333336, 'r1_recall': 0.7076923076923077, 'r1_f1': 0.49729729729729727, 'pegasus_entailment': 0.7633189161618551, 'gold_entailment': 0.5289441142231226, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 24, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 15, 'gold_ari': 14, 'gold_smog': 15}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39285714285714285, 'r1_recall': 0.5, 'r1_f1': 0.44, 'pegasus_entailment': 0.5217139100035032, 'gold_entailment': 0.3093561129644513, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5308641975308642, 'r1_recall': 0.5119047619047619, 'r1_f1': 0.5212121212121211, 'pegasus_entailment': 0.7101891239484152, 'gold_entailment': 0.5483917246262232, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 17, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36363636363636365, 'r1_recall': 0.4155844155844156, 'r1_f1': 0.38787878787878793, 'pegasus_entailment': 0.5119253508746624, 'gold_entailment': 0.25849786897500354, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2916666666666667, 'r1_recall': 0.525, 'r1_f1': 0.37500000000000006, 'pegasus_entailment': 0.5735501885414124, 'gold_entailment': 0.3306366664667924, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5148514851485149, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5810055865921788, 'pegasus_entailment': 0.7151769740240914, 'gold_entailment': 0.34429857805371283, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3877551020408163, 'r1_recall': 0.5, 'r1_f1': 0.43678160919540227, 'pegasus_entailment': 0.41372030377388, 'gold_entailment': 0.3919481833775838, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2786885245901639, 'r1_recall': 0.6, 'r1_f1': 0.3805970149253731, 'pegasus_entailment': 0.4888289677245276, 'gold_entailment': 0.4459564693272114, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6782608695652174, 'r1_recall': 0.5954198473282443, 'r1_f1': 0.6341463414634146, 'pegasus_entailment': 0.4069873919710517, 'gold_entailment': 0.49441533039013547, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 22, 'gold_ari': 32, 'gold_smog': 25}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5517241379310345, 'r1_recall': 0.4528301886792453, 'r1_f1': 0.4974093264248704, 'pegasus_entailment': 0.31677574043472606, 'gold_entailment': 0.2969045517966151, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6694214876033058, 'r1_recall': 0.4426229508196721, 'r1_f1': 0.5328947368421052, 'pegasus_entailment': 0.8042348474264145, 'gold_entailment': 0.27694701350161005, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3770491803278688, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.46464646464646464, 'pegasus_entailment': 0.3983178536097209, 'gold_entailment': 0.47234558407217264, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 22, 'pegasus_ari': 31, 'pegasus_smog': 24, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4878048780487805, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.5581395348837209, 'pegasus_entailment': 0.41429625265300274, 'gold_entailment': 0.35849029074112576, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7272727272727273, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.6299212598425198, 'pegasus_entailment': 0.4175658017396927, 'gold_entailment': 0.5060733978947004, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6101694915254238, 'r1_recall': 0.3564356435643564, 'r1_f1': 0.45, 'pegasus_entailment': 0.027322534006088972, 'gold_entailment': 0.05588476941920817, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5185185185185185, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5436893203883496, 'pegasus_entailment': 0.3227109824074432, 'gold_entailment': 0.0994844107190147, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.5625000000000001, 'pegasus_entailment': 0.6369003109866753, 'gold_entailment': 0.0996675374917686, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 22, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6592592592592592, 'r1_recall': 0.6691729323308271, 'r1_f1': 0.664179104477612, 'pegasus_entailment': 0.47892444650642574, 'gold_entailment': 0.5281771961599588, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 25}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5277777777777778, 'r1_recall': 0.4222222222222222, 'r1_f1': 0.46913580246913583, 'pegasus_entailment': 0.4055817524592082, 'gold_entailment': 0.2564845234155655, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43478260869565216, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.396284032613039, 'gold_entailment': 0.4591295897960663, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 21}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41964285714285715, 'r1_recall': 0.42342342342342343, 'r1_f1': 0.4215246636771301, 'pegasus_entailment': 0.665084034204483, 'gold_entailment': 0.51890729367733, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7358490566037735, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.6393442622950819, 'pegasus_entailment': 0.7704564929008484, 'gold_entailment': 0.5325973076202596, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23076923076923078, 'r1_recall': 0.54, 'r1_f1': 0.32335329341317365, 'pegasus_entailment': 0.10709759835153818, 'gold_entailment': 0.02856582053937018, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 15, 'gold_smog': 18}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27044025157232704, 'r1_recall': 0.7678571428571429, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.4307361841201782, 'gold_entailment': 0.34381429354349774, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2153846153846154, 'r1_recall': 0.2978723404255319, 'r1_f1': 0.25, 'pegasus_entailment': 0.38805734117825824, 'gold_entailment': 0.4855263829231262, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 14, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.425, 'r1_recall': 0.4788732394366197, 'r1_f1': 0.45033112582781454, 'pegasus_entailment': 0.4726495295763016, 'gold_entailment': 0.08087711366824805, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 17, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5533980582524272, 'r1_recall': 0.3114754098360656, 'r1_f1': 0.3986013986013986, 'pegasus_entailment': 0.33548392355442047, 'gold_entailment': 0.3407306674635038, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5631067961165048, 'r1_recall': 0.4233576642335766, 'r1_f1': 0.48333333333333334, 'pegasus_entailment': 0.8609839081764221, 'gold_entailment': 0.130555992325147, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 20, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 19, 'gold_ari': 31, 'gold_smog': 24}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6764705882352942, 'r1_recall': 0.5054945054945055, 'r1_f1': 0.5786163522012578, 'pegasus_entailment': 0.6435031990210215, 'gold_entailment': 0.5267151594161987, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 27, 'gold_coleman_liau': 21, 'gold_ari': 32, 'gold_smog': 26}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5034013605442177, 'r1_recall': 0.556390977443609, 'r1_f1': 0.5285714285714286, 'pegasus_entailment': 0.4667734056711197, 'gold_entailment': 0.5137449922040105, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5325443786982249, 'r1_recall': 0.5487804878048781, 'r1_f1': 0.5405405405405406, 'pegasus_entailment': 0.39296892533699673, 'gold_entailment': 0.2821655347943306, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 17, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7884615384615384, 'r1_recall': 0.4079601990049751, 'r1_f1': 0.5377049180327867, 'pegasus_entailment': 0.7278128067652384, 'gold_entailment': 0.27594199823215604, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 24, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3592233009708738, 'r1_recall': 0.37, 'r1_f1': 0.3645320197044335, 'pegasus_entailment': 0.38528786102930707, 'gold_entailment': 0.2942257250348727, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 26, 'gold_smog': 25}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6231884057971014, 'r1_recall': 0.5375, 'r1_f1': 0.5771812080536913, 'pegasus_entailment': 0.4951770300976932, 'gold_entailment': 0.5575645267963409, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.449438202247191, 'r1_recall': 0.4878048780487805, 'r1_f1': 0.4678362573099415, 'pegasus_entailment': 0.036385397892445326, 'gold_entailment': 0.21970761958800722, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 25, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2823529411764706, 'r1_recall': 0.5, 'r1_f1': 0.3609022556390977, 'pegasus_entailment': 0.21853036747779697, 'gold_entailment': 0.1416958992679914, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 17, 'gold_smog': 19}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3046875, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.4083769633507853, 'pegasus_entailment': 0.6752748680301011, 'gold_entailment': 0.32572677250330645, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.225, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.31578947368421056, 'pegasus_entailment': 0.15956347668543458, 'gold_entailment': 0.07542950293282047, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 21, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3835616438356164, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.3758389261744966, 'pegasus_entailment': 0.38182199001312256, 'gold_entailment': 0.04064810276031494, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 38, 'gold_coleman_liau': 19, 'gold_ari': 46, 'gold_smog': 30}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6057692307692307, 'r1_recall': 0.3423913043478261, 'r1_f1': 0.43750000000000006, 'pegasus_entailment': 0.6280152425169945, 'gold_entailment': 0.5992544293403625, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 25, 'gold_smog': 19}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2391304347826087, 'r1_recall': 0.3283582089552239, 'r1_f1': 0.2767295597484277, 'pegasus_entailment': 0.33417019844055174, 'gold_entailment': 0.16365988552570343, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 16}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6814159292035398, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.5480427046263345, 'pegasus_entailment': 0.479865600168705, 'gold_entailment': 0.382345041881005, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6141732283464567, 'r1_recall': 0.5909090909090909, 'r1_f1': 0.6023166023166022, 'pegasus_entailment': 0.28141659051179885, 'gold_entailment': 0.29884912772104144, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 20, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6923076923076923, 'r1_recall': 0.45569620253164556, 'r1_f1': 0.549618320610687, 'pegasus_entailment': 0.3308212459087372, 'gold_entailment': 0.6176746189594269, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6831683168316832, 'r1_recall': 0.23310810810810811, 'r1_f1': 0.34760705289672544, 'pegasus_entailment': 0.6380592361092567, 'gold_entailment': 0.365424092572469, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3577981651376147, 'r1_recall': 0.7090909090909091, 'r1_f1': 0.475609756097561, 'pegasus_entailment': 0.5887458583872233, 'gold_entailment': 0.338435849485298, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7333333333333333, 'r1_recall': 0.39086294416243655, 'r1_f1': 0.509933774834437, 'pegasus_entailment': 0.20490989042446017, 'gold_entailment': 0.2021928975979487, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 21, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34615384615384615, 'r1_recall': 0.6, 'r1_f1': 0.43902439024390244, 'pegasus_entailment': 0.06493831301728885, 'gold_entailment': 0.048695915611460805, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 23, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5714285714285714, 'r1_recall': 0.4878048780487805, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.7332732230424881, 'gold_entailment': 0.725471094250679, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 18}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5742574257425742, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5631067961165049, 'pegasus_entailment': 0.5579222937424978, 'gold_entailment': 0.44354602694511414, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 23, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 22}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7368421052631579, 'r1_recall': 0.5343511450381679, 'r1_f1': 0.6194690265486725, 'pegasus_entailment': 0.28946630097925663, 'gold_entailment': 0.37624027331670123, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 18, 'gold_ari': 29, 'gold_smog': 20}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.34951456310679613, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.4235294117647059, 'pegasus_entailment': 0.36451474018394947, 'gold_entailment': 0.40991804003715515, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 16}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.24375, 'r1_recall': 0.6842105263157895, 'r1_f1': 0.35944700460829493, 'pegasus_entailment': 0.43909582992394763, 'gold_entailment': 0.6405704021453857, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 21, 'pegasus_ari': 36, 'pegasus_smog': 25, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 23, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3046875, 'r1_recall': 0.6842105263157895, 'r1_f1': 0.42162162162162165, 'pegasus_entailment': 0.6631737500429153, 'gold_entailment': 0.6222971975803375, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5619047619047619, 'r1_recall': 0.4609375, 'r1_f1': 0.5064377682403434, 'pegasus_entailment': 0.2649472542107105, 'gold_entailment': 0.28554567992687224, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6692913385826772, 'r1_recall': 0.47752808988764045, 'r1_f1': 0.5573770491803278, 'pegasus_entailment': 0.5736024053767323, 'gold_entailment': 0.6158444344997406, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5850340136054422, 'r1_recall': 0.5276073619631901, 'r1_f1': 0.5548387096774194, 'pegasus_entailment': 0.7714420159657797, 'gold_entailment': 0.4366451442241669, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6178861788617886, 'r1_recall': 0.39378238341968913, 'r1_f1': 0.4810126582278481, 'pegasus_entailment': 0.7864760756492615, 'gold_entailment': 0.4550936213797993, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.472, 'r1_recall': 0.5841584158415841, 'r1_f1': 0.5221238938053097, 'pegasus_entailment': 0.7424290895462036, 'gold_entailment': 0.08544209351142247, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 15, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 23, 'gold_smog': 17}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4188034188034188, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.48756218905472637, 'pegasus_entailment': 0.4023629905035098, 'gold_entailment': 0.3632155954837799, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.373015873015873, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.4351851851851852, 'pegasus_entailment': 0.7226472187787294, 'gold_entailment': 0.6624298505485058, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 23, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2736842105263158, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.3561643835616438, 'pegasus_entailment': 0.11675985405842464, 'gold_entailment': 0.27595046907663345, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6118421052631579, 'r1_recall': 0.6283783783783784, 'r1_f1': 0.62, 'pegasus_entailment': 0.6362300763527552, 'gold_entailment': 0.3641702277319772, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 15, 'gold_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5703703703703704, 'r1_recall': 0.5877862595419847, 'r1_f1': 0.5789473684210527, 'pegasus_entailment': 0.720140489935875, 'gold_entailment': 0.346959562599659, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5784313725490197, 'r1_recall': 0.5, 'r1_f1': 0.5363636363636364, 'pegasus_entailment': 0.8698602616786957, 'gold_entailment': 0.03591304668225348, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8, 'r1_recall': 0.5230769230769231, 'r1_f1': 0.6325581395348837, 'pegasus_entailment': 0.5753185078501701, 'gold_entailment': 0.3154743850231171, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5647058823529412, 'r1_recall': 0.40336134453781514, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.24264019075781107, 'gold_entailment': 0.39928197488188744, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6956521739130435, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.6177606177606177, 'pegasus_entailment': 0.5201976792886853, 'gold_entailment': 0.37492545396089555, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5161290322580645, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5245901639344263, 'pegasus_entailment': 0.2776159793138504, 'gold_entailment': 0.19206691207364202, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 15}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6, 'r1_recall': 0.6541353383458647, 'r1_f1': 0.6258992805755396, 'pegasus_entailment': 0.701292042930921, 'gold_entailment': 0.443665087223053, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5202702702702703, 'r1_recall': 0.3632075471698113, 'r1_f1': 0.4277777777777778, 'pegasus_entailment': 0.7876913448174795, 'gold_entailment': 0.48462880328297614, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3023255813953488, 'r1_recall': 0.45614035087719296, 'r1_f1': 0.3636363636363636, 'pegasus_entailment': 0.3516860917210579, 'gold_entailment': 0.648234635591507, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5086206896551724, 'r1_recall': 0.4609375, 'r1_f1': 0.48360655737704916, 'pegasus_entailment': 0.7063781172037125, 'gold_entailment': 0.37827932396903635, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22023809523809523, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.3288888888888889, 'pegasus_entailment': 0.49173719584941866, 'gold_entailment': 0.30084139481186867, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 22}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6915887850467289, 'r1_recall': 0.387434554973822, 'r1_f1': 0.4966442953020135, 'pegasus_entailment': 0.4860863536596298, 'gold_entailment': 0.36655490951878683, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4880952380952381, 'r1_recall': 0.5578231292517006, 'r1_f1': 0.5206349206349206, 'pegasus_entailment': 0.43276001885533333, 'gold_entailment': 0.3166217717031638, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 21}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4431137724550898, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.46105919003115264, 'pegasus_entailment': 0.8728111743927002, 'gold_entailment': 0.5257430076599121, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41605839416058393, 'r1_recall': 0.76, 'r1_f1': 0.5377358490566038, 'pegasus_entailment': 0.8480560630559921, 'gold_entailment': 0.5537057756446302, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.553030303030303, 'r1_recall': 0.6347826086956522, 'r1_f1': 0.5910931174089068, 'pegasus_entailment': 0.6458246197019305, 'gold_entailment': 0.32668511755764484, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 15, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.616822429906542, 'r1_recall': 0.43137254901960786, 'r1_f1': 0.5076923076923077, 'pegasus_entailment': 0.7097740322351456, 'gold_entailment': 0.37749894335865974, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5370370370370371, 'r1_recall': 0.5686274509803921, 'r1_f1': 0.5523809523809524, 'pegasus_entailment': 0.09025252256542445, 'gold_entailment': 0.3003640715032816, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3069306930693069, 'r1_recall': 0.543859649122807, 'r1_f1': 0.3924050632911393, 'pegasus_entailment': 0.3961614891886711, 'gold_entailment': 0.24751507739226022, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 21, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43023255813953487, 'r1_recall': 0.578125, 'r1_f1': 0.49333333333333335, 'pegasus_entailment': 0.48122696205973625, 'gold_entailment': 0.27557611442171037, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4787234042553192, 'r1_recall': 0.6, 'r1_f1': 0.5325443786982249, 'pegasus_entailment': 0.28445637474457425, 'gold_entailment': 0.2210256028920412, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 21, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47619047619047616, 'r1_recall': 0.7547169811320755, 'r1_f1': 0.5839416058394161, 'pegasus_entailment': 0.8553995341062546, 'gold_entailment': 0.7505869269371033, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 15, 'gold_ari': 14, 'gold_smog': 17}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5486725663716814, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6019417475728155, 'pegasus_entailment': 0.4613921120762825, 'gold_entailment': 0.2753560334444046, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5064935064935064, 'r1_recall': 0.6724137931034483, 'r1_f1': 0.5777777777777778, 'pegasus_entailment': 0.4831901916768402, 'gold_entailment': 0.6944848448038101, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 12, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6938775510204082, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6799999999999999, 'pegasus_entailment': 0.4707633312791586, 'gold_entailment': 0.48433642089366913, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 28, 'gold_coleman_liau': 18, 'gold_ari': 33, 'gold_smog': 25}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.65, 'r1_recall': 0.41139240506329117, 'r1_f1': 0.5038759689922481, 'pegasus_entailment': 0.6501880008727312, 'gold_entailment': 0.2958093211054802, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3142857142857143, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.40740740740740744, 'pegasus_entailment': 0.23922596328581372, 'gold_entailment': 0.24630354903638363, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 23, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5869565217391305, 'r1_recall': 0.5436241610738255, 'r1_f1': 0.5644599303135888, 'pegasus_entailment': 0.5400812506675721, 'gold_entailment': 0.4694910109043121, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5445544554455446, 'r1_recall': 0.40145985401459855, 'r1_f1': 0.46218487394957986, 'pegasus_entailment': 0.6341959804296493, 'gold_entailment': 0.3086937256157398, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 23}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.6818181818181818, 'r1_f1': 0.576923076923077, 'pegasus_entailment': 0.22790134645765647, 'gold_entailment': 0.32550959661602974, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851063829787234, 'r1_recall': 0.4954954954954955, 'r1_f1': 0.5365853658536586, 'pegasus_entailment': 0.6454927722613016, 'gold_entailment': 0.626514345407486, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2824858757062147, 'r1_recall': 0.625, 'r1_f1': 0.38910505836575876, 'pegasus_entailment': 0.662777203321457, 'gold_entailment': 0.2518798417877406, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5384615384615384, 'r1_recall': 0.3858267716535433, 'r1_f1': 0.4495412844036697, 'pegasus_entailment': 0.6673648655414581, 'gold_entailment': 0.46485574756349834, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7142857142857143, 'r1_recall': 0.45685279187817257, 'r1_f1': 0.5572755417956656, 'pegasus_entailment': 0.48399512097239494, 'gold_entailment': 0.47930464381352067, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7226890756302521, 'r1_recall': 0.35390946502057613, 'r1_f1': 0.47513812154696133, 'pegasus_entailment': 0.48341700434684753, 'gold_entailment': 0.19440931314602494, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 17, 'gold_ari': 24, 'gold_smog': 20}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7721518987341772, 'r1_recall': 0.43884892086330934, 'r1_f1': 0.5596330275229358, 'pegasus_entailment': 0.4624102876987308, 'gold_entailment': 0.5317986130539794, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1875, 'r1_recall': 0.2465753424657534, 'r1_f1': 0.21301775147928995, 'pegasus_entailment': 0.002802051545586437, 'gold_entailment': 0.011228120458933214, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 20, 'gold_ari': 27, 'gold_smog': 24}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.29213483146067415, 'r1_recall': 0.4262295081967213, 'r1_f1': 0.3466666666666666, 'pegasus_entailment': 0.12440862786024809, 'gold_entailment': 0.05375770421233028, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 14, 'pegasus_ari': 11, 'pegasus_smog': 12, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5252525252525253, 'r1_recall': 0.6046511627906976, 'r1_f1': 0.5621621621621622, 'pegasus_entailment': 0.6038991049863398, 'gold_entailment': 0.34510510445882875, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4673913043478261, 'r1_recall': 0.581081081081081, 'r1_f1': 0.5180722891566265, 'pegasus_entailment': 0.26027009015281993, 'gold_entailment': 0.21066339313983917, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7303370786516854, 'r1_recall': 0.3735632183908046, 'r1_f1': 0.49429657794676807, 'pegasus_entailment': 0.44532370115630326, 'gold_entailment': 0.25103636607527735, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 22}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45217391304347826, 'r1_recall': 0.3611111111111111, 'r1_f1': 0.4015444015444015, 'pegasus_entailment': 0.19654152039438486, 'gold_entailment': 0.2533270694315434, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6936936936936937, 'r1_recall': 0.39487179487179486, 'r1_f1': 0.5032679738562091, 'pegasus_entailment': 0.7262692302465439, 'gold_entailment': 0.4992276310920715, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 18, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5609756097560976, 'r1_recall': 0.6301369863013698, 'r1_f1': 0.5935483870967743, 'pegasus_entailment': 0.5703517124056816, 'gold_entailment': 0.557810865342617, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4594594594594595, 'r1_recall': 0.68, 'r1_f1': 0.5483870967741935, 'pegasus_entailment': 0.4544612541794777, 'gold_entailment': 0.33694658692305285, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49019607843137253, 'r1_recall': 0.43859649122807015, 'r1_f1': 0.46296296296296297, 'pegasus_entailment': 0.7797038406133652, 'gold_entailment': 0.6019188389182091, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7586206896551724, 'r1_recall': 0.17553191489361702, 'r1_f1': 0.28509719222462204, 'pegasus_entailment': 0.4930597096681595, 'gold_entailment': 0.5267946179956198, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4430379746835443, 'r1_recall': 0.5932203389830508, 'r1_f1': 0.5072463768115942, 'pegasus_entailment': 0.7786299586296082, 'gold_entailment': 0.7776883641878763, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5702479338842975, 'r1_recall': 0.4107142857142857, 'r1_f1': 0.4775086505190311, 'pegasus_entailment': 0.7133971899747849, 'gold_entailment': 0.4468252675142139, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5172413793103449, 'r1_recall': 0.46511627906976744, 'r1_f1': 0.4897959183673469, 'pegasus_entailment': 0.5425601094961167, 'gold_entailment': 0.3347137368284166, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 22}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45098039215686275, 'r1_recall': 0.46308724832214765, 'r1_f1': 0.45695364238410596, 'pegasus_entailment': 0.762558114528656, 'gold_entailment': 0.41083624213933945, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 18, 'gold_ari': 26, 'gold_smog': 21}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5317919075144508, 'r1_recall': 0.5443786982248521, 'r1_f1': 0.5380116959064327, 'pegasus_entailment': 0.4170837886631489, 'gold_entailment': 0.24450431444815227, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.591304347826087, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.5528455284552846, 'pegasus_entailment': 0.4893946126103401, 'gold_entailment': 0.28794454857707025, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 17, 'pegasus_ari': 35, 'pegasus_smog': 24, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40425531914893614, 'r1_recall': 0.3064516129032258, 'r1_f1': 0.34862385321100914, 'pegasus_entailment': 0.7241023977597555, 'gold_entailment': 0.4554596294959386, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41353383458646614, 'r1_recall': 0.6626506024096386, 'r1_f1': 0.5092592592592593, 'pegasus_entailment': 0.43734047282487154, 'gold_entailment': 0.4315773434937, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.27058823529411763, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.3709677419354838, 'pegasus_entailment': 0.33076416701078415, 'gold_entailment': 0.16193843260407448, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5287356321839081, 'r1_recall': 0.39655172413793105, 'r1_f1': 0.4532019704433498, 'pegasus_entailment': 0.3575606355443597, 'gold_entailment': 0.2951561287045479, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 23}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5899280575539568, 'r1_recall': 0.44324324324324327, 'r1_f1': 0.5061728395061729, 'pegasus_entailment': 0.5705349400639534, 'gold_entailment': 0.4292580485343933, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7142857142857143, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.6954572548468908, 'gold_entailment': 0.03789310979967316, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 26, 'gold_coleman_liau': 17, 'gold_ari': 31, 'gold_smog': 23}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6985294117647058, 'r1_recall': 0.24675324675324675, 'r1_f1': 0.36468330134357, 'pegasus_entailment': 0.49483497589826586, 'gold_entailment': 0.2790159705807181, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6915887850467289, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.5896414342629482, 'pegasus_entailment': 0.6116052567958832, 'gold_entailment': 0.5134633978207906, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2781954887218045, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.37373737373737365, 'pegasus_entailment': 0.8069819062948227, 'gold_entailment': 0.562969450528423, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42105263157894735, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5161290322580646, 'pegasus_entailment': 0.45717047809739597, 'gold_entailment': 0.1043025025477012, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43529411764705883, 'r1_recall': 0.4567901234567901, 'r1_f1': 0.4457831325301204, 'pegasus_entailment': 0.3351326098976036, 'gold_entailment': 0.1214962319645565, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 16}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5402298850574713, 'r1_recall': 0.4519230769230769, 'r1_f1': 0.49214659685863876, 'pegasus_entailment': 0.6541886428991953, 'gold_entailment': 0.616302140057087, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3008849557522124, 'r1_recall': 0.3953488372093023, 'r1_f1': 0.3417085427135678, 'pegasus_entailment': 0.4357873033732176, 'gold_entailment': 0.29490005150437354, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 22, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3534136546184739, 'r1_recall': 0.5641025641025641, 'r1_f1': 0.4345679012345679, 'pegasus_entailment': 0.5457244999706745, 'gold_entailment': 0.4125517872827394, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6260162601626016, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.5347222222222222, 'pegasus_entailment': 0.6071138282616934, 'gold_entailment': 0.4158506244421005, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43529411764705883, 'r1_recall': 0.6065573770491803, 'r1_f1': 0.5068493150684932, 'pegasus_entailment': 0.5521021974273026, 'gold_entailment': 0.4851773475529626, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 18}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5370370370370371, 'r1_recall': 0.58, 'r1_f1': 0.5576923076923077, 'pegasus_entailment': 0.7414882580439249, 'gold_entailment': 0.41309917469819385, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32098765432098764, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.41106719367588934, 'pegasus_entailment': 0.5106127460797628, 'gold_entailment': 0.20260049868375063, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6071428571428571, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.559670781893004, 'pegasus_entailment': 0.5555204749107361, 'gold_entailment': 0.3080955110490322, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40869565217391307, 'r1_recall': 0.5164835164835165, 'r1_f1': 0.45631067961165056, 'pegasus_entailment': 0.7398494124412537, 'gold_entailment': 0.4313918612897396, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3287671232876712, 'r1_recall': 0.6857142857142857, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.4439875949174166, 'gold_entailment': 0.41617411375045776, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3741496598639456, 'r1_recall': 0.7534246575342466, 'r1_f1': 0.5, 'pegasus_entailment': 0.7049635410308838, 'gold_entailment': 0.3223854328195254, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.352, 'r1_f1': 0.374468085106383, 'pegasus_entailment': 0.3241395130753517, 'gold_entailment': 0.06820030277594924, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5625, 'r1_recall': 0.5526315789473685, 'r1_f1': 0.5575221238938053, 'pegasus_entailment': 0.3384713400155306, 'gold_entailment': 0.21651930436491967, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3433734939759036, 'r1_recall': 0.6404494382022472, 'r1_f1': 0.44705882352941173, 'pegasus_entailment': 0.5056167755808149, 'gold_entailment': 0.30615380592644215, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 17}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22058823529411764, 'r1_recall': 0.3488372093023256, 'r1_f1': 0.27027027027027023, 'pegasus_entailment': 0.41605519875884056, 'gold_entailment': 0.6204044967889786, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 11, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6772151898734177, 'r1_recall': 0.4841628959276018, 'r1_f1': 0.5646437994722955, 'pegasus_entailment': 0.5005088597536087, 'gold_entailment': 0.46828600640098256, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6509433962264151, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6301369863013699, 'pegasus_entailment': 0.9620340764522552, 'gold_entailment': 0.20556215631465116, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 20}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21100917431192662, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.31506849315068497, 'pegasus_entailment': 0.37340215779840946, 'gold_entailment': 0.14195217192173004, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 23, 'gold_ari': 30, 'gold_smog': 22}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3087248322147651, 'r1_recall': 0.5609756097560976, 'r1_f1': 0.39826839826839827, 'pegasus_entailment': 0.6795563280582428, 'gold_entailment': 0.6221201717853546, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 14, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3435897435897436, 'r1_recall': 0.6261682242990654, 'r1_f1': 0.44370860927152317, 'pegasus_entailment': 0.37561421575290815, 'gold_entailment': 0.3418553307652473, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2887700534759358, 'r1_recall': 0.75, 'r1_f1': 0.41698841698841693, 'pegasus_entailment': 0.7246039807796478, 'gold_entailment': 0.40916750331719715, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6578947368421053, 'r1_recall': 0.5681818181818182, 'r1_f1': 0.6097560975609756, 'pegasus_entailment': 0.5111315511167049, 'gold_entailment': 0.21223137056222185, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7313432835820896, 'r1_recall': 0.550561797752809, 'r1_f1': 0.6282051282051283, 'pegasus_entailment': 0.4239158183336258, 'gold_entailment': 0.46024508277575177, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 16}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2876712328767123, 'r1_recall': 0.711864406779661, 'r1_f1': 0.4097560975609756, 'pegasus_entailment': 0.4204851971298922, 'gold_entailment': 0.09280480972180764, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6086956521739131, 'r1_recall': 0.5656565656565656, 'r1_f1': 0.5863874345549738, 'pegasus_entailment': 0.7097718380391598, 'gold_entailment': 0.41423723474144936, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 27, 'gold_coleman_liau': 21, 'gold_ari': 34, 'gold_smog': 23}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44339622641509435, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.46534653465346537, 'pegasus_entailment': 0.8817660361528397, 'gold_entailment': 0.7657084316015244, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4676258992805755, 'r1_recall': 0.6914893617021277, 'r1_f1': 0.5579399141630901, 'pegasus_entailment': 0.7239193320274353, 'gold_entailment': 0.2498886790126562, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.935251798561151, 'r1_recall': 0.24904214559386972, 'r1_f1': 0.39334341906202724, 'pegasus_entailment': 0.6042165532708168, 'gold_entailment': 0.5441024252213538, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5894039735099338, 'r1_recall': 0.445, 'r1_f1': 0.5071225071225072, 'pegasus_entailment': 0.5345028409113487, 'gold_entailment': 0.3538168952282932, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2900763358778626, 'r1_recall': 0.48717948717948717, 'r1_f1': 0.36363636363636365, 'pegasus_entailment': 0.0946352229054485, 'gold_entailment': 0.06342596793547273, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5975609756097561, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.5240641711229946, 'pegasus_entailment': 0.51763414144516, 'gold_entailment': 0.611433457583189, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6972477064220184, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.6204081632653061, 'pegasus_entailment': 0.466560497879982, 'gold_entailment': 0.5192978878815969, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 25, 'gold_smog': 21}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42934782608695654, 'r1_recall': 0.6991150442477876, 'r1_f1': 0.531986531986532, 'pegasus_entailment': 0.6267152607440949, 'gold_entailment': 0.40948309501012164, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 18, 'gold_ari': 26, 'gold_smog': 24}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.64, 'r1_recall': 0.5647058823529412, 'r1_f1': 0.6000000000000001, 'pegasus_entailment': 0.3788183505336444, 'gold_entailment': 0.32802048822244007, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43023255813953487, 'r1_recall': 0.5606060606060606, 'r1_f1': 0.48684210526315785, 'pegasus_entailment': 0.4885625522583723, 'gold_entailment': 0.21223004907369614, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.569620253164557, 'r1_recall': 0.4891304347826087, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.5793258175253868, 'gold_entailment': 0.7248006363709768, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4, 'r1_recall': 0.4819277108433735, 'r1_f1': 0.4371584699453552, 'pegasus_entailment': 0.5791305601596832, 'gold_entailment': 0.3935668667157491, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.673469387755102, 'r1_recall': 0.5238095238095238, 'r1_f1': 0.5892857142857143, 'pegasus_entailment': 0.6231166154146195, 'gold_entailment': 0.6145972410837809, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.57, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.5643564356435642, 'pegasus_entailment': 0.5941494703292847, 'gold_entailment': 0.3382012148698171, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6056338028169014, 'r1_recall': 0.5341614906832298, 'r1_f1': 0.5676567656765676, 'pegasus_entailment': 0.5430236130952835, 'gold_entailment': 0.5509413719177246, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3855421686746988, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.45714285714285713, 'pegasus_entailment': 0.818808913230896, 'gold_entailment': 0.015305309556424618, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 15, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5654008438818565, 'r1_recall': 0.5929203539823009, 'r1_f1': 0.5788336933045356, 'pegasus_entailment': 0.454907956905663, 'gold_entailment': 0.47390027557100567, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 31, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40540540540540543, 'r1_recall': 0.5, 'r1_f1': 0.4477611940298507, 'pegasus_entailment': 0.113208650611341, 'gold_entailment': 0.06970329419709742, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 19, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5607476635514018, 'r1_recall': 0.594059405940594, 'r1_f1': 0.5769230769230769, 'pegasus_entailment': 0.7046860307455063, 'gold_entailment': 0.709111491839091, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 22}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3162393162393162, 'r1_recall': 0.7551020408163265, 'r1_f1': 0.4457831325301204, 'pegasus_entailment': 0.8129373788833618, 'gold_entailment': 0.47197216004133224, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.14285714285714285, 'r1_recall': 0.5, 'r1_f1': 0.22222222222222224, 'pegasus_entailment': 0.7653952687978745, 'gold_entailment': 0.24597783324619135, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5736434108527132, 'r1_recall': 0.5068493150684932, 'r1_f1': 0.5381818181818183, 'pegasus_entailment': 0.7966068685054779, 'gold_entailment': 0.470033744815737, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5833333333333334, 'r1_recall': 0.4739583333333333, 'r1_f1': 0.5229885057471264, 'pegasus_entailment': 0.688457652926445, 'gold_entailment': 0.2965553005536397, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 23, 'gold_flesch_kincaid': 34, 'gold_coleman_liau': 22, 'gold_ari': 42, 'gold_smog': 27}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49411764705882355, 'r1_recall': 0.5675675675675675, 'r1_f1': 0.5283018867924529, 'pegasus_entailment': 0.6126361563801765, 'gold_entailment': 0.33680439181625843, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.41818181818181815, 'r1_recall': 0.46464646464646464, 'r1_f1': 0.44019138755980863, 'pegasus_entailment': 0.4561115155617396, 'gold_entailment': 0.17230367908875147, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 23, 'pegasus_ari': 30, 'pegasus_smog': 24, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48514851485148514, 'r1_recall': 0.5903614457831325, 'r1_f1': 0.532608695652174, 'pegasus_entailment': 0.448513007722795, 'gold_entailment': 0.0969966563085715, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38095238095238093, 'r1_recall': 0.676056338028169, 'r1_f1': 0.4873096446700507, 'pegasus_entailment': 0.3329376397388322, 'gold_entailment': 0.4708811789751053, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 14, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 21, 'gold_ari': 28, 'gold_smog': 22}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5980392156862745, 'r1_recall': 0.5304347826086957, 'r1_f1': 0.5622119815668202, 'pegasus_entailment': 0.19891514480113984, 'gold_entailment': 0.11063961265608668, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5922330097087378, 'r1_recall': 0.3630952380952381, 'r1_f1': 0.4501845018450184, 'pegasus_entailment': 0.2944875567087105, 'gold_entailment': 0.361225243125643, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2, 'r1_recall': 0.4339622641509434, 'r1_f1': 0.2738095238095238, 'pegasus_entailment': 0.7070168256759644, 'gold_entailment': 0.12078769411891699, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 21}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4845360824742268, 'r1_recall': 0.4351851851851852, 'r1_f1': 0.4585365853658536, 'pegasus_entailment': 0.8895871837933859, 'gold_entailment': 0.20391795504838228, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 23, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5263157894736842, 'r1_recall': 0.4424778761061947, 'r1_f1': 0.4807692307692308, 'pegasus_entailment': 0.780542810757955, 'gold_entailment': 0.364722965285182, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3620689655172414, 'r1_recall': 0.5915492957746479, 'r1_f1': 0.4491978609625668, 'pegasus_entailment': 0.47822532430291176, 'gold_entailment': 0.5614807506402334, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 18}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49101796407185627, 'r1_recall': 0.3744292237442922, 'r1_f1': 0.4248704663212435, 'pegasus_entailment': 0.40427444204688073, 'gold_entailment': 0.383820455107424, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.22784810126582278, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.3157894736842105, 'pegasus_entailment': 0.8817067344983419, 'gold_entailment': 0.6938924491405487, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 21, 'gold_flesch_kincaid': 9, 'gold_coleman_liau': 13, 'gold_ari': 9, 'gold_smog': 13}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6057692307692307, 'r1_recall': 0.7590361445783133, 'r1_f1': 0.6737967914438502, 'pegasus_entailment': 0.8419237732887268, 'gold_entailment': 0.7516689300537109, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4067796610169492, 'r1_recall': 0.4897959183673469, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.3468850329518318, 'gold_entailment': 0.1950661651790142, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5806451612903226, 'r1_recall': 0.6352941176470588, 'r1_f1': 0.6067415730337079, 'pegasus_entailment': 0.4668327954908212, 'gold_entailment': 0.4683189569041133, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 16, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6890756302521008, 'r1_recall': 0.6356589147286822, 'r1_f1': 0.6612903225806451, 'pegasus_entailment': 0.5892683118581772, 'gold_entailment': 0.5860727459192276, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 18}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4322033898305085, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.49756097560975604, 'pegasus_entailment': 0.7105352878570557, 'gold_entailment': 0.39479096233844757, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5079365079365079, 'r1_recall': 0.48120300751879697, 'r1_f1': 0.49420849420849416, 'pegasus_entailment': 0.7977589249610901, 'gold_entailment': 0.2461542603559792, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5423728813559322, 'r1_recall': 0.5765765765765766, 'r1_f1': 0.5589519650655022, 'pegasus_entailment': 0.16075385212898255, 'gold_entailment': 0.1530832452699542, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5875, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.5340909090909091, 'pegasus_entailment': 0.3766850898973644, 'gold_entailment': 0.17934280633926392, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 28, 'gold_coleman_liau': 20, 'gold_ari': 33, 'gold_smog': 28}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6902654867256637, 'r1_recall': 0.5571428571428572, 'r1_f1': 0.616600790513834, 'pegasus_entailment': 0.6810897037386894, 'gold_entailment': 0.5997754693031311, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40939597315436244, 'r1_recall': 0.4236111111111111, 'r1_f1': 0.41638225255972694, 'pegasus_entailment': 0.6686475078264872, 'gold_entailment': 0.42755897467335063, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.632183908045977, 'r1_recall': 0.5978260869565217, 'r1_f1': 0.6145251396648045, 'pegasus_entailment': 0.6972609013319016, 'gold_entailment': 0.23393024897086434, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.581081081081081, 'r1_recall': 0.4174757281553398, 'r1_f1': 0.48587570621468923, 'pegasus_entailment': 0.615912077948451, 'gold_entailment': 0.4376660879701376, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.37209302325581395, 'r1_recall': 0.47761194029850745, 'r1_f1': 0.4183006535947712, 'pegasus_entailment': 0.5406750552356243, 'gold_entailment': 0.2765434585356464, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4909090909090909, 'r1_recall': 0.5934065934065934, 'r1_f1': 0.5373134328358209, 'pegasus_entailment': 0.8839104294776916, 'gold_entailment': 0.5161614641547203, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 17, 'gold_ari': 29, 'gold_smog': 21}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6239316239316239, 'r1_recall': 0.5104895104895105, 'r1_f1': 0.5615384615384617, 'pegasus_entailment': 0.6604979634284973, 'gold_entailment': 0.28219225639477374, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6262626262626263, 'r1_recall': 0.5081967213114754, 'r1_f1': 0.5610859728506787, 'pegasus_entailment': 0.42296793311834335, 'gold_entailment': 0.347453810274601, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6517857142857143, 'r1_recall': 0.4397590361445783, 'r1_f1': 0.5251798561151079, 'pegasus_entailment': 0.3389860957860947, 'gold_entailment': 0.3915687263011932, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5507246376811594, 'r1_recall': 0.6909090909090909, 'r1_f1': 0.6129032258064516, 'pegasus_entailment': 0.23103238300730786, 'gold_entailment': 0.05040660931263119, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42105263157894735, 'r1_recall': 0.6486486486486487, 'r1_f1': 0.5106382978723405, 'pegasus_entailment': 0.47034930903464556, 'gold_entailment': 0.22660833969712257, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6326530612244898, 'r1_recall': 0.45588235294117646, 'r1_f1': 0.5299145299145299, 'pegasus_entailment': 0.8514506459236145, 'gold_entailment': 0.5134935312800937, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 21, 'gold_smog': 21}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6733333333333333, 'r1_recall': 0.4675925925925926, 'r1_f1': 0.5519125683060109, 'pegasus_entailment': 0.5302981100976467, 'gold_entailment': 0.2667830880964175, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5607476635514018, 'r1_recall': 0.49586776859504134, 'r1_f1': 0.5263157894736842, 'pegasus_entailment': 0.40714678168296814, 'gold_entailment': 0.2104253532985846, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6507936507936508, 'r1_recall': 0.5734265734265734, 'r1_f1': 0.6096654275092936, 'pegasus_entailment': 0.27045184342811507, 'gold_entailment': 0.2679916364806039, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4766355140186916, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.5257731958762886, 'pegasus_entailment': 0.904844323794047, 'gold_entailment': 0.6752299120028814, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33663366336633666, 'r1_recall': 0.7472527472527473, 'r1_f1': 0.4641638225255973, 'pegasus_entailment': 0.8180527091026306, 'gold_entailment': 0.4372362007076542, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 20, 'pegasus_ari': 34, 'pegasus_smog': 24, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43410852713178294, 'r1_recall': 0.5490196078431373, 'r1_f1': 0.48484848484848486, 'pegasus_entailment': 0.2711918268352747, 'gold_entailment': 0.22105926414951682, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 15, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5357142857142857, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.21198144368827343, 'gold_entailment': 0.1052451857055227, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 24, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7017543859649122, 'r1_recall': 0.40404040404040403, 'r1_f1': 0.5128205128205128, 'pegasus_entailment': 0.24543481692671776, 'gold_entailment': 0.19042814783751966, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3368421052631579, 'r1_recall': 0.3595505617977528, 'r1_f1': 0.34782608695652173, 'pegasus_entailment': 0.5907532125711441, 'gold_entailment': 0.5516887530684471, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7211538461538461, 'r1_recall': 0.4601226993865031, 'r1_f1': 0.5617977528089888, 'pegasus_entailment': 0.3592535872012377, 'gold_entailment': 0.3285668392976125, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6078431372549019, 'r1_recall': 0.34065934065934067, 'r1_f1': 0.43661971830985913, 'pegasus_entailment': 0.4683259390294552, 'gold_entailment': 0.3943267799913883, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7954545454545454, 'r1_recall': 0.2545454545454545, 'r1_f1': 0.3856749311294766, 'pegasus_entailment': 0.24319838359951973, 'gold_entailment': 0.22338404092523786, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.5504587155963303, 'r1_f1': 0.48192771084337344, 'pegasus_entailment': 0.6738460138440132, 'gold_entailment': 0.682251513004303, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21, 'gold_flesch_kincaid': 29, 'gold_coleman_liau': 21, 'gold_ari': 36, 'gold_smog': 26}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.19811320754716982, 'r1_recall': 0.3620689655172414, 'r1_f1': 0.25609756097560976, 'pegasus_entailment': 0.46135734766721725, 'gold_entailment': 0.5682575106620789, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 15, 'gold_smog': 15}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6266666666666667, 'r1_recall': 0.2596685082872928, 'r1_f1': 0.3671875, 'pegasus_entailment': 0.596230814854304, 'gold_entailment': 0.25041912496089935, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 16, 'gold_ari': 21, 'gold_smog': 17}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.28125, 'r1_recall': 0.5844155844155844, 'r1_f1': 0.37974683544303794, 'pegasus_entailment': 0.5533402800559998, 'gold_entailment': 0.4478014186024666, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39436619718309857, 'r1_recall': 0.7, 'r1_f1': 0.5045045045045045, 'pegasus_entailment': 0.5491376556456089, 'gold_entailment': 0.3254823461174965, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6292134831460674, 'r1_recall': 0.6021505376344086, 'r1_f1': 0.6153846153846154, 'pegasus_entailment': 0.7965782359242439, 'gold_entailment': 0.27453804831020534, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3333333333333333, 'r1_recall': 0.654320987654321, 'r1_f1': 0.4416666666666667, 'pegasus_entailment': 0.308673994615674, 'gold_entailment': 0.26193892024457455, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35833333333333334, 'r1_recall': 0.4777777777777778, 'r1_f1': 0.40952380952380957, 'pegasus_entailment': 0.20282562674644092, 'gold_entailment': 0.16501388256438076, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 15, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2653061224489796, 'r1_recall': 0.37681159420289856, 'r1_f1': 0.31137724550898205, 'pegasus_entailment': 0.4143473831936717, 'gold_entailment': 0.09620473627001047, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 11, 'gold_coleman_liau': 14, 'gold_ari': 13, 'gold_smog': 15}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38666666666666666, 'r1_recall': 0.6041666666666666, 'r1_f1': 0.4715447154471545, 'pegasus_entailment': 0.3155415877699852, 'gold_entailment': 0.5355753810144961, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 18}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3888888888888889, 'r1_recall': 0.546875, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.18169837165623903, 'gold_entailment': 0.1330608675877253, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3151515151515151, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.40624999999999994, 'pegasus_entailment': 0.6681450208028158, 'gold_entailment': 0.2678331434726715, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 19, 'pegasus_ari': 35, 'pegasus_smog': 25, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.410958904109589, 'r1_recall': 0.6818181818181818, 'r1_f1': 0.5128205128205128, 'pegasus_entailment': 0.6296381533145905, 'gold_entailment': 0.3203612625598907, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 21, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.33766233766233766, 'r1_recall': 0.8387096774193549, 'r1_f1': 0.4814814814814815, 'pegasus_entailment': 0.5219065588898957, 'gold_entailment': 0.15059137297794223, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 15, 'gold_smog': 17}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5161290322580645, 'r1_recall': 0.7476635514018691, 'r1_f1': 0.6106870229007633, 'pegasus_entailment': 0.45285505056381226, 'gold_entailment': 0.274391021206975, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.367816091954023, 'r1_recall': 0.5079365079365079, 'r1_f1': 0.42666666666666664, 'pegasus_entailment': 0.5665963316336274, 'gold_entailment': 0.3084476888179779, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 21, 'gold_ari': 25, 'gold_smog': 18}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6258503401360545, 'r1_recall': 0.3471698113207547, 'r1_f1': 0.44660194174757284, 'pegasus_entailment': 0.4804023529092471, 'gold_entailment': 0.38931646943092346, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 17, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23741007194244604, 'r1_recall': 0.515625, 'r1_f1': 0.32512315270935965, 'pegasus_entailment': 0.5180015861988068, 'gold_entailment': 0.4917273670434952, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 19}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36, 'r1_recall': 0.391304347826087, 'r1_f1': 0.37499999999999994, 'pegasus_entailment': 0.7970127016305923, 'gold_entailment': 0.5962326377630234, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 22, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5309734513274337, 'r1_recall': 0.6, 'r1_f1': 0.5633802816901409, 'pegasus_entailment': 0.463740274310112, 'gold_entailment': 0.3709367960691452, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 18, 'gold_flesch_kincaid': 27, 'gold_coleman_liau': 18, 'gold_ari': 32, 'gold_smog': 24}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5, 'r1_recall': 0.4142857142857143, 'r1_f1': 0.453125, 'pegasus_entailment': 0.5003923639655113, 'gold_entailment': 0.5594767034053802, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 17, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5125, 'r1_recall': 0.43617021276595747, 'r1_f1': 0.47126436781609193, 'pegasus_entailment': 0.39241076335310937, 'gold_entailment': 0.25764474521080655, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4338235294117647, 'r1_recall': 0.4645669291338583, 'r1_f1': 0.44866920152091255, 'pegasus_entailment': 0.7338042248040437, 'gold_entailment': 0.2558267756830901, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36363636363636365, 'r1_recall': 0.4507042253521127, 'r1_f1': 0.40251572327044033, 'pegasus_entailment': 0.9140934199094772, 'gold_entailment': 0.0324706481769681, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 22, 'gold_ari': 28, 'gold_smog': 23}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40425531914893614, 'r1_recall': 0.6063829787234043, 'r1_f1': 0.4851063829787234, 'pegasus_entailment': 0.39520569145679474, 'gold_entailment': 0.2473367303609848, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45918367346938777, 'r1_recall': 0.5357142857142857, 'r1_f1': 0.49450549450549447, 'pegasus_entailment': 0.49284169264137745, 'gold_entailment': 0.4142226353287697, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.46078431372549017, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.5340909090909092, 'pegasus_entailment': 0.31159678963012993, 'gold_entailment': 0.23467694036662579, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 13, 'gold_smog': 15}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4523809523809524, 'r1_recall': 0.5671641791044776, 'r1_f1': 0.5033112582781457, 'pegasus_entailment': 0.5754340688387553, 'gold_entailment': 0.6108939349651337, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 25, 'gold_smog': 21}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32710280373831774, 'r1_recall': 0.546875, 'r1_f1': 0.40935672514619886, 'pegasus_entailment': 0.5939240083098412, 'gold_entailment': 0.5735413432121277, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 19, 'gold_ari': 24, 'gold_smog': 22}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.49324324324324326, 'r1_recall': 0.42196531791907516, 'r1_f1': 0.45482866043613707, 'pegasus_entailment': 0.6805567038910729, 'gold_entailment': 0.5312270628554481, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6448598130841121, 'r1_recall': 0.41818181818181815, 'r1_f1': 0.5073529411764705, 'pegasus_entailment': 0.5150900483131409, 'gold_entailment': 0.27409292245283723, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6941176470588235, 'r1_recall': 0.6020408163265306, 'r1_f1': 0.6448087431693988, 'pegasus_entailment': 0.5036765271797776, 'gold_entailment': 0.5668495271820575, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 16, 'pegasus_ari': 27, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 17}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5202702702702703, 'r1_recall': 0.4117647058823529, 'r1_f1': 0.45970149253731346, 'pegasus_entailment': 0.3335065692663193, 'gold_entailment': 0.16268663108348846, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4536082474226804, 'r1_recall': 0.4631578947368421, 'r1_f1': 0.45833333333333326, 'pegasus_entailment': 0.05501187569461763, 'gold_entailment': 0.23660295041433224, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 18, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4083333333333333, 'r1_recall': 0.6805555555555556, 'r1_f1': 0.5104166666666666, 'pegasus_entailment': 0.6565840418140093, 'gold_entailment': 0.43387224276860553, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 30, 'pegasus_smog': 23, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.1782178217821782, 'r1_recall': 0.32727272727272727, 'r1_f1': 0.23076923076923075, 'pegasus_entailment': 0.6031137928366661, 'gold_entailment': 0.0739024356007576, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2074074074074074, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.3163841807909604, 'pegasus_entailment': 0.5742225144058466, 'gold_entailment': 0.647544264793396, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43157894736842106, 'r1_recall': 0.5774647887323944, 'r1_f1': 0.4939759036144578, 'pegasus_entailment': 0.6189037651056424, 'gold_entailment': 0.30830344930291176, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 15}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.36046511627906974, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.4492753623188406, 'pegasus_entailment': 0.4594225753098726, 'gold_entailment': 0.37678176164627075, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 22, 'gold_smog': 18}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.4188034188034188, 'r1_f1': 0.4414414414414415, 'pegasus_entailment': 0.36486006947234273, 'gold_entailment': 0.12309609251096845, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 22, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6283185840707964, 'r1_recall': 0.5419847328244275, 'r1_f1': 0.5819672131147541, 'pegasus_entailment': 0.44732254184782505, 'gold_entailment': 0.2847847950955232, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5263157894736842, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.5586592178770949, 'pegasus_entailment': 0.5608211711514741, 'gold_entailment': 0.2260827108596762, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5597014925373134, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.4777070063694267, 'pegasus_entailment': 0.5713464140892028, 'gold_entailment': 0.3337388758858045, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 19, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4666666666666667, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5308056872037915, 'pegasus_entailment': 0.33102769986726344, 'gold_entailment': 0.42708516617616016, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4672131147540984, 'r1_recall': 0.5181818181818182, 'r1_f1': 0.49137931034482757, 'pegasus_entailment': 0.53441097214818, 'gold_entailment': 0.3546060845255852, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5137614678899083, 'r1_recall': 0.6086956521739131, 'r1_f1': 0.5572139303482587, 'pegasus_entailment': 0.5978433092435201, 'gold_entailment': 0.36207106802612543, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3983050847457627, 'r1_recall': 0.47, 'r1_f1': 0.4311926605504587, 'pegasus_entailment': 0.7795324921607971, 'gold_entailment': 0.7059247344732285, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 21, 'gold_ari': 20, 'gold_smog': 21}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.32038834951456313, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.3837209302325582, 'pegasus_entailment': 0.822136826813221, 'gold_entailment': 0.042697695549577475, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48598130841121495, 'r1_recall': 0.5977011494252874, 'r1_f1': 0.5360824742268042, 'pegasus_entailment': 0.8651788036028544, 'gold_entailment': 0.5504623651504517, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 18, 'gold_ari': 29, 'gold_smog': 20}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5537190082644629, 'r1_recall': 0.6568627450980392, 'r1_f1': 0.6008968609865472, 'pegasus_entailment': 0.7818095286687216, 'gold_entailment': 0.49091561883687973, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 23, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4297520661157025, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.5073170731707317, 'pegasus_entailment': 0.5124848112463951, 'gold_entailment': 0.31659936904907227, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.208, 'r1_recall': 0.5, 'r1_f1': 0.2937853107344633, 'pegasus_entailment': 0.5631636708974839, 'gold_entailment': 0.24063342002530894, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5612244897959183, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.45643153526970953, 'pegasus_entailment': 0.6546362116932869, 'gold_entailment': 0.569461053609848, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 22, 'gold_ari': 25, 'gold_smog': 22}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4296875, 'r1_recall': 0.632183908045977, 'r1_f1': 0.5116279069767442, 'pegasus_entailment': 0.26799532026052475, 'gold_entailment': 0.2231418564915657, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 22, 'gold_flesch_kincaid': 24, 'gold_coleman_liau': 20, 'gold_ari': 31, 'gold_smog': 24}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4153846153846154, 'r1_recall': 0.5, 'r1_f1': 0.453781512605042, 'pegasus_entailment': 0.6649755040804545, 'gold_entailment': 0.3185800868086517, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 19}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4129032258064516, 'r1_recall': 0.5289256198347108, 'r1_f1': 0.463768115942029, 'pegasus_entailment': 0.5115553677082062, 'gold_entailment': 0.4658358118363789, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 17}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4305555555555556, 'r1_recall': 0.2980769230769231, 'r1_f1': 0.3522727272727273, 'pegasus_entailment': 0.3176162876188755, 'gold_entailment': 0.055620395888884865, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5362318840579711, 'r1_recall': 0.5285714285714286, 'r1_f1': 0.5323741007194245, 'pegasus_entailment': 0.7025187412897745, 'gold_entailment': 0.6810179849465688, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2582781456953642, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.34977578475336324, 'pegasus_entailment': 0.854777971903483, 'gold_entailment': 0.2654717544404169, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 24, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 23, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5730337078651685, 'r1_recall': 0.5730337078651685, 'r1_f1': 0.5730337078651685, 'pegasus_entailment': 0.39690743945539, 'gold_entailment': 0.40812284126877785, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.23376623376623376, 'r1_recall': 0.4, 'r1_f1': 0.29508196721311475, 'pegasus_entailment': 0.42175460420548916, 'gold_entailment': 0.029046474490314722, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 15, 'pegasus_ari': 24, 'pegasus_smog': 17, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 13, 'gold_smog': 14}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5121951219512195, 'r1_recall': 0.6116504854368932, 'r1_f1': 0.5575221238938053, 'pegasus_entailment': 0.5621548414230346, 'gold_entailment': 0.35991270840168, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.09090909090909091, 'r1_recall': 0.4, 'r1_f1': 0.14814814814814814, 'pegasus_entailment': 0.538336917757988, 'gold_entailment': 0.3291983865201473, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 14}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.42857142857142855, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.4752475247524753, 'pegasus_entailment': 0.6735477894544601, 'gold_entailment': 0.38239416666328907, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 20}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2543859649122807, 'r1_recall': 0.7435897435897436, 'r1_f1': 0.3790849673202614, 'pegasus_entailment': 0.7352018840610981, 'gold_entailment': 0.9853993058204651, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5647058823529412, 'r1_recall': 0.32432432432432434, 'r1_f1': 0.4120171673819743, 'pegasus_entailment': 0.35761159658432007, 'gold_entailment': 0.2105733464871134, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5754716981132075, 'r1_recall': 0.5304347826086957, 'r1_f1': 0.5520361990950227, 'pegasus_entailment': 0.9463396966457367, 'gold_entailment': 0.5669945493340492, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3525641025641026, 'r1_recall': 0.5729166666666666, 'r1_f1': 0.43650793650793657, 'pegasus_entailment': 0.38645248115062714, 'gold_entailment': 0.10255175119770381, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 17, 'gold_ari': 23, 'gold_smog': 17}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6363636363636364, 'r1_recall': 0.5779816513761468, 'r1_f1': 0.6057692307692307, 'pegasus_entailment': 0.4083650171756744, 'gold_entailment': 0.312678004304568, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 20, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6388888888888888, 'r1_recall': 0.5, 'r1_f1': 0.5609756097560975, 'pegasus_entailment': 0.5443898504599929, 'gold_entailment': 0.27103747334331274, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 16, 'gold_ari': 15, 'gold_smog': 17}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8651685393258427, 'r1_recall': 0.21875, 'r1_f1': 0.3492063492063492, 'pegasus_entailment': 0.6374139590188861, 'gold_entailment': 0.4598361019577299, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4015151515151515, 'r1_recall': 0.4774774774774775, 'r1_f1': 0.43621399176954734, 'pegasus_entailment': 0.711170324257442, 'gold_entailment': 0.6340701162815094, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 18}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6233766233766234, 'r1_recall': 0.3221476510067114, 'r1_f1': 0.42477876106194684, 'pegasus_entailment': 0.6643380969762802, 'gold_entailment': 0.33112673163414, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7209302325581395, 'r1_recall': 0.4161073825503356, 'r1_f1': 0.5276595744680851, 'pegasus_entailment': 0.7100167691707611, 'gold_entailment': 0.705031442642212, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 13, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2786885245901639, 'r1_recall': 0.3469387755102041, 'r1_f1': 0.3090909090909091, 'pegasus_entailment': 0.33462226390838623, 'gold_entailment': 0.5220200717449188, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 19, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4132231404958678, 'r1_recall': 0.6944444444444444, 'r1_f1': 0.5181347150259067, 'pegasus_entailment': 0.5476490706205368, 'gold_entailment': 0.40603379905223846, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3096774193548387, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.4067796610169492, 'pegasus_entailment': 0.405851025134325, 'gold_entailment': 0.29830346753199893, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.762962962962963, 'r1_recall': 0.6866666666666666, 'r1_f1': 0.7228070175438596, 'pegasus_entailment': 0.502617295521001, 'gold_entailment': 0.47936743795871734, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 16, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43434343434343436, 'r1_recall': 0.6417910447761194, 'r1_f1': 0.5180722891566265, 'pegasus_entailment': 0.44455485604703426, 'gold_entailment': 0.07090111635625362, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 26, 'gold_smog': 20}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5851063829787234, 'r1_recall': 0.6395348837209303, 'r1_f1': 0.6111111111111112, 'pegasus_entailment': 0.7395394206047058, 'gold_entailment': 0.3346955570547531, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.38524590163934425, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.4795918367346938, 'pegasus_entailment': 0.7704614996910095, 'gold_entailment': 0.7705883085727692, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 21, 'gold_ari': 28, 'gold_smog': 24}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5217391304347826, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.48, 'pegasus_entailment': 0.8096733490626017, 'gold_entailment': 0.6366370419661204, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 21, 'gold_ari': 23, 'gold_smog': 22}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5698924731182796, 'r1_recall': 0.375886524822695, 'r1_f1': 0.452991452991453, 'pegasus_entailment': 0.616427555680275, 'gold_entailment': 0.57144362727801, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 19, 'gold_ari': 26, 'gold_smog': 23}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2616279069767442, 'r1_recall': 0.6870229007633588, 'r1_f1': 0.37894736842105264, 'pegasus_entailment': 0.6032745639483134, 'gold_entailment': 0.37712031540771324, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 33, 'pegasus_smog': 25, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5818181818181818, 'r1_recall': 0.4507042253521127, 'r1_f1': 0.5079365079365079, 'pegasus_entailment': 0.6065057069063187, 'gold_entailment': 0.5980380347796849, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 23, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 21}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5393258426966293, 'pegasus_entailment': 0.9374534785747528, 'gold_entailment': 0.298493883262078, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 24, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 20}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.367816091954023, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.6281761825084686, 'gold_entailment': 0.4943763851188123, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 24, 'gold_ari': 27, 'gold_smog': 23}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6382978723404256, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.5604746267199516, 'gold_entailment': 0.359744131565094, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 22, 'gold_ari': 26, 'gold_smog': 22}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6303030303030303, 'r1_recall': 0.34210526315789475, 'r1_f1': 0.4434968017057569, 'pegasus_entailment': 0.5943877995014191, 'gold_entailment': 0.21861272491514683, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 16, 'gold_ari': 16, 'gold_smog': 18}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.2204724409448819, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.29473684210526313, 'pegasus_entailment': 0.5179110914468765, 'gold_entailment': 0.38893143522242707, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 11, 'gold_coleman_liau': 15, 'gold_ari': 12, 'gold_smog': 16}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.35555555555555557, 'r1_recall': 0.6736842105263158, 'r1_f1': 0.4654545454545455, 'pegasus_entailment': 0.5424168209234873, 'gold_entailment': 0.23273458459880203, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6808510638297872, 'r1_recall': 0.4050632911392405, 'r1_f1': 0.5079365079365079, 'pegasus_entailment': 0.5256333807483315, 'gold_entailment': 0.48381292819976807, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 15, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 18, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3076923076923077, 'r1_recall': 0.41379310344827586, 'r1_f1': 0.35294117647058826, 'pegasus_entailment': 0.41848411336541175, 'gold_entailment': 0.22208488592877984, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 15, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 17}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7638888888888888, 'r1_recall': 0.30386740331491713, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.42523420602083206, 'gold_entailment': 0.33659833752446705, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 15, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 18}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5454545454545454, 'r1_recall': 0.4225352112676056, 'r1_f1': 0.47619047619047616, 'pegasus_entailment': 0.563409103701512, 'gold_entailment': 0.14822833737707697, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 16, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43137254901960786, 'r1_recall': 0.4631578947368421, 'r1_f1': 0.4467005076142132, 'pegasus_entailment': 0.5023513436317444, 'gold_entailment': 0.16808209009468555, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 16}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6020408163265306, 'r1_recall': 0.3430232558139535, 'r1_f1': 0.437037037037037, 'pegasus_entailment': 0.7113199383020401, 'gold_entailment': 0.5804830528795719, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 19, 'gold_smog': 20}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.47126436781609193, 'r1_recall': 0.5774647887323944, 'r1_f1': 0.5189873417721519, 'pegasus_entailment': 0.5303116559982299, 'gold_entailment': 0.3049267878135045, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.7333333333333333, 'r1_recall': 0.2644230769230769, 'r1_f1': 0.3886925795053003, 'pegasus_entailment': 0.7814111113548279, 'gold_entailment': 0.6673712246119976, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 17, 'gold_smog': 19}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.40268456375838924, 'r1_recall': 0.6451612903225806, 'r1_f1': 0.49586776859504134, 'pegasus_entailment': 0.7751800537109375, 'gold_entailment': 0.44503366500139235, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 19, 'gold_ari': 18, 'gold_smog': 19}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39655172413793105, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.4816753926701571, 'pegasus_entailment': 0.5255487179383636, 'gold_entailment': 0.2099466621875763, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 23, 'gold_coleman_liau': 19, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.48514851485148514, 'r1_recall': 0.6901408450704225, 'r1_f1': 0.5697674418604651, 'pegasus_entailment': 0.5260464770253748, 'gold_entailment': 0.09788094185447942, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 16, 'gold_ari': 18, 'gold_smog': 16}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5301204819277109, 'r1_recall': 0.43564356435643564, 'r1_f1': 0.4782608695652174, 'pegasus_entailment': 0.4756608363240957, 'gold_entailment': 0.3044598922133446, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6967213114754098, 'r1_recall': 0.4106280193236715, 'r1_f1': 0.5167173252279635, 'pegasus_entailment': 0.7188791275024414, 'gold_entailment': 0.43964487065871555, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 21, 'gold_coleman_liau': 18, 'gold_ari': 24, 'gold_smog': 21}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.39097744360902253, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.4425531914893617, 'pegasus_entailment': 0.6978340347607931, 'gold_entailment': 0.4419879138469696, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 15, 'gold_ari': 14, 'gold_smog': 16}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.3, 'r1_recall': 0.4, 'r1_f1': 0.34285714285714286, 'pegasus_entailment': 0.3303643986582756, 'gold_entailment': 0.3868693709373474, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 20, 'gold_ari': 24, 'gold_smog': 18}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4271356783919598, 'r1_recall': 0.47752808988764045, 'r1_f1': 0.4509283819628647, 'pegasus_entailment': 0.8528198003768921, 'gold_entailment': 0.5138355136538545, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 33, 'pegasus_smog': 22, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 18, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5882352941176471, 'r1_recall': 0.547945205479452, 'r1_f1': 0.5673758865248226, 'pegasus_entailment': 0.4537524878978729, 'gold_entailment': 0.2963012382388115, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16, 'gold_flesch_kincaid': 13, 'gold_coleman_liau': 17, 'gold_ari': 16, 'gold_smog': 15}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.44761904761904764, 'r1_recall': 0.618421052631579, 'r1_f1': 0.5193370165745856, 'pegasus_entailment': 0.3181113596074283, 'gold_entailment': 0.6093170940876007, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 21, 'gold_smog': 17}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5698924731182796, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.5760869565217391, 'pegasus_entailment': 0.4741951674222946, 'gold_entailment': 0.46453017741441727, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 14, 'gold_ari': 16, 'gold_smog': 16}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4838709677419355, 'r1_recall': 0.625, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.4669484317302704, 'gold_entailment': 0.34870303608477116, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 18, 'gold_ari': 22, 'gold_smog': 16}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.76, 'r1_recall': 0.16170212765957448, 'r1_f1': 0.26666666666666666, 'pegasus_entailment': 0.8152911265691122, 'gold_entailment': 0.4361045848239552, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 21, 'gold_smog': 20}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.582089552238806, 'r1_recall': 0.5492957746478874, 'r1_f1': 0.5652173913043479, 'pegasus_entailment': 0.5908023218313853, 'gold_entailment': 0.5687469020485878, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17, 'gold_flesch_kincaid': 14, 'gold_coleman_liau': 18, 'gold_ari': 17, 'gold_smog': 17}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.8365384615384616, 'r1_recall': 0.47540983606557374, 'r1_f1': 0.6062717770034843, 'pegasus_entailment': 0.42466316372156143, 'gold_entailment': 0.36526453495025635, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 17, 'gold_ari': 22, 'gold_smog': 19}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.43636363636363634, 'r1_recall': 0.5161290322580645, 'r1_f1': 0.4729064039408867, 'pegasus_entailment': 0.4304949749882023, 'gold_entailment': 0.18208953738212585, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16, 'gold_flesch_kincaid': 25, 'gold_coleman_liau': 17, 'gold_ari': 30, 'gold_smog': 21}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6893203883495146, 'r1_recall': 0.6120689655172413, 'r1_f1': 0.6484018264840183, 'pegasus_entailment': 0.4802610632032156, 'gold_entailment': 0.6374240289442241, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 16, 'gold_coleman_liau': 17, 'gold_ari': 18, 'gold_smog': 18}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.575, 'r1_recall': 0.7076923076923077, 'r1_f1': 0.6344827586206897, 'pegasus_entailment': 0.4300629520788789, 'gold_entailment': 0.029122572392225266, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 18, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 20, 'gold_ari': 25, 'gold_smog': 23}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.45, 'r1_recall': 0.4012738853503185, 'r1_f1': 0.42424242424242425, 'pegasus_entailment': 0.45643903501331806, 'gold_entailment': 0.29728448018431664, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 18, 'gold_flesch_kincaid': 18, 'gold_coleman_liau': 22, 'gold_ari': 21, 'gold_smog': 19}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.16551724137931034, 'r1_recall': 0.5, 'r1_f1': 0.24870466321243523, 'pegasus_entailment': 0.6642348617315292, 'gold_entailment': 0.18130562454462051, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 19, 'gold_ari': 20, 'gold_smog': 20}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.4880952380952381, 'r1_recall': 0.422680412371134, 'r1_f1': 0.4530386740331492, 'pegasus_entailment': 0.9837111632029215, 'gold_entailment': 0.12387602793751284, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 19, 'gold_flesch_kincaid': 22, 'gold_coleman_liau': 22, 'gold_ari': 27, 'gold_smog': 22}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.12264150943396226, 'r1_recall': 0.37142857142857144, 'r1_f1': 0.18439716312056736, 'pegasus_entailment': 0.39196261391043663, 'gold_entailment': 0.2706492837751284, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18, 'gold_flesch_kincaid': 15, 'gold_coleman_liau': 22, 'gold_ari': 20, 'gold_smog': 17}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5544554455445545, 'r1_recall': 0.5773195876288659, 'r1_f1': 0.5656565656565656, 'pegasus_entailment': 0.5776856616139412, 'gold_entailment': 0.4429062962299213, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 17, 'gold_ari': 19, 'gold_smog': 19}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5294117647058824, 'r1_recall': 0.5575221238938053, 'r1_f1': 0.543103448275862, 'pegasus_entailment': 0.4961768090724945, 'gold_entailment': 0.48534930497407913, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21, 'gold_flesch_kincaid': 19, 'gold_coleman_liau': 20, 'gold_ari': 23, 'gold_smog': 20}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.6194690265486725, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.564516129032258, 'pegasus_entailment': 0.5379573325626552, 'gold_entailment': 0.09014320905165125, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19, 'gold_flesch_kincaid': 17, 'gold_coleman_liau': 20, 'gold_ari': 20, 'gold_smog': 19}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.21428571428571427, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.27631578947368424, 'pegasus_entailment': 0.4725279920268804, 'gold_entailment': 0.12715866789221764, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 22, 'gold_ari': 24, 'gold_smog': 23}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'r1_precision': 0.5176470588235295, 'r1_recall': 0.44, 'r1_f1': 0.47567567567567565, 'pegasus_entailment': 0.502842354006134, 'gold_entailment': 0.3927481472492218, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19, 'gold_flesch_kincaid': 20, 'gold_coleman_liau': 19, 'gold_ari': 25, 'gold_smog': 19}
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.09090909090909091
MEAN
0.49614463965394695
MAX
0.935251798561151
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.16170212765957448
MEAN
0.5199183241363002
MAX
0.8387096774193549
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.14814814814814814
MEAN
0.4841095531911738
MAX
0.7228070175438596
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.002802051545586437
MEAN
0.5468577120635669
MAX
0.989773690700531
** Analysing column: gold_entailment



gold_entailment
Length after nones removed
616
MIN
0.0008654110206407495
MEAN
0.37267368104078724
MAX
0.9853993058204651
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
17
MAX
35
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
13
MEAN
17
MAX
23
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
11
MEAN
20
MAX
43
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
11
MEAN
18
MAX
29
** Analysing column: gold_flesch_kincaid



gold_flesch_kincaid
Length after nones removed
616
MIN
9
MEAN
17
MAX
38
** Analysing column: gold_coleman_liau



gold_coleman_liau
Length after nones removed
616
MIN
13
MEAN
18
MAX
25
** Analysing column: gold_ari



gold_ari
Length after nones removed
616
MIN
9
MEAN
20
MAX
46
** Analysing column: gold_smog



gold_smog
Length after nones removed
616
MIN
13
MEAN
19
MAX
30
{}
Entered file!
Imports done!
*** RUN *** 
eval_3d2
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 14:47:44.629426: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 14:47:45.183189: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/3d2_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3298429319371728, 'r1_recall': 0.5727272727272728, 'r1_f1': 0.4186046511627907, 'pegasus_entailment': 0.7348421573638916, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 18}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5670103092783505, 'r1_recall': 0.3179190751445087, 'r1_f1': 0.4074074074074074, 'pegasus_entailment': 0.7309638460477194, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2517482517482518, 'r1_recall': 0.6206896551724138, 'r1_f1': 0.35820895522388063, 'pegasus_entailment': 0.6365961134433746, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5688073394495413, 'r1_recall': 0.4806201550387597, 'r1_f1': 0.5210084033613446, 'pegasus_entailment': 0.6584216307383031, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 15}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5757575757575758, 'r1_recall': 0.3275862068965517, 'r1_f1': 0.41758241758241754, 'pegasus_entailment': 0.5801390588283539, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4925373134328358, 'r1_recall': 0.5076923076923077, 'r1_f1': 0.5, 'pegasus_entailment': 0.3117430403828621, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21348314606741572, 'r1_recall': 0.59375, 'r1_f1': 0.31404958677685946, 'pegasus_entailment': 0.35422632563859224, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23577235772357724, 'r1_recall': 0.9354838709677419, 'r1_f1': 0.37662337662337664, 'pegasus_entailment': 0.7180385775864124, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6324786324786325, 'r1_recall': 0.4966442953020134, 'r1_f1': 0.5563909774436091, 'pegasus_entailment': 0.5034523736685514, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5345911949685535, 'r1_recall': 0.6159420289855072, 'r1_f1': 0.5723905723905723, 'pegasus_entailment': 0.564056122303009, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.28, 'r1_f1': 0.3888888888888889, 'pegasus_entailment': 0.3792187472184499, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5135135135135135, 'r1_recall': 0.6386554621848739, 'r1_f1': 0.5692883895131086, 'pegasus_entailment': 0.6356559216976165, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6323529411764706, 'r1_recall': 0.40186915887850466, 'r1_f1': 0.4914285714285715, 'pegasus_entailment': 0.6316913291811943, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5833333333333334, 'r1_recall': 0.5568181818181818, 'r1_f1': 0.5697674418604651, 'pegasus_entailment': 0.554037480801344, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8421052631578947, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.4776119402985075, 'pegasus_entailment': 0.7531508604685465, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30526315789473685, 'r1_recall': 0.4915254237288136, 'r1_f1': 0.37662337662337664, 'pegasus_entailment': 0.5048609683290124, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 30, 'pegasus_smog': 21}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4260869565217391, 'r1_recall': 0.494949494949495, 'r1_f1': 0.4579439252336448, 'pegasus_entailment': 0.6442155539989471, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7804878048780488, 'r1_recall': 0.21476510067114093, 'r1_f1': 0.3368421052631579, 'pegasus_entailment': 0.3786345024903615, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5641025641025641, 'r1_recall': 0.40993788819875776, 'r1_f1': 0.4748201438848921, 'pegasus_entailment': 0.4121150076389313, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46226415094339623, 'r1_recall': 0.5632183908045977, 'r1_f1': 0.5077720207253887, 'pegasus_entailment': 0.5657297270838171, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49295774647887325, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.43209876543209885, 'pegasus_entailment': 0.3410031097009778, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5760869565217391, 'r1_recall': 0.35333333333333333, 'r1_f1': 0.4380165289256198, 'pegasus_entailment': 0.537751404568553, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4240506329113924, 'r1_recall': 0.6203703703703703, 'r1_f1': 0.5037593984962406, 'pegasus_entailment': 0.5630135110446385, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5248618784530387, 'r1_recall': 0.6985294117647058, 'r1_f1': 0.5993690851735016, 'pegasus_entailment': 0.5288663506507874, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3548387096774194, 'r1_recall': 0.66, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.8118254194657007, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6827586206896552, 'r1_recall': 0.5238095238095238, 'r1_f1': 0.592814371257485, 'pegasus_entailment': 0.4960894446287836, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5725806451612904, 'r1_recall': 0.5182481751824818, 'r1_f1': 0.5440613026819924, 'pegasus_entailment': 0.5141091383993626, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8055555555555556, 'r1_recall': 0.21641791044776118, 'r1_f1': 0.34117647058823525, 'pegasus_entailment': 0.7283573299646378, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46153846153846156, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.4255319148936171, 'pegasus_entailment': 0.6666218861937523, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 13, 'pegasus_ari': 12, 'pegasus_smog': 12}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4174757281553398, 'r1_recall': 0.3805309734513274, 'r1_f1': 0.39814814814814814, 'pegasus_entailment': 0.6875996738672256, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3838383838383838, 'r1_recall': 0.4367816091954023, 'r1_f1': 0.40860215053763443, 'pegasus_entailment': 0.47572206407785417, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5661375661375662, 'r1_recall': 0.5323383084577115, 'r1_f1': 0.5487179487179488, 'pegasus_entailment': 0.6990737080574035, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2713178294573643, 'r1_recall': 0.33980582524271846, 'r1_f1': 0.3017241379310345, 'pegasus_entailment': 0.7878545373678207, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4351851851851852, 'r1_recall': 0.4845360824742268, 'r1_f1': 0.4585365853658536, 'pegasus_entailment': 0.581709209519128, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24311926605504589, 'r1_recall': 0.6309523809523809, 'r1_f1': 0.3509933774834437, 'pegasus_entailment': 0.3763730178276698, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4918032786885246, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.5042016806722689, 'pegasus_entailment': 0.5448851361870766, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.4192139737991266, 'pegasus_entailment': 0.4345658798702061, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35294117647058826, 'r1_recall': 0.35294117647058826, 'r1_f1': 0.35294117647058826, 'pegasus_entailment': 0.6227951487526298, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2727272727272727, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.3975903614457832, 'pegasus_entailment': 0.543422244489193, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47706422018348627, 'r1_recall': 0.3132530120481928, 'r1_f1': 0.37818181818181823, 'pegasus_entailment': 0.854448989033699, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5434782608695652, 'r1_recall': 0.46875, 'r1_f1': 0.5033557046979866, 'pegasus_entailment': 0.7283451035618782, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42424242424242425, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.3916083916083916, 'pegasus_entailment': 0.5577957592904568, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3064516129032258, 'r1_recall': 0.5205479452054794, 'r1_f1': 0.3857868020304568, 'pegasus_entailment': 0.3960432656109333, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5681818181818182, 'r1_recall': 0.6097560975609756, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.8804706335067749, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3584905660377358, 'r1_recall': 0.48717948717948717, 'r1_f1': 0.41304347826086957, 'pegasus_entailment': 0.5101312287151814, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4915254237288136, 'r1_recall': 0.58, 'r1_f1': 0.5321100917431192, 'pegasus_entailment': 0.5870727449655533, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5546875, 'r1_recall': 0.6016949152542372, 'r1_f1': 0.5772357723577236, 'pegasus_entailment': 0.4805351038230583, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34972677595628415, 'r1_recall': 0.5765765765765766, 'r1_f1': 0.43537414965986393, 'pegasus_entailment': 0.7059793557439532, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47706422018348627, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.538860103626943, 'pegasus_entailment': 0.5856862127780914, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4230769230769231, 'r1_recall': 0.4230769230769231, 'r1_f1': 0.4230769230769231, 'pegasus_entailment': 0.3934514671564102, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3053435114503817, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.39024390243902435, 'pegasus_entailment': 0.6642530759175619, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 21}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19718309859154928, 'r1_recall': 0.5490196078431373, 'r1_f1': 0.29015544041450775, 'pegasus_entailment': 0.6255950505534807, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2925170068027211, 'r1_recall': 0.581081081081081, 'r1_f1': 0.3891402714932127, 'pegasus_entailment': 0.648321770131588, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.625, 'r1_recall': 0.2542372881355932, 'r1_f1': 0.3614457831325301, 'pegasus_entailment': 0.19365429505705833, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5641025641025641, 'r1_recall': 0.4943820224719101, 'r1_f1': 0.5269461077844311, 'pegasus_entailment': 0.4430672063802679, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35374149659863946, 'r1_recall': 0.7222222222222222, 'r1_f1': 0.4748858447488584, 'pegasus_entailment': 0.4993423938751221, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6746411483253588, 'r1_recall': 0.5617529880478087, 'r1_f1': 0.6130434782608695, 'pegasus_entailment': 0.7078457176685333, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3838383838383838, 'r1_recall': 0.59375, 'r1_f1': 0.4662576687116564, 'pegasus_entailment': 0.7683439999818802, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6576576576576577, 'r1_recall': 0.6033057851239669, 'r1_f1': 0.6293103448275863, 'pegasus_entailment': 0.4507698374800384, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39436619718309857, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.45344129554655865, 'pegasus_entailment': 0.5593235762789845, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4260869565217391, 'r1_recall': 0.5568181818181818, 'r1_f1': 0.48275862068965514, 'pegasus_entailment': 0.8589949309825897, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32727272727272727, 'r1_recall': 0.5, 'r1_f1': 0.3956043956043956, 'pegasus_entailment': 0.10395068023353815, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.53, 'r1_recall': 0.31547619047619047, 'r1_f1': 0.3955223880597015, 'pegasus_entailment': 0.6895746737718582, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38235294117647056, 'r1_recall': 0.4020618556701031, 'r1_f1': 0.3919597989949749, 'pegasus_entailment': 0.6515593125174443, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4242424242424242, 'pegasus_entailment': 0.40242371149361134, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7027027027027027, 'r1_recall': 0.6141732283464567, 'r1_f1': 0.6554621848739496, 'pegasus_entailment': 0.6133903935551643, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4945054945054945, 'r1_recall': 0.42452830188679247, 'r1_f1': 0.45685279187817257, 'pegasus_entailment': 0.9018978277842203, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2857142857142857, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.36900369003690037, 'pegasus_entailment': 0.4693586155772209, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7428571428571429, 'r1_recall': 0.22608695652173913, 'r1_f1': 0.3466666666666667, 'pegasus_entailment': 0.3757595717906952, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6428571428571429, 'r1_recall': 0.35294117647058826, 'r1_f1': 0.4556962025316456, 'pegasus_entailment': 0.4345832367738088, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48872180451127817, 'r1_recall': 0.39156626506024095, 'r1_f1': 0.4347826086956521, 'pegasus_entailment': 0.553230216105779, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.5, 'pegasus_entailment': 0.40507176518440247, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27941176470588236, 'r1_recall': 0.5757575757575758, 'r1_f1': 0.37623762376237624, 'pegasus_entailment': 0.4185632296305682, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6875, 'r1_recall': 0.4631578947368421, 'r1_f1': 0.5534591194968552, 'pegasus_entailment': 0.5352877229452133, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24404761904761904, 'r1_recall': 0.5694444444444444, 'r1_f1': 0.3416666666666667, 'pegasus_entailment': 0.3297430158903201, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34782608695652173, 'r1_recall': 0.6588235294117647, 'r1_f1': 0.4552845528455284, 'pegasus_entailment': 0.2953799915499985, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2727272727272727, 'r1_recall': 0.65625, 'r1_f1': 0.38532110091743116, 'pegasus_entailment': 0.9261597593625387, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4430379746835443, 'r1_recall': 0.6730769230769231, 'r1_f1': 0.5343511450381679, 'pegasus_entailment': 0.21698218459884325, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4485981308411215, 'r1_recall': 0.5581395348837209, 'r1_f1': 0.4974093264248705, 'pegasus_entailment': 0.5775022730231285, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3883495145631068, 'r1_recall': 0.5970149253731343, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.8476047962903976, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3652173913043478, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.43523316062176165, 'pegasus_entailment': 0.35738417208194734, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6521739130434783, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.6153846153846154, 'pegasus_entailment': 0.21687225719215347, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26495726495726496, 'r1_recall': 0.47692307692307695, 'r1_f1': 0.34065934065934067, 'pegasus_entailment': 0.657327675819397, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7272727272727273, 'r1_recall': 0.27586206896551724, 'r1_f1': 0.4, 'pegasus_entailment': 0.5872938632965088, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5565217391304348, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.6183574879227054, 'pegasus_entailment': 0.4879126101732254, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35064935064935066, 'r1_recall': 0.3103448275862069, 'r1_f1': 0.32926829268292684, 'pegasus_entailment': 0.4749605420511216, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19047619047619047, 'r1_recall': 0.20512820512820512, 'r1_f1': 0.19753086419753083, 'pegasus_entailment': 0.5608057444915175, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 22, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24806201550387597, 'r1_recall': 0.7111111111111111, 'r1_f1': 0.367816091954023, 'pegasus_entailment': 0.9110308885574341, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7974683544303798, 'r1_recall': 0.30288461538461536, 'r1_f1': 0.43902439024390244, 'pegasus_entailment': 0.5946804508566856, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3645833333333333, 'r1_recall': 0.5, 'r1_f1': 0.42168674698795183, 'pegasus_entailment': 0.6069659822969697, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5853658536585366, 'r1_recall': 0.625, 'r1_f1': 0.6045340050377833, 'pegasus_entailment': 0.5814330478509268, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.373134328358209, 'r1_f1': 0.4273504273504274, 'pegasus_entailment': 0.45492797195911405, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4639175257731959, 'r1_recall': 0.6164383561643836, 'r1_f1': 0.5294117647058824, 'pegasus_entailment': 0.4737698229029775, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6282051282051282, 'r1_recall': 0.4188034188034188, 'r1_f1': 0.5025641025641026, 'pegasus_entailment': 0.5861540362238884, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32142857142857145, 'r1_recall': 0.18556701030927836, 'r1_f1': 0.23529411764705885, 'pegasus_entailment': 0.9895817339420319, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5633802816901409, 'r1_recall': 0.4519774011299435, 'r1_f1': 0.5015673981191222, 'pegasus_entailment': 0.6606720864772797, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49411764705882355, 'r1_recall': 0.4329896907216495, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.4769299551844597, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43137254901960786, 'r1_recall': 0.3492063492063492, 'r1_f1': 0.38596491228070173, 'pegasus_entailment': 0.699637308716774, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37894736842105264, 'r1_recall': 0.5538461538461539, 'r1_f1': 0.45, 'pegasus_entailment': 0.6008887253701687, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46, 'r1_recall': 0.4107142857142857, 'r1_f1': 0.43396226415094336, 'pegasus_entailment': 0.5438035457627848, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4266666666666667, 'r1_recall': 0.5245901639344263, 'r1_f1': 0.4705882352941177, 'pegasus_entailment': 0.4553866076748818, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44285714285714284, 'r1_recall': 0.32978723404255317, 'r1_f1': 0.3780487804878049, 'pegasus_entailment': 0.72642832249403, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4012738853503185, 'r1_recall': 0.5478260869565217, 'r1_f1': 0.4632352941176471, 'pegasus_entailment': 0.7422184467315673, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4697986577181208, 'r1_recall': 0.625, 'r1_f1': 0.5363984674329502, 'pegasus_entailment': 0.7274633745352427, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 33, 'pegasus_smog': 25}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5204081632653061, 'r1_recall': 0.6375, 'r1_f1': 0.5730337078651685, 'pegasus_entailment': 0.8147348562876383, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.55, 'r1_recall': 0.34108527131782945, 'r1_f1': 0.4210526315789474, 'pegasus_entailment': 0.47684891149401665, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30927835051546393, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.40404040404040403, 'pegasus_entailment': 0.5963372215628624, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5434782608695652, 'r1_recall': 0.3125, 'r1_f1': 0.39682539682539686, 'pegasus_entailment': 0.4965834736824036, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43137254901960786, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.4971751412429378, 'pegasus_entailment': 0.4893276434740983, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27835051546391754, 'r1_recall': 0.45, 'r1_f1': 0.34394904458598724, 'pegasus_entailment': 0.682743239402771, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45555555555555555, 'r1_recall': 0.5942028985507246, 'r1_f1': 0.5157232704402516, 'pegasus_entailment': 0.8369361609220505, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6896551724137931, 'r1_recall': 0.45112781954887216, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.7505297660827637, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6140350877192983, 'r1_recall': 0.4430379746835443, 'r1_f1': 0.5147058823529411, 'pegasus_entailment': 0.4558984306640923, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.550561797752809, 'r1_f1': 0.5240641711229946, 'pegasus_entailment': 0.566013902425766, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46296296296296297, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.4201680672268908, 'pegasus_entailment': 0.5369201395660639, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.449438202247191, 'r1_f1': 0.4968944099378882, 'pegasus_entailment': 0.5293026204620089, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7476635514018691, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.5653710247349824, 'pegasus_entailment': 0.5792655311524868, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.591304347826087, 'r1_recall': 0.5074626865671642, 'r1_f1': 0.5461847389558233, 'pegasus_entailment': 0.6152117609162815, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47126436781609193, 'r1_recall': 0.43617021276595747, 'r1_f1': 0.4530386740331492, 'pegasus_entailment': 0.4779843406518921, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6571428571428571, 'r1_recall': 0.36220472440944884, 'r1_f1': 0.46700507614213194, 'pegasus_entailment': 0.7750187317530314, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5692307692307692, 'r1_recall': 0.42045454545454547, 'r1_f1': 0.48366013071895425, 'pegasus_entailment': 0.8768944144248962, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5772357723577236, 'r1_recall': 0.6173913043478261, 'r1_f1': 0.5966386554621849, 'pegasus_entailment': 0.7862015515565872, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3197278911564626, 'r1_recall': 0.618421052631579, 'r1_f1': 0.4215246636771301, 'pegasus_entailment': 0.589098185300827, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25252525252525254, 'r1_recall': 0.5813953488372093, 'r1_f1': 0.35211267605633806, 'pegasus_entailment': 0.48957785964012146, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5333333333333333, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5517241379310344, 'pegasus_entailment': 0.8626371026039124, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5655737704918032, 'r1_recall': 0.5267175572519084, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.5354201287031174, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34965034965034963, 'r1_recall': 0.625, 'r1_f1': 0.4484304932735426, 'pegasus_entailment': 0.613013532757759, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5208333333333334, 'r1_recall': 0.42735042735042733, 'r1_f1': 0.4694835680751174, 'pegasus_entailment': 0.9429163336753845, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4411764705882353, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.47619047619047616, 'pegasus_entailment': 0.4907437164802104, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3854166666666667, 'r1_recall': 0.6271186440677966, 'r1_f1': 0.47741935483870973, 'pegasus_entailment': 0.4125185890123248, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7247706422018348, 'r1_recall': 0.41798941798941797, 'r1_f1': 0.5302013422818791, 'pegasus_entailment': 0.19228354981169105, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5354330708661418, 'r1_recall': 0.5619834710743802, 'r1_f1': 0.5483870967741936, 'pegasus_entailment': 0.7388025753200054, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5408163265306123, 'r1_recall': 0.3419354838709677, 'r1_f1': 0.41897233201581024, 'pegasus_entailment': 0.7639823973178863, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.591304347826087, 'r1_recall': 0.4171779141104294, 'r1_f1': 0.4892086330935252, 'pegasus_entailment': 0.4615825294916119, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.504950495049505, 'r1_recall': 0.504950495049505, 'r1_f1': 0.504950495049505, 'pegasus_entailment': 0.3682576101273298, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46774193548387094, 'r1_recall': 0.4793388429752066, 'r1_f1': 0.473469387755102, 'pegasus_entailment': 0.6474110186100006, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3165829145728643, 'r1_recall': 0.6774193548387096, 'r1_f1': 0.43150684931506844, 'pegasus_entailment': 0.775412917137146, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.608, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5891472868217055, 'pegasus_entailment': 0.9140002876520157, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.34594594594594597, 'r1_f1': 0.43097643097643096, 'pegasus_entailment': 0.6280786097049713, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3611111111111111, 'r1_recall': 0.6724137931034483, 'r1_f1': 0.46987951807228917, 'pegasus_entailment': 0.6180088687688112, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3865546218487395, 'r1_recall': 0.5227272727272727, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.37814542055130007, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43617021276595747, 'r1_recall': 0.44086021505376344, 'r1_f1': 0.4385026737967915, 'pegasus_entailment': 0.6685436740517616, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42105263157894735, 'r1_recall': 0.4247787610619469, 'r1_f1': 0.4229074889867841, 'pegasus_entailment': 0.4996491730213165, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5747126436781609, 'r1_recall': 0.625, 'r1_f1': 0.5988023952095808, 'pegasus_entailment': 0.4781847968697548, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49137931034482757, 'r1_recall': 0.5643564356435643, 'r1_f1': 0.5253456221198156, 'pegasus_entailment': 0.7575436234474182, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 23, 'pegasus_ari': 26, 'pegasus_smog': 24}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5878787878787879, 'r1_recall': 0.46411483253588515, 'r1_f1': 0.518716577540107, 'pegasus_entailment': 0.8302194029092789, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5507246376811594, 'r1_recall': 0.4198895027624309, 'r1_f1': 0.47648902821316613, 'pegasus_entailment': 0.5665974795818329, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3177570093457944, 'r1_recall': 0.576271186440678, 'r1_f1': 0.4096385542168674, 'pegasus_entailment': 0.6564108191523701, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7142857142857143, 'r1_recall': 0.37037037037037035, 'r1_f1': 0.4878048780487805, 'pegasus_entailment': 0.21577957086265087, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37142857142857144, 'r1_recall': 0.6341463414634146, 'r1_f1': 0.46846846846846846, 'pegasus_entailment': 0.39793619016806286, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5303030303030303, 'r1_recall': 0.3645833333333333, 'r1_f1': 0.43209876543209874, 'pegasus_entailment': 0.5266178091987967, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44954128440366975, 'r1_recall': 0.532608695652174, 'r1_f1': 0.48756218905472637, 'pegasus_entailment': 0.6146176218986511, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6260869565217392, 'r1_recall': 0.3711340206185567, 'r1_f1': 0.4660194174757282, 'pegasus_entailment': 0.4548127732705325, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47183098591549294, 'r1_recall': 0.4036144578313253, 'r1_f1': 0.43506493506493504, 'pegasus_entailment': 0.4483971446752548, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 22, 'pegasus_ari': 34, 'pegasus_smog': 26}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28695652173913044, 'r1_recall': 0.559322033898305, 'r1_f1': 0.3793103448275862, 'pegasus_entailment': 0.6844747588038445, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5144508670520231, 'r1_recall': 0.5144508670520231, 'r1_f1': 0.5144508670520231, 'pegasus_entailment': 0.5360991756121317, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.35802469135802467, 'r1_f1': 0.41726618705035967, 'pegasus_entailment': 0.9416255354881287, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5075757575757576, 'r1_recall': 0.44966442953020136, 'r1_f1': 0.47686832740213525, 'pegasus_entailment': 0.6940502673387527, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.49074074074074076, 'r1_recall': 0.5698924731182796, 'r1_f1': 0.527363184079602, 'pegasus_entailment': 0.1699424615362659, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5862068965517241, 'r1_recall': 0.3167701863354037, 'r1_f1': 0.4112903225806452, 'pegasus_entailment': 0.2561538890004158, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.15315315315315314, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.22818791946308722, 'pegasus_entailment': 0.6677050534635782, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5757575757575758, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.5507246376811594, 'pegasus_entailment': 0.8654412865638733, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4122137404580153, 'r1_recall': 0.5242718446601942, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.6862590437134107, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5298507462686567, 'r1_recall': 0.43558282208588955, 'r1_f1': 0.47811447811447805, 'pegasus_entailment': 0.7456983029842377, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3776223776223776, 'r1_recall': 0.4954128440366973, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.43190934509038925, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5939849624060151, 'r1_recall': 0.44886363636363635, 'r1_f1': 0.511326860841424, 'pegasus_entailment': 0.4050767396887143, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5255474452554745, 'r1_recall': 0.48, 'r1_f1': 0.5017421602787456, 'pegasus_entailment': 0.3967253789305687, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5079365079365079, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.481203007518797, 'pegasus_entailment': 0.6720576087633768, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 19}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4954128440366973, 'r1_recall': 0.3624161073825503, 'r1_f1': 0.4186046511627907, 'pegasus_entailment': 0.33260222018829416, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2966507177033493, 'r1_recall': 0.6813186813186813, 'r1_f1': 0.41333333333333333, 'pegasus_entailment': 0.44876979757100344, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3624161073825503, 'r1_recall': 0.7012987012987013, 'r1_f1': 0.47787610619469034, 'pegasus_entailment': 0.5771097019314766, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3488372093023256, 'r1_recall': 0.6164383561643836, 'r1_f1': 0.44554455445544555, 'pegasus_entailment': 0.6869804710149765, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.696078431372549, 'r1_recall': 0.19293478260869565, 'r1_f1': 0.3021276595744681, 'pegasus_entailment': 0.5865449085831642, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5081967213114754, 'r1_recall': 0.5636363636363636, 'r1_f1': 0.5344827586206896, 'pegasus_entailment': 0.7450704082846642, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3804347826086957, 'r1_recall': 0.5645161290322581, 'r1_f1': 0.4545454545454546, 'pegasus_entailment': 0.5252612829208374, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45161290322580644, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.509090909090909, 'pegasus_entailment': 0.5930312871932983, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.848, 'r1_recall': 0.451063829787234, 'r1_f1': 0.5888888888888889, 'pegasus_entailment': 0.6785199145476023, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45695364238410596, 'r1_recall': 0.45394736842105265, 'r1_f1': 0.45544554455445546, 'pegasus_entailment': 0.29741659494382994, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40476190476190477, 'r1_recall': 0.5930232558139535, 'r1_f1': 0.4811320754716981, 'pegasus_entailment': 0.8214758187532425, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4158415841584158, 'r1_recall': 0.56, 'r1_f1': 0.4772727272727273, 'pegasus_entailment': 0.7344293296337128, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4491525423728814, 'r1_recall': 0.5888888888888889, 'r1_f1': 0.5096153846153846, 'pegasus_entailment': 0.5032514660153538, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6, 'r1_recall': 0.32926829268292684, 'r1_f1': 0.4251968503937008, 'pegasus_entailment': 0.6216092318296432, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8021978021978022, 'r1_recall': 0.25435540069686413, 'r1_f1': 0.3862433862433862, 'pegasus_entailment': 0.45255130529403687, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7894736842105263, 'r1_recall': 0.25139664804469275, 'r1_f1': 0.38135593220338987, 'pegasus_entailment': 0.48174259066581726, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.535031847133758, 'r1_recall': 0.7368421052631579, 'r1_f1': 0.6199261992619925, 'pegasus_entailment': 0.6112629175186157, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6354166666666666, 'r1_recall': 0.46923076923076923, 'r1_f1': 0.5398230088495576, 'pegasus_entailment': 0.6432356745004654, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5412844036697247, 'r1_recall': 0.5673076923076923, 'r1_f1': 0.5539906103286385, 'pegasus_entailment': 0.4645259715616703, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3288590604026846, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.4206008583690988, 'pegasus_entailment': 0.8624179561932882, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6165413533834586, 'r1_recall': 0.5061728395061729, 'r1_f1': 0.5559322033898304, 'pegasus_entailment': 0.8173076808452606, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47058823529411764, 'r1_recall': 0.5194805194805194, 'r1_f1': 0.49382716049382713, 'pegasus_entailment': 0.3856522996599476, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.592, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.5501858736059478, 'pegasus_entailment': 0.5324289724230766, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5679012345679012, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.5897435897435898, 'pegasus_entailment': 0.5469396710395813, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4962962962962963, 'r1_recall': 0.5537190082644629, 'r1_f1': 0.5234375, 'pegasus_entailment': 0.6852131336927414, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6015037593984962, 'r1_recall': 0.7207207207207207, 'r1_f1': 0.6557377049180327, 'pegasus_entailment': 0.7152285152114928, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5185185185185185, 'r1_recall': 0.34355828220858897, 'r1_f1': 0.41328413284132837, 'pegasus_entailment': 0.3930696830153465, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5981308411214953, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.45229681978798586, 'pegasus_entailment': 0.44428209494799376, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5490196078431373, 'r1_recall': 0.7, 'r1_f1': 0.6153846153846154, 'pegasus_entailment': 0.716097061522305, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29591836734693877, 'r1_recall': 0.48333333333333334, 'r1_f1': 0.36708860759493667, 'pegasus_entailment': 0.2349606603384018, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3563218390804598, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.42176870748299317, 'pegasus_entailment': 0.4237683638930321, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5113636363636364, 'r1_recall': 0.45918367346938777, 'r1_f1': 0.48387096774193544, 'pegasus_entailment': 0.24797931779175997, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.512, 'r1_recall': 0.49230769230769234, 'r1_f1': 0.5019607843137256, 'pegasus_entailment': 0.6341019570827484, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.25862068965517243, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.37037037037037046, 'pegasus_entailment': 0.7137131105992012, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4338235294117647, 'r1_recall': 0.5175438596491229, 'r1_f1': 0.47200000000000003, 'pegasus_entailment': 0.5326001085340977, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3904109589041096, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.443579766536965, 'pegasus_entailment': 0.40606483817100525, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7021276595744681, 'r1_recall': 0.3013698630136986, 'r1_f1': 0.42172523961661335, 'pegasus_entailment': 0.3764108708128333, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46551724137931033, 'r1_recall': 0.6585365853658537, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.6172560812905431, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3732394366197183, 'r1_recall': 0.6022727272727273, 'r1_f1': 0.46086956521739136, 'pegasus_entailment': 0.46185902059078215, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5752212389380531, 'r1_recall': 0.6435643564356436, 'r1_f1': 0.6074766355140188, 'pegasus_entailment': 0.08419657498598099, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5487804878048781, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.4736842105263158, 'pegasus_entailment': 0.15370569378137589, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1984732824427481, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.29050279329608936, 'pegasus_entailment': 0.2787112466758117, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48598130841121495, 'r1_recall': 0.5252525252525253, 'r1_f1': 0.5048543689320388, 'pegasus_entailment': 0.41883407284816104, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5588235294117647, 'r1_recall': 0.24050632911392406, 'r1_f1': 0.336283185840708, 'pegasus_entailment': 0.5262583494186401, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47282608695652173, 'r1_recall': 0.5506329113924051, 'r1_f1': 0.5087719298245614, 'pegasus_entailment': 0.6767398033823285, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6336633663366337, 'r1_recall': 0.3316062176165803, 'r1_f1': 0.435374149659864, 'pegasus_entailment': 0.34595276415348053, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.525, 'r1_recall': 0.4, 'r1_f1': 0.4540540540540541, 'pegasus_entailment': 0.4068168370674054, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5683453237410072, 'r1_recall': 0.632, 'r1_f1': 0.5984848484848484, 'pegasus_entailment': 0.5395154416561126, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2803738317757009, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.3773584905660377, 'pegasus_entailment': 0.11153487022966146, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26373626373626374, 'r1_recall': 0.39344262295081966, 'r1_f1': 0.31578947368421056, 'pegasus_entailment': 0.4461833171080798, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4020618556701031, 'r1_recall': 0.6290322580645161, 'r1_f1': 0.49056603773584906, 'pegasus_entailment': 0.4877253378120561, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28421052631578947, 'r1_recall': 0.4576271186440678, 'r1_f1': 0.35064935064935066, 'pegasus_entailment': 0.6068232111632824, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.379746835443038, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.44117647058823534, 'pegasus_entailment': 0.44474547877907755, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23129251700680273, 'r1_recall': 0.3434343434343434, 'r1_f1': 0.2764227642276423, 'pegasus_entailment': 0.590437525510788, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3116883116883117, 'r1_recall': 0.6, 'r1_f1': 0.41025641025641024, 'pegasus_entailment': 0.27151846264799434, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42792792792792794, 'r1_recall': 0.5491329479768786, 'r1_f1': 0.4810126582278481, 'pegasus_entailment': 0.4514639973640442, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41379310344827586, 'r1_recall': 0.45, 'r1_f1': 0.4311377245508982, 'pegasus_entailment': 0.3524085810141904, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6083333333333333, 'r1_recall': 0.4101123595505618, 'r1_f1': 0.4899328859060403, 'pegasus_entailment': 0.6008139178156853, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6727272727272727, 'r1_recall': 0.45962732919254656, 'r1_f1': 0.5461254612546126, 'pegasus_entailment': 0.2739464584738016, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6835443037974683, 'r1_recall': 0.40298507462686567, 'r1_f1': 0.5070422535211268, 'pegasus_entailment': 0.28634559246711433, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7083333333333334, 'r1_recall': 0.27983539094650206, 'r1_f1': 0.4011799410029499, 'pegasus_entailment': 0.29430646263062954, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5192307692307693, 'r1_recall': 0.6585365853658537, 'r1_f1': 0.5806451612903226, 'pegasus_entailment': 0.7152362863222758, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6951219512195121, 'r1_recall': 0.375, 'r1_f1': 0.4871794871794871, 'pegasus_entailment': 0.3263723449781537, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28225806451612906, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.35714285714285715, 'pegasus_entailment': 0.6356514483457432, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6065573770491803, 'r1_recall': 0.33183856502242154, 'r1_f1': 0.4289855072463768, 'pegasus_entailment': 0.5826140344142914, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36923076923076925, 'r1_recall': 0.21238938053097345, 'r1_f1': 0.2696629213483146, 'pegasus_entailment': 0.4116910969217618, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3402061855670103, 'r1_recall': 0.717391304347826, 'r1_f1': 0.46153846153846156, 'pegasus_entailment': 0.4639314687810838, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.430939226519337, 'r1_f1': 0.5234899328859061, 'pegasus_entailment': 0.22483497187495233, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6101694915254238, 'r1_recall': 0.4067796610169492, 'r1_f1': 0.48813559322033906, 'pegasus_entailment': 0.42349207075312734, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5742574257425742, 'r1_recall': 0.6041666666666666, 'r1_f1': 0.5888324873096447, 'pegasus_entailment': 0.5862513229250907, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5677966101694916, 'r1_recall': 0.46206896551724136, 'r1_f1': 0.5095057034220531, 'pegasus_entailment': 0.7491622318824133, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.08187134502923976, 'r1_recall': 0.5, 'r1_f1': 0.1407035175879397, 'pegasus_entailment': 0.20340391397476196, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22764227642276422, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.30939226519337015, 'pegasus_entailment': 0.5152977940936884, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6046511627906976, 'r1_recall': 0.4369747899159664, 'r1_f1': 0.5073170731707317, 'pegasus_entailment': 0.2052080084104091, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36134453781512604, 'r1_recall': 0.6056338028169014, 'r1_f1': 0.4526315789473684, 'pegasus_entailment': 0.6449704945087433, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2523364485981308, 'r1_recall': 0.4909090909090909, 'r1_f1': 0.3333333333333333, 'pegasus_entailment': 0.580224851767222, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2815533980582524, 'r1_recall': 0.35802469135802467, 'r1_f1': 0.31521739130434784, 'pegasus_entailment': 0.36968053160235287, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5609756097560976, 'r1_recall': 0.5679012345679012, 'r1_f1': 0.5644171779141105, 'pegasus_entailment': 0.6768870448383192, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4691358024691358, 'r1_recall': 0.4578313253012048, 'r1_f1': 0.46341463414634143, 'pegasus_entailment': 0.06486569593350093, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5289256198347108, 'r1_recall': 0.5765765765765766, 'r1_f1': 0.5517241379310346, 'pegasus_entailment': 0.16741595976054668, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.20833333333333334, 'r1_f1': 0.3174603174603175, 'pegasus_entailment': 0.5522402942180633, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.591304347826087, 'r1_recall': 0.3063063063063063, 'r1_f1': 0.4035608308605341, 'pegasus_entailment': 0.4655510224401951, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31496062992125984, 'r1_recall': 0.5128205128205128, 'r1_f1': 0.39024390243902435, 'pegasus_entailment': 0.4492850874861081, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5584415584415584, 'r1_recall': 0.41346153846153844, 'r1_f1': 0.4751381215469613, 'pegasus_entailment': 0.28043892482916516, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21052631578947367, 'r1_recall': 0.547945205479452, 'r1_f1': 0.3041825095057034, 'pegasus_entailment': 0.23863291274756193, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 19, 'pegasus_ari': 32, 'pegasus_smog': 24}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4117647058823529, 'r1_recall': 0.4307692307692308, 'r1_f1': 0.4210526315789474, 'pegasus_entailment': 0.30681025609374046, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5588235294117647, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.5428571428571428, 'pegasus_entailment': 0.45162861545880634, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5316455696202531, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.525, 'pegasus_entailment': 0.2995118023827672, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35398230088495575, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.42328042328042326, 'pegasus_entailment': 0.9137134154637655, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.38095238095238093, 'r1_f1': 0.4324324324324324, 'pegasus_entailment': 0.3424883104550342, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6132075471698113, 'r1_recall': 0.4140127388535032, 'r1_f1': 0.494296577946768, 'pegasus_entailment': 0.8214298486709595, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.711340206185567, 'r1_recall': 0.4791666666666667, 'r1_f1': 0.5726141078838175, 'pegasus_entailment': 0.5192443281412125, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36231884057971014, 'r1_recall': 0.5319148936170213, 'r1_f1': 0.43103448275862066, 'pegasus_entailment': 0.3543339447739224, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6030150753768844, 'r1_recall': 0.6282722513089005, 'r1_f1': 0.6153846153846154, 'pegasus_entailment': 0.4400359243154526, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36082474226804123, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.47945205479452063, 'pegasus_entailment': 0.7571660180886587, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5147058823529411, 'r1_recall': 0.42168674698795183, 'r1_f1': 0.46357615894039733, 'pegasus_entailment': 0.4108598679304123, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 12, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.449438202247191, 'r1_recall': 0.5128205128205128, 'r1_f1': 0.4790419161676646, 'pegasus_entailment': 0.5236429693177342, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3602941176470588, 'r1_recall': 0.6049382716049383, 'r1_f1': 0.45161290322580644, 'pegasus_entailment': 0.7576796859502792, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5811965811965812, 'r1_recall': 0.49635036496350365, 'r1_f1': 0.5354330708661418, 'pegasus_entailment': 0.7871238142251968, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.16666666666666666, 'r1_recall': 0.20454545454545456, 'r1_f1': 0.18367346938775508, 'pegasus_entailment': 0.8998277634382248, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2672413793103448, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.35428571428571426, 'pegasus_entailment': 0.8098358064889908, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.525, 'r1_recall': 0.4701492537313433, 'r1_f1': 0.49606299212598426, 'pegasus_entailment': 0.5717770010232925, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5350877192982456, 'r1_recall': 0.391025641025641, 'r1_f1': 0.4518518518518518, 'pegasus_entailment': 0.30285973846912384, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37398373983739835, 'r1_recall': 0.7076923076923077, 'r1_f1': 0.4893617021276596, 'pegasus_entailment': 0.7566434741020203, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4067796610169492, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.46601941747572817, 'pegasus_entailment': 0.44218563493341206, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4625, 'r1_recall': 0.44047619047619047, 'r1_f1': 0.45121951219512196, 'pegasus_entailment': 0.6266898910204569, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4457831325301205, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.46249999999999997, 'pegasus_entailment': 0.44304477112988633, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26973684210526316, 'r1_recall': 0.5125, 'r1_f1': 0.35344827586206895, 'pegasus_entailment': 0.5985130469004313, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5060240963855421, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5217391304347826, 'pegasus_entailment': 0.5234116017818451, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3300970873786408, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.37988826815642457, 'pegasus_entailment': 0.48047983944416045, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37142857142857144, 'r1_recall': 0.4588235294117647, 'r1_f1': 0.41052631578947374, 'pegasus_entailment': 0.3732333779335022, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6938775510204082, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.5938864628820961, 'pegasus_entailment': 0.4068734338507056, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4536082474226804, 'r1_recall': 0.41509433962264153, 'r1_f1': 0.43349753694581283, 'pegasus_entailment': 0.07665338087826967, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6714285714285714, 'r1_recall': 0.5136612021857924, 'r1_f1': 0.5820433436532507, 'pegasus_entailment': 0.6659915099541346, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4339622641509434, 'r1_recall': 0.6052631578947368, 'r1_f1': 0.5054945054945055, 'pegasus_entailment': 0.42931078020483254, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.3804347826086957, 'r1_f1': 0.4320987654320988, 'pegasus_entailment': 0.33472659904509783, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7372262773722628, 'r1_recall': 0.4675925925925926, 'r1_f1': 0.5722379603399433, 'pegasus_entailment': 0.2494339388795197, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5333333333333333, 'r1_recall': 0.5544554455445545, 'r1_f1': 0.5436893203883496, 'pegasus_entailment': 0.2385635015865167, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5915492957746479, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.49704142011834324, 'pegasus_entailment': 0.07520179813727737, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38613861386138615, 'r1_recall': 0.5571428571428572, 'r1_f1': 0.45614035087719296, 'pegasus_entailment': 0.5802864006254822, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6134453781512605, 'r1_recall': 0.5488721804511278, 'r1_f1': 0.5793650793650794, 'pegasus_entailment': 0.439473744132556, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5833333333333334, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.4666666666666666, 'pegasus_entailment': 0.2270530511935552, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 12, 'pegasus_smog': 13}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.44, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.4583333333333333, 'pegasus_entailment': 0.4460999697446823, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4406779661016949, 'r1_recall': 0.46846846846846846, 'r1_f1': 0.4541484716157205, 'pegasus_entailment': 0.6724190215269724, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 26}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5471698113207547, 'r1_recall': 0.42028985507246375, 'r1_f1': 0.47540983606557374, 'pegasus_entailment': 0.4061697781085968, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24528301886792453, 'r1_recall': 0.52, 'r1_f1': 0.3333333333333333, 'pegasus_entailment': 0.4809692561626434, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2746478873239437, 'r1_recall': 0.6964285714285714, 'r1_f1': 0.3939393939393939, 'pegasus_entailment': 0.36738834977149964, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1357142857142857, 'r1_recall': 0.40425531914893614, 'r1_f1': 0.2032085561497326, 'pegasus_entailment': 0.18972714138882502, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4126984126984127, 'r1_recall': 0.36619718309859156, 'r1_f1': 0.38805970149253727, 'pegasus_entailment': 0.236556565699478, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5052631578947369, 'r1_recall': 0.26229508196721313, 'r1_f1': 0.34532374100719426, 'pegasus_entailment': 0.26008071936666965, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4049079754601227, 'r1_recall': 0.48175182481751827, 'r1_f1': 0.44000000000000006, 'pegasus_entailment': 0.7903611063957214, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5416666666666666, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.4785276073619632, 'pegasus_entailment': 0.3498586749192327, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4090909090909091, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.43902439024390244, 'pegasus_entailment': 0.40411991626024246, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5563380281690141, 'r1_recall': 0.4817073170731707, 'r1_f1': 0.5163398692810457, 'pegasus_entailment': 0.5431040227413177, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7321428571428571, 'r1_recall': 0.4079601990049751, 'r1_f1': 0.523961661341853, 'pegasus_entailment': 0.4338844632729888, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3707865168539326, 'r1_recall': 0.33, 'r1_f1': 0.3492063492063492, 'pegasus_entailment': 0.43851054087281227, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7068965517241379, 'r1_recall': 0.5125, 'r1_f1': 0.5942028985507246, 'pegasus_entailment': 0.5017181215807796, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.375, 'r1_recall': 0.36585365853658536, 'r1_f1': 0.3703703703703704, 'pegasus_entailment': 0.006110206129960716, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 26}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18333333333333332, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.2619047619047619, 'pegasus_entailment': 0.7591863870620728, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3953488372093023, 'r1_recall': 0.5396825396825397, 'r1_f1': 0.4563758389261745, 'pegasus_entailment': 0.4540665769018233, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1282051282051282, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.21052631578947367, 'pegasus_entailment': 0.7147993437945843, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.37037037037037035, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.4083533058874309, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6049382716049383, 'r1_recall': 0.266304347826087, 'r1_f1': 0.369811320754717, 'pegasus_entailment': 0.5081219255924225, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3157894736842105, 'r1_recall': 0.44776119402985076, 'r1_f1': 0.37037037037037035, 'pegasus_entailment': 0.28342368006706237, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5903614457831325, 'r1_recall': 0.2916666666666667, 'r1_f1': 0.3904382470119522, 'pegasus_entailment': 0.46892241993919015, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49019607843137253, 'r1_recall': 0.5681818181818182, 'r1_f1': 0.5263157894736843, 'pegasus_entailment': 0.33860598717417034, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5396825396825397, 'r1_recall': 0.43037974683544306, 'r1_f1': 0.47887323943661975, 'pegasus_entailment': 0.4301091343164444, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7238095238095238, 'r1_recall': 0.25675675675675674, 'r1_f1': 0.37905236907730677, 'pegasus_entailment': 0.5976445898413658, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3673469387755102, 'r1_recall': 0.6545454545454545, 'r1_f1': 0.4705882352941177, 'pegasus_entailment': 0.5309756265953183, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6440677966101694, 'r1_recall': 0.38578680203045684, 'r1_f1': 0.48253968253968255, 'pegasus_entailment': 0.19262277334928513, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3626373626373626, 'r1_recall': 0.55, 'r1_f1': 0.4370860927152318, 'pegasus_entailment': 0.3880271414915721, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5346534653465347, 'r1_recall': 0.43902439024390244, 'r1_f1': 0.4821428571428572, 'pegasus_entailment': 0.7389291882514953, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4774774774774775, 'r1_recall': 0.5047619047619047, 'r1_f1': 0.49074074074074076, 'pegasus_entailment': 0.5373435895889997, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.78125, 'r1_recall': 0.5725190839694656, 'r1_f1': 0.6607929515418502, 'pegasus_entailment': 0.41156620513647796, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3793103448275862, 'r1_recall': 0.3283582089552239, 'r1_f1': 0.35200000000000004, 'pegasus_entailment': 0.5808025300502777, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22875816993464052, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.33333333333333337, 'pegasus_entailment': 0.4643034189939499, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 21, 'pegasus_ari': 35, 'pegasus_smog': 24}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26490066225165565, 'r1_recall': 0.7017543859649122, 'r1_f1': 0.38461538461538464, 'pegasus_entailment': 0.7497343868017197, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5514018691588785, 'r1_recall': 0.4609375, 'r1_f1': 0.502127659574468, 'pegasus_entailment': 0.3304274193942547, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6470588235294118, 'r1_recall': 0.4943820224719101, 'r1_f1': 0.5605095541401274, 'pegasus_entailment': 0.6392634436488152, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6131386861313869, 'r1_recall': 0.5153374233128835, 'r1_f1': 0.56, 'pegasus_entailment': 0.6385226428508759, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6126760563380281, 'r1_recall': 0.45077720207253885, 'r1_f1': 0.5194029850746269, 'pegasus_entailment': 0.6433861196041107, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5208333333333334, 'r1_recall': 0.49504950495049505, 'r1_f1': 0.5076142131979695, 'pegasus_entailment': 0.3601360201835632, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3132530120481928, 'r1_recall': 0.6190476190476191, 'r1_f1': 0.41600000000000004, 'pegasus_entailment': 0.4153551533818245, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44680851063829785, 'r1_recall': 0.23333333333333334, 'r1_f1': 0.30656934306569344, 'pegasus_entailment': 0.45914114577074844, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 19, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2815533980582524, 'r1_recall': 0.5686274509803921, 'r1_f1': 0.3766233766233766, 'pegasus_entailment': 0.28460291773080826, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6052631578947368, 'r1_recall': 0.46621621621621623, 'r1_f1': 0.5267175572519085, 'pegasus_entailment': 0.484067623813947, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5789473684210527, 'r1_recall': 0.5038167938931297, 'r1_f1': 0.5387755102040817, 'pegasus_entailment': 0.5531729268841445, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.4067796610169492, 'r1_f1': 0.4897959183673469, 'pegasus_entailment': 0.9103708068529764, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7857142857142857, 'r1_recall': 0.5076923076923077, 'r1_f1': 0.6168224299065421, 'pegasus_entailment': 0.5902798821528753, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49166666666666664, 'r1_recall': 0.4957983193277311, 'r1_f1': 0.4937238493723849, 'pegasus_entailment': 0.2434557887415091, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6022727272727273, 'r1_recall': 0.3680555555555556, 'r1_f1': 0.45689655172413796, 'pegasus_entailment': 0.3832315467298031, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5818181818181818, 'r1_recall': 0.35555555555555557, 'r1_f1': 0.4413793103448276, 'pegasus_entailment': 0.24318273862202963, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4117647058823529, 'r1_recall': 0.6842105263157895, 'r1_f1': 0.5141242937853107, 'pegasus_entailment': 0.6520061619579792, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6440677966101694, 'r1_recall': 0.3584905660377358, 'r1_f1': 0.4606060606060606, 'pegasus_entailment': 0.6048681378364563, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32432432432432434, 'r1_recall': 0.42105263157894735, 'r1_f1': 0.36641221374045807, 'pegasus_entailment': 0.49772993847727776, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6582278481012658, 'r1_recall': 0.40625, 'r1_f1': 0.5024154589371981, 'pegasus_entailment': 0.9439619332551956, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3870967741935484, 'r1_recall': 0.21052631578947367, 'r1_f1': 0.2727272727272727, 'pegasus_entailment': 0.2626360356807709, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.616, 'r1_recall': 0.4031413612565445, 'r1_f1': 0.48734177215189867, 'pegasus_entailment': 0.6042161136865616, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5524475524475524, 'r1_recall': 0.5374149659863946, 'r1_f1': 0.5448275862068965, 'pegasus_entailment': 0.23221524820352593, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5128205128205128, 'r1_recall': 0.38961038961038963, 'r1_f1': 0.4428044280442804, 'pegasus_entailment': 0.884244700272878, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 30, 'pegasus_smog': 22}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3900709219858156, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.5092592592592593, 'pegasus_entailment': 0.6645169101655484, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5116279069767442, 'r1_recall': 0.5739130434782609, 'r1_f1': 0.5409836065573771, 'pegasus_entailment': 0.5947190920511881, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.593103448275862, 'r1_recall': 0.5620915032679739, 'r1_f1': 0.5771812080536912, 'pegasus_entailment': 0.6597759574651718, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6551724137931034, 'r1_recall': 0.18627450980392157, 'r1_f1': 0.29007633587786263, 'pegasus_entailment': 0.5421923995018005, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 14}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2882882882882883, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.380952380952381, 'pegasus_entailment': 0.37146581783890725, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48717948717948717, 'r1_recall': 0.59375, 'r1_f1': 0.5352112676056338, 'pegasus_entailment': 0.5839210224803537, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4479166666666667, 'r1_recall': 0.5733333333333334, 'r1_f1': 0.5029239766081871, 'pegasus_entailment': 0.15920962148811668, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39080459770114945, 'r1_recall': 0.6415094339622641, 'r1_f1': 0.4857142857142857, 'pegasus_entailment': 0.6545245870947838, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5098039215686274, 'r1_recall': 0.27956989247311825, 'r1_f1': 0.36111111111111105, 'pegasus_entailment': 0.4068358540534973, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43157894736842106, 'r1_recall': 0.7068965517241379, 'r1_f1': 0.5359477124183006, 'pegasus_entailment': 0.7006362861332794, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5434782608695652, 'r1_recall': 0.49019607843137253, 'r1_f1': 0.5154639175257731, 'pegasus_entailment': 0.2872748665511608, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.62, 'r1_recall': 0.3924050632911392, 'r1_f1': 0.4806201550387597, 'pegasus_entailment': 0.5301170647144318, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.6140350877192983, 'r1_f1': 0.3553299492385787, 'pegasus_entailment': 0.5617388139168421, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6451612903225806, 'r1_recall': 0.40268456375838924, 'r1_f1': 0.49586776859504134, 'pegasus_entailment': 0.5939038395881653, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5862068965517241, 'r1_recall': 0.3722627737226277, 'r1_f1': 0.45535714285714285, 'pegasus_entailment': 0.5297812342643737, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5357142857142857, 'r1_recall': 0.6818181818181818, 'r1_f1': 0.6, 'pegasus_entailment': 0.2437334058340639, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5111111111111111, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.5609756097560976, 'pegasus_entailment': 0.7440721640984217, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3270440251572327, 'r1_recall': 0.65, 'r1_f1': 0.4351464435146443, 'pegasus_entailment': 0.7516457699239254, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5113636363636364, 'r1_recall': 0.3543307086614173, 'r1_f1': 0.41860465116279066, 'pegasus_entailment': 0.5250939857214689, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7232142857142857, 'r1_recall': 0.41116751269035534, 'r1_f1': 0.5242718446601943, 'pegasus_entailment': 0.6269644647836685, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7319587628865979, 'r1_recall': 0.29218106995884774, 'r1_f1': 0.4176470588235294, 'pegasus_entailment': 0.29485001489520074, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7209302325581395, 'r1_recall': 0.22302158273381295, 'r1_f1': 0.3406593406593407, 'pegasus_entailment': 0.4002259826908509, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.20952380952380953, 'r1_recall': 0.3013698630136986, 'r1_f1': 0.24719101123595502, 'pegasus_entailment': 0.0025677504017949104, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.20454545454545456, 'r1_recall': 0.14754098360655737, 'r1_f1': 0.17142857142857143, 'pegasus_entailment': 0.3248114585876465, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.5116279069767442, 'r1_f1': 0.5398773006134969, 'pegasus_entailment': 0.38635529143114883, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48148148148148145, 'r1_recall': 0.527027027027027, 'r1_f1': 0.5032258064516129, 'pegasus_entailment': 0.31082818703725934, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6074766355140186, 'r1_recall': 0.3735632183908046, 'r1_f1': 0.4626334519572953, 'pegasus_entailment': 0.4045937471756978, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4036697247706422, 'r1_recall': 0.3055555555555556, 'r1_f1': 0.34782608695652173, 'pegasus_entailment': 0.32265178970992564, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.625, 'r1_recall': 0.4358974358974359, 'r1_f1': 0.513595166163142, 'pegasus_entailment': 0.7981118559837341, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48514851485148514, 'r1_recall': 0.6712328767123288, 'r1_f1': 0.5632183908045977, 'pegasus_entailment': 0.6235193411509196, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45714285714285713, 'r1_recall': 0.64, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.5591433122754097, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4956521739130435, 'r1_recall': 0.5, 'r1_f1': 0.4978165938864629, 'pegasus_entailment': 0.5019792914390564, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8256880733944955, 'r1_recall': 0.2393617021276596, 'r1_f1': 0.3711340206185567, 'pegasus_entailment': 0.7488087813059489, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4367816091954023, 'r1_recall': 0.6440677966101694, 'r1_f1': 0.5205479452054794, 'pegasus_entailment': 0.5855334997177124, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6973684210526315, 'r1_recall': 0.31547619047619047, 'r1_f1': 0.43442622950819665, 'pegasus_entailment': 0.5870307783285776, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46153846153846156, 'r1_recall': 0.5581395348837209, 'r1_f1': 0.5052631578947369, 'pegasus_entailment': 0.5513060204684734, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.33557046979865773, 'r1_f1': 0.4016064257028113, 'pegasus_entailment': 0.732067209482193, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5664335664335665, 'r1_recall': 0.47928994082840237, 'r1_f1': 0.5192307692307693, 'pegasus_entailment': 0.4230862579175404, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5151515151515151, 'r1_recall': 0.5190839694656488, 'r1_f1': 0.5171102661596958, 'pegasus_entailment': 0.7740555653969446, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4931506849315068, 'r1_recall': 0.2903225806451613, 'r1_f1': 0.3654822335025381, 'pegasus_entailment': 0.5490661337971687, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35294117647058826, 'r1_recall': 0.43373493975903615, 'r1_f1': 0.3891891891891892, 'pegasus_entailment': 0.44176048412919044, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25263157894736843, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.3582089552238806, 'pegasus_entailment': 0.4631181061267853, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.63, 'r1_recall': 0.5431034482758621, 'r1_f1': 0.5833333333333334, 'pegasus_entailment': 0.23030591796850786, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6428571428571429, 'r1_recall': 0.3891891891891892, 'r1_f1': 0.4848484848484849, 'pegasus_entailment': 0.6134675920009613, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6417910447761194, 'r1_recall': 0.4479166666666667, 'r1_f1': 0.5276073619631902, 'pegasus_entailment': 0.9471827149391174, 'pegasus_flesch_kincaid': 37, 'pegasus_coleman_liau': 22, 'pegasus_ari': 44, 'pegasus_smog': 30}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7, 'r1_recall': 0.34545454545454546, 'r1_f1': 0.4626086956521739, 'pegasus_entailment': 0.522038646042347, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6842105263157895, 'r1_recall': 0.3611111111111111, 'r1_f1': 0.4727272727272728, 'pegasus_entailment': 0.5385150164365768, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2835820895522388, 'r1_recall': 0.5846153846153846, 'r1_f1': 0.3819095477386934, 'pegasus_entailment': 0.634530131239444, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4875, 'r1_recall': 0.65, 'r1_f1': 0.5571428571428572, 'pegasus_entailment': 0.23540060556600415, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33707865168539325, 'r1_recall': 0.37037037037037035, 'r1_f1': 0.3529411764705882, 'pegasus_entailment': 0.33810117390627664, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6071428571428571, 'r1_recall': 0.49038461538461536, 'r1_f1': 0.5425531914893617, 'pegasus_entailment': 0.6239332358042399, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3049645390070922, 'r1_recall': 0.5, 'r1_f1': 0.3788546255506608, 'pegasus_entailment': 0.7945975542068482, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49222797927461137, 'r1_recall': 0.6089743589743589, 'r1_f1': 0.5444126074498566, 'pegasus_entailment': 0.3983780820854008, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5467625899280576, 'r1_recall': 0.46060606060606063, 'r1_f1': 0.5000000000000001, 'pegasus_entailment': 0.5879911730686823, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 32, 'pegasus_smog': 24}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4367816091954023, 'r1_recall': 0.6229508196721312, 'r1_f1': 0.5135135135135136, 'pegasus_entailment': 0.35444110018822056, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6068965517241379, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.5966101694915253, 'pegasus_entailment': 0.5458487212657929, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3464052287581699, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.4344262295081967, 'pegasus_entailment': 0.263184657599777, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3575418994413408, 'r1_recall': 0.48854961832061067, 'r1_f1': 0.4129032258064516, 'pegasus_entailment': 0.5293537910495486, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.358974358974359, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.4534412955465587, 'pegasus_entailment': 0.7193211793899537, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5196850393700787, 'r1_recall': 0.6285714285714286, 'r1_f1': 0.5689655172413792, 'pegasus_entailment': 0.40351516753435135, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.6301369863013698, 'r1_f1': 0.5575757575757576, 'pegasus_entailment': 0.4351447205990553, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.371900826446281, 'r1_recall': 0.36, 'r1_f1': 0.36585365853658536, 'pegasus_entailment': 0.45372974425554274, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47244094488188976, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.4979253112033195, 'pegasus_entailment': 0.40472527500241995, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36428571428571427, 'r1_recall': 0.5730337078651685, 'r1_f1': 0.44541484716157204, 'pegasus_entailment': 0.6482043663660685, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18681318681318682, 'r1_recall': 0.3953488372093023, 'r1_f1': 0.25373134328358204, 'pegasus_entailment': 0.7702344357967377, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7373737373737373, 'r1_recall': 0.33031674208144796, 'r1_f1': 0.45624999999999993, 'pegasus_entailment': 0.5788265645503998, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.6194690265486725, 'r1_f1': 0.5857740585774059, 'pegasus_entailment': 0.9619560043017069, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 20}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2692307692307692, 'r1_recall': 0.7567567567567568, 'r1_f1': 0.3971631205673759, 'pegasus_entailment': 0.43837795220315456, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2781065088757396, 'r1_recall': 0.573170731707317, 'r1_f1': 0.3745019920318725, 'pegasus_entailment': 0.5408442937768996, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39766081871345027, 'r1_recall': 0.6355140186915887, 'r1_f1': 0.4892086330935252, 'pegasus_entailment': 0.5439504583676656, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2517482517482518, 'r1_recall': 0.5, 'r1_f1': 0.33488372093023255, 'pegasus_entailment': 0.7157898445924123, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.21621621621621623, 'r1_recall': 0.18181818181818182, 'r1_f1': 0.19753086419753088, 'pegasus_entailment': 0.6300407648086548, 'pegasus_flesch_kincaid': 35, 'pegasus_coleman_liau': 18, 'pegasus_ari': 44, 'pegasus_smog': 21}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49411764705882355, 'r1_recall': 0.47191011235955055, 'r1_f1': 0.48275862068965514, 'pegasus_entailment': 0.46309512108564377, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26717557251908397, 'r1_recall': 0.5932203389830508, 'r1_f1': 0.3684210526315789, 'pegasus_entailment': 0.45375665618727606, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6268656716417911, 'r1_recall': 0.42424242424242425, 'r1_f1': 0.5060240963855421, 'pegasus_entailment': 0.5649393449227015, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45901639344262296, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.5137614678899083, 'pegasus_entailment': 0.7788800001144409, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5083333333333333, 'r1_recall': 0.648936170212766, 'r1_f1': 0.5700934579439252, 'pegasus_entailment': 0.6945918500423431, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8245614035087719, 'r1_recall': 0.18007662835249041, 'r1_f1': 0.29559748427672955, 'pegasus_entailment': 0.6337522864341736, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6040268456375839, 'r1_recall': 0.45, 'r1_f1': 0.5157593123209169, 'pegasus_entailment': 0.755778431892395, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.29523809523809524, 'r1_recall': 0.3974358974358974, 'r1_f1': 0.33879781420765026, 'pegasus_entailment': 0.11266082897782326, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5578947368421052, 'r1_recall': 0.5047619047619047, 'r1_f1': 0.53, 'pegasus_entailment': 0.6183049418032169, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5929203539823009, 'r1_recall': 0.49264705882352944, 'r1_f1': 0.5381526104417671, 'pegasus_entailment': 0.42684748619794843, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3870967741935484, 'r1_recall': 0.6371681415929203, 'r1_f1': 0.4816053511705686, 'pegasus_entailment': 0.768895665804545, 'pegasus_flesch_kincaid': 32, 'pegasus_coleman_liau': 19, 'pegasus_ari': 39, 'pegasus_smog': 24}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.53125, 'r1_recall': 0.4, 'r1_f1': 0.45637583892617456, 'pegasus_entailment': 0.20899538695812225, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3684210526315789, 'r1_recall': 0.42424242424242425, 'r1_f1': 0.3943661971830986, 'pegasus_entailment': 0.2783938171342015, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.5217391304347826, 'r1_f1': 0.5333333333333332, 'pegasus_entailment': 0.5516135593255361, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4214876033057851, 'r1_recall': 0.6144578313253012, 'r1_f1': 0.5, 'pegasus_entailment': 0.49345711153000593, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7692307692307693, 'r1_recall': 0.3968253968253968, 'r1_f1': 0.5235602094240838, 'pegasus_entailment': 0.752319723367691, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43283582089552236, 'r1_recall': 0.5686274509803921, 'r1_f1': 0.4915254237288136, 'pegasus_entailment': 0.44603067450225353, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5608108108108109, 'r1_recall': 0.515527950310559, 'r1_f1': 0.5372168284789645, 'pegasus_entailment': 0.5600055356820425, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3063063063063063, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.4047619047619047, 'pegasus_entailment': 0.3408030692759591, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6938775510204082, 'r1_recall': 0.45132743362831856, 'r1_f1': 0.546916890080429, 'pegasus_entailment': 0.5024844735860825, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28225806451612906, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.3804347826086956, 'pegasus_entailment': 0.19616781175136566, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41911764705882354, 'r1_recall': 0.5643564356435643, 'r1_f1': 0.4810126582278481, 'pegasus_entailment': 0.6399791911244392, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3815789473684211, 'r1_recall': 0.5918367346938775, 'r1_f1': 0.464, 'pegasus_entailment': 0.44931860640645027, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 19}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2361111111111111, 'r1_recall': 0.3695652173913043, 'r1_f1': 0.28813559322033905, 'pegasus_entailment': 0.031281706877052784, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6015625, 'r1_recall': 0.5273972602739726, 'r1_f1': 0.5620437956204378, 'pegasus_entailment': 0.9051435391108195, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5625, 'r1_recall': 0.46875, 'r1_f1': 0.5113636363636364, 'pegasus_entailment': 0.6417219400405884, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3620689655172414, 'r1_recall': 0.5675675675675675, 'r1_f1': 0.4421052631578948, 'pegasus_entailment': 0.43472109762951733, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43243243243243246, 'r1_recall': 0.48484848484848486, 'r1_f1': 0.45714285714285713, 'pegasus_entailment': 0.34386456990614533, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5172413793103449, 'r1_recall': 0.5421686746987951, 'r1_f1': 0.5294117647058824, 'pegasus_entailment': 0.42009375989437103, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3515625, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.45226130653266333, 'pegasus_entailment': 0.42296581502471653, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5686274509803921, 'r1_recall': 0.5043478260869565, 'r1_f1': 0.5345622119815668, 'pegasus_entailment': 0.2489472939632833, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4141791044776119, 'r1_recall': 0.6607142857142857, 'r1_f1': 0.5091743119266054, 'pegasus_entailment': 0.4645467496344021, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23232323232323232, 'r1_recall': 0.4339622641509434, 'r1_f1': 0.3026315789473684, 'pegasus_entailment': 0.5943262260407209, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5487804878048781, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.4736842105263158, 'pegasus_entailment': 0.6278156896587461, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.627906976744186, 'r1_recall': 0.4778761061946903, 'r1_f1': 0.542713567839196, 'pegasus_entailment': 0.8494073748588562, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40425531914893614, 'r1_recall': 0.5352112676056338, 'r1_f1': 0.4606060606060606, 'pegasus_entailment': 0.41213854821398854, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5369127516778524, 'r1_recall': 0.365296803652968, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.4801815077662468, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.15384615384615385, 'r1_recall': 0.34285714285714286, 'r1_f1': 0.21238938053097345, 'pegasus_entailment': 0.7050967911879221, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4772727272727273, 'r1_recall': 0.7590361445783133, 'r1_f1': 0.5860465116279071, 'pegasus_entailment': 0.8325150460004807, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2336448598130841, 'r1_recall': 0.5102040816326531, 'r1_f1': 0.3205128205128205, 'pegasus_entailment': 0.32309246249496937, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.864406779661017, 'r1_recall': 0.3, 'r1_f1': 0.4454148471615721, 'pegasus_entailment': 0.8976621031761169, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5847457627118644, 'r1_recall': 0.5348837209302325, 'r1_f1': 0.5587044534412956, 'pegasus_entailment': 0.685135817527771, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47115384615384615, 'r1_recall': 0.5632183908045977, 'r1_f1': 0.5130890052356021, 'pegasus_entailment': 0.7306873083114624, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.40601503759398494, 'r1_f1': 0.48430493273542596, 'pegasus_entailment': 0.9041483203570048, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4589041095890411, 'r1_recall': 0.6036036036036037, 'r1_f1': 0.5214007782101167, 'pegasus_entailment': 0.23875132855027914, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5368421052631579, 'r1_recall': 0.53125, 'r1_f1': 0.5340314136125656, 'pegasus_entailment': 0.3429542500525713, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5192307692307693, 'r1_recall': 0.5785714285714286, 'r1_f1': 0.5472972972972974, 'pegasus_entailment': 0.7587377556732723, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39473684210526316, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.40540540540540543, 'pegasus_entailment': 0.6925706962744395, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6375, 'r1_recall': 0.5543478260869565, 'r1_f1': 0.5930232558139535, 'pegasus_entailment': 0.529898576438427, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.618421052631579, 'r1_recall': 0.4563106796116505, 'r1_f1': 0.5251396648044693, 'pegasus_entailment': 0.42065965104848146, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4696969696969697, 'r1_recall': 0.4626865671641791, 'r1_f1': 0.4661654135338346, 'pegasus_entailment': 0.5076046412189802, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39097744360902253, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.4642857142857143, 'pegasus_entailment': 0.9329998731613159, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4825174825174825, 'r1_recall': 0.4825174825174825, 'r1_f1': 0.4825174825174825, 'pegasus_entailment': 0.4627571769058704, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6133333333333333, 'r1_recall': 0.3770491803278688, 'r1_f1': 0.46700507614213194, 'pegasus_entailment': 0.5095080708463987, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5887850467289719, 'r1_recall': 0.3795180722891566, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.4064180441200733, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5074626865671642, 'r1_recall': 0.6181818181818182, 'r1_f1': 0.5573770491803278, 'pegasus_entailment': 0.27941806614398956, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3790322580645161, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.4747474747474748, 'pegasus_entailment': 0.2979620277349438, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7226890756302521, 'r1_recall': 0.4215686274509804, 'r1_f1': 0.5325077399380805, 'pegasus_entailment': 0.7841584533452988, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.696, 'r1_recall': 0.4027777777777778, 'r1_f1': 0.5102639296187683, 'pegasus_entailment': 0.43829023763537406, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5232558139534884, 'r1_recall': 0.371900826446281, 'r1_f1': 0.4347826086956522, 'pegasus_entailment': 0.4401325393468142, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5547945205479452, 'r1_recall': 0.5664335664335665, 'r1_f1': 0.5605536332179931, 'pegasus_entailment': 0.1124482392333448, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.424, 'r1_recall': 0.6091954022988506, 'r1_f1': 0.5, 'pegasus_entailment': 0.8973497003316879, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3707865168539326, 'r1_recall': 0.7252747252747253, 'r1_f1': 0.4907063197026023, 'pegasus_entailment': 0.7678297519683838, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3137254901960784, 'r1_recall': 0.3137254901960784, 'r1_f1': 0.3137254901960784, 'pegasus_entailment': 0.342763289809227, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4787234042553192, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.4326923076923077, 'pegasus_entailment': 0.21263628546148539, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.55, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4916201117318436, 'pegasus_entailment': 0.13265020423568785, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31, 'r1_recall': 0.34831460674157305, 'r1_f1': 0.328042328042328, 'pegasus_entailment': 0.5542602613568306, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.543859649122807, 'r1_recall': 0.1901840490797546, 'r1_f1': 0.28181818181818186, 'pegasus_entailment': 0.6011435935894648, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 23, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6428571428571429, 'r1_recall': 0.2967032967032967, 'r1_f1': 0.40601503759398505, 'pegasus_entailment': 0.7523938789963722, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8230088495575221, 'r1_recall': 0.3381818181818182, 'r1_f1': 0.47938144329896915, 'pegasus_entailment': 0.1573428362607956, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.460431654676259, 'r1_recall': 0.5871559633027523, 'r1_f1': 0.5161290322580645, 'pegasus_entailment': 0.5225567147135735, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19736842105263158, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.28571428571428575, 'pegasus_entailment': 0.43560120676245007, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5764705882352941, 'r1_recall': 0.27071823204419887, 'r1_f1': 0.3684210526315789, 'pegasus_entailment': 0.672848661740621, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2677595628415301, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.37692307692307697, 'pegasus_entailment': 0.43008183836936953, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35526315789473684, 'r1_recall': 0.675, 'r1_f1': 0.4655172413793103, 'pegasus_entailment': 0.7237662523984909, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5104166666666666, 'r1_recall': 0.5268817204301075, 'r1_f1': 0.5185185185185186, 'pegasus_entailment': 0.7711820205052694, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3695652173913043, 'r1_recall': 0.6296296296296297, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.4261125889606774, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.375, 'r1_recall': 0.1, 'r1_f1': 0.15789473684210528, 'pegasus_entailment': 0.29609861969947815, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35714285714285715, 'r1_recall': 0.36231884057971014, 'r1_f1': 0.3597122302158273, 'pegasus_entailment': 0.27966607191289466, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4818181818181818, 'r1_recall': 0.5520833333333334, 'r1_f1': 0.5145631067961165, 'pegasus_entailment': 0.47136465460062027, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40217391304347827, 'r1_recall': 0.578125, 'r1_f1': 0.47435897435897434, 'pegasus_entailment': 0.3170475587248802, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.424, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.4907407407407407, 'pegasus_entailment': 0.7034923632939657, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35526315789473684, 'r1_recall': 0.6136363636363636, 'r1_f1': 0.45, 'pegasus_entailment': 0.6325504064559937, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3081761006289308, 'r1_recall': 0.7903225806451613, 'r1_f1': 0.44343891402714936, 'pegasus_entailment': 0.5990760028362274, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4090909090909091, 'r1_recall': 0.5046728971962616, 'r1_f1': 0.45188284518828453, 'pegasus_entailment': 0.4535597488284111, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32, 'r1_recall': 0.38095238095238093, 'r1_f1': 0.34782608695652173, 'pegasus_entailment': 0.25642286764923483, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.654320987654321, 'r1_recall': 0.4, 'r1_f1': 0.49648711943793905, 'pegasus_entailment': 0.46491899341344833, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25862068965517243, 'r1_recall': 0.703125, 'r1_f1': 0.3781512605042017, 'pegasus_entailment': 0.6375335395336151, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49295774647887325, 'r1_recall': 0.3804347826086957, 'r1_f1': 0.4294478527607362, 'pegasus_entailment': 0.44619176909327507, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3841059602649007, 'r1_recall': 0.58, 'r1_f1': 0.46215139442231074, 'pegasus_entailment': 0.4432586133480072, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5681818181818182, 'r1_recall': 0.35714285714285715, 'r1_f1': 0.4385964912280702, 'pegasus_entailment': 0.5491022896021605, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49056603773584906, 'r1_recall': 0.5531914893617021, 'r1_f1': 0.52, 'pegasus_entailment': 0.4630765289068222, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.28346456692913385, 'r1_f1': 0.3730569948186529, 'pegasus_entailment': 0.6544707790017128, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3076923076923077, 'r1_recall': 0.5633802816901409, 'r1_f1': 0.39800995024875624, 'pegasus_entailment': 0.9226711988449097, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46875, 'r1_recall': 0.4787234042553192, 'r1_f1': 0.47368421052631576, 'pegasus_entailment': 0.34593469952233136, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3533834586466165, 'r1_recall': 0.5595238095238095, 'r1_f1': 0.43317972350230416, 'pegasus_entailment': 0.3995883048822482, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35714285714285715, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.4301075268817204, 'pegasus_entailment': 0.3466932202378909, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4606741573033708, 'r1_recall': 0.6119402985074627, 'r1_f1': 0.5256410256410257, 'pegasus_entailment': 0.6518175601959229, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3894736842105263, 'r1_recall': 0.578125, 'r1_f1': 0.46540880503144655, 'pegasus_entailment': 0.5579730272293091, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4906832298136646, 'r1_recall': 0.45664739884393063, 'r1_f1': 0.47305389221556887, 'pegasus_entailment': 0.6915470446859088, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.46060606060606063, 'r1_f1': 0.5100671140939598, 'pegasus_entailment': 0.45111246034502983, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6857142857142857, 'r1_recall': 0.4897959183673469, 'r1_f1': 0.5714285714285715, 'pegasus_entailment': 0.9916422168413798, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6228070175438597, 'r1_recall': 0.37967914438502676, 'r1_f1': 0.4717607973421927, 'pegasus_entailment': 0.18654210232198237, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47058823529411764, 'r1_recall': 0.3368421052631579, 'r1_f1': 0.3926380368098159, 'pegasus_entailment': 0.16979951209699115, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.7361111111111112, 'r1_f1': 0.4588744588744589, 'pegasus_entailment': 0.6396491898534199, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1610738255033557, 'r1_recall': 0.43636363636363634, 'r1_f1': 0.23529411764705885, 'pegasus_entailment': 0.7142255256573359, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2376237623762376, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.3356643356643357, 'pegasus_entailment': 0.521023528650403, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5172413793103449, 'r1_recall': 0.4225352112676056, 'r1_f1': 0.46511627906976744, 'pegasus_entailment': 0.6149252218504747, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2727272727272727, 'r1_recall': 0.6346153846153846, 'r1_f1': 0.3815028901734104, 'pegasus_entailment': 0.2852693134918809, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.40384615384615385, 'r1_recall': 0.358974358974359, 'r1_f1': 0.38009049773755654, 'pegasus_entailment': 0.4740392155945301, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 23, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6336633663366337, 'r1_recall': 0.48854961832061067, 'r1_f1': 0.5517241379310344, 'pegasus_entailment': 0.3782331198453903, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46078431372549017, 'r1_recall': 0.5595238095238095, 'r1_f1': 0.5053763440860215, 'pegasus_entailment': 0.6438579671084881, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5287356321839081, 'r1_recall': 0.25555555555555554, 'r1_f1': 0.34456928838951306, 'pegasus_entailment': 0.4937569797039032, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29743589743589743, 'r1_recall': 0.6373626373626373, 'r1_f1': 0.4055944055944055, 'pegasus_entailment': 0.60926211306027, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41134751773049644, 'r1_recall': 0.5272727272727272, 'r1_f1': 0.4621513944223107, 'pegasus_entailment': 0.5121818333864212, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3157894736842105, 'r1_recall': 0.5869565217391305, 'r1_f1': 0.41064638783269963, 'pegasus_entailment': 0.6567687094211578, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4329896907216495, 'r1_recall': 0.42, 'r1_f1': 0.4263959390862944, 'pegasus_entailment': 0.6388003289699554, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3008849557522124, 'r1_recall': 0.4927536231884058, 'r1_f1': 0.3736263736263737, 'pegasus_entailment': 0.888015553355217, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 18, 'pegasus_ari': 35, 'pegasus_smog': 25}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48695652173913045, 'r1_recall': 0.6436781609195402, 'r1_f1': 0.5544554455445545, 'pegasus_entailment': 0.7653776109218597, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6935483870967742, 'r1_recall': 0.4215686274509804, 'r1_f1': 0.524390243902439, 'pegasus_entailment': 0.5631491045157114, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4180327868852459, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.4951456310679611, 'pegasus_entailment': 0.4344054516404867, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24390243902439024, 'r1_recall': 0.38461538461538464, 'r1_f1': 0.2985074626865672, 'pegasus_entailment': 0.2862356621772051, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.56, 'r1_recall': 0.3916083916083916, 'r1_f1': 0.46090534979423864, 'pegasus_entailment': 0.8239734619855881, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4563106796116505, 'r1_recall': 0.5402298850574713, 'r1_f1': 0.4947368421052632, 'pegasus_entailment': 0.39643675088882446, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4696969696969697, 'r1_recall': 0.5740740740740741, 'r1_f1': 0.5166666666666667, 'pegasus_entailment': 0.6318082188566526, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5247524752475248, 'r1_recall': 0.4380165289256198, 'r1_f1': 0.4774774774774775, 'pegasus_entailment': 0.5251282691955567, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4714285714285714, 'r1_recall': 0.3173076923076923, 'r1_f1': 0.3793103448275862, 'pegasus_entailment': 0.19603902520611882, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44329896907216493, 'r1_recall': 0.6142857142857143, 'r1_f1': 0.5149700598802396, 'pegasus_entailment': 0.6673281848430633, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3277310924369748, 'r1_recall': 0.5416666666666666, 'r1_f1': 0.40837696335078527, 'pegasus_entailment': 0.7385891437530517, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49137931034482757, 'r1_recall': 0.6404494382022472, 'r1_f1': 0.5560975609756097, 'pegasus_entailment': 0.3976619889338811, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 15, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2235294117647059, 'r1_recall': 0.4222222222222222, 'r1_f1': 0.2923076923076923, 'pegasus_entailment': 0.2982502648374066, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.391025641025641, 'r1_recall': 0.5922330097087378, 'r1_f1': 0.47104247104247104, 'pegasus_entailment': 0.6737608343362809, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1262135922330097, 'r1_recall': 0.37142857142857144, 'r1_f1': 0.18840579710144928, 'pegasus_entailment': 0.4711124859750271, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4126984126984127, 'r1_recall': 0.5777777777777777, 'r1_f1': 0.48148148148148145, 'pegasus_entailment': 0.30288588744588196, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2647058823529412, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.3829787234042553, 'pegasus_entailment': 0.6748018302023411, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43137254901960786, 'r1_recall': 0.44594594594594594, 'r1_f1': 0.4385382059800665, 'pegasus_entailment': 0.25810880746160236, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44936708860759494, 'r1_recall': 0.6173913043478261, 'r1_f1': 0.5201465201465202, 'pegasus_entailment': 0.9564281553030014, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3588235294117647, 'r1_recall': 0.6354166666666666, 'r1_f1': 0.4586466165413534, 'pegasus_entailment': 0.4468917779624462, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4700854700854701, 'r1_recall': 0.5045871559633027, 'r1_f1': 0.48672566371681414, 'pegasus_entailment': 0.43202572762966157, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6195652173913043, 'r1_recall': 0.41304347826086957, 'r1_f1': 0.49565217391304345, 'pegasus_entailment': 0.47455371419588727, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8777777777777778, 'r1_recall': 0.22443181818181818, 'r1_f1': 0.3574660633484163, 'pegasus_entailment': 0.6568206860683858, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4263565891472868, 'r1_recall': 0.4954954954954955, 'r1_f1': 0.4583333333333333, 'pegasus_entailment': 0.7466578960418702, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46218487394957986, 'r1_recall': 0.3691275167785235, 'r1_f1': 0.41044776119402987, 'pegasus_entailment': 0.551119402050972, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8271604938271605, 'r1_recall': 0.44966442953020136, 'r1_f1': 0.5826086956521739, 'pegasus_entailment': 0.7483320385217667, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1830065359477124, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.2772277227722772, 'pegasus_entailment': 0.6752706865469614, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38461538461538464, 'r1_recall': 0.625, 'r1_f1': 0.4761904761904762, 'pegasus_entailment': 0.37076153317466376, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3053435114503817, 'r1_recall': 0.49382716049382713, 'r1_f1': 0.3773584905660377, 'pegasus_entailment': 0.3673239961266518, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6474358974358975, 'r1_recall': 0.6733333333333333, 'r1_f1': 0.6601307189542485, 'pegasus_entailment': 0.4862288245931268, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2621359223300971, 'r1_recall': 0.40298507462686567, 'r1_f1': 0.31764705882352945, 'pegasus_entailment': 0.9560164014498392, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5581395348837209, 'r1_recall': 0.5581395348837209, 'r1_f1': 0.5581395348837209, 'pegasus_entailment': 0.6306626542160908, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3879310344827586, 'r1_recall': 0.6081081081081081, 'r1_f1': 0.47368421052631576, 'pegasus_entailment': 0.6608258545398712, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3949579831932773, 'r1_recall': 0.5802469135802469, 'r1_f1': 0.47, 'pegasus_entailment': 0.51931465168794, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6351351351351351, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.4372093023255814, 'pegasus_entailment': 0.7509132226308187, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3490566037735849, 'r1_recall': 0.5648854961832062, 'r1_f1': 0.43148688046647227, 'pegasus_entailment': 0.6128891855478287, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5783132530120482, 'r1_recall': 0.4507042253521127, 'r1_f1': 0.5065963060686016, 'pegasus_entailment': 0.6112197399139404, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5157894736842106, 'r1_recall': 0.5444444444444444, 'r1_f1': 0.5297297297297296, 'pegasus_entailment': 0.845866060256958, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5063291139240507, 'r1_recall': 0.7017543859649122, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.6418455342451731, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6060606060606061, 'r1_recall': 0.42328042328042326, 'r1_f1': 0.49844236760124616, 'pegasus_entailment': 0.485844662279955, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6470588235294118, 'r1_recall': 0.3256578947368421, 'r1_f1': 0.4332603938730853, 'pegasus_entailment': 0.6097066942602396, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20909090909090908, 'r1_recall': 0.36507936507936506, 'r1_f1': 0.2658959537572254, 'pegasus_entailment': 0.527444027364254, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3351063829787234, 'r1_recall': 0.6631578947368421, 'r1_f1': 0.4452296819787986, 'pegasus_entailment': 0.3964262657931873, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6097560975609756, 'r1_recall': 0.47468354430379744, 'r1_f1': 0.5338078291814946, 'pegasus_entailment': 0.5518397368490696, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28421052631578947, 'r1_recall': 0.46551724137931033, 'r1_f1': 0.35294117647058826, 'pegasus_entailment': 0.5726606789976358, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.696969696969697, 'r1_recall': 0.2541436464088398, 'r1_f1': 0.3724696356275304, 'pegasus_entailment': 0.4005734125773112, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4948453608247423, 'r1_recall': 0.3380281690140845, 'r1_f1': 0.401673640167364, 'pegasus_entailment': 0.41296844743192196, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36752136752136755, 'r1_recall': 0.45263157894736844, 'r1_f1': 0.4056603773584906, 'pegasus_entailment': 0.20467613274231553, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.61, 'r1_recall': 0.3546511627906977, 'r1_f1': 0.44852941176470584, 'pegasus_entailment': 0.6531010791659355, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4777777777777778, 'r1_recall': 0.6056338028169014, 'r1_f1': 0.5341614906832298, 'pegasus_entailment': 0.5766782343387604, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6301369863013698, 'r1_recall': 0.4423076923076923, 'r1_f1': 0.519774011299435, 'pegasus_entailment': 0.6471229096253713, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3978494623655914, 'r1_recall': 0.3978494623655914, 'r1_f1': 0.3978494623655913, 'pegasus_entailment': 0.49456743709743023, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.24719101123595505, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.34782608695652173, 'pegasus_entailment': 0.7415408611297607, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4326923076923077, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.5142857142857142, 'pegasus_entailment': 0.22999720345251262, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5180722891566265, 'r1_recall': 0.42574257425742573, 'r1_f1': 0.4673913043478261, 'pegasus_entailment': 0.3722886787727475, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6788990825688074, 'r1_recall': 0.357487922705314, 'r1_f1': 0.46835443037974683, 'pegasus_entailment': 0.78851617872715, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.376, 'r1_recall': 0.46078431372549017, 'r1_f1': 0.4140969162995594, 'pegasus_entailment': 0.5515184253454208, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23529411764705882, 'r1_recall': 0.6, 'r1_f1': 0.33802816901408456, 'pegasus_entailment': 0.41187408442298573, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8018867924528302, 'r1_recall': 0.47752808988764045, 'r1_f1': 0.5985915492957746, 'pegasus_entailment': 0.5912662707269192, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3968253968253968, 'r1_recall': 0.684931506849315, 'r1_f1': 0.5025125628140703, 'pegasus_entailment': 0.5540206730365753, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4608695652173913, 'r1_recall': 0.6973684210526315, 'r1_f1': 0.5549738219895288, 'pegasus_entailment': 0.5135835462715477, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 15}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.4835164835164835, 'r1_f1': 0.46315789473684205, 'pegasus_entailment': 0.6572319467862447, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5163398692810458, 'r1_recall': 0.6583333333333333, 'r1_f1': 0.5787545787545788, 'pegasus_entailment': 0.6550711430609226, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8229166666666666, 'r1_recall': 0.11205673758865248, 'r1_f1': 0.1972534332084894, 'pegasus_entailment': 0.8510186672210693, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5932203389830508, 'r1_recall': 0.49295774647887325, 'r1_f1': 0.5384615384615384, 'pegasus_entailment': 0.5928280234336853, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.864, 'r1_recall': 0.5901639344262295, 'r1_f1': 0.7012987012987012, 'pegasus_entailment': 0.4530572980642319, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46788990825688076, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.504950495049505, 'pegasus_entailment': 0.2968821016450723, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5859375, 'r1_recall': 0.646551724137931, 'r1_f1': 0.6147540983606558, 'pegasus_entailment': 0.4598015566977362, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4177215189873418, 'r1_recall': 0.5076923076923077, 'r1_f1': 0.4583333333333333, 'pegasus_entailment': 0.5634877078700811, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4852941176470588, 'r1_recall': 0.42038216560509556, 'r1_f1': 0.4505119453924915, 'pegasus_entailment': 0.48986796438694, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21238938053097345, 'r1_recall': 0.5, 'r1_f1': 0.2981366459627329, 'pegasus_entailment': 0.5418317392468452, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.423728813559322, 'r1_recall': 0.25773195876288657, 'r1_f1': 0.3205128205128205, 'pegasus_entailment': 0.9739246666431427, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.15053763440860216, 'r1_recall': 0.4, 'r1_f1': 0.21875, 'pegasus_entailment': 0.42391079221852124, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.5773195876288659, 'r1_f1': 0.5743589743589743, 'pegasus_entailment': 0.4821102836479743, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.456, 'r1_recall': 0.504424778761062, 'r1_f1': 0.4789915966386555, 'pegasus_entailment': 0.5068236738443375, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6129032258064516, 'r1_recall': 0.4222222222222222, 'r1_f1': 0.5, 'pegasus_entailment': 0.3685628976672888, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25806451612903225, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.32653061224489793, 'pegasus_entailment': 0.36471202166285366, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.54, 'r1_f1': 0.5966850828729282, 'pegasus_entailment': 0.7884694486856461, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
** Analysing column: malformed_chain



malformed_chain
Length after nones removed
616
MIN
0
MEAN
0
MAX
1
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.08187134502923976
MEAN
0.47446573668026015
MAX
0.8777777777777778
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.1
MEAN
0.48945881639842265
MAX
0.9354838709677419
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.1407035175879397
MEAN
0.4556962379004928
MAX
0.7012987012987012
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.0025677504017949104
MEAN
0.5304324475526858
MAX
0.9916422168413798
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
17
MAX
37
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
12
MEAN
18
MAX
23
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
12
MEAN
20
MAX
44
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
12
MEAN
18
MAX
30
{}
Entered file!
Imports done!
*** RUN *** 
eval_4d2
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 14:51:25.735383: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 14:51:26.286690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/4d2_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4146341463414634, 'r1_recall': 0.4636363636363636, 'r1_f1': 0.43776824034334766, 'pegasus_entailment': 0.7444711327552795, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 15}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5652173913043478, 'r1_recall': 0.37572254335260113, 'r1_f1': 0.4513888888888889, 'pegasus_entailment': 0.6694509238004684, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3561643835616438, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.3969465648854962, 'pegasus_entailment': 0.6127078235149384, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6792452830188679, 'r1_recall': 0.5581395348837209, 'r1_f1': 0.6127659574468084, 'pegasus_entailment': 0.6228114019613713, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7078651685393258, 'r1_recall': 0.3620689655172414, 'r1_f1': 0.47908745247148293, 'pegasus_entailment': 0.5705259641011556, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.4018275409936905, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18, 'r1_recall': 0.5625, 'r1_f1': 0.2727272727272727, 'pegasus_entailment': 0.5000313106924296, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20618556701030927, 'r1_recall': 0.6451612903225806, 'r1_f1': 0.31249999999999994, 'pegasus_entailment': 0.5283948604483157, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6548672566371682, 'r1_recall': 0.4966442953020134, 'r1_f1': 0.564885496183206, 'pegasus_entailment': 0.7190784414609274, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5737704918032787, 'r1_recall': 0.5072463768115942, 'r1_f1': 0.5384615384615384, 'pegasus_entailment': 0.6827211181322733, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6931818181818182, 'r1_recall': 0.4066666666666667, 'r1_f1': 0.5126050420168068, 'pegasus_entailment': 0.5561190942923228, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6354166666666666, 'r1_recall': 0.5126050420168067, 'r1_f1': 0.5674418604651162, 'pegasus_entailment': 0.6767682234446207, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7571428571428571, 'r1_recall': 0.4953271028037383, 'r1_f1': 0.5988700564971752, 'pegasus_entailment': 0.6891614298025767, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.620253164556962, 'r1_recall': 0.5568181818181818, 'r1_f1': 0.5868263473053892, 'pegasus_entailment': 0.4852171043554942, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6145833333333334, 'r1_recall': 0.3072916666666667, 'r1_f1': 0.40972222222222227, 'pegasus_entailment': 0.7371505697568258, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2807017543859649, 'r1_recall': 0.5423728813559322, 'r1_f1': 0.3699421965317919, 'pegasus_entailment': 0.6367162838578224, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39325842696629215, 'r1_recall': 0.35353535353535354, 'r1_f1': 0.3723404255319149, 'pegasus_entailment': 0.6331592947244644, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6804123711340206, 'r1_recall': 0.2214765100671141, 'r1_f1': 0.3341772151898735, 'pegasus_entailment': 0.30583305408557254, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5373134328358209, 'r1_recall': 0.4472049689440994, 'r1_f1': 0.488135593220339, 'pegasus_entailment': 0.3529582768678665, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4205607476635514, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.46391752577319584, 'pegasus_entailment': 0.6059127709362656, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6180555555555556, 'r1_recall': 0.489010989010989, 'r1_f1': 0.5460122699386503, 'pegasus_entailment': 0.3458660587668419, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 13, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.4266666666666667, 'r1_f1': 0.4353741496598639, 'pegasus_entailment': 0.8732439279556274, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 33, 'pegasus_smog': 24}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3404255319148936, 'r1_recall': 0.2962962962962963, 'r1_f1': 0.3168316831683168, 'pegasus_entailment': 0.6889724880456924, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7107438016528925, 'r1_recall': 0.6323529411764706, 'r1_f1': 0.6692607003891051, 'pegasus_entailment': 0.48394931356112164, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31683168316831684, 'r1_recall': 0.64, 'r1_f1': 0.42384105960264906, 'pegasus_entailment': 0.807329973578453, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6935483870967742, 'r1_recall': 0.6825396825396826, 'r1_f1': 0.6880000000000001, 'pegasus_entailment': 0.6238576732575893, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5725806451612904, 'r1_recall': 0.5182481751824818, 'r1_f1': 0.5440613026819924, 'pegasus_entailment': 0.45341491848230364, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.717948717948718, 'r1_recall': 0.31343283582089554, 'r1_f1': 0.43636363636363645, 'pegasus_entailment': 0.627209926644961, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3, 'r1_recall': 0.5921052631578947, 'r1_f1': 0.3982300884955752, 'pegasus_entailment': 0.7906872729460398, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40384615384615385, 'r1_recall': 0.37168141592920356, 'r1_f1': 0.38709677419354843, 'pegasus_entailment': 0.7101313769817352, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4175824175824176, 'r1_recall': 0.4367816091954023, 'r1_f1': 0.4269662921348315, 'pegasus_entailment': 0.5147378593683243, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5421052631578948, 'r1_recall': 0.5124378109452736, 'r1_f1': 0.5268542199488492, 'pegasus_entailment': 0.6923885010182858, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3, 'r1_recall': 0.34951456310679613, 'r1_f1': 0.32286995515695066, 'pegasus_entailment': 0.780769693851471, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.416, 'r1_recall': 0.5360824742268041, 'r1_f1': 0.4684684684684684, 'pegasus_entailment': 0.47935664653778076, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.294478527607362, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.38866396761133604, 'pegasus_entailment': 0.456091596186161, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46956521739130436, 'r1_recall': 0.46551724137931033, 'r1_f1': 0.4675324675324675, 'pegasus_entailment': 0.535964785516262, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.37662337662337664, 'r1_recall': 0.8405797101449275, 'r1_f1': 0.5201793721973094, 'pegasus_entailment': 0.5887601256370545, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2777777777777778, 'r1_recall': 0.5147058823529411, 'r1_f1': 0.36082474226804123, 'pegasus_entailment': 0.6260082311928272, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23076923076923078, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.3510638297872341, 'pegasus_entailment': 0.659473828971386, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45145631067961167, 'r1_recall': 0.5602409638554217, 'r1_f1': 0.5000000000000001, 'pegasus_entailment': 0.9156578481197357, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5308641975308642, 'r1_recall': 0.5375, 'r1_f1': 0.5341614906832298, 'pegasus_entailment': 0.7012334540486336, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.7012987012987013, 'r1_f1': 0.5837837837837838, 'pegasus_entailment': 0.9336663782596588, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40860215053763443, 'r1_recall': 0.5205479452054794, 'r1_f1': 0.45783132530120485, 'pegasus_entailment': 0.4045109028617541, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7808219178082192, 'r1_recall': 0.4634146341463415, 'r1_f1': 0.5816326530612245, 'pegasus_entailment': 0.8440303206443787, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3543307086614173, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.4390243902439024, 'pegasus_entailment': 0.5529226124286651, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.543046357615894, 'r1_recall': 0.5466666666666666, 'r1_f1': 0.5448504983388706, 'pegasus_entailment': 0.575241819024086, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6483516483516484, 'r1_recall': 0.5, 'r1_f1': 0.5645933014354068, 'pegasus_entailment': 0.5230681200822195, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48226950354609927, 'r1_recall': 0.6126126126126126, 'r1_f1': 0.5396825396825397, 'pegasus_entailment': 0.6138130307197571, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38926174496644295, 'r1_recall': 0.6904761904761905, 'r1_f1': 0.49785407725321895, 'pegasus_entailment': 0.5555731505155563, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3902439024390244, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.4229074889867842, 'pegasus_entailment': 0.3853693772107363, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45263157894736844, 'r1_recall': 0.581081081081081, 'r1_f1': 0.5088757396449705, 'pegasus_entailment': 0.36142235808074474, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2, 'r1_recall': 0.7058823529411765, 'r1_f1': 0.3116883116883117, 'pegasus_entailment': 0.45659031509421766, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3484848484848485, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.44660194174757284, 'pegasus_entailment': 0.3955013729631901, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6511627906976745, 'r1_recall': 0.3163841807909605, 'r1_f1': 0.4258555133079849, 'pegasus_entailment': 0.278866421431303, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.449438202247191, 'r1_f1': 0.5369127516778522, 'pegasus_entailment': 0.48353951424360275, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5263157894736842, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.5405405405405405, 'pegasus_entailment': 0.32739364604155224, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6823529411764706, 'r1_recall': 0.23107569721115537, 'r1_f1': 0.34523809523809523, 'pegasus_entailment': 0.23368429640928903, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3402061855670103, 'r1_recall': 0.515625, 'r1_f1': 0.4099378881987578, 'pegasus_entailment': 0.672908385284245, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6046511627906976, 'r1_recall': 0.6446280991735537, 'r1_f1': 0.624, 'pegasus_entailment': 0.5473072727521261, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 20}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5137614678899083, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.5233644859813085, 'pegasus_entailment': 0.49624938052147627, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38461538461538464, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.41666666666666663, 'pegasus_entailment': 0.776798889040947, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32456140350877194, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.3978494623655914, 'pegasus_entailment': 0.3130284771323204, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5142857142857142, 'r1_recall': 0.32142857142857145, 'r1_f1': 0.3956043956043956, 'pegasus_entailment': 0.715877503156662, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5180722891566265, 'r1_recall': 0.44329896907216493, 'r1_f1': 0.47777777777777775, 'pegasus_entailment': 0.6111564586559931, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32075471698113206, 'r1_recall': 0.7083333333333334, 'r1_f1': 0.44155844155844154, 'pegasus_entailment': 0.5098614792029063, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6728971962616822, 'r1_recall': 0.5669291338582677, 'r1_f1': 0.6153846153846154, 'pegasus_entailment': 0.549334429204464, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4954954954954955, 'r1_recall': 0.5188679245283019, 'r1_f1': 0.5069124423963134, 'pegasus_entailment': 0.8990023136138916, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45081967213114754, 'r1_recall': 0.5729166666666666, 'r1_f1': 0.5045871559633027, 'pegasus_entailment': 0.505346400042375, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5752212389380531, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.5701754385964912, 'pegasus_entailment': 0.27101567389036063, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4017857142857143, 'r1_recall': 0.4411764705882353, 'r1_f1': 0.42056074766355145, 'pegasus_entailment': 0.8930995663007101, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.49404761904761907, 'r1_recall': 0.5, 'r1_f1': 0.4970059880239521, 'pegasus_entailment': 0.6968116909265518, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22842639593908629, 'r1_recall': 0.6617647058823529, 'r1_f1': 0.33962264150943394, 'pegasus_entailment': 0.5560828531160951, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3050847457627119, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.391304347826087, 'pegasus_entailment': 0.24512859154492617, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6854838709677419, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.5414012738853503, 'pegasus_entailment': 0.4907299454013507, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 19}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2905405405405405, 'r1_recall': 0.5972222222222222, 'r1_f1': 0.3909090909090909, 'pegasus_entailment': 0.4785392791032791, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4027777777777778, 'r1_recall': 0.6823529411764706, 'r1_f1': 0.5065502183406113, 'pegasus_entailment': 0.4213678588469823, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30434782608695654, 'r1_recall': 0.65625, 'r1_f1': 0.4158415841584159, 'pegasus_entailment': 0.9490441977977753, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34375, 'r1_recall': 0.4230769230769231, 'r1_f1': 0.3793103448275862, 'pegasus_entailment': 0.9164540966351827, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40559440559440557, 'r1_recall': 0.6744186046511628, 'r1_f1': 0.5065502183406113, 'pegasus_entailment': 0.5925259962677956, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33884297520661155, 'r1_recall': 0.6119402985074627, 'r1_f1': 0.4361702127659574, 'pegasus_entailment': 0.708044508472085, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.425, 'r1_recall': 0.6538461538461539, 'r1_f1': 0.5151515151515152, 'pegasus_entailment': 0.4596976935863495, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 24}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.69, 'r1_recall': 0.6699029126213593, 'r1_f1': 0.6798029556650246, 'pegasus_entailment': 0.34361235424876213, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3185840707964602, 'r1_recall': 0.5538461538461539, 'r1_f1': 0.4044943820224719, 'pegasus_entailment': 0.464577279984951, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4752475247524752, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.5106382978723404, 'pegasus_entailment': 0.4700566254556179, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.6195652173913043, 'r1_f1': 0.6096256684491979, 'pegasus_entailment': 0.4873967071374257, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3387096774193548, 'r1_recall': 0.4827586206896552, 'r1_f1': 0.39810426540284355, 'pegasus_entailment': 0.5543115228414536, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24, 'r1_recall': 0.23076923076923078, 'r1_f1': 0.23529411764705882, 'pegasus_entailment': 0.8791715900103251, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 22, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3835616438356164, 'r1_recall': 0.6222222222222222, 'r1_f1': 0.4745762711864407, 'pegasus_entailment': 0.9701667726039886, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7954545454545454, 'r1_recall': 0.33653846153846156, 'r1_f1': 0.47297297297297297, 'pegasus_entailment': 0.6153529584407806, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2396694214876033, 'r1_recall': 0.4142857142857143, 'r1_f1': 0.3036649214659686, 'pegasus_entailment': 0.7938768863677979, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5233644859813084, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.746991787637983, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 26}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.509090909090909, 'r1_recall': 0.417910447761194, 'r1_f1': 0.4590163934426229, 'pegasus_entailment': 0.34556247293949127, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40298507462686567, 'r1_recall': 0.7397260273972602, 'r1_f1': 0.5217391304347826, 'pegasus_entailment': 0.8667904138565063, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5544554455445545, 'r1_recall': 0.47863247863247865, 'r1_f1': 0.5137614678899082, 'pegasus_entailment': 0.7130399122834206, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32075471698113206, 'r1_recall': 0.17525773195876287, 'r1_f1': 0.22666666666666666, 'pegasus_entailment': 0.9918626844882965, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.578125, 'r1_recall': 0.4180790960451977, 'r1_f1': 0.4852459016393443, 'pegasus_entailment': 0.7186873108148575, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4631578947368421, 'r1_recall': 0.4536082474226804, 'r1_f1': 0.45833333333333326, 'pegasus_entailment': 0.3519315365701914, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5632183908045977, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.460093896713615, 'pegasus_entailment': 0.8869929611682892, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3225806451612903, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.379746835443038, 'pegasus_entailment': 0.7117458656430244, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40186915887850466, 'r1_recall': 0.38392857142857145, 'r1_f1': 0.3926940639269407, 'pegasus_entailment': 0.8189968764781952, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 34, 'pegasus_smog': 22}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42168674698795183, 'r1_recall': 0.5737704918032787, 'r1_f1': 0.4861111111111111, 'pegasus_entailment': 0.7396999970078468, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4329896907216495, 'r1_recall': 0.44680851063829785, 'r1_f1': 0.4397905759162304, 'pegasus_entailment': 0.6870561316609383, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3883495145631068, 'r1_recall': 0.6956521739130435, 'r1_f1': 0.49844236760124605, 'pegasus_entailment': 0.7300601303577423, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47619047619047616, 'r1_recall': 0.625, 'r1_f1': 0.5405405405405405, 'pegasus_entailment': 0.5985491080209613, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 25}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5304347826086957, 'r1_recall': 0.7625, 'r1_f1': 0.6256410256410256, 'pegasus_entailment': 0.67937882989645, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6125, 'r1_recall': 0.3798449612403101, 'r1_f1': 0.46889952153110054, 'pegasus_entailment': 0.5997485915819804, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.436241610738255, 'r1_recall': 0.6310679611650486, 'r1_f1': 0.5158730158730159, 'pegasus_entailment': 0.6224416553974151, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5120481927710844, 'r1_recall': 0.53125, 'r1_f1': 0.5214723926380368, 'pegasus_entailment': 0.7196571926275889, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40625, 'r1_recall': 0.52, 'r1_f1': 0.45614035087719296, 'pegasus_entailment': 0.03347761929035187, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25862068965517243, 'r1_recall': 0.25, 'r1_f1': 0.25423728813559326, 'pegasus_entailment': 0.9320093989372253, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5154639175257731, 'r1_recall': 0.7246376811594203, 'r1_f1': 0.6024096385542168, 'pegasus_entailment': 0.926842674612999, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6016260162601627, 'r1_recall': 0.556390977443609, 'r1_f1': 0.578125, 'pegasus_entailment': 0.5499982476234436, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6081081081081081, 'r1_recall': 0.569620253164557, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.5723429152742028, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.421875, 'r1_recall': 0.6067415730337079, 'r1_f1': 0.4976958525345621, 'pegasus_entailment': 0.6047394394874572, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43243243243243246, 'r1_recall': 0.36923076923076925, 'r1_f1': 0.3983402489626556, 'pegasus_entailment': 0.75539231300354, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6231884057971014, 'r1_recall': 0.48314606741573035, 'r1_f1': 0.5443037974683544, 'pegasus_entailment': 0.5312754288315773, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6733333333333333, 'r1_recall': 0.5738636363636364, 'r1_f1': 0.6196319018404909, 'pegasus_entailment': 0.7308745384216309, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.625, 'r1_recall': 0.41044776119402987, 'r1_f1': 0.49549549549549554, 'pegasus_entailment': 0.4275934983044863, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.453781512605042, 'r1_recall': 0.574468085106383, 'r1_f1': 0.5070422535211269, 'pegasus_entailment': 0.480677576106973, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7045454545454546, 'r1_recall': 0.4881889763779528, 'r1_f1': 0.5767441860465117, 'pegasus_entailment': 0.8098782896995544, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4244604316546763, 'r1_recall': 0.6704545454545454, 'r1_f1': 0.5198237885462554, 'pegasus_entailment': 0.782235344250997, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6024096385542169, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.5050505050505051, 'pegasus_entailment': 0.8495800296465555, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36885245901639346, 'r1_recall': 0.5921052631578947, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.6261117719113827, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2204724409448819, 'r1_recall': 0.6511627906976745, 'r1_f1': 0.3294117647058823, 'pegasus_entailment': 0.5305761978030205, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5735294117647058, 'r1_recall': 0.6964285714285714, 'r1_f1': 0.6290322580645161, 'pegasus_entailment': 0.8588724732398987, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6262626262626263, 'r1_recall': 0.4732824427480916, 'r1_f1': 0.5391304347826086, 'pegasus_entailment': 0.559096023440361, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.344, 'r1_recall': 0.5375, 'r1_f1': 0.4195121951219512, 'pegasus_entailment': 0.536765918135643, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4859154929577465, 'r1_recall': 0.5897435897435898, 'r1_f1': 0.5328185328185329, 'pegasus_entailment': 0.8355384111404419, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5074626865671642, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.544, 'pegasus_entailment': 0.6181278750300407, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4418604651162791, 'r1_recall': 0.6440677966101694, 'r1_f1': 0.5241379310344827, 'pegasus_entailment': 0.26443818025290966, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.71, 'r1_recall': 0.37566137566137564, 'r1_f1': 0.4913494809688581, 'pegasus_entailment': 0.0877784825861454, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 22}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5163934426229508, 'r1_recall': 0.5206611570247934, 'r1_f1': 0.5185185185185185, 'pegasus_entailment': 0.7610556524246931, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5471698113207547, 'r1_recall': 0.3741935483870968, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.744743545850118, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 14, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6633663366336634, 'r1_recall': 0.4110429447852761, 'r1_f1': 0.5075757575757576, 'pegasus_entailment': 0.4674163207411766, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5882352941176471, 'r1_recall': 0.39603960396039606, 'r1_f1': 0.4733727810650888, 'pegasus_entailment': 0.5762543578942617, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4105960264900662, 'r1_recall': 0.512396694214876, 'r1_f1': 0.45588235294117646, 'pegasus_entailment': 0.8319357872009278, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3105263157894737, 'r1_recall': 0.6344086021505376, 'r1_f1': 0.41696113074204955, 'pegasus_entailment': 0.6642813632885615, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5966386554621849, 'r1_recall': 0.5338345864661654, 'r1_f1': 0.5634920634920635, 'pegasus_entailment': 0.7798850893974304, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7558139534883721, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.47970479704797053, 'pegasus_entailment': 0.4791891574859619, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3508771929824561, 'r1_recall': 0.6896551724137931, 'r1_f1': 0.46511627906976744, 'pegasus_entailment': 0.6791091933846474, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.41, 'r1_recall': 0.4659090909090909, 'r1_f1': 0.43617021276595747, 'pegasus_entailment': 0.47817930206656456, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3805309734513274, 'r1_recall': 0.46236559139784944, 'r1_f1': 0.4174757281553398, 'pegasus_entailment': 0.335289865732193, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5132743362831859, 'r1_f1': 0.5065502183406114, 'pegasus_entailment': 0.6930526793003082, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5272727272727272, 'r1_recall': 0.725, 'r1_f1': 0.6105263157894736, 'pegasus_entailment': 0.37229938556750614, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5346534653465347, 'r1_f1': 0.5167464114832536, 'pegasus_entailment': 0.7208705147107443, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.45933014354066987, 'r1_f1': 0.526027397260274, 'pegasus_entailment': 0.8503865897655487, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6148148148148148, 'r1_recall': 0.4585635359116022, 'r1_f1': 0.5253164556962026, 'pegasus_entailment': 0.37509792546431225, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32978723404255317, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.4052287581699346, 'pegasus_entailment': 0.5841076727956533, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7872340425531915, 'r1_recall': 0.4567901234567901, 'r1_f1': 0.578125, 'pegasus_entailment': 0.21755847707390785, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4811320754716981, 'r1_recall': 0.6219512195121951, 'r1_f1': 0.5425531914893618, 'pegasus_entailment': 0.47795233502984047, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49019607843137253, 'r1_recall': 0.2604166666666667, 'r1_f1': 0.3401360544217687, 'pegasus_entailment': 0.6426375806331635, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4198473282442748, 'r1_recall': 0.5978260869565217, 'r1_f1': 0.4932735426008969, 'pegasus_entailment': 0.6229214668273926, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6593406593406593, 'r1_recall': 0.30927835051546393, 'r1_f1': 0.42105263157894735, 'pegasus_entailment': 0.36372576157251996, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.591304347826087, 'r1_recall': 0.40963855421686746, 'r1_f1': 0.4839857651245552, 'pegasus_entailment': 0.5027884542942047, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39805825242718446, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.5061728395061729, 'pegasus_entailment': 0.7526588340600332, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6601941747572816, 'r1_recall': 0.3930635838150289, 'r1_f1': 0.49275362318840576, 'pegasus_entailment': 0.4800668756167094, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4864864864864865, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4645161290322581, 'pegasus_entailment': 0.5389042297999064, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4883720930232558, 'r1_recall': 0.4228187919463087, 'r1_f1': 0.45323741007194246, 'pegasus_entailment': 0.5840649530291557, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45161290322580644, 'r1_recall': 0.6021505376344086, 'r1_f1': 0.5161290322580645, 'pegasus_entailment': 0.3514923349488527, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.49107142857142855, 'r1_recall': 0.3416149068322981, 'r1_f1': 0.40293040293040294, 'pegasus_entailment': 0.2430663749575615, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.18072289156626506, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.24793388429752067, 'pegasus_entailment': 0.32958969349662465, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6105263157894737, 'r1_recall': 0.5370370370370371, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.7250311851501465, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5294117647058824, 'r1_recall': 0.5242718446601942, 'r1_f1': 0.5268292682926828, 'pegasus_entailment': 0.7936188727617264, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4350282485875706, 'r1_recall': 0.4723926380368098, 'r1_f1': 0.45294117647058824, 'pegasus_entailment': 0.8101469228665034, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45925925925925926, 'r1_recall': 0.5688073394495413, 'r1_f1': 0.5081967213114753, 'pegasus_entailment': 0.43634097650647163, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4857142857142857, 'r1_recall': 0.38636363636363635, 'r1_f1': 0.4303797468354431, 'pegasus_entailment': 0.4423443426688512, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4329896907216495, 'r1_recall': 0.28, 'r1_f1': 0.3400809716599191, 'pegasus_entailment': 0.8374154766400655, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6413043478260869, 'r1_recall': 0.42142857142857143, 'r1_f1': 0.5086206896551724, 'pegasus_entailment': 0.44008978456258774, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4838709677419355, 'r1_recall': 0.30201342281879195, 'r1_f1': 0.371900826446281, 'pegasus_entailment': 0.5835882425308228, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36419753086419754, 'r1_recall': 0.6483516483516484, 'r1_f1': 0.466403162055336, 'pegasus_entailment': 0.5586524829268456, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 34, 'pegasus_smog': 23}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4777777777777778, 'r1_recall': 0.5584415584415584, 'r1_f1': 0.5149700598802396, 'pegasus_entailment': 0.6988606452941895, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 20}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3813559322033898, 'r1_recall': 0.6164383561643836, 'r1_f1': 0.4712041884816754, 'pegasus_entailment': 0.15215827524662018, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7619047619047619, 'r1_recall': 0.21739130434782608, 'r1_f1': 0.3382663847780127, 'pegasus_entailment': 0.5998794659972191, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4728682170542636, 'r1_recall': 0.5545454545454546, 'r1_f1': 0.5104602510460251, 'pegasus_entailment': 0.9847099930047989, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.5080645161290323, 'r1_f1': 0.5228215767634854, 'pegasus_entailment': 0.7425786852836609, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.575, 'r1_f1': 0.5348837209302325, 'pegasus_entailment': 0.7064514259497324, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8409090909090909, 'r1_recall': 0.4723404255319149, 'r1_f1': 0.6049046321525886, 'pegasus_entailment': 0.7182165384292603, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4634146341463415, 'r1_recall': 0.5, 'r1_f1': 0.48101265822784817, 'pegasus_entailment': 0.24924166819878987, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3584905660377358, 'r1_recall': 0.6627906976744186, 'r1_f1': 0.46530612244897956, 'pegasus_entailment': 0.6303460150957108, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3482142857142857, 'r1_recall': 0.52, 'r1_f1': 0.41711229946524064, 'pegasus_entailment': 0.6733416467905045, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3790322580645161, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.4392523364485982, 'pegasus_entailment': 0.7799076914787293, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.61, 'r1_recall': 0.3719512195121951, 'r1_f1': 0.46212121212121215, 'pegasus_entailment': 0.7724236994981766, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8160919540229885, 'r1_recall': 0.24738675958188153, 'r1_f1': 0.37967914438502676, 'pegasus_entailment': 0.33340180665254593, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.75, 'r1_recall': 0.3016759776536313, 'r1_f1': 0.4302788844621514, 'pegasus_entailment': 0.5884541471799215, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.553030303030303, 'r1_recall': 0.6403508771929824, 'r1_f1': 0.5934959349593496, 'pegasus_entailment': 0.46639395505189896, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6831683168316832, 'r1_recall': 0.5307692307692308, 'r1_f1': 0.5974025974025974, 'pegasus_entailment': 0.7821817398071289, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 23}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4222222222222222, 'r1_recall': 0.5480769230769231, 'r1_f1': 0.47698744769874474, 'pegasus_entailment': 0.5591401606798172, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.43589743589743596, 'pegasus_entailment': 0.9362344443798065, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6238532110091743, 'r1_recall': 0.41975308641975306, 'r1_f1': 0.5018450184501845, 'pegasus_entailment': 0.6119451001286507, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.59375, 'r1_recall': 0.7402597402597403, 'r1_f1': 0.6589595375722545, 'pegasus_entailment': 0.394996730145067, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5511811023622047, 'r1_recall': 0.4861111111111111, 'r1_f1': 0.5166051660516606, 'pegasus_entailment': 0.5549194812774658, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.56, 'r1_f1': 0.5793103448275861, 'pegasus_entailment': 0.5558383961518606, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.461038961038961, 'r1_recall': 0.5867768595041323, 'r1_f1': 0.5163636363636364, 'pegasus_entailment': 0.7766616642475128, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6909090909090909, 'r1_recall': 0.6846846846846847, 'r1_f1': 0.6877828054298641, 'pegasus_entailment': 0.49826850928366184, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6019417475728155, 'r1_recall': 0.3803680981595092, 'r1_f1': 0.4661654135338346, 'pegasus_entailment': 0.2871922155221303, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 24}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6017699115044248, 'r1_recall': 0.38636363636363635, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.3412942737340927, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48091603053435117, 'r1_recall': 0.7875, 'r1_f1': 0.5971563981042654, 'pegasus_entailment': 0.7002632273361087, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23846153846153847, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.3263157894736842, 'pegasus_entailment': 0.5839461833238602, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3163265306122449, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.3924050632911393, 'pegasus_entailment': 0.6598343253135681, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43434343434343436, 'r1_recall': 0.4387755102040816, 'r1_f1': 0.43654822335025373, 'pegasus_entailment': 0.2504466399550438, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6016260162601627, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.5849802371541502, 'pegasus_entailment': 0.5908371917903423, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.6304347826086957, 'r1_f1': 0.35802469135802467, 'pegasus_entailment': 0.7378079114714637, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5537190082644629, 'r1_recall': 0.5877192982456141, 'r1_f1': 0.570212765957447, 'pegasus_entailment': 0.512027632445097, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45255474452554745, 'r1_recall': 0.5585585585585585, 'r1_f1': 0.5, 'pegasus_entailment': 0.455177690833807, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7117117117117117, 'r1_recall': 0.3607305936073059, 'r1_f1': 0.47878787878787876, 'pegasus_entailment': 0.5257260343059897, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.6829268292682927, 'r1_f1': 0.6021505376344086, 'pegasus_entailment': 0.6214940252248198, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42063492063492064, 'r1_recall': 0.6022727272727273, 'r1_f1': 0.4953271028037383, 'pegasus_entailment': 0.7691210955381393, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5619834710743802, 'r1_recall': 0.6732673267326733, 'r1_f1': 0.6126126126126127, 'pegasus_entailment': 0.17698776088654994, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4806201550387597, 'r1_recall': 0.5740740740740741, 'r1_f1': 0.5232067510548524, 'pegasus_entailment': 0.20117624141275883, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26666666666666666, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.3660130718954248, 'pegasus_entailment': 0.40602368526160715, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.59375, 'r1_recall': 0.5757575757575758, 'r1_f1': 0.5846153846153846, 'pegasus_entailment': 0.5592094540596009, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5289256198347108, 'r1_recall': 0.4050632911392405, 'r1_f1': 0.45878136200716846, 'pegasus_entailment': 0.2981831009189288, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6434782608695652, 'r1_recall': 0.46835443037974683, 'r1_f1': 0.5421245421245422, 'pegasus_entailment': 0.40037916228175163, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.616822429906542, 'r1_recall': 0.34196891191709844, 'r1_f1': 0.44, 'pegasus_entailment': 0.4143464267253876, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5806451612903226, 'r1_recall': 0.5142857142857142, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.6761938532193502, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5877192982456141, 'r1_recall': 0.536, 'r1_f1': 0.5606694560669457, 'pegasus_entailment': 0.5375417947769165, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.36538461538461536, 'r1_f1': 0.42222222222222217, 'pegasus_entailment': 0.8884657422701517, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29347826086956524, 'r1_recall': 0.4426229508196721, 'r1_f1': 0.35294117647058826, 'pegasus_entailment': 0.4234404496382922, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 14}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4375, 'r1_recall': 0.5645161290322581, 'r1_f1': 0.4929577464788733, 'pegasus_entailment': 0.8833660880724589, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3229166666666667, 'r1_recall': 0.5254237288135594, 'r1_f1': 0.4000000000000001, 'pegasus_entailment': 0.4319556523114443, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.425, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.4358974358974359, 'pegasus_entailment': 0.48498602708180744, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36633663366336633, 'r1_recall': 0.37373737373737376, 'r1_f1': 0.37, 'pegasus_entailment': 0.5175601877272129, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2653061224489796, 'r1_recall': 0.65, 'r1_f1': 0.3768115942028986, 'pegasus_entailment': 0.8688450455665588, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 32, 'pegasus_smog': 24}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42574257425742573, 'r1_recall': 0.49710982658959535, 'r1_f1': 0.4586666666666666, 'pegasus_entailment': 0.3921014042571187, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4140625, 'r1_recall': 0.6625, 'r1_f1': 0.5096153846153846, 'pegasus_entailment': 0.35660714904467267, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5689655172413793, 'r1_recall': 0.3707865168539326, 'r1_f1': 0.4489795918367347, 'pegasus_entailment': 0.6437714397907257, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7111111111111111, 'r1_recall': 0.39751552795031053, 'r1_f1': 0.5099601593625498, 'pegasus_entailment': 0.13664319925010204, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5445544554455446, 'r1_recall': 0.41044776119402987, 'r1_f1': 0.4680851063829788, 'pegasus_entailment': 0.25547654344700277, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6728971962616822, 'r1_recall': 0.2962962962962963, 'r1_f1': 0.41142857142857137, 'pegasus_entailment': 0.4688647612929344, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45098039215686275, 'r1_recall': 0.5609756097560976, 'r1_f1': 0.5, 'pegasus_entailment': 0.6030058066050211, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6707317073170732, 'r1_recall': 0.3618421052631579, 'r1_f1': 0.47008547008547014, 'pegasus_entailment': 0.40091420570388436, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30327868852459017, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.38144329896907214, 'pegasus_entailment': 0.6669193897396326, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.691358024691358, 'r1_recall': 0.25112107623318386, 'r1_f1': 0.3684210526315789, 'pegasus_entailment': 0.4722487762570381, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28205128205128205, 'r1_recall': 0.2920353982300885, 'r1_f1': 0.28695652173913044, 'pegasus_entailment': 0.2996280584484339, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32967032967032966, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.43795620437956206, 'pegasus_entailment': 0.13584206998348236, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6129032258064516, 'r1_recall': 0.4198895027624309, 'r1_f1': 0.49836065573770494, 'pegasus_entailment': 0.41323973536491393, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5833333333333334, 'r1_recall': 0.3559322033898305, 'r1_f1': 0.4421052631578947, 'pegasus_entailment': 0.3798638373613358, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2955665024630542, 'r1_recall': 0.625, 'r1_f1': 0.4013377926421405, 'pegasus_entailment': 0.7679224191233516, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6333333333333333, 'r1_recall': 0.5241379310344828, 'r1_f1': 0.5735849056603772, 'pegasus_entailment': 0.8378613233566284, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.14736842105263157, 'r1_recall': 0.5, 'r1_f1': 0.2276422764227642, 'pegasus_entailment': 0.33038490563631057, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1870967741935484, 'r1_recall': 0.5, 'r1_f1': 0.27230046948356806, 'pegasus_entailment': 0.675854966044426, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6451612903225806, 'r1_recall': 0.5042016806722689, 'r1_f1': 0.5660377358490566, 'pegasus_entailment': 0.4385720541079839, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3467741935483871, 'r1_recall': 0.6056338028169014, 'r1_f1': 0.441025641025641, 'pegasus_entailment': 0.7112539887428284, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2882882882882883, 'r1_recall': 0.5818181818181818, 'r1_f1': 0.38554216867469876, 'pegasus_entailment': 0.7781752496957779, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30392156862745096, 'r1_recall': 0.38271604938271603, 'r1_f1': 0.33879781420765026, 'pegasus_entailment': 0.4378936819266528, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.6037735849056604, 'pegasus_entailment': 0.8697647651036581, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.52, 'r1_recall': 0.46987951807228917, 'r1_f1': 0.4936708860759494, 'pegasus_entailment': 0.3338967598974705, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5590551181102362, 'r1_recall': 0.6396396396396397, 'r1_f1': 0.596638655462185, 'pegasus_entailment': 0.29798583360388875, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7086614173228346, 'r1_recall': 0.26785714285714285, 'r1_f1': 0.3887688984881209, 'pegasus_entailment': 0.6117390632629395, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5752212389380531, 'r1_recall': 0.2927927927927928, 'r1_f1': 0.38805970149253727, 'pegasus_entailment': 0.368030721321702, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36752136752136755, 'r1_recall': 0.5512820512820513, 'r1_f1': 0.44102564102564107, 'pegasus_entailment': 0.6475750133395195, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7037037037037037, 'r1_recall': 0.5480769230769231, 'r1_f1': 0.6162162162162163, 'pegasus_entailment': 0.3639751486480236, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2909090909090909, 'r1_recall': 0.4383561643835616, 'r1_f1': 0.34972677595628415, 'pegasus_entailment': 0.5940685371557871, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4024390243902439, 'r1_recall': 0.5076923076923077, 'r1_f1': 0.4489795918367347, 'pegasus_entailment': 0.21311647444963455, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46808510638297873, 'r1_recall': 0.6111111111111112, 'r1_f1': 0.5301204819277109, 'pegasus_entailment': 0.6122121140360832, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5972222222222222, 'r1_recall': 0.5308641975308642, 'r1_f1': 0.5620915032679739, 'pegasus_entailment': 0.6094744255145391, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 14}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4473684210526316, 'r1_recall': 0.4473684210526316, 'r1_f1': 0.4473684210526316, 'pegasus_entailment': 0.9029853641986847, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 15, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5441176470588235, 'r1_recall': 0.44047619047619047, 'r1_f1': 0.4868421052631579, 'pegasus_entailment': 0.30553184309974313, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6396396396396397, 'r1_recall': 0.45222929936305734, 'r1_f1': 0.5298507462686567, 'pegasus_entailment': 0.8343355059623718, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.616822429906542, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.5258964143426293, 'pegasus_entailment': 0.5093335583806038, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38513513513513514, 'r1_recall': 0.6063829787234043, 'r1_f1': 0.4710743801652893, 'pegasus_entailment': 0.4307665386702865, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6047904191616766, 'r1_recall': 0.5287958115183246, 'r1_f1': 0.5642458100558659, 'pegasus_entailment': 0.48816022525231045, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.24, 'r1_recall': 0.7346938775510204, 'r1_f1': 0.36180904522613067, 'pegasus_entailment': 0.8019844591617584, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 23, 'pegasus_ari': 36, 'pegasus_smog': 28}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5542168674698795, 'r1_recall': 0.5542168674698795, 'r1_f1': 0.5542168674698795, 'pegasus_entailment': 0.7802265683809916, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.5, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.6436097901314497, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 12}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5319148936170213, 'r1_recall': 0.6172839506172839, 'r1_f1': 0.5714285714285713, 'pegasus_entailment': 0.3650123305618763, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5467625899280576, 'r1_recall': 0.5547445255474452, 'r1_f1': 0.5507246376811595, 'pegasus_entailment': 0.7822348326444626, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23333333333333334, 'r1_recall': 0.3181818181818182, 'r1_f1': 0.2692307692307693, 'pegasus_entailment': 0.782502144575119, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 20, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25210084033613445, 'r1_recall': 0.5084745762711864, 'r1_f1': 0.33707865168539325, 'pegasus_entailment': 0.7963678687810898, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5590551181102362, 'r1_recall': 0.5298507462686567, 'r1_f1': 0.5440613026819924, 'pegasus_entailment': 0.7086443901062012, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5727272727272728, 'r1_recall': 0.40384615384615385, 'r1_f1': 0.47368421052631576, 'pegasus_entailment': 0.22778382450342177, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3695652173913043, 'r1_recall': 0.7846153846153846, 'r1_f1': 0.5024630541871922, 'pegasus_entailment': 0.7307687550783157, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38317757009345793, 'r1_recall': 0.4659090909090909, 'r1_f1': 0.42051282051282046, 'pegasus_entailment': 0.6050817507008711, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5111111111111111, 'r1_recall': 0.5476190476190477, 'r1_f1': 0.5287356321839081, 'pegasus_entailment': 0.5499101082483927, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43478260869565216, 'r1_recall': 0.5194805194805194, 'r1_f1': 0.4733727810650888, 'pegasus_entailment': 0.5417298106476665, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25477707006369427, 'r1_recall': 0.5, 'r1_f1': 0.3375527426160338, 'pegasus_entailment': 0.6517086277405421, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5375722543352601, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.5653495440729484, 'pegasus_entailment': 0.7541218996047974, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3389830508474576, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.41237113402061853, 'pegasus_entailment': 0.3670961752533913, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25225225225225223, 'r1_recall': 0.6588235294117647, 'r1_f1': 0.36482084690553745, 'pegasus_entailment': 0.5338184339925647, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6936936936936937, 'r1_recall': 0.5877862595419847, 'r1_f1': 0.6363636363636364, 'pegasus_entailment': 0.34946442674845457, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4329896907216495, 'r1_recall': 0.39622641509433965, 'r1_f1': 0.41379310344827586, 'pegasus_entailment': 0.26269884034991264, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7920792079207921, 'r1_recall': 0.4371584699453552, 'r1_f1': 0.5633802816901409, 'pegasus_entailment': 0.6396435722708702, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.28651685393258425, 'r1_recall': 0.6710526315789473, 'r1_f1': 0.4015748031496063, 'pegasus_entailment': 0.38436618633568287, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5130434782608696, 'r1_recall': 0.6413043478260869, 'r1_f1': 0.5700483091787439, 'pegasus_entailment': 0.36865061335265636, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.668918918918919, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.5439560439560439, 'pegasus_entailment': 0.38600407550111415, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6219512195121951, 'r1_recall': 0.504950495049505, 'r1_f1': 0.5573770491803278, 'pegasus_entailment': 0.022974513296503574, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5392156862745098, 'r1_recall': 0.5612244897959183, 'r1_f1': 0.5499999999999999, 'pegasus_entailment': 0.1047386497957632, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.39805825242718446, 'r1_recall': 0.5857142857142857, 'r1_f1': 0.4739884393063584, 'pegasus_entailment': 0.5630463644241294, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7, 'r1_recall': 0.631578947368421, 'r1_f1': 0.6640316205533596, 'pegasus_entailment': 0.3682808515926202, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5277777777777778, 'r1_recall': 0.4222222222222222, 'r1_f1': 0.46913580246913583, 'pegasus_entailment': 0.40079450607299805, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.55, 'r1_recall': 0.3826086956521739, 'r1_f1': 0.4512820512820513, 'pegasus_entailment': 0.565836121638616, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41904761904761906, 'r1_recall': 0.3963963963963964, 'r1_f1': 0.4074074074074074, 'pegasus_entailment': 0.7410467465718588, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7254901960784313, 'r1_recall': 0.5362318840579711, 'r1_f1': 0.6166666666666667, 'pegasus_entailment': 0.8752594192822775, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.20610687022900764, 'r1_recall': 0.54, 'r1_f1': 0.2983425414364641, 'pegasus_entailment': 0.08160261635202914, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4430379746835443, 'r1_recall': 0.625, 'r1_f1': 0.5185185185185185, 'pegasus_entailment': 0.42599132657051086, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.18947368421052632, 'r1_recall': 0.3829787234042553, 'r1_f1': 0.2535211267605634, 'pegasus_entailment': 0.3560933470726013, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.425, 'r1_recall': 0.4788732394366197, 'r1_f1': 0.45033112582781454, 'pegasus_entailment': 0.4726495295763016, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5194805194805194, 'r1_recall': 0.4371584699453552, 'r1_f1': 0.4747774480712166, 'pegasus_entailment': 0.40221239626407623, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 15, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4714285714285714, 'r1_recall': 0.48175182481751827, 'r1_f1': 0.4765342960288809, 'pegasus_entailment': 0.7827632784843445, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5686274509803921, 'r1_recall': 0.6373626373626373, 'r1_f1': 0.6010362694300517, 'pegasus_entailment': 0.7286163046956062, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4550561797752809, 'r1_recall': 0.6090225563909775, 'r1_f1': 0.5209003215434083, 'pegasus_entailment': 0.38639849703758955, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5369127516778524, 'r1_recall': 0.4878048780487805, 'r1_f1': 0.5111821086261981, 'pegasus_entailment': 0.37238496790329617, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7209302325581395, 'r1_recall': 0.4626865671641791, 'r1_f1': 0.5636363636363636, 'pegasus_entailment': 0.6973941326141357, 'pegasus_flesch_kincaid': 34, 'pegasus_coleman_liau': 19, 'pegasus_ari': 40, 'pegasus_smog': 28}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2992125984251969, 'r1_recall': 0.38, 'r1_f1': 0.33480176211453744, 'pegasus_entailment': 0.4157695956528187, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40594059405940597, 'r1_recall': 0.5125, 'r1_f1': 0.4530386740331492, 'pegasus_entailment': 0.9710010439157486, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5212765957446809, 'r1_recall': 0.5975609756097561, 'r1_f1': 0.5568181818181819, 'pegasus_entailment': 0.32674658643857885, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1896551724137931, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.2682926829268293, 'pegasus_entailment': 0.4422093816101551, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 12, 'pegasus_ari': 10, 'pegasus_smog': 15}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24817518248175183, 'r1_recall': 0.5396825396825397, 'r1_f1': 0.33999999999999997, 'pegasus_entailment': 0.7034736010245979, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21176470588235294, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.3025210084033613, 'pegasus_entailment': 0.2671034703031182, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2815533980582524, 'r1_recall': 0.3815789473684211, 'r1_f1': 0.324022346368715, 'pegasus_entailment': 0.705104187130928, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.2608695652173913, 'r1_f1': 0.366412213740458, 'pegasus_entailment': 0.4779355712234974, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 17}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30612244897959184, 'r1_recall': 0.44776119402985076, 'r1_f1': 0.36363636363636365, 'pegasus_entailment': 0.315474105377992, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5483870967741935, 'r1_recall': 0.40476190476190477, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.34459428787231444, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5666666666666667, 'r1_recall': 0.5151515151515151, 'r1_f1': 0.5396825396825397, 'pegasus_entailment': 0.31540120641390484, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6697247706422018, 'r1_recall': 0.4620253164556962, 'r1_f1': 0.5468164794007491, 'pegasus_entailment': 0.7457675933837891, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6764705882352942, 'r1_recall': 0.23310810810810811, 'r1_f1': 0.34673366834170855, 'pegasus_entailment': 0.665856346487999, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3023255813953488, 'r1_recall': 0.7090909090909091, 'r1_f1': 0.42391304347826086, 'pegasus_entailment': 0.6208240643143654, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7311827956989247, 'r1_recall': 0.34517766497461927, 'r1_f1': 0.46896551724137936, 'pegasus_entailment': 0.21182203888893128, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.375, 'r1_recall': 0.55, 'r1_f1': 0.44594594594594594, 'pegasus_entailment': 0.389722208182017, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5648148148148148, 'r1_recall': 0.4959349593495935, 'r1_f1': 0.5281385281385281, 'pegasus_entailment': 0.691787526011467, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.58, 'r1_recall': 0.5523809523809524, 'r1_f1': 0.5658536585365854, 'pegasus_entailment': 0.7287337382634481, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7128712871287128, 'r1_recall': 0.549618320610687, 'r1_f1': 0.6206896551724138, 'pegasus_entailment': 0.2824291264017423, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3364485981308411, 'r1_recall': 0.5373134328358209, 'r1_f1': 0.41379310344827586, 'pegasus_entailment': 0.5525418917338053, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26277372262773724, 'r1_recall': 0.631578947368421, 'r1_f1': 0.3711340206185567, 'pegasus_entailment': 0.47880323231220245, 'pegasus_flesch_kincaid': 36, 'pegasus_coleman_liau': 20, 'pegasus_ari': 43, 'pegasus_smog': 27}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22981366459627328, 'r1_recall': 0.6491228070175439, 'r1_f1': 0.3394495412844037, 'pegasus_entailment': 0.6982872039079666, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.546875, 'r1_recall': 0.546875, 'r1_f1': 0.546875, 'pegasus_entailment': 0.3892614357173443, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6012658227848101, 'r1_recall': 0.5337078651685393, 'r1_f1': 0.5654761904761905, 'pegasus_entailment': 0.41736343236906187, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6330935251798561, 'r1_recall': 0.5398773006134969, 'r1_f1': 0.5827814569536423, 'pegasus_entailment': 0.6985654830932617, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.624, 'r1_recall': 0.40414507772020725, 'r1_f1': 0.490566037735849, 'pegasus_entailment': 0.7027577459812164, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42276422764227645, 'r1_recall': 0.5148514851485149, 'r1_f1': 0.4642857142857143, 'pegasus_entailment': 0.8138550668954849, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37037037037037035, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.45662100456621, 'pegasus_entailment': 0.43804182165435385, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.415929203539823, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.4630541871921182, 'pegasus_entailment': 0.6481020243838429, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2857142857142857, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.3661971830985915, 'pegasus_entailment': 0.09943162401517232, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6164383561643836, 'r1_recall': 0.6081081081081081, 'r1_f1': 0.6122448979591837, 'pegasus_entailment': 0.5928626706202825, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5981308411214953, 'r1_recall': 0.48854961832061067, 'r1_f1': 0.5378151260504201, 'pegasus_entailment': 0.5036757367663085, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7230769230769231, 'r1_recall': 0.3983050847457627, 'r1_f1': 0.5136612021857924, 'pegasus_entailment': 0.9645333886146545, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7181818181818181, 'r1_recall': 0.6076923076923076, 'r1_f1': 0.6583333333333333, 'pegasus_entailment': 0.6812905271848043, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.51, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.46575342465753417, 'pegasus_entailment': 0.3687994755455293, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6637931034482759, 'r1_recall': 0.5347222222222222, 'r1_f1': 0.5923076923076923, 'pegasus_entailment': 0.6600017994642258, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5641025641025641, 'r1_recall': 0.4888888888888889, 'r1_f1': 0.5238095238095238, 'pegasus_entailment': 0.41945621371269226, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.59, 'r1_recall': 0.44360902255639095, 'r1_f1': 0.5064377682403433, 'pegasus_entailment': 0.8845803141593933, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6695652173913044, 'r1_recall': 0.3632075471698113, 'r1_f1': 0.47094801223241584, 'pegasus_entailment': 0.6501234322786331, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.34594594594594597, 'pegasus_entailment': 0.30402669799514115, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5670103092783505, 'r1_recall': 0.4296875, 'r1_f1': 0.4888888888888889, 'pegasus_entailment': 0.2779076211154461, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3392857142857143, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.44970414201183434, 'pegasus_entailment': 0.5265488564968109, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6277372262773723, 'r1_recall': 0.450261780104712, 'r1_f1': 0.524390243902439, 'pegasus_entailment': 0.5352659732103348, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44502617801047123, 'r1_recall': 0.5782312925170068, 'r1_f1': 0.5029585798816568, 'pegasus_entailment': 0.37357812374830246, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5086206896551724, 'r1_recall': 0.38311688311688313, 'r1_f1': 0.437037037037037, 'pegasus_entailment': 0.8457697033882141, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43410852713178294, 'r1_recall': 0.7466666666666667, 'r1_f1': 0.5490196078431372, 'pegasus_entailment': 0.668788643926382, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43523316062176165, 'r1_recall': 0.7304347826086957, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.7084570154547691, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.568, 'r1_recall': 0.46405228758169936, 'r1_f1': 0.5107913669064749, 'pegasus_entailment': 0.7136535247166952, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5092592592592593, 'r1_recall': 0.5392156862745098, 'r1_f1': 0.5238095238095237, 'pegasus_entailment': 0.26461450904607775, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31313131313131315, 'r1_recall': 0.543859649122807, 'r1_f1': 0.39743589743589747, 'pegasus_entailment': 0.3857461787760258, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4470588235294118, 'r1_recall': 0.59375, 'r1_f1': 0.5100671140939598, 'pegasus_entailment': 0.5820176843553782, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5161290322580645, 'r1_recall': 0.64, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.1763026174157858, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4810126582278481, 'r1_recall': 0.7169811320754716, 'r1_f1': 0.5757575757575758, 'pegasus_entailment': 0.8459522724151611, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.504, 'r1_recall': 0.6774193548387096, 'r1_f1': 0.5779816513761469, 'pegasus_entailment': 0.4886067658662796, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35789473684210527, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.4134679310955107, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6767676767676768, 'r1_recall': 0.6568627450980392, 'r1_f1': 0.6666666666666667, 'pegasus_entailment': 0.5531190969049931, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6161616161616161, 'r1_recall': 0.3860759493670886, 'r1_f1': 0.47470817120622566, 'pegasus_entailment': 0.6424889434129, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31, 'r1_recall': 0.543859649122807, 'r1_f1': 0.39490445859872614, 'pegasus_entailment': 0.40479302080348134, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6638655462184874, 'r1_recall': 0.5302013422818792, 'r1_f1': 0.5895522388059702, 'pegasus_entailment': 0.6046799421310425, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5217391304347826, 'r1_recall': 0.35036496350364965, 'r1_f1': 0.4192139737991266, 'pegasus_entailment': 0.6719161868095398, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5421686746987951, 'r1_recall': 0.6818181818181818, 'r1_f1': 0.6040268456375839, 'pegasus_entailment': 0.07457954878918827, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5568181818181818, 'r1_recall': 0.44144144144144143, 'r1_f1': 0.4924623115577889, 'pegasus_entailment': 0.6947434743245443, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3058823529411765, 'r1_recall': 0.65, 'r1_f1': 0.41600000000000004, 'pegasus_entailment': 0.6195839315652847, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5054945054945055, 'r1_recall': 0.36220472440944884, 'r1_f1': 0.4220183486238532, 'pegasus_entailment': 0.6029576162497202, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.644927536231884, 'r1_recall': 0.4517766497461929, 'r1_f1': 0.5313432835820896, 'pegasus_entailment': 0.3369411788880825, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7105263157894737, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.453781512605042, 'pegasus_entailment': 0.3816449474543333, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6576576576576577, 'r1_recall': 0.5251798561151079, 'r1_f1': 0.584, 'pegasus_entailment': 0.5647763879969716, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.14124293785310735, 'r1_recall': 0.3424657534246575, 'r1_f1': 0.2, 'pegasus_entailment': 0.002422826752687494, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3375, 'r1_recall': 0.4426229508196721, 'r1_f1': 0.3829787234042554, 'pegasus_entailment': 0.2427261816803366, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5959595959595959, 'r1_recall': 0.686046511627907, 'r1_f1': 0.6378378378378378, 'pegasus_entailment': 0.5694848671555519, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43617021276595747, 'r1_recall': 0.5540540540540541, 'r1_f1': 0.4880952380952381, 'pegasus_entailment': 0.24456173181533813, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.532967032967033, 'r1_recall': 0.5574712643678161, 'r1_f1': 0.5449438202247192, 'pegasus_entailment': 0.6229161381721496, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4098360655737705, 'r1_recall': 0.3472222222222222, 'r1_f1': 0.3759398496240602, 'pegasus_entailment': 0.35598167264834046, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6268656716417911, 'r1_recall': 0.4307692307692308, 'r1_f1': 0.5106382978723405, 'pegasus_entailment': 0.7973864525556564, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5512820512820513, 'r1_recall': 0.589041095890411, 'r1_f1': 0.5695364238410597, 'pegasus_entailment': 0.5172711908817291, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4636363636363636, 'r1_recall': 0.68, 'r1_f1': 0.5513513513513514, 'pegasus_entailment': 0.45809801295399666, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46923076923076923, 'r1_recall': 0.5350877192982456, 'r1_f1': 0.5, 'pegasus_entailment': 0.7889416019121805, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.639344262295082, 'r1_recall': 0.2074468085106383, 'r1_f1': 0.3132530120481928, 'pegasus_entailment': 0.6339450120925904, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3113207547169811, 'r1_recall': 0.559322033898305, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.5176110044121742, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7159090909090909, 'r1_recall': 0.375, 'r1_f1': 0.49218750000000006, 'pegasus_entailment': 0.5895891090234121, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.441340782122905, 'r1_recall': 0.6124031007751938, 'r1_f1': 0.512987012987013, 'pegasus_entailment': 0.6584297776222229, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5824175824175825, 'r1_recall': 0.35570469798657717, 'r1_f1': 0.4416666666666667, 'pegasus_entailment': 0.8418052991231283, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6377952755905512, 'r1_recall': 0.47928994082840237, 'r1_f1': 0.5472972972972974, 'pegasus_entailment': 0.40092804096639156, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6513761467889908, 'r1_recall': 0.5419847328244275, 'r1_f1': 0.5916666666666667, 'pegasus_entailment': 0.6452926496664683, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4470588235294118, 'r1_recall': 0.3064516129032258, 'r1_f1': 0.3636363636363637, 'pegasus_entailment': 0.5972260038057963, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40145985401459855, 'r1_recall': 0.6626506024096386, 'r1_f1': 0.5, 'pegasus_entailment': 0.4320931853726506, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2604166666666667, 'r1_recall': 0.6410256410256411, 'r1_f1': 0.3703703703703704, 'pegasus_entailment': 0.4436323530972004, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45454545454545453, 'r1_recall': 0.5172413793103449, 'r1_f1': 0.4838709677419355, 'pegasus_entailment': 0.360270057618618, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6730769230769231, 'r1_recall': 0.3783783783783784, 'r1_f1': 0.48442906574394473, 'pegasus_entailment': 0.4126456279773265, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7068965517241379, 'r1_recall': 0.4270833333333333, 'r1_f1': 0.5324675324675324, 'pegasus_entailment': 0.9654142260551453, 'pegasus_flesch_kincaid': 33, 'pegasus_coleman_liau': 22, 'pegasus_ari': 39, 'pegasus_smog': 29}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7262569832402235, 'r1_recall': 0.33766233766233766, 'r1_f1': 0.4609929078014184, 'pegasus_entailment': 0.4424214256661279, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7611940298507462, 'r1_recall': 0.3541666666666667, 'r1_f1': 0.4834123222748815, 'pegasus_entailment': 0.6143056899309158, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25903614457831325, 'r1_recall': 0.6615384615384615, 'r1_f1': 0.3722943722943723, 'pegasus_entailment': 0.4355976700782776, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32061068702290074, 'r1_recall': 0.7, 'r1_f1': 0.43979057591623033, 'pegasus_entailment': 0.38663254380226136, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38, 'r1_recall': 0.4691358024691358, 'r1_f1': 0.4198895027624309, 'pegasus_entailment': 0.3341523340592782, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43157894736842106, 'r1_recall': 0.3942307692307692, 'r1_f1': 0.4120603015075377, 'pegasus_entailment': 0.7125851035118103, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2619047619047619, 'r1_recall': 0.38372093023255816, 'r1_f1': 0.3113207547169812, 'pegasus_entailment': 0.5495309568941593, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4, 'r1_recall': 0.5256410256410257, 'r1_f1': 0.4542936288088643, 'pegasus_entailment': 0.6471688866615295, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 14, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6120689655172413, 'r1_recall': 0.4303030303030303, 'r1_f1': 0.5053380782918149, 'pegasus_entailment': 0.7227631449699402, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.5901639344262295, 'r1_f1': 0.496551724137931, 'pegasus_entailment': 0.7331307819113135, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5294117647058824, 'r1_recall': 0.54, 'r1_f1': 0.5346534653465347, 'pegasus_entailment': 0.6270806448800224, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4444444444444444, 'r1_recall': 0.6153846153846154, 'r1_f1': 0.5161290322580646, 'pegasus_entailment': 0.33051775582134724, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6341463414634146, 'r1_recall': 0.3969465648854962, 'r1_f1': 0.4882629107981221, 'pegasus_entailment': 0.41792208701372147, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45217391304347826, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5048543689320388, 'pegasus_entailment': 0.5840363681316376, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44155844155844154, 'r1_recall': 0.6476190476190476, 'r1_f1': 0.525096525096525, 'pegasus_entailment': 0.4465103766747883, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.40625, 'r1_recall': 0.7123287671232876, 'r1_f1': 0.5174129353233831, 'pegasus_entailment': 0.46607450023293495, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42105263157894735, 'r1_recall': 0.32, 'r1_f1': 0.3636363636363636, 'pegasus_entailment': 0.2524565467610955, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5573770491803278, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.576271186440678, 'pegasus_entailment': 0.3694284028315451, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4057971014492754, 'r1_recall': 0.6292134831460674, 'r1_f1': 0.49339207048458156, 'pegasus_entailment': 0.31593561843037604, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.6744186046511628, 'r1_f1': 0.4461538461538461, 'pegasus_entailment': 0.3775640436215326, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.48868778280542985, 'r1_f1': 0.5639686684073106, 'pegasus_entailment': 0.4729231645663579, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6509433962264151, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6301369863013699, 'pegasus_entailment': 0.9620340764522552, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 22}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.313953488372093, 'r1_recall': 0.7297297297297297, 'r1_f1': 0.43902439024390244, 'pegasus_entailment': 0.5478938271601995, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4, 'r1_recall': 0.6341463414634146, 'r1_f1': 0.49056603773584906, 'pegasus_entailment': 0.808735579252243, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 13}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3422459893048128, 'r1_recall': 0.5981308411214953, 'r1_f1': 0.435374149659864, 'pegasus_entailment': 0.49664678672949475, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.41379310344827586, 'pegasus_entailment': 0.7014288306236267, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4117647058823529, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.5, 'pegasus_entailment': 0.6784124141559005, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45544554455445546, 'r1_recall': 0.5168539325842697, 'r1_f1': 0.4842105263157895, 'pegasus_entailment': 0.3659364618360996, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3, 'r1_recall': 0.711864406779661, 'r1_f1': 0.4221105527638191, 'pegasus_entailment': 0.41956439820933156, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5684210526315789, 'r1_recall': 0.5454545454545454, 'r1_f1': 0.5567010309278351, 'pegasus_entailment': 0.574154682457447, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4811320754716981, 'r1_recall': 0.53125, 'r1_f1': 0.504950495049505, 'pegasus_entailment': 0.8681904474894205, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4117647058823529, 'r1_recall': 0.5212765957446809, 'r1_f1': 0.460093896713615, 'pegasus_entailment': 0.8770277500152588, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8904109589041096, 'r1_recall': 0.24904214559386972, 'r1_f1': 0.38922155688622756, 'pegasus_entailment': 0.689355785648028, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5503875968992248, 'r1_recall': 0.355, 'r1_f1': 0.4316109422492401, 'pegasus_entailment': 0.6950813929239908, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23846153846153847, 'r1_recall': 0.3974358974358974, 'r1_f1': 0.29807692307692313, 'pegasus_entailment': 0.12507748816694533, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6338028169014085, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.5113636363636364, 'pegasus_entailment': 0.5415166139602661, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 18, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.68, 'r1_recall': 0.5, 'r1_f1': 0.576271186440678, 'pegasus_entailment': 0.3638786420226097, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.35678391959798994, 'r1_recall': 0.6283185840707964, 'r1_f1': 0.4551282051282051, 'pegasus_entailment': 0.7952338457107544, 'pegasus_flesch_kincaid': 34, 'pegasus_coleman_liau': 20, 'pegasus_ari': 42, 'pegasus_smog': 26}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5569620253164557, 'r1_recall': 0.5176470588235295, 'r1_f1': 0.5365853658536586, 'pegasus_entailment': 0.4831910679737727, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34615384615384615, 'r1_recall': 0.4090909090909091, 'r1_f1': 0.37500000000000006, 'pegasus_entailment': 0.26772380620241165, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 30, 'pegasus_smog': 20}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.4891304347826087, 'r1_f1': 0.5202312138728324, 'pegasus_entailment': 0.49933280423283577, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3482142857142857, 'r1_recall': 0.46987951807228917, 'r1_f1': 0.4, 'pegasus_entailment': 0.4733418520539999, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6559139784946236, 'r1_recall': 0.48412698412698413, 'r1_f1': 0.5570776255707762, 'pegasus_entailment': 0.5643767982721328, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5317460317460317, 'r1_recall': 0.6568627450980392, 'r1_f1': 0.5877192982456141, 'pegasus_entailment': 0.5240236613899469, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6214285714285714, 'r1_recall': 0.5403726708074534, 'r1_f1': 0.5780730897009967, 'pegasus_entailment': 0.5938585519790649, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3563218390804598, 'r1_recall': 0.543859649122807, 'r1_f1': 0.4305555555555556, 'pegasus_entailment': 0.5774400420486927, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7461538461538462, 'r1_recall': 0.42920353982300885, 'r1_f1': 0.5449438202247191, 'pegasus_entailment': 0.6602593461672465, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 20}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32894736842105265, 'r1_recall': 0.4166666666666667, 'r1_f1': 0.3676470588235294, 'pegasus_entailment': 0.44736649592717487, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5825242718446602, 'r1_recall': 0.594059405940594, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.597746416926384, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3076923076923077, 'r1_recall': 0.7346938775510204, 'r1_f1': 0.43373493975903615, 'pegasus_entailment': 0.6235589114949107, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.16083916083916083, 'r1_recall': 0.5, 'r1_f1': 0.24338624338624337, 'pegasus_entailment': 0.686783391237259, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6, 'r1_recall': 0.5342465753424658, 'r1_f1': 0.5652173913043479, 'pegasus_entailment': 0.8961665829022726, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 17, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7083333333333334, 'r1_recall': 0.53125, 'r1_f1': 0.6071428571428571, 'pegasus_entailment': 0.5914654657244682, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4819277108433735, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.5095541401273885, 'pegasus_entailment': 0.42958517900357646, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4205607476635514, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.4368932038834951, 'pegasus_entailment': 0.46648714939753216, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 23, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5857142857142857, 'r1_recall': 0.4939759036144578, 'r1_f1': 0.5359477124183006, 'pegasus_entailment': 0.3466459661722183, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32919254658385094, 'r1_recall': 0.7464788732394366, 'r1_f1': 0.45689655172413796, 'pegasus_entailment': 0.31645672135055064, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.445859872611465, 'r1_recall': 0.6086956521739131, 'r1_f1': 0.5147058823529412, 'pegasus_entailment': 0.47586985528469083, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5620915032679739, 'r1_recall': 0.5119047619047619, 'r1_f1': 0.5358255451713396, 'pegasus_entailment': 0.5100622326135635, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2076923076923077, 'r1_recall': 0.5094339622641509, 'r1_f1': 0.29508196721311475, 'pegasus_entailment': 0.6849335134029388, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4857142857142857, 'r1_recall': 0.4722222222222222, 'r1_f1': 0.47887323943661975, 'pegasus_entailment': 0.7352795700232188, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4426229508196721, 'r1_recall': 0.4778761061946903, 'r1_f1': 0.4595744680851064, 'pegasus_entailment': 0.7532083690166473, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35, 'r1_recall': 0.5915492957746479, 'r1_f1': 0.43979057591623033, 'pegasus_entailment': 0.4487797051668167, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5359116022099447, 'r1_recall': 0.4429223744292237, 'r1_f1': 0.485, 'pegasus_entailment': 0.5004650130867958, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 31, 'pegasus_smog': 26}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1702127659574468, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.24806201550387597, 'pegasus_entailment': 0.7626012936234474, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5876288659793815, 'r1_recall': 0.6867469879518072, 'r1_f1': 0.6333333333333333, 'pegasus_entailment': 0.8178334385156631, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25274725274725274, 'r1_recall': 0.46938775510204084, 'r1_f1': 0.32857142857142857, 'pegasus_entailment': 0.3798382884512345, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5822784810126582, 'r1_recall': 0.5411764705882353, 'r1_f1': 0.5609756097560976, 'pegasus_entailment': 0.6456417888402939, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 14, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5915492957746479, 'r1_recall': 0.6511627906976745, 'r1_f1': 0.6199261992619927, 'pegasus_entailment': 0.6886632412672042, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5420560747663551, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5979381443298968, 'pegasus_entailment': 0.5807883948087692, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4621212121212121, 'r1_recall': 0.45864661654135336, 'r1_f1': 0.460377358490566, 'pegasus_entailment': 0.597563099116087, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47019867549668876, 'r1_recall': 0.6396396396396397, 'r1_f1': 0.5419847328244275, 'pegasus_entailment': 0.2665090948343277, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5164835164835165, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.5026737967914437, 'pegasus_entailment': 0.3958970159292221, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.608, 'r1_recall': 0.5428571428571428, 'r1_f1': 0.5735849056603773, 'pegasus_entailment': 0.8386620879173279, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5346534653465347, 'r1_recall': 0.375, 'r1_f1': 0.44081632653061226, 'pegasus_entailment': 0.5966607987880707, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6373626373626373, 'r1_recall': 0.6304347826086957, 'r1_f1': 0.633879781420765, 'pegasus_entailment': 0.7103262096643448, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6025641025641025, 'r1_recall': 0.4563106796116505, 'r1_f1': 0.5193370165745858, 'pegasus_entailment': 0.4203059909244378, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3972602739726027, 'r1_recall': 0.43283582089552236, 'r1_f1': 0.4142857142857143, 'pegasus_entailment': 0.4793517142534256, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38636363636363635, 'r1_recall': 0.5604395604395604, 'r1_f1': 0.45739910313901344, 'pegasus_entailment': 0.9407247543334961, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6565656565656566, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.5371900826446281, 'pegasus_entailment': 0.7116402983665466, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6333333333333333, 'r1_recall': 0.4672131147540984, 'r1_f1': 0.5377358490566038, 'pegasus_entailment': 0.49619363248348236, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6186440677966102, 'r1_recall': 0.4397590361445783, 'r1_f1': 0.5140845070422535, 'pegasus_entailment': 0.33389566242694857, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5068493150684932, 'r1_recall': 0.6727272727272727, 'r1_f1': 0.578125, 'pegasus_entailment': 0.2585871632521351, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4819277108433735, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.5095541401273885, 'pegasus_entailment': 0.5989743340760469, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6176470588235294, 'r1_recall': 0.4117647058823529, 'r1_f1': 0.4941176470588236, 'pegasus_entailment': 0.9081464290618897, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7142857142857143, 'r1_recall': 0.2777777777777778, 'r1_f1': 0.4, 'pegasus_entailment': 0.17842229083180428, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 22}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4462809917355372, 'r1_recall': 0.4462809917355372, 'r1_f1': 0.4462809917355372, 'pegasus_entailment': 0.38466294258832934, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6240601503759399, 'r1_recall': 0.5804195804195804, 'r1_f1': 0.6014492753623188, 'pegasus_entailment': 0.2679301844909787, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.5632183908045977, 'r1_f1': 0.5297297297297298, 'pegasus_entailment': 0.9017541408538818, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4025157232704403, 'r1_recall': 0.7032967032967034, 'r1_f1': 0.512, 'pegasus_entailment': 0.7340094149112701, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.424, 'r1_recall': 0.5196078431372549, 'r1_f1': 0.46696035242290745, 'pegasus_entailment': 0.2617284548468888, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5301204819277109, 'r1_recall': 0.38596491228070173, 'r1_f1': 0.4467005076142132, 'pegasus_entailment': 0.173368559529384, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4230769230769231, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4334975369458128, 'pegasus_entailment': 0.21802279073745012, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34951456310679613, 'r1_recall': 0.4044943820224719, 'r1_f1': 0.375, 'pegasus_entailment': 0.5614780634641647, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7232142857142857, 'r1_recall': 0.49693251533742333, 'r1_f1': 0.589090909090909, 'pegasus_entailment': 0.32371363043785095, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.1978021978021978, 'r1_f1': 0.29032258064516125, 'pegasus_entailment': 0.7202626268068949, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7340425531914894, 'r1_recall': 0.2509090909090909, 'r1_f1': 0.37398373983739835, 'pegasus_entailment': 0.13107179198414087, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5221238938053098, 'r1_recall': 0.5412844036697247, 'r1_f1': 0.5315315315315315, 'pegasus_entailment': 0.5043993443250656, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.14705882352941177, 'r1_recall': 0.3448275862068966, 'r1_f1': 0.20618556701030927, 'pegasus_entailment': 0.7611465871334075, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 13, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6388888888888888, 'r1_recall': 0.2541436464088398, 'r1_f1': 0.36363636363636365, 'pegasus_entailment': 0.7412648598353068, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38333333333333336, 'r1_recall': 0.5974025974025974, 'r1_f1': 0.46700507614213205, 'pegasus_entailment': 0.45729513963063556, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3532934131736527, 'r1_recall': 0.7375, 'r1_f1': 0.4777327935222673, 'pegasus_entailment': 0.5097744427621365, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6333333333333333, 'r1_recall': 0.6129032258064516, 'r1_f1': 0.6229508196721313, 'pegasus_entailment': 0.8256654217839241, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3695652173913043, 'r1_recall': 0.6296296296296297, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.36737420766924817, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34074074074074073, 'r1_recall': 0.5111111111111111, 'r1_f1': 0.40888888888888886, 'pegasus_entailment': 0.22086656318667033, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29411764705882354, 'r1_recall': 0.5072463768115942, 'r1_f1': 0.3723404255319149, 'pegasus_entailment': 0.6648022555746138, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4375, 'r1_recall': 0.65625, 'r1_f1': 0.525, 'pegasus_entailment': 0.4189812032771962, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38317757009345793, 'r1_recall': 0.640625, 'r1_f1': 0.4795321637426901, 'pegasus_entailment': 0.24816097575239837, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32075471698113206, 'r1_recall': 0.5604395604395604, 'r1_f1': 0.40800000000000003, 'pegasus_entailment': 0.6485990583896637, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.6590909090909091, 'r1_f1': 0.5686274509803921, 'pegasus_entailment': 0.5647896478573481, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4032258064516129, 'r1_recall': 0.8064516129032258, 'r1_f1': 0.5376344086021505, 'pegasus_entailment': 0.6525989755988121, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4233128834355828, 'r1_recall': 0.6448598130841121, 'r1_f1': 0.5111111111111112, 'pegasus_entailment': 0.8227545022964478, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 19, 'pegasus_ari': 35, 'pegasus_smog': 26}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35802469135802467, 'r1_recall': 0.4603174603174603, 'r1_f1': 0.4027777777777778, 'pegasus_entailment': 0.5013342751190066, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7843137254901961, 'r1_recall': 0.3018867924528302, 'r1_f1': 0.435967302452316, 'pegasus_entailment': 0.40854107961058617, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37606837606837606, 'r1_recall': 0.6875, 'r1_f1': 0.4861878453038673, 'pegasus_entailment': 0.4723321497440338, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44047619047619047, 'r1_recall': 0.40217391304347827, 'r1_f1': 0.4204545454545454, 'pegasus_entailment': 0.6690264567732811, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4492753623188406, 'r1_recall': 0.62, 'r1_f1': 0.5210084033613446, 'pegasus_entailment': 0.6055862506230673, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5051546391752577, 'r1_recall': 0.35, 'r1_f1': 0.41350210970464135, 'pegasus_entailment': 0.5605651717633009, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5841584158415841, 'r1_recall': 0.6276595744680851, 'r1_f1': 0.6051282051282051, 'pegasus_entailment': 0.37430555671453475, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38095238095238093, 'r1_recall': 0.5039370078740157, 'r1_f1': 0.43389830508474575, 'pegasus_entailment': 0.7205760938425859, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3364485981308411, 'r1_recall': 0.5070422535211268, 'r1_f1': 0.40449438202247184, 'pegasus_entailment': 0.9426589757204056, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33505154639175255, 'r1_recall': 0.6914893617021277, 'r1_f1': 0.45138888888888884, 'pegasus_entailment': 0.4268002316355705, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3617021276595745, 'r1_recall': 0.40476190476190477, 'r1_f1': 0.3820224719101123, 'pegasus_entailment': 0.3946496956050396, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4339622641509434, 'r1_recall': 0.6216216216216216, 'r1_f1': 0.5111111111111112, 'pegasus_entailment': 0.28816146217286587, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4246575342465753, 'r1_recall': 0.4626865671641791, 'r1_f1': 0.44285714285714284, 'pegasus_entailment': 0.8424924810727438, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29411764705882354, 'r1_recall': 0.546875, 'r1_f1': 0.3825136612021858, 'pegasus_entailment': 0.5009281237920126, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4206896551724138, 'r1_recall': 0.35260115606936415, 'r1_f1': 0.38364779874213834, 'pegasus_entailment': 0.6884706701551165, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5460526315789473, 'r1_recall': 0.503030303030303, 'r1_f1': 0.5236593059936909, 'pegasus_entailment': 0.4308182641863823, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.6530612244897959, 'r1_f1': 0.6095238095238094, 'pegasus_entailment': 0.7304733274504542, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4861111111111111, 'r1_recall': 0.37433155080213903, 'r1_f1': 0.42296072507552873, 'pegasus_entailment': 0.41132546961307526, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5053763440860215, 'r1_recall': 0.49473684210526314, 'r1_f1': 0.5, 'pegasus_entailment': 0.17137603129958734, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43157894736842106, 'r1_recall': 0.5694444444444444, 'r1_f1': 0.49101796407185627, 'pegasus_entailment': 0.5554590649902821, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1782178217821782, 'r1_recall': 0.32727272727272727, 'r1_f1': 0.23076923076923075, 'pegasus_entailment': 0.6031137928366661, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1885245901639344, 'r1_recall': 0.5476190476190477, 'r1_f1': 0.28048780487804875, 'pegasus_entailment': 0.4284013081341982, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.6338028169014085, 'r1_f1': 0.5113636363636364, 'pegasus_entailment': 0.8923010379076004, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27419354838709675, 'r1_recall': 0.6538461538461539, 'r1_f1': 0.38636363636363635, 'pegasus_entailment': 0.48869218677282333, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4262295081967213, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.4351464435146443, 'pegasus_entailment': 0.43069869341949624, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 31, 'pegasus_smog': 24}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6293103448275862, 'r1_recall': 0.5572519083969466, 'r1_f1': 0.5910931174089069, 'pegasus_entailment': 0.44796405732631683, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45121951219512196, 'r1_recall': 0.44047619047619047, 'r1_f1': 0.44578313253012053, 'pegasus_entailment': 0.5210512725170702, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 12}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5645161290322581, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.4605263157894737, 'pegasus_entailment': 0.5613986611366272, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5346534653465347, 'r1_recall': 0.5934065934065934, 'r1_f1': 0.5625, 'pegasus_entailment': 0.42794475704431534, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4318181818181818, 'r1_recall': 0.5181818181818182, 'r1_f1': 0.4710743801652893, 'pegasus_entailment': 0.6293681301176548, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.30434782608695654, 'r1_recall': 0.6086956521739131, 'r1_f1': 0.4057971014492754, 'pegasus_entailment': 0.6748266637325286, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45045045045045046, 'r1_recall': 0.5, 'r1_f1': 0.4739336492890995, 'pegasus_entailment': 0.7677317361036936, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.308411214953271, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.37499999999999994, 'pegasus_entailment': 0.8831396102905273, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 18, 'pegasus_ari': 34, 'pegasus_smog': 24}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.52, 'r1_recall': 0.5977011494252874, 'r1_f1': 0.5561497326203209, 'pegasus_entailment': 0.8541878312826157, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.52, 'r1_recall': 0.5098039215686274, 'r1_f1': 0.5148514851485149, 'pegasus_entailment': 0.8826821645100912, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32727272727272727, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.43373493975903615, 'pegasus_entailment': 0.6689807027578354, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23232323232323232, 'r1_recall': 0.4423076923076923, 'r1_f1': 0.304635761589404, 'pegasus_entailment': 0.3970381213972966, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5095541401273885, 'r1_recall': 0.5594405594405595, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.7796700298786163, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4492753623188406, 'r1_recall': 0.7126436781609196, 'r1_f1': 0.5511111111111111, 'pegasus_entailment': 0.39139899611473083, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3717948717948718, 'r1_recall': 0.5370370370370371, 'r1_f1': 0.43939393939393945, 'pegasus_entailment': 0.7252814471721649, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.53125, 'r1_recall': 0.4214876033057851, 'r1_f1': 0.4700460829493088, 'pegasus_entailment': 0.6994909346103668, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4305555555555556, 'r1_recall': 0.2980769230769231, 'r1_f1': 0.3522727272727273, 'pegasus_entailment': 0.25040580960921943, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45, 'r1_recall': 0.6428571428571429, 'r1_f1': 0.5294117647058824, 'pegasus_entailment': 0.7207957282662392, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3826086956521739, 'r1_recall': 0.6111111111111112, 'r1_f1': 0.47058823529411764, 'pegasus_entailment': 0.9317698627710342, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3900709219858156, 'r1_recall': 0.6179775280898876, 'r1_f1': 0.4782608695652174, 'pegasus_entailment': 0.5099079748615623, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19718309859154928, 'r1_recall': 0.3111111111111111, 'r1_f1': 0.2413793103448276, 'pegasus_entailment': 0.5412535984069109, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3314917127071823, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.42253521126760557, 'pegasus_entailment': 0.4457071080803871, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.11029411764705882, 'r1_recall': 0.42857142857142855, 'r1_f1': 0.17543859649122806, 'pegasus_entailment': 0.6393171946207682, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28440366972477066, 'r1_recall': 0.6888888888888889, 'r1_f1': 0.40259740259740256, 'pegasus_entailment': 0.5428184867778327, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2777777777777778, 'r1_recall': 0.7692307692307693, 'r1_f1': 0.40816326530612246, 'pegasus_entailment': 0.8962098956108093, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 20}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5376344086021505, 'r1_recall': 0.33783783783783783, 'r1_f1': 0.4149377593360996, 'pegasus_entailment': 0.20058237512906393, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48026315789473684, 'r1_recall': 0.6347826086956522, 'r1_f1': 0.5468164794007491, 'pegasus_entailment': 0.8848073333501816, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3780487804878049, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.47692307692307695, 'pegasus_entailment': 0.3950699456036091, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4304635761589404, 'r1_recall': 0.5963302752293578, 'r1_f1': 0.5, 'pegasus_entailment': 0.47415022055308026, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7127659574468085, 'r1_recall': 0.4855072463768116, 'r1_f1': 0.5775862068965516, 'pegasus_entailment': 0.5173121131956577, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.875, 'r1_recall': 0.21875, 'r1_f1': 0.35, 'pegasus_entailment': 0.6140953763388097, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4094488188976378, 'r1_recall': 0.46846846846846846, 'r1_f1': 0.43697478991596633, 'pegasus_entailment': 0.7503554821014404, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5925925925925926, 'r1_recall': 0.3221476510067114, 'r1_f1': 0.41739130434782606, 'pegasus_entailment': 0.5835655828317007, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.746268656716418, 'r1_recall': 0.33557046979865773, 'r1_f1': 0.46296296296296297, 'pegasus_entailment': 0.6607837080955505, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 16}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25217391304347825, 'r1_recall': 0.5918367346938775, 'r1_f1': 0.35365853658536583, 'pegasus_entailment': 0.6299770817160606, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.425, 'r1_recall': 0.7083333333333334, 'r1_f1': 0.53125, 'pegasus_entailment': 0.5361908872922262, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.34532374100719426, 'r1_recall': 0.5925925925925926, 'r1_f1': 0.43636363636363634, 'pegasus_entailment': 0.45333522707223894, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.8666666666666667, 'r1_recall': 0.52, 'r1_f1': 0.65, 'pegasus_entailment': 0.509337991476059, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 29, 'pegasus_smog': 23}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.25925925925925924, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.3465346534653465, 'pegasus_entailment': 0.5047692414373159, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.526829268292683, 'r1_recall': 0.627906976744186, 'r1_f1': 0.572944297082228, 'pegasus_entailment': 0.9166067242622375, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 16, 'pegasus_ari': 26, 'pegasus_smog': 18}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40476190476190477, 'r1_recall': 0.6891891891891891, 'r1_f1': 0.51, 'pegasus_entailment': 0.7564972192049026, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3897058823529412, 'r1_recall': 0.654320987654321, 'r1_f1': 0.4884792626728111, 'pegasus_entailment': 0.5750885549932718, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49206349206349204, 'r1_recall': 0.4397163120567376, 'r1_f1': 0.4644194756554307, 'pegasus_entailment': 0.5888237562030554, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36257309941520466, 'r1_recall': 0.4732824427480916, 'r1_f1': 0.4105960264900662, 'pegasus_entailment': 0.6308868378400803, 'pegasus_flesch_kincaid': 31, 'pegasus_coleman_liau': 21, 'pegasus_ari': 38, 'pegasus_smog': 26}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6302521008403361, 'r1_recall': 0.352112676056338, 'r1_f1': 0.45180722891566266, 'pegasus_entailment': 0.4726468125979106, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 26, 'pegasus_smog': 24}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6056338028169014, 'r1_recall': 0.4777777777777778, 'r1_f1': 0.5341614906832298, 'pegasus_entailment': 0.4736934155225754, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34065934065934067, 'r1_recall': 0.543859649122807, 'r1_f1': 0.41891891891891897, 'pegasus_entailment': 0.5928656955560049, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5867768595041323, 'r1_recall': 0.37566137566137564, 'r1_f1': 0.45806451612903226, 'pegasus_entailment': 0.5044777169823647, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6423841059602649, 'r1_recall': 0.3190789473684211, 'r1_f1': 0.4263736263736264, 'pegasus_entailment': 0.6255021020770073, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.15492957746478872, 'r1_recall': 0.3492063492063492, 'r1_f1': 0.21463414634146338, 'pegasus_entailment': 0.6453132480382919, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42857142857142855, 'r1_recall': 0.6631578947368421, 'r1_f1': 0.5206611570247933, 'pegasus_entailment': 0.403402116894722, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6836734693877551, 'r1_recall': 0.4240506329113924, 'r1_f1': 0.5234374999999999, 'pegasus_entailment': 0.462316888384521, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.325, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.3768115942028986, 'pegasus_entailment': 0.4004717245697975, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5344827586206896, 'r1_recall': 0.3425414364640884, 'r1_f1': 0.4175084175084175, 'pegasus_entailment': 0.5696811825037003, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5915492957746479, 'r1_recall': 0.29577464788732394, 'r1_f1': 0.39436619718309857, 'pegasus_entailment': 0.931306779384613, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4772727272727273, 'r1_recall': 0.4421052631578947, 'r1_f1': 0.45901639344262296, 'pegasus_entailment': 0.3210659953765571, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5630252100840336, 'r1_recall': 0.38953488372093026, 'r1_f1': 0.4604810996563574, 'pegasus_entailment': 0.7342121362686157, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3898305084745763, 'r1_recall': 0.647887323943662, 'r1_f1': 0.48677248677248675, 'pegasus_entailment': 0.4943094372749329, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6486486486486487, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.5393258426966292, 'pegasus_entailment': 0.5958486437797547, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39869281045751637, 'r1_recall': 0.6559139784946236, 'r1_f1': 0.4959349593495935, 'pegasus_entailment': 0.7683200240135193, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.29333333333333333, 'r1_recall': 0.5866666666666667, 'r1_f1': 0.39111111111111113, 'pegasus_entailment': 0.6867952644824982, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.44954128440366975, 'r1_recall': 0.6901408450704225, 'r1_f1': 0.5444444444444445, 'pegasus_entailment': 0.3819605705793947, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.49504950495049505, 'r1_f1': 0.5235602094240838, 'pegasus_entailment': 0.2650079026352614, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 13, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.620253164556962, 'r1_recall': 0.47342995169082125, 'r1_f1': 0.5369863013698629, 'pegasus_entailment': 0.6833783745765686, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.390625, 'r1_recall': 0.49019607843137253, 'r1_f1': 0.4347826086956521, 'pegasus_entailment': 0.6366895238558451, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3, 'r1_recall': 0.35, 'r1_f1': 0.3230769230769231, 'pegasus_entailment': 0.39698904752731323, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6576576576576577, 'r1_recall': 0.4101123595505618, 'r1_f1': 0.5051903114186851, 'pegasus_entailment': 0.7920957008997599, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5145631067961165, 'r1_recall': 0.726027397260274, 'r1_f1': 0.6022727272727273, 'pegasus_entailment': 0.44147954881191254, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40298507462686567, 'r1_recall': 0.7105263157894737, 'r1_f1': 0.5142857142857143, 'pegasus_entailment': 0.3388755025807768, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6071428571428571, 'r1_recall': 0.5604395604395604, 'r1_f1': 0.5828571428571429, 'pegasus_entailment': 0.460161825021108, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5588235294117647, 'r1_recall': 0.6333333333333333, 'r1_f1': 0.59375, 'pegasus_entailment': 0.7583140105009079, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7704918032786885, 'r1_recall': 0.13333333333333333, 'r1_f1': 0.22732769044740025, 'pegasus_entailment': 0.824417769908905, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5029940119760479, 'r1_recall': 0.5915492957746479, 'r1_f1': 0.5436893203883495, 'pegasus_entailment': 0.6133005678653717, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8207547169811321, 'r1_recall': 0.47540983606557374, 'r1_f1': 0.6020761245674741, 'pegasus_entailment': 0.4052615687251091, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.375, 'r1_recall': 0.5161290322580645, 'r1_f1': 0.4343891402714932, 'pegasus_entailment': 0.3793397694826126, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.625, 'r1_recall': 0.5603448275862069, 'r1_f1': 0.5909090909090908, 'pegasus_entailment': 0.5804723761975765, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41284403669724773, 'r1_recall': 0.6923076923076923, 'r1_f1': 0.5172413793103449, 'pegasus_entailment': 0.2385821733623743, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5636363636363636, 'r1_recall': 0.39490445859872614, 'r1_f1': 0.46441947565543074, 'pegasus_entailment': 0.3807106213644147, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19047619047619047, 'r1_recall': 0.5, 'r1_f1': 0.27586206896551724, 'pegasus_entailment': 0.6568746045231819, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5319148936170213, 'r1_recall': 0.5154639175257731, 'r1_f1': 0.5235602094240838, 'pegasus_entailment': 0.9578053653240204, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 19, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.11965811965811966, 'r1_recall': 0.4, 'r1_f1': 0.18421052631578946, 'pegasus_entailment': 0.6441221088171005, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5773195876288659, 'r1_recall': 0.5773195876288659, 'r1_f1': 0.5773195876288659, 'pegasus_entailment': 0.693779855966568, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5384615384615384, 'r1_recall': 0.5575221238938053, 'r1_f1': 0.5478260869565217, 'pegasus_entailment': 0.5145249565442404, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6504854368932039, 'r1_recall': 0.4962962962962963, 'r1_f1': 0.5630252100840336, 'pegasus_entailment': 0.36047184467315674, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23711340206185566, 'r1_recall': 0.42592592592592593, 'r1_f1': 0.304635761589404, 'pegasus_entailment': 0.43698221296072004, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4387755102040816, 'r1_recall': 0.43, 'r1_f1': 0.4343434343434343, 'pegasus_entailment': 0.5563248097896576, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
** Analysing column: malformed_chain



malformed_chain
Length after nones removed
616
MIN
0
MEAN
0
MAX
1
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.11029411764705882
MEAN
0.48141931500862234
MAX
0.8904109589041096
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.13333333333333333
MEAN
0.51285806291861
MAX
0.8405797101449275
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.17543859649122806
MEAN
0.4726727885910914
MAX
0.6880000000000001
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.002422826752687494
MEAN
0.5587482053890708
MAX
0.9918626844882965
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
11
MEAN
18
MAX
36
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
12
MEAN
17
MAX
23
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
10
MEAN
21
MAX
43
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
12
MEAN
19
MAX
29
{}
Entered file!
Imports done!
*** RUN *** 
eval_5d2
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 14:54:52.858452: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 14:54:53.754684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/5d2_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
**** Analysing with oreo version...
** Loading results csv
*** Analysing case 0
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37333333333333335, 'r1_recall': 0.509090909090909, 'r1_f1': 0.4307692307692308, 'pegasus_entailment': 0.6115750014781952, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 1
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5494505494505495, 'r1_recall': 0.28901734104046245, 'r1_f1': 0.3787878787878789, 'pegasus_entailment': 0.7598638733228048, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 2
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3561643835616438, 'r1_recall': 0.4482758620689655, 'r1_f1': 0.3969465648854962, 'pegasus_entailment': 0.6127078235149384, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 3
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5403225806451613, 'r1_recall': 0.5193798449612403, 'r1_f1': 0.5296442687747036, 'pegasus_entailment': 0.5842858355026692, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 16}
*** Analysing case 4
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6956521739130435, 'r1_recall': 0.367816091954023, 'r1_f1': 0.48120300751879697, 'pegasus_entailment': 0.46148580461740496, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 5
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4573643410852713, 'r1_recall': 0.45384615384615384, 'r1_f1': 0.4555984555984556, 'pegasus_entailment': 0.3236233085393906, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 6
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.17346938775510204, 'r1_recall': 0.53125, 'r1_f1': 0.26153846153846155, 'pegasus_entailment': 0.45756004254023236, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 7
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27472527472527475, 'r1_recall': 0.8064516129032258, 'r1_f1': 0.40983606557377045, 'pegasus_entailment': 0.5884719689687093, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 8
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7209302325581395, 'r1_recall': 0.4161073825503356, 'r1_f1': 0.5276595744680851, 'pegasus_entailment': 0.6538144946098328, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 9
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6528925619834711, 'r1_recall': 0.572463768115942, 'r1_f1': 0.61003861003861, 'pegasus_entailment': 0.5872775216897329, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 10
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7222222222222222, 'r1_recall': 0.3466666666666667, 'r1_f1': 0.4684684684684684, 'pegasus_entailment': 0.41406606137752533, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 11
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5338983050847458, 'r1_recall': 0.5294117647058824, 'r1_f1': 0.5316455696202531, 'pegasus_entailment': 0.6612891554832458, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 12
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6710526315789473, 'r1_recall': 0.4766355140186916, 'r1_f1': 0.5573770491803279, 'pegasus_entailment': 0.8185312151908875, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 13
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5942028985507246, 'r1_recall': 0.4659090909090909, 'r1_f1': 0.5222929936305732, 'pegasus_entailment': 0.5763680767267942, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 14
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7590361445783133, 'r1_recall': 0.328125, 'r1_f1': 0.45818181818181813, 'pegasus_entailment': 0.7202640175819397, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 15
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1875, 'r1_recall': 0.2033898305084746, 'r1_f1': 0.1951219512195122, 'pegasus_entailment': 0.6483420232931772, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 16
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36879432624113473, 'r1_recall': 0.5252525252525253, 'r1_f1': 0.4333333333333333, 'pegasus_entailment': 0.6831628620624542, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 17
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7878787878787878, 'r1_recall': 0.26174496644295303, 'r1_f1': 0.39294710327455923, 'pegasus_entailment': 0.23410137929022312, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 18
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5882352941176471, 'r1_recall': 0.37267080745341613, 'r1_f1': 0.45627376425855515, 'pegasus_entailment': 0.3040904601414998, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 19
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35714285714285715, 'r1_recall': 0.5747126436781609, 'r1_f1': 0.44052863436123346, 'pegasus_entailment': 0.5093731778208166, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 20
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5483870967741935, 'r1_recall': 0.37362637362637363, 'r1_f1': 0.4444444444444445, 'pegasus_entailment': 0.3937962104876836, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 21
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5084745762711864, 'r1_recall': 0.4, 'r1_f1': 0.44776119402985076, 'pegasus_entailment': 0.4773606862872839, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 22
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42424242424242425, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.5689589500427246, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 23
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6395348837209303, 'r1_recall': 0.40441176470588236, 'r1_f1': 0.49549549549549543, 'pegasus_entailment': 0.5195132493972778, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 24
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44, 'r1_recall': 0.66, 'r1_f1': 0.5279999999999999, 'pegasus_entailment': 0.5545938275754452, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 25
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7083333333333334, 'r1_recall': 0.5396825396825397, 'r1_f1': 0.6126126126126126, 'pegasus_entailment': 0.46406122744083406, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 26
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6037735849056604, 'r1_recall': 0.46715328467153283, 'r1_f1': 0.5267489711934156, 'pegasus_entailment': 0.510853773355484, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 27
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7701149425287356, 'r1_recall': 0.25, 'r1_f1': 0.3774647887323944, 'pegasus_entailment': 0.6124545216560364, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 28
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47619047619047616, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.4316546762589928, 'pegasus_entailment': 0.2718936949968338, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 29
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4065934065934066, 'r1_recall': 0.3274336283185841, 'r1_f1': 0.36274509803921573, 'pegasus_entailment': 0.5351805587609609, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 30
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3630573248407643, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.4672131147540984, 'pegasus_entailment': 0.594984894990921, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 31
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6065573770491803, 'r1_recall': 0.5522388059701493, 'r1_f1': 0.578125, 'pegasus_entailment': 0.7917952736218771, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 32
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24358974358974358, 'r1_recall': 0.36893203883495146, 'r1_f1': 0.29343629343629346, 'pegasus_entailment': 0.7097152695059776, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 33
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4507042253521127, 'r1_recall': 0.32989690721649484, 'r1_f1': 0.38095238095238093, 'pegasus_entailment': 0.6168331149965525, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 34
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3, 'r1_recall': 0.5, 'r1_f1': 0.37499999999999994, 'pegasus_entailment': 0.4612551884104808, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 35
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6049382716049383, 'r1_recall': 0.4224137931034483, 'r1_f1': 0.4974619289340101, 'pegasus_entailment': 0.267160464823246, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 36
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.39072847682119205, 'r1_recall': 0.855072463768116, 'r1_f1': 0.5363636363636364, 'pegasus_entailment': 0.6791648983955383, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 37
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36082474226804123, 'r1_recall': 0.5147058823529411, 'r1_f1': 0.4242424242424242, 'pegasus_entailment': 0.639914090745151, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 38
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23076923076923078, 'r1_recall': 0.7333333333333333, 'r1_f1': 0.3510638297872341, 'pegasus_entailment': 0.6637586280703545, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 39
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5405405405405406, 'r1_recall': 0.3614457831325301, 'r1_f1': 0.4332129963898917, 'pegasus_entailment': 0.9094644039869308, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 40
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5923566878980892, 'r1_recall': 0.58125, 'r1_f1': 0.5867507886435332, 'pegasus_entailment': 0.5770272649824619, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 41
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45569620253164556, 'r1_recall': 0.4675324675324675, 'r1_f1': 0.4615384615384615, 'pegasus_entailment': 0.43265604053158313, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 42
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40217391304347827, 'r1_recall': 0.5068493150684932, 'r1_f1': 0.44848484848484854, 'pegasus_entailment': 0.40266725483040017, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 43
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.75, 'r1_recall': 0.5121951219512195, 'r1_f1': 0.6086956521739131, 'pegasus_entailment': 0.5605195723474026, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 44
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23529411764705882, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.31168831168831174, 'pegasus_entailment': 0.6530719958245754, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 22}
*** Analysing case 45
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44660194174757284, 'r1_recall': 0.30666666666666664, 'r1_f1': 0.36363636363636365, 'pegasus_entailment': 0.790607213973999, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 34, 'pegasus_smog': 22}
*** Analysing case 46
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5096774193548387, 'r1_recall': 0.6694915254237288, 'r1_f1': 0.5787545787545787, 'pegasus_entailment': 0.32184758215832215, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 47
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5350877192982456, 'r1_recall': 0.5495495495495496, 'r1_f1': 0.5422222222222223, 'pegasus_entailment': 0.6928569316864014, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 48
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4351145038167939, 'r1_recall': 0.6785714285714286, 'r1_f1': 0.530232558139535, 'pegasus_entailment': 0.40493958480656145, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 49
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3105590062111801, 'r1_recall': 0.4807692307692308, 'r1_f1': 0.3773584905660377, 'pegasus_entailment': 0.3591605991125107, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 50
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40869565217391307, 'r1_recall': 0.6351351351351351, 'r1_f1': 0.4973544973544973, 'pegasus_entailment': 0.5905499830842018, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 51
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2052980132450331, 'r1_recall': 0.6078431372549019, 'r1_f1': 0.30693069306930687, 'pegasus_entailment': 0.5455556383563412, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 52
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2878787878787879, 'r1_recall': 0.5135135135135135, 'r1_f1': 0.36893203883495146, 'pegasus_entailment': 0.5743681430816651, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 53
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6351351351351351, 'r1_recall': 0.2655367231638418, 'r1_f1': 0.37450199203187245, 'pegasus_entailment': 0.19932902604341507, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 54
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6206896551724138, 'r1_recall': 0.5056179775280899, 'r1_f1': 0.5572755417956656, 'pegasus_entailment': 0.3728234335780144, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 55
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.28169014084507044, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.37383177570093457, 'pegasus_entailment': 0.5175390928983689, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 56
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5923566878980892, 'r1_recall': 0.3705179282868526, 'r1_f1': 0.4558823529411765, 'pegasus_entailment': 0.6096627749502659, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 57
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46835443037974683, 'r1_recall': 0.578125, 'r1_f1': 0.5174825174825174, 'pegasus_entailment': 0.47513427833716076, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 58
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7053571428571429, 'r1_recall': 0.6528925619834711, 'r1_f1': 0.6781115879828326, 'pegasus_entailment': 0.42969915581246215, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 59
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3626373626373626, 'r1_recall': 0.6285714285714286, 'r1_f1': 0.4599303135888501, 'pegasus_entailment': 0.5934453904628754, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 60
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3923076923076923, 'r1_recall': 0.5795454545454546, 'r1_f1': 0.46788990825688076, 'pegasus_entailment': 0.8431368768215179, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 61
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.336283185840708, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.41081081081081083, 'pegasus_entailment': 0.30770368268713355, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 62
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5242718446601942, 'r1_recall': 0.32142857142857145, 'r1_f1': 0.39852398523985244, 'pegasus_entailment': 0.730649933218956, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 63
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32666666666666666, 'r1_recall': 0.5051546391752577, 'r1_f1': 0.3967611336032389, 'pegasus_entailment': 0.8106765126188596, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 64
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4246575342465753, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.512396694214876, 'pegasus_entailment': 0.43964346249898273, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 65
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6607142857142857, 'r1_recall': 0.5826771653543307, 'r1_f1': 0.6192468619246861, 'pegasus_entailment': 0.6236967816948891, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 66
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47107438016528924, 'r1_recall': 0.5377358490566038, 'r1_f1': 0.5022026431718062, 'pegasus_entailment': 0.7626731693744659, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 67
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4411764705882353, 'r1_recall': 0.46875, 'r1_f1': 0.45454545454545453, 'pegasus_entailment': 0.4856181234121323, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 68
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.48695652173913045, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.3347058688911299, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 69
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6481481481481481, 'r1_recall': 0.3431372549019608, 'r1_f1': 0.4487179487179487, 'pegasus_entailment': 0.6928176482518514, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 70
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4625, 'r1_recall': 0.4457831325301205, 'r1_f1': 0.4539877300613497, 'pegasus_entailment': 0.6386201530694962, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 71
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4017857142857143, 'r1_recall': 0.6617647058823529, 'r1_f1': 0.5, 'pegasus_entailment': 0.31922749678293866, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 72
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3142857142857143, 'r1_recall': 0.5, 'r1_f1': 0.38596491228070173, 'pegasus_entailment': 0.9011369496583939, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 73
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6857142857142857, 'r1_recall': 0.5052631578947369, 'r1_f1': 0.5818181818181819, 'pegasus_entailment': 0.6504602611064911, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 74
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3130434782608696, 'r1_recall': 0.5, 'r1_f1': 0.3850267379679145, 'pegasus_entailment': 0.3926175255328417, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 75
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44339622641509435, 'r1_recall': 0.5529411764705883, 'r1_f1': 0.49214659685863876, 'pegasus_entailment': 0.3343339338898659, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 76
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2746478873239437, 'r1_recall': 0.609375, 'r1_f1': 0.3786407766990291, 'pegasus_entailment': 0.9376637101173401, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 77
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4032258064516129, 'r1_recall': 0.4807692307692308, 'r1_f1': 0.43859649122807015, 'pegasus_entailment': 0.17239447496831417, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 78
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4084507042253521, 'r1_recall': 0.6744186046511628, 'r1_f1': 0.5087719298245613, 'pegasus_entailment': 0.6240362301468849, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 79
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33695652173913043, 'r1_recall': 0.4626865671641791, 'r1_f1': 0.389937106918239, 'pegasus_entailment': 0.8138797879219055, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 80
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5056179775280899, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.5389221556886228, 'pegasus_entailment': 0.3819707930088043, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 81
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.594059405940594, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.2352050936431624, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 82
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33980582524271846, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.4166666666666667, 'pegasus_entailment': 0.5525264746199051, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 83
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4260869565217391, 'r1_recall': 0.5632183908045977, 'r1_f1': 0.48514851485148514, 'pegasus_entailment': 0.44734661118127406, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 84
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.17391304347826086, 'r1_f1': 0.25806451612903225, 'pegasus_entailment': 0.42332305014133453, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 85
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.21022727272727273, 'r1_recall': 0.42528735632183906, 'r1_f1': 0.28136882129277563, 'pegasus_entailment': 0.6014472889713943, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 86
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2558139534883721, 'r1_recall': 0.28205128205128205, 'r1_f1': 0.2682926829268293, 'pegasus_entailment': 0.5616256212815642, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 14}
*** Analysing case 87
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2988505747126437, 'r1_recall': 0.5777777777777777, 'r1_f1': 0.393939393939394, 'pegasus_entailment': 0.9378903309504191, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 88
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7115384615384616, 'r1_recall': 0.3557692307692308, 'r1_f1': 0.4743589743589744, 'pegasus_entailment': 0.4119340628385544, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 89
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31666666666666665, 'r1_recall': 0.5428571428571428, 'r1_f1': 0.4, 'pegasus_entailment': 0.4996903100516647, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 90
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5193370165745856, 'r1_recall': 0.4895833333333333, 'r1_f1': 0.5040214477211796, 'pegasus_entailment': 0.6807783246040344, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 91
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49264705882352944, 'r1_recall': 0.5, 'r1_f1': 0.4962962962962963, 'pegasus_entailment': 0.44281920914848644, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 92
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4365079365079365, 'r1_recall': 0.7534246575342466, 'r1_f1': 0.5527638190954773, 'pegasus_entailment': 0.6258925667498261, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 93
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45774647887323944, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.5019305019305019, 'pegasus_entailment': 0.6389762843027711, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 15, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 94
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32727272727272727, 'r1_recall': 0.18556701030927836, 'r1_f1': 0.2368421052631579, 'pegasus_entailment': 0.9904266893863678, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 95
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.632183908045977, 'r1_recall': 0.3107344632768362, 'r1_f1': 0.4166666666666667, 'pegasus_entailment': 0.5850710868835449, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 96
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45794392523364486, 'r1_recall': 0.5051546391752577, 'r1_f1': 0.4803921568627451, 'pegasus_entailment': 0.5705479085445404, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 97
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4392523364485981, 'r1_recall': 0.373015873015873, 'r1_f1': 0.4034334763948498, 'pegasus_entailment': 0.5360481753945351, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 98
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.31932773109243695, 'r1_recall': 0.5846153846153846, 'r1_f1': 0.41304347826086957, 'pegasus_entailment': 0.6351787775754929, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 99
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5212765957446809, 'r1_recall': 0.4375, 'r1_f1': 0.47572815533980584, 'pegasus_entailment': 0.7391711473464966, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 100
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38271604938271603, 'r1_recall': 0.5081967213114754, 'r1_f1': 0.43661971830985913, 'pegasus_entailment': 0.659699410200119, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 13}
*** Analysing case 101
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4567901234567901, 'r1_recall': 0.39361702127659576, 'r1_f1': 0.4228571428571428, 'pegasus_entailment': 0.6629329267889261, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 102
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4166666666666667, 'r1_recall': 0.6521739130434783, 'r1_f1': 0.5084745762711865, 'pegasus_entailment': 0.7541697442531585, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 103
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.504, 'r1_recall': 0.5625, 'r1_f1': 0.5316455696202531, 'pegasus_entailment': 0.5619356594979763, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 104
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33125, 'r1_recall': 0.6625, 'r1_f1': 0.4416666666666667, 'pegasus_entailment': 0.7544201612472534, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 105
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5504587155963303, 'r1_recall': 0.46511627906976744, 'r1_f1': 0.5042016806722689, 'pegasus_entailment': 0.4064277149736881, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 106
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5514018691588785, 'r1_recall': 0.5728155339805825, 'r1_f1': 0.5619047619047619, 'pegasus_entailment': 0.6405346803367138, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 107
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5161290322580645, 'r1_recall': 0.4, 'r1_f1': 0.4507042253521127, 'pegasus_entailment': 0.5911065662900606, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 108
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.31496062992125984, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.39603960396039606, 'pegasus_entailment': 0.4786293514383336, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 109
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.25806451612903225, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.34782608695652173, 'pegasus_entailment': 0.4076640826339523, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 110
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43478260869565216, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.8914365321397781, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 111
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48344370860927155, 'r1_recall': 0.5488721804511278, 'r1_f1': 0.5140845070422535, 'pegasus_entailment': 0.69965960085392, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 112
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6875, 'r1_recall': 0.5569620253164557, 'r1_f1': 0.6153846153846154, 'pegasus_entailment': 0.46899417811073363, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 113
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.452991452991453, 'r1_recall': 0.5955056179775281, 'r1_f1': 0.5145631067961165, 'pegasus_entailment': 0.5912953093647957, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 114
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3544973544973545, 'r1_recall': 0.5153846153846153, 'r1_f1': 0.4200626959247649, 'pegasus_entailment': 0.590422896357874, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 115
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6829268292682927, 'r1_recall': 0.47191011235955055, 'r1_f1': 0.558139534883721, 'pegasus_entailment': 0.574665492773056, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 116
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7016129032258065, 'r1_recall': 0.4943181818181818, 'r1_f1': 0.58, 'pegasus_entailment': 0.5156022720038891, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 117
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4794520547945205, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.5, 'pegasus_entailment': 0.4145296171385174, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 118
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4563106796116505, 'r1_recall': 0.5, 'r1_f1': 0.47715736040609136, 'pegasus_entailment': 0.39416818154859357, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 119
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6885245901639344, 'r1_recall': 0.33070866141732286, 'r1_f1': 0.4468085106382979, 'pegasus_entailment': 0.7529306213061014, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 120
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5555555555555556, 'r1_recall': 0.625, 'r1_f1': 0.5882352941176471, 'pegasus_entailment': 0.72182996571064, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 121
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5132743362831859, 'r1_recall': 0.5043478260869565, 'r1_f1': 0.5087719298245613, 'pegasus_entailment': 0.584490954875946, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 18}
*** Analysing case 122
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3560606060606061, 'r1_recall': 0.618421052631579, 'r1_f1': 0.4519230769230769, 'pegasus_entailment': 0.5855731278657913, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 123
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22123893805309736, 'r1_recall': 0.5813953488372093, 'r1_f1': 0.32051282051282054, 'pegasus_entailment': 0.5946978032588959, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 124
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5526315789473685, 'r1_recall': 0.75, 'r1_f1': 0.6363636363636364, 'pegasus_entailment': 0.3427880802191794, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 125
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5683453237410072, 'r1_recall': 0.6030534351145038, 'r1_f1': 0.5851851851851851, 'pegasus_entailment': 0.5427781209349632, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 126
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.275, 'r1_f1': 0.3548387096774194, 'pegasus_entailment': 0.3287636488676071, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 13, 'pegasus_ari': 11, 'pegasus_smog': 15}
*** Analysing case 127
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.631578947368421, 'r1_recall': 0.5128205128205128, 'r1_f1': 0.5660377358490566, 'pegasus_entailment': 0.6385106053203344, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 128
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5619834710743802, 'r1_recall': 0.5862068965517241, 'r1_f1': 0.5738396624472574, 'pegasus_entailment': 0.7065477768580118, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 129
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36538461538461536, 'r1_recall': 0.6440677966101694, 'r1_f1': 0.4662576687116564, 'pegasus_entailment': 0.37436588257551195, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 130
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.5436893203883495, 'pegasus_entailment': 0.07398531849806507, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 131
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7448979591836735, 'r1_recall': 0.6033057851239669, 'r1_f1': 0.6666666666666667, 'pegasus_entailment': 0.6957511813379824, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 132
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6138613861386139, 'r1_recall': 0.4, 'r1_f1': 0.484375, 'pegasus_entailment': 0.8626004457473755, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 133
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5572519083969466, 'r1_recall': 0.44785276073619634, 'r1_f1': 0.49659863945578236, 'pegasus_entailment': 0.6372936125844717, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 134
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5813953488372093, 'r1_recall': 0.49504950495049505, 'r1_f1': 0.53475935828877, 'pegasus_entailment': 0.4154680445790291, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 135
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4566929133858268, 'r1_recall': 0.4793388429752066, 'r1_f1': 0.467741935483871, 'pegasus_entailment': 0.7909341752529144, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 136
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2863636363636364, 'r1_recall': 0.6774193548387096, 'r1_f1': 0.40255591054313095, 'pegasus_entailment': 0.6394667824109396, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 137
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6694214876033058, 'r1_recall': 0.6090225563909775, 'r1_f1': 0.6377952755905512, 'pegasus_entailment': 0.7989461794495583, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 138
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7040816326530612, 'r1_recall': 0.372972972972973, 'r1_f1': 0.48763250883392223, 'pegasus_entailment': 0.6150806546211243, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 139
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4367816091954023, 'r1_recall': 0.6551724137931034, 'r1_f1': 0.5241379310344828, 'pegasus_entailment': 0.457336263731122, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 140
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4666666666666667, 'r1_recall': 0.4772727272727273, 'r1_f1': 0.4719101123595506, 'pegasus_entailment': 0.4841199778020382, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 141
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4270833333333333, 'r1_recall': 0.44086021505376344, 'r1_f1': 0.43386243386243384, 'pegasus_entailment': 0.6988864243030548, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 142
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5360824742268041, 'r1_recall': 0.46017699115044247, 'r1_f1': 0.49523809523809526, 'pegasus_entailment': 0.6969681531190872, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 143
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5922330097087378, 'r1_recall': 0.7625, 'r1_f1': 0.6666666666666666, 'pegasus_entailment': 0.5300065279006958, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 144
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5789473684210527, 'r1_recall': 0.43564356435643564, 'r1_f1': 0.4971751412429379, 'pegasus_entailment': 0.6400363504886627, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 145
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5988372093023255, 'r1_recall': 0.49282296650717705, 'r1_f1': 0.5406824146981627, 'pegasus_entailment': 0.7619868874549866, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 146
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5474452554744526, 'r1_recall': 0.4143646408839779, 'r1_f1': 0.4716981132075471, 'pegasus_entailment': 0.5701313143596053, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 17}
*** Analysing case 147
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36666666666666664, 'r1_recall': 0.559322033898305, 'r1_f1': 0.44295302013422816, 'pegasus_entailment': 0.6752041904255748, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 148
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7435897435897436, 'r1_recall': 0.35802469135802467, 'r1_f1': 0.4833333333333333, 'pegasus_entailment': 0.1738992885996898, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 149
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3951612903225806, 'r1_recall': 0.5975609756097561, 'r1_f1': 0.47572815533980584, 'pegasus_entailment': 0.4716818481683731, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 150
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46788990825688076, 'r1_recall': 0.53125, 'r1_f1': 0.4975609756097561, 'pegasus_entailment': 0.6125685513019562, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 151
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4634146341463415, 'r1_recall': 0.6195652173913043, 'r1_f1': 0.5302325581395348, 'pegasus_entailment': 0.503111606836319, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 152
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6904761904761905, 'r1_recall': 0.29896907216494845, 'r1_f1': 0.41726618705035967, 'pegasus_entailment': 0.6224924027919769, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 153
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5228758169934641, 'r1_recall': 0.4819277108433735, 'r1_f1': 0.5015673981191222, 'pegasus_entailment': 0.5370026901364326, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 22, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 154
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.36771300448430494, 'pegasus_entailment': 0.689915681630373, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 155
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.66, 'r1_recall': 0.3815028901734104, 'r1_f1': 0.48351648351648346, 'pegasus_entailment': 0.35417877286672594, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 156
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.37037037037037035, 'r1_f1': 0.425531914893617, 'pegasus_entailment': 0.8843394219875336, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 23}
*** Analysing case 157
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.48951048951048953, 'r1_recall': 0.4697986577181208, 'r1_f1': 0.4794520547945205, 'pegasus_entailment': 0.5588666588068009, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 158
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3873239436619718, 'r1_recall': 0.5913978494623656, 'r1_f1': 0.4680851063829787, 'pegasus_entailment': 0.577768656037127, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 159
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6067415730337079, 'r1_recall': 0.33540372670807456, 'r1_f1': 0.432, 'pegasus_entailment': 0.4702848394711812, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 160
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1724137931034483, 'r1_recall': 0.39473684210526316, 'r1_f1': 0.24000000000000002, 'pegasus_entailment': 0.33109155483543873, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 161
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5564516129032258, 'r1_recall': 0.6388888888888888, 'r1_f1': 0.5948275862068966, 'pegasus_entailment': 0.8446146696805954, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 162
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46875, 'r1_recall': 0.5825242718446602, 'r1_f1': 0.5194805194805194, 'pegasus_entailment': 0.6521521757046381, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 163
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.515625, 'r1_recall': 0.4049079754601227, 'r1_f1': 0.4536082474226804, 'pegasus_entailment': 0.7303230881690979, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 13, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 164
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.415929203539823, 'r1_recall': 0.43119266055045874, 'r1_f1': 0.4234234234234234, 'pegasus_entailment': 0.5351912714540958, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 165
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.475177304964539, 'r1_recall': 0.3806818181818182, 'r1_f1': 0.4227129337539432, 'pegasus_entailment': 0.3378958112249772, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 166
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5256410256410257, 'r1_recall': 0.2733333333333333, 'r1_f1': 0.3596491228070175, 'pegasus_entailment': 0.38880448959146935, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 167
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.44508670520231214, 'r1_recall': 0.55, 'r1_f1': 0.49201277955271566, 'pegasus_entailment': 0.6828626564570835, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 168
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4594594594594595, 'r1_recall': 0.4563758389261745, 'r1_f1': 0.45791245791245794, 'pegasus_entailment': 0.57964528799057, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 169
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3716216216216216, 'r1_recall': 0.6043956043956044, 'r1_f1': 0.4602510460251046, 'pegasus_entailment': 0.7237293362617493, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 170
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38461538461538464, 'r1_recall': 0.6493506493506493, 'r1_f1': 0.48309178743961356, 'pegasus_entailment': 0.6809957772493362, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 171
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.41904761904761906, 'r1_recall': 0.6027397260273972, 'r1_f1': 0.49438202247191004, 'pegasus_entailment': 0.31243613362312317, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 21, 'pegasus_ari': 36, 'pegasus_smog': 26}
*** Analysing case 172
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6261682242990654, 'r1_recall': 0.18206521739130435, 'r1_f1': 0.28210526315789475, 'pegasus_entailment': 0.7047715112566948, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 173
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43703703703703706, 'r1_recall': 0.5363636363636364, 'r1_f1': 0.4816326530612245, 'pegasus_entailment': 0.6595925252884627, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 174
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4369747899159664, 'r1_recall': 0.41935483870967744, 'r1_f1': 0.4279835390946502, 'pegasus_entailment': 0.485667304135859, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 175
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4576271186440678, 'r1_recall': 0.675, 'r1_f1': 0.5454545454545455, 'pegasus_entailment': 0.5994711170593897, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 176
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7450980392156863, 'r1_recall': 0.4851063829787234, 'r1_f1': 0.5876288659793814, 'pegasus_entailment': 0.6878353238105774, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 177
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4695121951219512, 'r1_recall': 0.506578947368421, 'r1_f1': 0.4873417721518987, 'pegasus_entailment': 0.25355737863315475, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 178
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44166666666666665, 'r1_recall': 0.6162790697674418, 'r1_f1': 0.5145631067961165, 'pegasus_entailment': 0.7961849719285965, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 179
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3898305084745763, 'r1_recall': 0.6133333333333333, 'r1_f1': 0.47668393782383417, 'pegasus_entailment': 0.4612613581120968, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 180
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.39166666666666666, 'r1_recall': 0.5222222222222223, 'r1_f1': 0.4476190476190476, 'pegasus_entailment': 0.7934860825538635, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 181
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5877192982456141, 'r1_recall': 0.40853658536585363, 'r1_f1': 0.48201438848920863, 'pegasus_entailment': 0.6623623775584357, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 16}
*** Analysing case 182
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8068181818181818, 'r1_recall': 0.24738675958188153, 'r1_f1': 0.3786666666666666, 'pegasus_entailment': 0.3600131571292877, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 183
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.746268656716418, 'r1_recall': 0.27932960893854747, 'r1_f1': 0.4065040650406504, 'pegasus_entailment': 0.5106915831565857, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 184
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46408839779005523, 'r1_recall': 0.7368421052631579, 'r1_f1': 0.5694915254237288, 'pegasus_entailment': 0.5532552599906921, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 185
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3888888888888889, 'r1_recall': 0.1076923076923077, 'r1_f1': 0.16867469879518074, 'pegasus_entailment': 0.8878397941589355, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 12, 'pegasus_smog': 14}
*** Analysing case 186
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.44881889763779526, 'r1_recall': 0.5480769230769231, 'r1_f1': 0.4935064935064935, 'pegasus_entailment': 0.5506481498479843, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 187
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38095238095238093, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.4848484848484849, 'pegasus_entailment': 0.9456979393959045, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 188
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7195121951219512, 'r1_recall': 0.36419753086419754, 'r1_f1': 0.4836065573770492, 'pegasus_entailment': 0.5298856943845749, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 189
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47572815533980584, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.5444444444444444, 'pegasus_entailment': 0.1477975668385625, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 190
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5955882352941176, 'r1_recall': 0.5625, 'r1_f1': 0.5785714285714285, 'pegasus_entailment': 0.6124342978000641, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 31, 'pegasus_smog': 23}
*** Analysing case 191
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6615384615384615, 'r1_recall': 0.5733333333333334, 'r1_f1': 0.6142857142857143, 'pegasus_entailment': 0.6401668985684713, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 192
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41530054644808745, 'r1_recall': 0.628099173553719, 'r1_f1': 0.5, 'pegasus_entailment': 0.6704418361186981, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 21}
*** Analysing case 193
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7, 'r1_recall': 0.6936936936936937, 'r1_f1': 0.6968325791855203, 'pegasus_entailment': 0.46756625501438975, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 194
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6103896103896104, 'r1_recall': 0.2883435582822086, 'r1_f1': 0.39166666666666666, 'pegasus_entailment': 0.2952444441616535, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 195
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5625, 'r1_recall': 0.35795454545454547, 'r1_f1': 0.43750000000000006, 'pegasus_entailment': 0.5786575153470039, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 196
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5425531914893617, 'r1_recall': 0.6375, 'r1_f1': 0.5862068965517241, 'pegasus_entailment': 0.6644155830144882, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 197
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.248, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.33513513513513515, 'pegasus_entailment': 0.566954318434, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 198
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33695652173913043, 'r1_recall': 0.5166666666666667, 'r1_f1': 0.40789473684210525, 'pegasus_entailment': 0.5751105348269144, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 199
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43137254901960786, 'r1_recall': 0.4489795918367347, 'r1_f1': 0.43999999999999995, 'pegasus_entailment': 0.18999333307147026, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 200
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.592, 'r1_recall': 0.5692307692307692, 'r1_f1': 0.580392156862745, 'pegasus_entailment': 0.7095234245061874, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 201
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23577235772357724, 'r1_recall': 0.6304347826086957, 'r1_f1': 0.3431952662721894, 'pegasus_entailment': 0.7447598045691848, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 202
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48026315789473684, 'r1_recall': 0.6403508771929824, 'r1_f1': 0.548872180451128, 'pegasus_entailment': 0.776798677444458, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 203
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5151515151515151, 'r1_recall': 0.6126126126126126, 'r1_f1': 0.5596707818930041, 'pegasus_entailment': 0.4386916854127776, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 204
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7062937062937062, 'r1_recall': 0.4611872146118721, 'r1_f1': 0.5580110497237569, 'pegasus_entailment': 0.5671888500452041, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 205
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48333333333333334, 'r1_recall': 0.7073170731707317, 'r1_f1': 0.5742574257425742, 'pegasus_entailment': 0.5572447897866368, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 206
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39361702127659576, 'r1_recall': 0.42045454545454547, 'r1_f1': 0.40659340659340665, 'pegasus_entailment': 0.692373052239418, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 207
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.456, 'r1_recall': 0.5643564356435643, 'r1_f1': 0.504424778761062, 'pegasus_entailment': 0.17935621365904808, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 208
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.504424778761062, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.5158371040723982, 'pegasus_entailment': 0.21517833843827247, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 209
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19444444444444445, 'r1_recall': 0.5833333333333334, 'r1_f1': 0.2916666666666667, 'pegasus_entailment': 0.11458897916600108, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 210
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4732142857142857, 'r1_recall': 0.5353535353535354, 'r1_f1': 0.5023696682464455, 'pegasus_entailment': 0.5017418891191483, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 211
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5070422535211268, 'r1_recall': 0.45569620253164556, 'r1_f1': 0.48, 'pegasus_entailment': 0.5070431530475616, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 212
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.45614035087719296, 'r1_recall': 0.4936708860759494, 'r1_f1': 0.47416413373860183, 'pegasus_entailment': 0.5382806211709976, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 213
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6619718309859155, 'r1_recall': 0.24352331606217617, 'r1_f1': 0.3560606060606061, 'pegasus_entailment': 0.42946272529661655, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 14, 'pegasus_smog': 18}
*** Analysing case 214
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7291666666666666, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.6965174129353233, 'pegasus_entailment': 0.7926880419254303, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 21, 'pegasus_ari': 33, 'pegasus_smog': 24}
*** Analysing case 215
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5206611570247934, 'r1_recall': 0.504, 'r1_f1': 0.5121951219512195, 'pegasus_entailment': 0.5965649400438581, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 216
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42028985507246375, 'r1_recall': 0.5576923076923077, 'r1_f1': 0.4793388429752066, 'pegasus_entailment': 0.4182561408961192, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 217
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29292929292929293, 'r1_recall': 0.47540983606557374, 'r1_f1': 0.3625, 'pegasus_entailment': 0.3458342436157788, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 14}
*** Analysing case 218
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4722222222222222, 'r1_recall': 0.5483870967741935, 'r1_f1': 0.5074626865671641, 'pegasus_entailment': 0.3038710809778422, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 20}
*** Analysing case 219
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23770491803278687, 'r1_recall': 0.4915254237288136, 'r1_f1': 0.32044198895027626, 'pegasus_entailment': 0.4039854362607002, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 220
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4953271028037383, 'r1_recall': 0.4649122807017544, 'r1_f1': 0.4796380090497737, 'pegasus_entailment': 0.5044006109237671, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 24}
*** Analysing case 221
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3619047619047619, 'r1_recall': 0.3838383838383838, 'r1_f1': 0.37254901960784315, 'pegasus_entailment': 0.49799228087067604, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 222
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22429906542056074, 'r1_recall': 0.6, 'r1_f1': 0.326530612244898, 'pegasus_entailment': 0.45862102322280407, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 223
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.42790697674418604, 'r1_recall': 0.5317919075144508, 'r1_f1': 0.47422680412371127, 'pegasus_entailment': 0.4120323657989502, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 224
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3783783783783784, 'r1_recall': 0.35, 'r1_f1': 0.36363636363636365, 'pegasus_entailment': 0.39197395741939545, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 13, 'pegasus_smog': 17}
*** Analysing case 225
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5892857142857143, 'r1_recall': 0.3707865168539326, 'r1_f1': 0.45517241379310347, 'pegasus_entailment': 0.5739059065069471, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 21, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 226
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6972477064220184, 'r1_recall': 0.4720496894409938, 'r1_f1': 0.5629629629629629, 'pegasus_entailment': 0.19764588524897894, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 227
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.3805970149253731, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.1177477256860584, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 228
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7160493827160493, 'r1_recall': 0.23868312757201646, 'r1_f1': 0.35802469135802467, 'pegasus_entailment': 0.4794957935810089, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 229
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4380952380952381, 'r1_recall': 0.5609756097560976, 'r1_f1': 0.4919786096256685, 'pegasus_entailment': 0.8052410185337067, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 18, 'pegasus_ari': 33, 'pegasus_smog': 22}
*** Analysing case 230
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5072463768115942, 'r1_recall': 0.23026315789473684, 'r1_f1': 0.3167420814479638, 'pegasus_entailment': 0.5510073501616717, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 231
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23684210526315788, 'r1_recall': 0.5, 'r1_f1': 0.32142857142857145, 'pegasus_entailment': 0.6270971042769296, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 232
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5287356321839081, 'r1_recall': 0.2062780269058296, 'r1_f1': 0.2967741935483871, 'pegasus_entailment': 0.7126134485006332, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 233
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.32894736842105265, 'r1_recall': 0.22123893805309736, 'r1_f1': 0.2645502645502646, 'pegasus_entailment': 0.3731187549419701, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 234
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2357142857142857, 'r1_recall': 0.717391304347826, 'r1_f1': 0.3548387096774194, 'pegasus_entailment': 0.9543441087007523, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 235
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6434782608695652, 'r1_recall': 0.4088397790055249, 'r1_f1': 0.5, 'pegasus_entailment': 0.21187995250026384, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 18}
*** Analysing case 236
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.3389830508474576, 'r1_f1': 0.4332129963898917, 'pegasus_entailment': 0.3950333041138947, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 237
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28078817733990147, 'r1_recall': 0.59375, 'r1_f1': 0.38127090301003347, 'pegasus_entailment': 0.8955531120300293, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 238
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6129032258064516, 'r1_recall': 0.5241379310344828, 'r1_f1': 0.5650557620817844, 'pegasus_entailment': 0.8116526703039805, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 239
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.14285714285714285, 'r1_recall': 0.6071428571428571, 'r1_f1': 0.23129251700680267, 'pegasus_entailment': 0.26450393348932266, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 14}
*** Analysing case 240
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19594594594594594, 'r1_recall': 0.5, 'r1_f1': 0.2815533980582524, 'pegasus_entailment': 0.628827636440595, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 241
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5494505494505495, 'r1_recall': 0.42016806722689076, 'r1_f1': 0.4761904761904762, 'pegasus_entailment': 0.5255946666002274, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 242
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3761467889908257, 'r1_recall': 0.5774647887323944, 'r1_f1': 0.45555555555555555, 'pegasus_entailment': 0.86918123960495, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 243
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23728813559322035, 'r1_recall': 0.509090909090909, 'r1_f1': 0.3236994219653179, 'pegasus_entailment': 0.5989515036344528, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 244
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27884615384615385, 'r1_recall': 0.35802469135802467, 'r1_f1': 0.31351351351351353, 'pegasus_entailment': 0.3789836831856519, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 245
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4297520661157025, 'r1_recall': 0.6419753086419753, 'r1_f1': 0.5148514851485149, 'pegasus_entailment': 0.8600623905658722, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 246
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40594059405940597, 'r1_recall': 0.4939759036144578, 'r1_f1': 0.44565217391304346, 'pegasus_entailment': 0.2767308389302343, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 247
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5040650406504065, 'r1_recall': 0.5585585585585585, 'r1_f1': 0.5299145299145298, 'pegasus_entailment': 0.4020487293601036, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 248
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6842105263157895, 'r1_recall': 0.2708333333333333, 'r1_f1': 0.38805970149253727, 'pegasus_entailment': 0.6247775256633759, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 249
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6, 'r1_recall': 0.3108108108108108, 'r1_f1': 0.40949554896142426, 'pegasus_entailment': 0.42367191053926945, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 250
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36936936936936937, 'r1_recall': 0.5256410256410257, 'r1_f1': 0.4338624338624339, 'pegasus_entailment': 0.7589334189891815, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 251
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.575, 'r1_recall': 0.6634615384615384, 'r1_f1': 0.6160714285714285, 'pegasus_entailment': 0.6404471658170223, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 252
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2361111111111111, 'r1_recall': 0.4657534246575342, 'r1_f1': 0.3133640552995392, 'pegasus_entailment': 0.44919398687779905, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 253
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26126126126126126, 'r1_recall': 0.4461538461538462, 'r1_f1': 0.3295454545454546, 'pegasus_entailment': 0.43605308681726457, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 254
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.425531914893617, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.48192771084337355, 'pegasus_entailment': 0.615190714597702, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 255
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4864864864864865, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5625, 'pegasus_entailment': 0.5566440778784454, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 256
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3783783783783784, 'r1_recall': 0.5526315789473685, 'r1_f1': 0.44919786096256686, 'pegasus_entailment': 0.8852891623973846, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 257
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.5714285714285714, 'r1_f1': 0.5714285714285714, 'pegasus_entailment': 0.5468614461521307, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 17}
*** Analysing case 258
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5862068965517241, 'r1_recall': 0.43312101910828027, 'r1_f1': 0.49816849816849823, 'pegasus_entailment': 0.7778378625710806, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 259
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6635514018691588, 'r1_recall': 0.4930555555555556, 'r1_f1': 0.5657370517928286, 'pegasus_entailment': 0.5037613213062286, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 260
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36054421768707484, 'r1_recall': 0.5638297872340425, 'r1_f1': 0.4398340248962656, 'pegasus_entailment': 0.2841750959632918, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 261
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6114649681528662, 'r1_recall': 0.5026178010471204, 'r1_f1': 0.5517241379310345, 'pegasus_entailment': 0.3521799381290163, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 262
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3490566037735849, 'r1_recall': 0.7551020408163265, 'r1_f1': 0.4774193548387097, 'pegasus_entailment': 0.7049704948440194, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 263
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46534653465346537, 'r1_recall': 0.5662650602409639, 'r1_f1': 0.5108695652173914, 'pegasus_entailment': 0.7626789808273315, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 14, 'pegasus_smog': 16}
*** Analysing case 264
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.45054945054945056, 'r1_recall': 0.5256410256410257, 'r1_f1': 0.48520710059171596, 'pegasus_entailment': 0.5019234049832448, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 265
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4435483870967742, 'r1_recall': 0.6790123456790124, 'r1_f1': 0.5365853658536586, 'pegasus_entailment': 0.47635123282670977, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 266
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5811965811965812, 'r1_recall': 0.49635036496350365, 'r1_f1': 0.5354330708661418, 'pegasus_entailment': 0.7871238142251968, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 267
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.26666666666666666, 'r1_recall': 0.36363636363636365, 'r1_f1': 0.30769230769230765, 'pegasus_entailment': 0.3866307120770216, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 268
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.25742574257425743, 'r1_recall': 0.4406779661016949, 'r1_f1': 0.32500000000000007, 'pegasus_entailment': 0.712619386613369, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 23, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 269
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.4701492537313433, 'r1_f1': 0.5271966527196653, 'pegasus_entailment': 0.6558682322502136, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 17, 'pegasus_ari': 33, 'pegasus_smog': 21}
*** Analysing case 270
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5454545454545454, 'r1_recall': 0.4230769230769231, 'r1_f1': 0.4765342960288808, 'pegasus_entailment': 0.4606052227318287, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 271
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3779527559055118, 'r1_recall': 0.7384615384615385, 'r1_f1': 0.5, 'pegasus_entailment': 0.6966434828937054, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 272
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5194805194805194, 'r1_recall': 0.45454545454545453, 'r1_f1': 0.4848484848484848, 'pegasus_entailment': 0.5747135616838932, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 273
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.475, 'r1_recall': 0.4523809523809524, 'r1_f1': 0.46341463414634143, 'pegasus_entailment': 0.7249991099039713, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 274
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5070422535211268, 'r1_recall': 0.4675324675324675, 'r1_f1': 0.48648648648648646, 'pegasus_entailment': 0.4068881389684975, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 275
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2796610169491525, 'r1_recall': 0.4125, 'r1_f1': 0.33333333333333326, 'pegasus_entailment': 0.6281787923404148, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 276
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.564935064935065, 'r1_recall': 0.5576923076923077, 'r1_f1': 0.5612903225806453, 'pegasus_entailment': 0.56850276225143, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 277
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4025974025974026, 'r1_recall': 0.40789473684210525, 'r1_f1': 0.40522875816993464, 'pegasus_entailment': 0.25048715248703957, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 278
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.381294964028777, 'r1_recall': 0.6235294117647059, 'r1_f1': 0.4732142857142857, 'pegasus_entailment': 0.4727176781743765, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 279
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5655737704918032, 'r1_recall': 0.5267175572519084, 'r1_f1': 0.5454545454545454, 'pegasus_entailment': 0.43474692925810815, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 280
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3841059602649007, 'r1_recall': 0.5471698113207547, 'r1_f1': 0.45136186770428016, 'pegasus_entailment': 0.7236073732376098, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 281
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6296296296296297, 'r1_recall': 0.5573770491803278, 'r1_f1': 0.591304347826087, 'pegasus_entailment': 0.6117092285837445, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 282
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4230769230769231, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.4888888888888889, 'pegasus_entailment': 0.6428432166576385, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 283
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47619047619047616, 'r1_recall': 0.43478260869565216, 'r1_f1': 0.4545454545454545, 'pegasus_entailment': 0.31691196002066135, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 284
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7850467289719626, 'r1_recall': 0.3888888888888889, 'r1_f1': 0.5201238390092878, 'pegasus_entailment': 0.23927418179810048, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 285
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48514851485148514, 'r1_recall': 0.48514851485148514, 'r1_f1': 0.48514851485148514, 'pegasus_entailment': 0.24329654399771244, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 286
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5483870967741935, 'r1_recall': 0.3469387755102041, 'r1_f1': 0.425, 'pegasus_entailment': 0.10360656911507249, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 287
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4155844155844156, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.43537414965986393, 'pegasus_entailment': 0.665198489325121, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 288
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6363636363636364, 'r1_recall': 0.631578947368421, 'r1_f1': 0.6339622641509434, 'pegasus_entailment': 0.5346378795802593, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 289
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6428571428571429, 'r1_recall': 0.5, 'r1_f1': 0.5625000000000001, 'pegasus_entailment': 0.3144248326619466, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 13, 'pegasus_ari': 13, 'pegasus_smog': 13}
*** Analysing case 290
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5371900826446281, 'r1_recall': 0.5652173913043478, 'r1_f1': 0.5508474576271186, 'pegasus_entailment': 0.5611620664596557, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 291
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42592592592592593, 'r1_recall': 0.4144144144144144, 'r1_f1': 0.4200913242009132, 'pegasus_entailment': 0.6601887866854668, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 292
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6904761904761905, 'r1_recall': 0.42028985507246375, 'r1_f1': 0.5225225225225225, 'pegasus_entailment': 0.9570502638816833, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 293
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.21551724137931033, 'r1_recall': 0.5, 'r1_f1': 0.30120481927710846, 'pegasus_entailment': 0.25056929199490696, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 294
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43529411764705883, 'r1_recall': 0.6607142857142857, 'r1_f1': 0.5248226950354609, 'pegasus_entailment': 0.48020654916763306, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 20, 'pegasus_ari': 30, 'pegasus_smog': 25}
*** Analysing case 295
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.07627118644067797, 'r1_recall': 0.3829787234042553, 'r1_f1': 0.12720848056537104, 'pegasus_entailment': 0.6155631201607841, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 296
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3253968253968254, 'r1_recall': 0.5774647887323944, 'r1_f1': 0.41624365482233505, 'pegasus_entailment': 0.9272867143154144, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 297
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6375, 'r1_recall': 0.2786885245901639, 'r1_f1': 0.38783269961977185, 'pegasus_entailment': 0.38469995309909183, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 14, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 298
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.44954128440366975, 'r1_recall': 0.35766423357664234, 'r1_f1': 0.3983739837398374, 'pegasus_entailment': 0.7425954739252726, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 299
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4777777777777778, 'r1_recall': 0.4725274725274725, 'r1_f1': 0.47513812154696133, 'pegasus_entailment': 0.7772535234689713, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 300
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46629213483146065, 'r1_recall': 0.6240601503759399, 'r1_f1': 0.5337620578778135, 'pegasus_entailment': 0.3943489821006854, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 301
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5436241610738255, 'r1_recall': 0.49390243902439024, 'r1_f1': 0.5175718849840256, 'pegasus_entailment': 0.4417526572942734, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 302
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7777777777777778, 'r1_recall': 0.38308457711442784, 'r1_f1': 0.5133333333333333, 'pegasus_entailment': 0.6500471830368042, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 303
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2956521739130435, 'r1_recall': 0.34, 'r1_f1': 0.3162790697674419, 'pegasus_entailment': 0.376177246371905, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 304
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3826086956521739, 'r1_recall': 0.55, 'r1_f1': 0.4512820512820513, 'pegasus_entailment': 0.5134493904188275, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 305
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37349397590361444, 'r1_recall': 0.3780487804878049, 'r1_f1': 0.37575757575757573, 'pegasus_entailment': 0.003579447162337601, 'pegasus_flesch_kincaid': 26, 'pegasus_coleman_liau': 21, 'pegasus_ari': 30, 'pegasus_smog': 26}
*** Analysing case 306
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.23076923076923078, 'r1_recall': 0.4375, 'r1_f1': 0.3021582733812949, 'pegasus_entailment': 0.2858038867513339, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 13, 'pegasus_ari': 12, 'pegasus_smog': 16}
*** Analysing case 307
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3063063063063063, 'r1_recall': 0.5396825396825397, 'r1_f1': 0.3908045977011494, 'pegasus_entailment': 0.6931428405456245, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 308
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1810344827586207, 'r1_recall': 0.6176470588235294, 'r1_f1': 0.28, 'pegasus_entailment': 0.6097655692137778, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 309
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3564356435643564, 'r1_recall': 0.47368421052631576, 'r1_f1': 0.4067796610169491, 'pegasus_entailment': 0.36813971896966297, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 310
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6376811594202898, 'r1_recall': 0.2391304347826087, 'r1_f1': 0.3478260869565218, 'pegasus_entailment': 0.6871088941891988, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 311
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3392857142857143, 'r1_recall': 0.2835820895522388, 'r1_f1': 0.30894308943089427, 'pegasus_entailment': 0.21125494688749313, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 15}
*** Analysing case 312
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5918367346938775, 'r1_recall': 0.34523809523809523, 'r1_f1': 0.43609022556390975, 'pegasus_entailment': 0.2675054273568094, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 313
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5748031496062992, 'r1_recall': 0.553030303030303, 'r1_f1': 0.5637065637065636, 'pegasus_entailment': 0.2904787864536047, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 314
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6578947368421053, 'r1_recall': 0.47468354430379744, 'r1_f1': 0.5514705882352942, 'pegasus_entailment': 0.5455460796753565, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 315
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6831683168316832, 'r1_recall': 0.23310810810810811, 'r1_f1': 0.34760705289672544, 'pegasus_entailment': 0.6422588229179382, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 316
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4794520547945205, 'r1_recall': 0.6363636363636364, 'r1_f1': 0.546875, 'pegasus_entailment': 0.7314231775235385, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 17}
*** Analysing case 317
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6408450704225352, 'r1_recall': 0.4619289340101523, 'r1_f1': 0.536873156342183, 'pegasus_entailment': 0.11720823496580124, 'pegasus_flesch_kincaid': 27, 'pegasus_coleman_liau': 20, 'pegasus_ari': 33, 'pegasus_smog': 23}
*** Analysing case 318
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3595505617977528, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.42953020134228187, 'pegasus_entailment': 0.5454985598723093, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 319
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3954802259887006, 'r1_recall': 0.5691056910569106, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.8493285179138184, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 320
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4473684210526316, 'r1_recall': 0.4857142857142857, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.6202397346496582, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 321
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6111111111111112, 'r1_recall': 0.4198473282442748, 'r1_f1': 0.497737556561086, 'pegasus_entailment': 0.6164925843477249, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 322
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33043478260869563, 'r1_recall': 0.5671641791044776, 'r1_f1': 0.41758241758241754, 'pegasus_entailment': 0.503422985970974, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 323
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3404255319148936, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.42384105960264895, 'pegasus_entailment': 0.22722693035999933, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 23, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 324
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2422360248447205, 'r1_recall': 0.6842105263157895, 'r1_f1': 0.35779816513761464, 'pegasus_entailment': 0.712080442905426, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 325
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5841584158415841, 'r1_recall': 0.4609375, 'r1_f1': 0.5152838427947598, 'pegasus_entailment': 0.32914358377456665, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 326
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6197183098591549, 'r1_recall': 0.4943820224719101, 'r1_f1': 0.55, 'pegasus_entailment': 0.6960833444900345, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 327
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5785714285714286, 'r1_recall': 0.49693251533742333, 'r1_f1': 0.5346534653465347, 'pegasus_entailment': 0.6110453282793363, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 328
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6290322580645161, 'r1_recall': 0.40414507772020725, 'r1_f1': 0.4921135646687697, 'pegasus_entailment': 0.7918730020523072, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 329
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40869565217391307, 'r1_recall': 0.46534653465346537, 'r1_f1': 0.4351851851851852, 'pegasus_entailment': 0.834866464138031, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 330
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34965034965034963, 'r1_recall': 0.5952380952380952, 'r1_f1': 0.44052863436123346, 'pegasus_entailment': 0.38839084814701763, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 331
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28776978417266186, 'r1_recall': 0.4444444444444444, 'r1_f1': 0.3493449781659389, 'pegasus_entailment': 0.5086874453616994, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 332
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43037974683544306, 'r1_recall': 0.6666666666666666, 'r1_f1': 0.5230769230769231, 'pegasus_entailment': 0.23569690932830176, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 333
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6037735849056604, 'r1_recall': 0.43243243243243246, 'r1_f1': 0.5039370078740159, 'pegasus_entailment': 0.30738315135240557, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 334
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5370370370370371, 'r1_recall': 0.44274809160305345, 'r1_f1': 0.48535564853556495, 'pegasus_entailment': 0.36607431032462046, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 335
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5681818181818182, 'r1_recall': 0.423728813559322, 'r1_f1': 0.4854368932038835, 'pegasus_entailment': 0.8753639310598373, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 336
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7307692307692307, 'r1_recall': 0.5846153846153846, 'r1_f1': 0.6495726495726495, 'pegasus_entailment': 0.8557998239994049, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 20, 'pegasus_ari': 34, 'pegasus_smog': 24}
*** Analysing case 337
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5086206896551724, 'r1_recall': 0.4957983193277311, 'r1_f1': 0.502127659574468, 'pegasus_entailment': 0.3263038681470789, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 338
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.43243243243243246, 'pegasus_entailment': 0.08699997887015343, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 339
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4927536231884058, 'r1_recall': 0.37777777777777777, 'r1_f1': 0.4276729559748428, 'pegasus_entailment': 0.33858174085617065, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 340
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6020408163265306, 'r1_recall': 0.44360902255639095, 'r1_f1': 0.5108225108225107, 'pegasus_entailment': 0.6789278462529182, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 341
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5132743362831859, 'r1_recall': 0.27358490566037735, 'r1_f1': 0.35692307692307695, 'pegasus_entailment': 0.7693875233332316, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 342
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2564102564102564, 'r1_recall': 0.5263157894736842, 'r1_f1': 0.3448275862068965, 'pegasus_entailment': 0.3032138113464628, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 343
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6477272727272727, 'r1_recall': 0.4453125, 'r1_f1': 0.5277777777777778, 'pegasus_entailment': 0.5988938035443425, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 344
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2595419847328244, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.36170212765957444, 'pegasus_entailment': 0.5426520794630051, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 345
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7321428571428571, 'r1_recall': 0.4293193717277487, 'r1_f1': 0.5412541254125413, 'pegasus_entailment': 0.5431368748346964, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 346
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5398230088495575, 'r1_recall': 0.41496598639455784, 'r1_f1': 0.46923076923076923, 'pegasus_entailment': 0.2705789875239134, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 347
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4868421052631579, 'r1_recall': 0.4805194805194805, 'r1_f1': 0.48366013071895425, 'pegasus_entailment': 0.8668896913528442, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 348
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.37583892617449666, 'r1_recall': 0.7466666666666667, 'r1_f1': 0.5, 'pegasus_entailment': 0.8690317571163177, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 349
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5615384615384615, 'r1_recall': 0.6347826086956522, 'r1_f1': 0.5959183673469388, 'pegasus_entailment': 0.5083232820034027, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 350
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5916666666666667, 'r1_recall': 0.46405228758169936, 'r1_f1': 0.5201465201465202, 'pegasus_entailment': 0.7152962684631348, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 17, 'pegasus_ari': 36, 'pegasus_smog': 20}
*** Analysing case 351
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4411764705882353, 'r1_f1': 0.46875, 'pegasus_entailment': 0.28538992744870484, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 352
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3563218390804598, 'r1_recall': 0.543859649122807, 'r1_f1': 0.4305555555555556, 'pegasus_entailment': 0.36593693867325783, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 353
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4857142857142857, 'r1_recall': 0.53125, 'r1_f1': 0.5074626865671641, 'pegasus_entailment': 0.5445028026588261, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 354
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4326923076923077, 'r1_recall': 0.6, 'r1_f1': 0.5027932960893856, 'pegasus_entailment': 0.18412560725118965, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 355
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4605263157894737, 'r1_recall': 0.660377358490566, 'r1_f1': 0.5426356589147286, 'pegasus_entailment': 0.8229853808879852, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 356
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5632183908045977, 'r1_recall': 0.5268817204301075, 'r1_f1': 0.5444444444444445, 'pegasus_entailment': 0.482737772166729, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 357
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3333333333333333, 'r1_recall': 0.5344827586206896, 'r1_f1': 0.41059602649006616, 'pegasus_entailment': 0.25174007564783096, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 358
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.8055555555555556, 'r1_recall': 0.5686274509803921, 'r1_f1': 0.6666666666666667, 'pegasus_entailment': 0.6487989127635956, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 359
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.55, 'r1_recall': 0.4873417721518987, 'r1_f1': 0.516778523489933, 'pegasus_entailment': 0.6786064008871714, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 17, 'pegasus_ari': 30, 'pegasus_smog': 24}
*** Analysing case 360
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.23776223776223776, 'r1_recall': 0.5964912280701754, 'r1_f1': 0.33999999999999997, 'pegasus_entailment': 0.5239853598177433, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 361
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6140350877192983, 'r1_recall': 0.4697986577181208, 'r1_f1': 0.532319391634981, 'pegasus_entailment': 0.6619677742322286, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 362
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5975609756097561, 'r1_recall': 0.35766423357664234, 'r1_f1': 0.4474885844748858, 'pegasus_entailment': 0.6101442476113638, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 363
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5227272727272727, 'r1_recall': 0.696969696969697, 'r1_f1': 0.5974025974025974, 'pegasus_entailment': 0.33049069593350094, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 364
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4491525423728814, 'r1_recall': 0.4774774774774775, 'r1_f1': 0.462882096069869, 'pegasus_entailment': 0.6504695981740951, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 365
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38095238095238093, 'r1_recall': 0.6, 'r1_f1': 0.4660194174757281, 'pegasus_entailment': 0.6688690930604935, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 366
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4878048780487805, 'r1_recall': 0.31496062992125984, 'r1_f1': 0.3827751196172248, 'pegasus_entailment': 0.605635792016983, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 367
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6635514018691588, 'r1_recall': 0.3604060913705584, 'r1_f1': 0.4671052631578947, 'pegasus_entailment': 0.41865632124245167, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 368
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6578947368421053, 'r1_recall': 0.30864197530864196, 'r1_f1': 0.42016806722689076, 'pegasus_entailment': 0.3827493451535702, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 369
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5971223021582733, 'r1_recall': 0.5971223021582733, 'r1_f1': 0.5971223021582733, 'pegasus_entailment': 0.6072940879190961, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 370
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1810344827586207, 'r1_recall': 0.2876712328767123, 'r1_f1': 0.22222222222222218, 'pegasus_entailment': 0.002808688976801932, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 371
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2948717948717949, 'r1_recall': 0.3770491803278688, 'r1_f1': 0.3309352517985611, 'pegasus_entailment': 0.13589763144652048, 'pegasus_flesch_kincaid': 10, 'pegasus_coleman_liau': 11, 'pegasus_ari': 10, 'pegasus_smog': 12}
*** Analysing case 372
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38345864661654133, 'r1_recall': 0.5930232558139535, 'r1_f1': 0.4657534246575342, 'pegasus_entailment': 0.5011975395027548, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 373
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4020618556701031, 'r1_recall': 0.527027027027027, 'r1_f1': 0.45614035087719296, 'pegasus_entailment': 0.21694189112167805, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 374
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5524475524475524, 'r1_recall': 0.4540229885057471, 'r1_f1': 0.498422712933754, 'pegasus_entailment': 0.509243827845369, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 375
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4868421052631579, 'r1_recall': 0.2569444444444444, 'r1_f1': 0.33636363636363636, 'pegasus_entailment': 0.24163465108722448, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 376
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.632, 'r1_recall': 0.40512820512820513, 'r1_f1': 0.49375, 'pegasus_entailment': 0.7862944155931473, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 377
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4639175257731959, 'r1_recall': 0.6164383561643836, 'r1_f1': 0.5294117647058824, 'pegasus_entailment': 0.7270911733309428, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 378
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5113636363636364, 'r1_recall': 0.6, 'r1_f1': 0.5521472392638037, 'pegasus_entailment': 0.44531241431832314, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 379
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.47058823529411764, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.5119999999999999, 'pegasus_entailment': 0.7830026894807816, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 18}
*** Analysing case 380
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7176470588235294, 'r1_recall': 0.1622340425531915, 'r1_f1': 0.2646420824295011, 'pegasus_entailment': 0.6967212557792664, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 381
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.28346456692913385, 'r1_recall': 0.6101694915254238, 'r1_f1': 0.3870967741935483, 'pegasus_entailment': 0.5863045036792756, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 382
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5576923076923077, 'r1_recall': 0.34523809523809523, 'r1_f1': 0.42647058823529416, 'pegasus_entailment': 0.6488556116819382, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 383
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.4418604651162791, 'r1_f1': 0.46913580246913583, 'pegasus_entailment': 0.5425734147429466, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 384
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5842696629213483, 'r1_recall': 0.348993288590604, 'r1_f1': 0.43697478991596633, 'pegasus_entailment': 0.7986474633216858, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 19, 'pegasus_ari': 30, 'pegasus_smog': 22}
*** Analysing case 385
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5686274509803921, 'r1_recall': 0.514792899408284, 'r1_f1': 0.5403726708074533, 'pegasus_entailment': 0.6178972318768501, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 386
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5179856115107914, 'r1_recall': 0.549618320610687, 'r1_f1': 0.5333333333333334, 'pegasus_entailment': 0.6224713996052742, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 15, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 387
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4878048780487805, 'r1_recall': 0.3225806451612903, 'r1_f1': 0.3883495145631068, 'pegasus_entailment': 0.544108010828495, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 388
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4322033898305085, 'r1_recall': 0.6144578313253012, 'r1_f1': 0.5074626865671641, 'pegasus_entailment': 0.4355950327590108, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 389
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2727272727272727, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.3620689655172414, 'pegasus_entailment': 0.43927573785185814, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 390
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5212765957446809, 'r1_recall': 0.4224137931034483, 'r1_f1': 0.46666666666666673, 'pegasus_entailment': 0.40116557478904724, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 391
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6190476190476191, 'r1_recall': 0.35135135135135137, 'r1_f1': 0.4482758620689656, 'pegasus_entailment': 0.6429335236549377, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 392
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.68, 'r1_recall': 0.53125, 'r1_f1': 0.5964912280701754, 'pegasus_entailment': 0.8371017575263977, 'pegasus_flesch_kincaid': 38, 'pegasus_coleman_liau': 18, 'pegasus_ari': 45, 'pegasus_smog': 30}
*** Analysing case 393
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7027027027027027, 'r1_recall': 0.33766233766233766, 'r1_f1': 0.45614035087719296, 'pegasus_entailment': 0.6270179940121514, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 394
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6805555555555556, 'r1_recall': 0.3402777777777778, 'r1_f1': 0.45370370370370366, 'pegasus_entailment': 0.5769786387681961, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 19}
*** Analysing case 395
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.291044776119403, 'r1_recall': 0.6, 'r1_f1': 0.3919597989949749, 'pegasus_entailment': 0.6416426688432694, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 396
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20987654320987653, 'r1_recall': 0.5666666666666667, 'r1_f1': 0.3063063063063063, 'pegasus_entailment': 0.5571252048015595, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 397
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.359375, 'r1_recall': 0.2839506172839506, 'r1_f1': 0.31724137931034485, 'pegasus_entailment': 0.9903484980265299, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 22, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 398
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44660194174757284, 'r1_recall': 0.4423076923076923, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.7712495923042297, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 23, 'pegasus_smog': 19}
*** Analysing case 399
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3203125, 'r1_recall': 0.47674418604651164, 'r1_f1': 0.383177570093458, 'pegasus_entailment': 0.8189804553985596, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 400
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4972375690607735, 'r1_recall': 0.5769230769230769, 'r1_f1': 0.5341246290801186, 'pegasus_entailment': 0.5022698268294334, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 401
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.576, 'r1_recall': 0.43636363636363634, 'r1_f1': 0.496551724137931, 'pegasus_entailment': 0.7126408219337463, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 19, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 402
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33962264150943394, 'r1_recall': 0.5901639344262295, 'r1_f1': 0.4311377245508982, 'pegasus_entailment': 0.1280921249805639, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 403
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5298013245033113, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.53156146179402, 'pegasus_entailment': 0.6571421573559443, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 404
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35714285714285715, 'r1_recall': 0.4945054945054945, 'r1_f1': 0.4147465437788018, 'pegasus_entailment': 0.34409371558576823, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 405
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5504587155963303, 'r1_recall': 0.4580152671755725, 'r1_f1': 0.5, 'pegasus_entailment': 0.382532333334287, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 406
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5089285714285714, 'r1_recall': 0.6263736263736264, 'r1_f1': 0.5615763546798029, 'pegasus_entailment': 0.5788039922714233, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 407
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5299145299145299, 'r1_recall': 0.5904761904761905, 'r1_f1': 0.5585585585585586, 'pegasus_entailment': 0.4480772688984871, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 408
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4396551724137931, 'r1_recall': 0.6986301369863014, 'r1_f1': 0.5396825396825397, 'pegasus_entailment': 0.46496032923460007, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 409
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36538461538461536, 'r1_recall': 0.304, 'r1_f1': 0.3318777292576419, 'pegasus_entailment': 0.5087353454437107, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 410
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4647887323943662, 'r1_recall': 0.5789473684210527, 'r1_f1': 0.515625, 'pegasus_entailment': 0.553895252943039, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 20}
*** Analysing case 411
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.41379310344827586, 'r1_recall': 0.5393258426966292, 'r1_f1': 0.4682926829268293, 'pegasus_entailment': 0.3988733470439911, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 25, 'pegasus_smog': 18}
*** Analysing case 412
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2818181818181818, 'r1_recall': 0.7209302325581395, 'r1_f1': 0.40522875816993464, 'pegasus_entailment': 0.45947661623358727, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 413
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6866666666666666, 'r1_recall': 0.4660633484162896, 'r1_f1': 0.555256064690027, 'pegasus_entailment': 0.455425711614745, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 414
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6509433962264151, 'r1_recall': 0.6106194690265486, 'r1_f1': 0.6301369863013699, 'pegasus_entailment': 0.9620340764522552, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 35, 'pegasus_smog': 22}
*** Analysing case 415
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29213483146067415, 'r1_recall': 0.7027027027027027, 'r1_f1': 0.4126984126984127, 'pegasus_entailment': 0.5063235660394033, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 416
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3188405797101449, 'r1_recall': 0.5365853658536586, 'r1_f1': 0.39999999999999997, 'pegasus_entailment': 0.5452102601528168, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 13}
*** Analysing case 417
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37423312883435583, 'r1_recall': 0.5700934579439252, 'r1_f1': 0.4518518518518518, 'pegasus_entailment': 0.6300334384044012, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 418
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3202614379084967, 'r1_recall': 0.6805555555555556, 'r1_f1': 0.43555555555555553, 'pegasus_entailment': 0.5788802603880564, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 419
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3877551020408163, 'r1_recall': 0.4318181818181818, 'r1_f1': 0.4086021505376344, 'pegasus_entailment': 0.9048068722089132, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 18}
*** Analysing case 420
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.42696629213483145, 'r1_f1': 0.5205479452054794, 'pegasus_entailment': 0.4836004674434662, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 421
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3014705882352941, 'r1_recall': 0.6949152542372882, 'r1_f1': 0.4205128205128205, 'pegasus_entailment': 0.36199762317119166, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 17}
*** Analysing case 422
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6190476190476191, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.48148148148148145, 'pegasus_entailment': 0.47472940882047016, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 423
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.55, 'r1_recall': 0.4583333333333333, 'r1_f1': 0.5, 'pegasus_entailment': 0.8423315087954203, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 424
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4236111111111111, 'r1_recall': 0.648936170212766, 'r1_f1': 0.5126050420168068, 'pegasus_entailment': 0.7120996475219726, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 425
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.916030534351145, 'r1_recall': 0.22988505747126436, 'r1_f1': 0.3675344563552833, 'pegasus_entailment': 0.6340669755424772, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 426
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6423841059602649, 'r1_recall': 0.485, 'r1_f1': 0.5527065527065527, 'pegasus_entailment': 0.5015932034168925, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 427
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3106796116504854, 'r1_recall': 0.41025641025641024, 'r1_f1': 0.3535911602209944, 'pegasus_entailment': 0.10466119647026062, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 428
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6341463414634146, 'r1_recall': 0.49523809523809526, 'r1_f1': 0.5561497326203207, 'pegasus_entailment': 0.5754261016845703, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 429
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.5, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.41244319304823873, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 430
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38613861386138615, 'r1_recall': 0.6902654867256637, 'r1_f1': 0.49523809523809526, 'pegasus_entailment': 0.8384492248296738, 'pegasus_flesch_kincaid': 28, 'pegasus_coleman_liau': 20, 'pegasus_ari': 34, 'pegasus_smog': 25}
*** Analysing case 431
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4948453608247423, 'r1_recall': 0.5647058823529412, 'r1_f1': 0.5274725274725275, 'pegasus_entailment': 0.28618573894103366, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 432
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.43209876543209874, 'r1_recall': 0.5303030303030303, 'r1_f1': 0.4761904761904762, 'pegasus_entailment': 0.48499984480440617, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 22, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 433
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5238095238095238, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.5, 'pegasus_entailment': 0.4468916406234105, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 434
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41333333333333333, 'r1_recall': 0.37349397590361444, 'r1_f1': 0.3924050632911392, 'pegasus_entailment': 0.3297278508543968, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 19}
*** Analysing case 435
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.7692307692307693, 'r1_recall': 0.3968253968253968, 'r1_f1': 0.5235602094240838, 'pegasus_entailment': 0.752319723367691, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 23, 'pegasus_smog': 22}
*** Analysing case 436
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5588235294117647, 'r1_recall': 0.5588235294117647, 'r1_f1': 0.5588235294117647, 'pegasus_entailment': 0.4529508911073208, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 437
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5138121546961326, 'r1_recall': 0.577639751552795, 'r1_f1': 0.543859649122807, 'pegasus_entailment': 0.5365153231791088, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 438
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.32, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.4076433121019108, 'pegasus_entailment': 0.9824907332658768, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 439
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7163120567375887, 'r1_recall': 0.4469026548672566, 'r1_f1': 0.5504087193460491, 'pegasus_entailment': 0.4232473528633515, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 440
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.25396825396825395, 'r1_recall': 0.5333333333333333, 'r1_f1': 0.3440860215053763, 'pegasus_entailment': 0.10384100954979658, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 15, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 441
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5391304347826087, 'r1_recall': 0.6138613861386139, 'r1_f1': 0.5740740740740741, 'pegasus_entailment': 0.617369718849659, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 16}
*** Analysing case 442
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2589928057553957, 'r1_recall': 0.7346938775510204, 'r1_f1': 0.3829787234042553, 'pegasus_entailment': 0.4046226553618908, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 19}
*** Analysing case 443
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.22123893805309736, 'r1_recall': 0.5434782608695652, 'r1_f1': 0.3144654088050315, 'pegasus_entailment': 0.5525568403303623, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 444
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5954198473282443, 'r1_recall': 0.5342465753424658, 'r1_f1': 0.5631768953068592, 'pegasus_entailment': 0.8968883752822876, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 445
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5668789808917197, 'r1_recall': 0.4635416666666667, 'r1_f1': 0.510028653295129, 'pegasus_entailment': 0.653382882475853, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 22, 'pegasus_ari': 30, 'pegasus_smog': 23}
*** Analysing case 446
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41509433962264153, 'r1_recall': 0.2972972972972973, 'r1_f1': 0.3464566929133859, 'pegasus_entailment': 0.7124414145946503, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 22, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 447
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4470588235294118, 'r1_recall': 0.3838383838383838, 'r1_f1': 0.4130434782608695, 'pegasus_entailment': 0.29509086068719625, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 448
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47, 'r1_recall': 0.5662650602409639, 'r1_f1': 0.5136612021857923, 'pegasus_entailment': 0.30115858018398284, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 449
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3888888888888889, 'r1_recall': 0.6901408450704225, 'r1_f1': 0.49746192893401014, 'pegasus_entailment': 0.3903261336187522, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 450
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5272727272727272, 'r1_recall': 0.5043478260869565, 'r1_f1': 0.5155555555555555, 'pegasus_entailment': 0.33550648515423137, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 451
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5981308411214953, 'r1_recall': 0.38095238095238093, 'r1_f1': 0.4654545454545454, 'pegasus_entailment': 0.4510543942451477, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 452
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24509803921568626, 'r1_recall': 0.4716981132075472, 'r1_f1': 0.3225806451612903, 'pegasus_entailment': 0.3823559229495004, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 453
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6056338028169014, 'r1_recall': 0.39814814814814814, 'r1_f1': 0.4804469273743017, 'pegasus_entailment': 0.5565374245246252, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 454
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.616822429906542, 'r1_recall': 0.584070796460177, 'r1_f1': 0.6000000000000001, 'pegasus_entailment': 0.7904253154993057, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 455
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4065934065934066, 'r1_recall': 0.5211267605633803, 'r1_f1': 0.45679012345679015, 'pegasus_entailment': 0.5382085293531418, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 456
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5370370370370371, 'r1_recall': 0.3972602739726027, 'r1_f1': 0.4566929133858268, 'pegasus_entailment': 0.5039723794907331, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 457
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.16666666666666666, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.2442748091603053, 'pegasus_entailment': 0.7618318125605583, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 20}
*** Analysing case 458
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.484375, 'r1_recall': 0.7469879518072289, 'r1_f1': 0.5876777251184835, 'pegasus_entailment': 0.5491658300161362, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 459
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.24509803921568626, 'r1_recall': 0.5102040816326531, 'r1_f1': 0.3311258278145695, 'pegasus_entailment': 0.37585719923178357, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 22, 'pegasus_ari': 27, 'pegasus_smog': 24}
*** Analysing case 460
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6964285714285714, 'r1_recall': 0.4588235294117647, 'r1_f1': 0.5531914893617021, 'pegasus_entailment': 0.851566880941391, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 461
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7029702970297029, 'r1_recall': 0.5503875968992248, 'r1_f1': 0.6173913043478262, 'pegasus_entailment': 0.7885714570681254, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 21, 'pegasus_ari': 26, 'pegasus_smog': 23}
*** Analysing case 462
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4247787610619469, 'r1_recall': 0.5517241379310345, 'r1_f1': 0.48, 'pegasus_entailment': 0.7379960894584656, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 463
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5161290322580645, 'r1_recall': 0.48120300751879697, 'r1_f1': 0.4980544747081712, 'pegasus_entailment': 0.812883049249649, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 464
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5084745762711864, 'r1_recall': 0.5405405405405406, 'r1_f1': 0.5240174672489083, 'pegasus_entailment': 0.3098113551735878, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 22, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 465
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.49504950495049505, 'r1_recall': 0.5208333333333334, 'r1_f1': 0.5076142131979695, 'pegasus_entailment': 0.2909077728788058, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 466
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.5571428571428572, 'r1_f1': 0.6070038910505836, 'pegasus_entailment': 0.5498151313513517, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 467
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40131578947368424, 'r1_recall': 0.4236111111111111, 'r1_f1': 0.41216216216216217, 'pegasus_entailment': 0.6965013146400452, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 468
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.33695652173913043, 'r1_f1': 0.4025974025974026, 'pegasus_entailment': 0.7652113735675812, 'pegasus_flesch_kincaid': 13, 'pegasus_coleman_liau': 18, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 469
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5540540540540541, 'r1_recall': 0.39805825242718446, 'r1_f1': 0.4632768361581921, 'pegasus_entailment': 0.2741798684000969, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 19}
*** Analysing case 470
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.33653846153846156, 'r1_recall': 0.5223880597014925, 'r1_f1': 0.4093567251461988, 'pegasus_entailment': 0.36780557843546074, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 22}
*** Analysing case 471
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.47368421052631576, 'r1_recall': 0.5934065934065934, 'r1_f1': 0.5268292682926828, 'pegasus_entailment': 0.91678287088871, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 15, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 472
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.5384615384615384, 'r1_f1': 0.5185185185185186, 'pegasus_entailment': 0.7451376616954803, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 27, 'pegasus_smog': 21}
*** Analysing case 473
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6222222222222222, 'r1_recall': 0.45901639344262296, 'r1_f1': 0.5283018867924528, 'pegasus_entailment': 0.5114264264702797, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 474
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5877192982456141, 'r1_recall': 0.4036144578313253, 'r1_f1': 0.4785714285714286, 'pegasus_entailment': 0.4982694983482361, 'pegasus_flesch_kincaid': 25, 'pegasus_coleman_liau': 21, 'pegasus_ari': 29, 'pegasus_smog': 24}
*** Analysing case 475
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49333333333333335, 'r1_recall': 0.6727272727272727, 'r1_f1': 0.5692307692307692, 'pegasus_entailment': 0.19399202056229115, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 476
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4368932038834951, 'r1_recall': 0.6081081081081081, 'r1_f1': 0.5084745762711864, 'pegasus_entailment': 0.5375480502843857, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 477
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6272189349112426, 'r1_recall': 0.5196078431372549, 'r1_f1': 0.5683646112600537, 'pegasus_entailment': 0.880976402759552, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 478
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.3333333333333333, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.2958672471344471, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 479
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.550561797752809, 'r1_recall': 0.4049586776859504, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.40148257308950025, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 20, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 480
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6384615384615384, 'r1_recall': 0.5804195804195804, 'r1_f1': 0.6080586080586081, 'pegasus_entailment': 0.23527948341021934, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 481
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40707964601769914, 'r1_recall': 0.5287356321839081, 'r1_f1': 0.4600000000000001, 'pegasus_entailment': 0.7563952393829823, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 482
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.34210526315789475, 'r1_recall': 0.7142857142857143, 'r1_f1': 0.4626334519572954, 'pegasus_entailment': 0.8166858553886414, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 20, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 483
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4166666666666667, 'r1_recall': 0.5882352941176471, 'r1_f1': 0.48780487804878053, 'pegasus_entailment': 0.40517624219258624, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 484
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.56, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.4444444444444444, 'pegasus_entailment': 0.16859595477581024, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 21, 'pegasus_ari': 28, 'pegasus_smog': 24}
*** Analysing case 485
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.48717948717948717, 'r1_recall': 0.3838383838383838, 'r1_f1': 0.4293785310734463, 'pegasus_entailment': 0.39586299657821655, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 486
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.36363636363636365, 'r1_recall': 0.4044943820224719, 'r1_f1': 0.3829787234042553, 'pegasus_entailment': 0.5684722438454628, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 487
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.4601226993865031, 'r1_f1': 0.5208333333333334, 'pegasus_entailment': 0.4219630179660661, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 15, 'pegasus_smog': 16}
*** Analysing case 488
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5765765765765766, 'r1_recall': 0.3516483516483517, 'r1_f1': 0.4368600682593857, 'pegasus_entailment': 0.5218934714794159, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 489
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6509433962264151, 'r1_recall': 0.2509090909090909, 'r1_f1': 0.3622047244094488, 'pegasus_entailment': 0.17052941117435694, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 490
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5392156862745098, 'r1_recall': 0.5045871559633027, 'r1_f1': 0.5213270142180094, 'pegasus_entailment': 0.5669700503349304, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 491
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18691588785046728, 'r1_recall': 0.3448275862068966, 'r1_f1': 0.24242424242424243, 'pegasus_entailment': 0.5561590590514243, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 492
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6, 'r1_recall': 0.26519337016574585, 'r1_f1': 0.367816091954023, 'pegasus_entailment': 0.5246260911226273, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 493
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.22566371681415928, 'r1_recall': 0.6623376623376623, 'r1_f1': 0.33663366336633666, 'pegasus_entailment': 0.48526134424739414, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 494
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.35714285714285715, 'r1_recall': 0.6875, 'r1_f1': 0.4700854700854701, 'pegasus_entailment': 0.534579174593091, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 21}
*** Analysing case 495
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5894736842105263, 'r1_recall': 0.6021505376344086, 'r1_f1': 0.5957446808510638, 'pegasus_entailment': 0.8105862319469452, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 16}
*** Analysing case 496
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.408, 'r1_recall': 0.6296296296296297, 'r1_f1': 0.49514563106796117, 'pegasus_entailment': 0.40632144520059227, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 497
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2727272727272727, 'r1_recall': 0.4666666666666667, 'r1_f1': 0.3442622950819672, 'pegasus_entailment': 0.3060409836471081, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 498
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2857142857142857, 'r1_recall': 0.5507246376811594, 'r1_f1': 0.37623762376237624, 'pegasus_entailment': 0.6213514979928731, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 17}
*** Analysing case 499
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4766355140186916, 'r1_recall': 0.53125, 'r1_f1': 0.5024630541871922, 'pegasus_entailment': 0.546993114054203, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 500
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29365079365079366, 'r1_recall': 0.578125, 'r1_f1': 0.3894736842105263, 'pegasus_entailment': 0.5377764612436294, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 501
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.36551724137931035, 'r1_recall': 0.5824175824175825, 'r1_f1': 0.4491525423728814, 'pegasus_entailment': 0.7073058784008026, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 17, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 502
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.35135135135135137, 'r1_recall': 0.5909090909090909, 'r1_f1': 0.4406779661016949, 'pegasus_entailment': 0.5720545394080025, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 503
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.38524590163934425, 'r1_recall': 0.7580645161290323, 'r1_f1': 0.5108695652173914, 'pegasus_entailment': 0.6629846400581301, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 504
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.27346938775510204, 'r1_recall': 0.6261682242990654, 'r1_f1': 0.38068181818181823, 'pegasus_entailment': 0.5404697738587856, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 21, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 505
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39080459770114945, 'r1_recall': 0.5396825396825397, 'r1_f1': 0.4533333333333333, 'pegasus_entailment': 0.32564527541399, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 506
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6724137931034483, 'r1_recall': 0.44150943396226416, 'r1_f1': 0.5330296127562643, 'pegasus_entailment': 0.4931558022896449, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 507
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3611111111111111, 'r1_recall': 0.609375, 'r1_f1': 0.45348837209302323, 'pegasus_entailment': 0.4511070449370891, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 508
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44086021505376344, 'r1_recall': 0.44565217391304346, 'r1_f1': 0.4432432432432432, 'pegasus_entailment': 0.48342615067958833, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 16}
*** Analysing case 509
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5833333333333334, 'r1_recall': 0.49, 'r1_f1': 0.532608695652174, 'pegasus_entailment': 0.5629258155822754, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 28, 'pegasus_smog': 20}
*** Analysing case 510
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49019607843137253, 'r1_recall': 0.35714285714285715, 'r1_f1': 0.4132231404958677, 'pegasus_entailment': 0.5390736442059278, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 511
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5974025974025974, 'r1_recall': 0.48936170212765956, 'r1_f1': 0.5380116959064328, 'pegasus_entailment': 0.35910879299044607, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 15}
*** Analysing case 512
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46540880503144655, 'r1_recall': 0.5826771653543307, 'r1_f1': 0.5174825174825175, 'pegasus_entailment': 0.5447708779829554, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 513
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3125, 'r1_recall': 0.5633802816901409, 'r1_f1': 0.4020100502512563, 'pegasus_entailment': 0.930869460105896, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 18, 'pegasus_ari': 29, 'pegasus_smog': 21}
*** Analysing case 514
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.46956521739130436, 'r1_recall': 0.574468085106383, 'r1_f1': 0.5167464114832536, 'pegasus_entailment': 0.31779349986463784, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 515
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.40625, 'r1_recall': 0.4642857142857143, 'r1_f1': 0.4333333333333333, 'pegasus_entailment': 0.6798059148713946, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 516
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.38613861386138615, 'r1_recall': 0.527027027027027, 'r1_f1': 0.44571428571428573, 'pegasus_entailment': 0.3453181395307183, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 25, 'pegasus_smog': 23}
*** Analysing case 517
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43478260869565216, 'r1_recall': 0.29850746268656714, 'r1_f1': 0.35398230088495575, 'pegasus_entailment': 0.6713614761829376, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 518
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.34579439252336447, 'r1_recall': 0.578125, 'r1_f1': 0.43274853801169594, 'pegasus_entailment': 0.4938108205795288, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 519
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4556213017751479, 'r1_recall': 0.44508670520231214, 'r1_f1': 0.4502923976608187, 'pegasus_entailment': 0.7556751668453217, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 520
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6074766355140186, 'r1_recall': 0.3939393939393939, 'r1_f1': 0.47794117647058826, 'pegasus_entailment': 0.44774083197116854, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 21, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 521
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5394736842105263, 'r1_recall': 0.41836734693877553, 'r1_f1': 0.471264367816092, 'pegasus_entailment': 0.9154935598373413, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 14, 'pegasus_ari': 13, 'pegasus_smog': 15}
*** Analysing case 522
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4055299539170507, 'r1_recall': 0.47058823529411764, 'r1_f1': 0.43564356435643564, 'pegasus_entailment': 0.43134811396400136, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 523
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5303030303030303, 'r1_recall': 0.3684210526315789, 'r1_f1': 0.4347826086956521, 'pegasus_entailment': 0.1857348136836663, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 524
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4065934065934066, 'r1_recall': 0.5138888888888888, 'r1_f1': 0.4539877300613497, 'pegasus_entailment': 0.5106549546122551, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 21, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 525
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.1782178217821782, 'r1_recall': 0.32727272727272727, 'r1_f1': 0.23076923076923075, 'pegasus_entailment': 0.6091945394873619, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 526
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.19801980198019803, 'r1_recall': 0.47619047619047616, 'r1_f1': 0.2797202797202797, 'pegasus_entailment': 0.44672188628464937, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 527
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3953488372093023, 'r1_recall': 0.4788732394366197, 'r1_f1': 0.43312101910828027, 'pegasus_entailment': 0.6293026904265085, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 528
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29245283018867924, 'r1_recall': 0.5961538461538461, 'r1_f1': 0.3924050632911393, 'pegasus_entailment': 0.3618337884545326, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 529
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3680555555555556, 'r1_recall': 0.452991452991453, 'r1_f1': 0.40613026819923376, 'pegasus_entailment': 0.4915002251509577, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 22, 'pegasus_ari': 28, 'pegasus_smog': 22}
*** Analysing case 530
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6633663366336634, 'r1_recall': 0.5114503816793893, 'r1_f1': 0.5775862068965517, 'pegasus_entailment': 0.5077106013894082, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 531
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4606741573033708, 'r1_recall': 0.4880952380952381, 'r1_f1': 0.47398843930635837, 'pegasus_entailment': 0.8679467737674713, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 17, 'pegasus_smog': 14}
*** Analysing case 532
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5212765957446809, 'r1_recall': 0.2722222222222222, 'r1_f1': 0.3576642335766423, 'pegasus_entailment': 0.5578264832496643, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 16, 'pegasus_ari': 16, 'pegasus_smog': 17}
*** Analysing case 533
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3125, 'r1_recall': 0.6593406593406593, 'r1_f1': 0.4240282685512367, 'pegasus_entailment': 0.34755926579236984, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 22}
*** Analysing case 534
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.33532934131736525, 'r1_recall': 0.509090909090909, 'r1_f1': 0.4043321299638989, 'pegasus_entailment': 0.6084096804261208, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 29, 'pegasus_smog': 22}
*** Analysing case 535
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3609022556390977, 'r1_recall': 0.5217391304347826, 'r1_f1': 0.42666666666666664, 'pegasus_entailment': 0.5313996771971384, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 536
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2621951219512195, 'r1_recall': 0.43, 'r1_f1': 0.3257575757575758, 'pegasus_entailment': 0.5714825640122095, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 16}
*** Analysing case 537
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.308411214953271, 'r1_recall': 0.4782608695652174, 'r1_f1': 0.37499999999999994, 'pegasus_entailment': 0.8831396102905273, 'pegasus_flesch_kincaid': 29, 'pegasus_coleman_liau': 18, 'pegasus_ari': 34, 'pegasus_smog': 24}
*** Analysing case 538
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46835443037974683, 'r1_recall': 0.42528735632183906, 'r1_f1': 0.4457831325301205, 'pegasus_entailment': 0.6483666738495231, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 539
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5185185185185185, 'r1_recall': 0.5490196078431373, 'r1_f1': 0.5333333333333333, 'pegasus_entailment': 0.5923212934285402, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 20, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 540
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2904761904761905, 'r1_recall': 0.7261904761904762, 'r1_f1': 0.4149659863945579, 'pegasus_entailment': 0.6053175528844198, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 21, 'pegasus_ari': 27, 'pegasus_smog': 22}
*** Analysing case 541
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.20987654320987653, 'r1_recall': 0.6538461538461539, 'r1_f1': 0.31775700934579443, 'pegasus_entailment': 0.6151959504932165, 'pegasus_flesch_kincaid': 24, 'pegasus_coleman_liau': 19, 'pegasus_ari': 28, 'pegasus_smog': 23}
*** Analysing case 542
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5307692307692308, 'r1_recall': 0.4825174825174825, 'r1_f1': 0.5054945054945056, 'pegasus_entailment': 0.6582466550171375, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 20, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 543
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4375, 'r1_recall': 0.5632183908045977, 'r1_f1': 0.492462311557789, 'pegasus_entailment': 0.30583605617284776, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 544
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4492753623188406, 'r1_recall': 0.5740740740740741, 'r1_f1': 0.5040650406504064, 'pegasus_entailment': 0.6288177020226916, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 17}
*** Analysing case 545
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46308724832214765, 'r1_recall': 0.5702479338842975, 'r1_f1': 0.5111111111111111, 'pegasus_entailment': 0.49817947298288345, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 546
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4024390243902439, 'r1_recall': 0.3173076923076923, 'r1_f1': 0.3548387096774194, 'pegasus_entailment': 0.31730947401374576, 'pegasus_flesch_kincaid': 12, 'pegasus_coleman_liau': 16, 'pegasus_ari': 14, 'pegasus_smog': 13}
*** Analysing case 547
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5, 'r1_recall': 0.45714285714285713, 'r1_f1': 0.4776119402985075, 'pegasus_entailment': 0.5245779156684875, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 548
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3275862068965517, 'r1_recall': 0.5277777777777778, 'r1_f1': 0.40425531914893614, 'pegasus_entailment': 0.8849328756332397, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 549
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5154639175257731, 'r1_recall': 0.5617977528089888, 'r1_f1': 0.5376344086021505, 'pegasus_entailment': 0.273670163936913, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 550
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.15126050420168066, 'r1_recall': 0.4, 'r1_f1': 0.2195121951219512, 'pegasus_entailment': 0.5188833732778827, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 551
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4846153846153846, 'r1_recall': 0.6116504854368932, 'r1_f1': 0.5407725321888412, 'pegasus_entailment': 0.5611127585172653, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 552
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.11224489795918367, 'r1_recall': 0.3142857142857143, 'r1_f1': 0.16541353383458646, 'pegasus_entailment': 0.3538768794387579, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 553
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.37333333333333335, 'r1_recall': 0.6222222222222222, 'r1_f1': 0.4666666666666667, 'pegasus_entailment': 0.30590831325389445, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 19, 'pegasus_ari': 18, 'pegasus_smog': 18}
*** Analysing case 554
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.22137404580152673, 'r1_recall': 0.7435897435897436, 'r1_f1': 0.3411764705882353, 'pegasus_entailment': 0.7269619941711426, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 555
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4161849710982659, 'r1_recall': 0.4864864864864865, 'r1_f1': 0.44859813084112155, 'pegasus_entailment': 0.3020217094038214, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 556
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5520833333333334, 'r1_recall': 0.4608695652173913, 'r1_f1': 0.5023696682464455, 'pegasus_entailment': 0.9518148899078369, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 557
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.37349397590361444, 'r1_recall': 0.6458333333333334, 'r1_f1': 0.47328244274809167, 'pegasus_entailment': 0.4574371464550495, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 558
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.44, 'r1_recall': 0.6055045871559633, 'r1_f1': 0.5096525096525096, 'pegasus_entailment': 0.46616795446191517, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 559
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.49230769230769234, 'r1_recall': 0.463768115942029, 'r1_f1': 0.47761194029850745, 'pegasus_entailment': 0.4364282488822937, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 560
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.872093023255814, 'r1_recall': 0.21306818181818182, 'r1_f1': 0.3424657534246575, 'pegasus_entailment': 0.5768330409191549, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 19}
*** Analysing case 561
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5, 'r1_recall': 0.4594594594594595, 'r1_f1': 0.47887323943661975, 'pegasus_entailment': 0.710747230052948, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 562
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.41739130434782606, 'r1_recall': 0.3221476510067114, 'r1_f1': 0.3636363636363636, 'pegasus_entailment': 0.6980856895446778, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 22, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 563
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7692307692307693, 'r1_recall': 0.33557046979865773, 'r1_f1': 0.4672897196261682, 'pegasus_entailment': 0.7706096768379211, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 15}
*** Analysing case 564
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1694915254237288, 'r1_recall': 0.6122448979591837, 'r1_f1': 0.2654867256637168, 'pegasus_entailment': 0.6167119592428207, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 16, 'pegasus_ari': 28, 'pegasus_smog': 19}
*** Analysing case 565
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4098360655737705, 'r1_recall': 0.6944444444444444, 'r1_f1': 0.5154639175257733, 'pegasus_entailment': 0.49586227536201477, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 17, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 566
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.34615384615384615, 'r1_recall': 0.5555555555555556, 'r1_f1': 0.4265402843601896, 'pegasus_entailment': 0.4284016951918602, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 567
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7087378640776699, 'r1_recall': 0.4866666666666667, 'r1_f1': 0.5770750988142292, 'pegasus_entailment': 0.3297549734512965, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 17, 'pegasus_ari': 24, 'pegasus_smog': 21}
*** Analysing case 568
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.20422535211267606, 'r1_recall': 0.43283582089552236, 'r1_f1': 0.27751196172248804, 'pegasus_entailment': 0.9677087324006217, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 21}
*** Analysing case 569
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6283783783783784, 'r1_recall': 0.5406976744186046, 'r1_f1': 0.58125, 'pegasus_entailment': 0.6961405754089356, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 570
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4108527131782946, 'r1_recall': 0.7162162162162162, 'r1_f1': 0.522167487684729, 'pegasus_entailment': 0.7278061032295227, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 571
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.37398373983739835, 'r1_recall': 0.5679012345679012, 'r1_f1': 0.45098039215686275, 'pegasus_entailment': 0.5806121349334716, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 572
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.46788990825688076, 'r1_recall': 0.3617021276595745, 'r1_f1': 0.40800000000000003, 'pegasus_entailment': 0.5722023546695709, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 573
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3532110091743119, 'r1_recall': 0.5877862595419847, 'r1_f1': 0.4412607449856733, 'pegasus_entailment': 0.6080492053713117, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 19, 'pegasus_ari': 26, 'pegasus_smog': 22}
*** Analysing case 574
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6201550387596899, 'r1_recall': 0.3755868544600939, 'r1_f1': 0.4678362573099415, 'pegasus_entailment': 0.36353057995438576, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 16, 'pegasus_ari': 22, 'pegasus_smog': 22}
*** Analysing case 575
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5571428571428572, 'r1_recall': 0.43333333333333335, 'r1_f1': 0.4875, 'pegasus_entailment': 0.9574130177497864, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 21, 'pegasus_ari': 22, 'pegasus_smog': 21}
*** Analysing case 576
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.4383561643835616, 'r1_recall': 0.5614035087719298, 'r1_f1': 0.49230769230769234, 'pegasus_entailment': 0.4347357327739398, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 577
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6666666666666666, 'r1_recall': 0.31746031746031744, 'r1_f1': 0.43010752688172044, 'pegasus_entailment': 0.573101669549942, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 21}
*** Analysing case 578
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6346153846153846, 'r1_recall': 0.3256578947368421, 'r1_f1': 0.43043478260869567, 'pegasus_entailment': 0.6101715080440044, 'pegasus_flesch_kincaid': 23, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 23}
*** Analysing case 579
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.3157894736842105, 'r1_recall': 0.38095238095238093, 'r1_f1': 0.34532374100719426, 'pegasus_entailment': 0.4849691241979599, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 16, 'pegasus_smog': 18}
*** Analysing case 580
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.425531914893617, 'r1_recall': 0.631578947368421, 'r1_f1': 0.5084745762711865, 'pegasus_entailment': 0.5544402420520782, 'pegasus_flesch_kincaid': 19, 'pegasus_coleman_liau': 18, 'pegasus_ari': 22, 'pegasus_smog': 20}
*** Analysing case 581
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5714285714285714, 'r1_recall': 0.5569620253164557, 'r1_f1': 0.564102564102564, 'pegasus_entailment': 0.6308579295873642, 'pegasus_flesch_kincaid': 22, 'pegasus_coleman_liau': 18, 'pegasus_ari': 27, 'pegasus_smog': 20}
*** Analysing case 582
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.359375, 'r1_recall': 0.39655172413793105, 'r1_f1': 0.3770491803278689, 'pegasus_entailment': 0.5839318633079529, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 20, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 583
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.6071428571428571, 'r1_recall': 0.4696132596685083, 'r1_f1': 0.5295950155763239, 'pegasus_entailment': 0.4508640706539154, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 16, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 584
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5405405405405406, 'r1_recall': 0.28169014084507044, 'r1_f1': 0.37037037037037035, 'pegasus_entailment': 0.9222656091054281, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 585
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4, 'r1_recall': 0.4, 'r1_f1': 0.4000000000000001, 'pegasus_entailment': 0.3035786197520792, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 17, 'pegasus_smog': 16}
*** Analysing case 586
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5871559633027523, 'r1_recall': 0.37209302325581395, 'r1_f1': 0.4555160142348755, 'pegasus_entailment': 0.6581119149923325, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 587
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4810126582278481, 'r1_recall': 0.5352112676056338, 'r1_f1': 0.5066666666666666, 'pegasus_entailment': 0.45923240259289744, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 19, 'pegasus_ari': 17, 'pegasus_smog': 18}
*** Analysing case 588
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.696, 'r1_recall': 0.4182692307692308, 'r1_f1': 0.5225225225225225, 'pegasus_entailment': 0.6933180928230286, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 589
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.39325842696629215, 'r1_recall': 0.3763440860215054, 'r1_f1': 0.38461538461538464, 'pegasus_entailment': 0.6757038235664368, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 23, 'pegasus_smog': 16}
*** Analysing case 590
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.2709677419354839, 'r1_recall': 0.56, 'r1_f1': 0.3652173913043478, 'pegasus_entailment': 0.6905631065368653, 'pegasus_flesch_kincaid': 20, 'pegasus_coleman_liau': 18, 'pegasus_ari': 23, 'pegasus_smog': 20}
*** Analysing case 591
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.3769230769230769, 'r1_recall': 0.6901408450704225, 'r1_f1': 0.4875621890547263, 'pegasus_entailment': 0.5668604344129562, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 20}
*** Analysing case 592
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.569620253164557, 'r1_recall': 0.44554455445544555, 'r1_f1': 0.5, 'pegasus_entailment': 0.3716442833344142, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 14, 'pegasus_ari': 17, 'pegasus_smog': 15}
*** Analysing case 593
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7368421052631579, 'r1_recall': 0.4057971014492754, 'r1_f1': 0.5233644859813084, 'pegasus_entailment': 0.6208369731903076, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 19}
*** Analysing case 594
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4339622641509434, 'r1_recall': 0.45098039215686275, 'r1_f1': 0.4423076923076923, 'pegasus_entailment': 0.7211384296417236, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 18, 'pegasus_ari': 18, 'pegasus_smog': 16}
*** Analysing case 595
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.29411764705882354, 'r1_recall': 0.5, 'r1_f1': 0.37037037037037035, 'pegasus_entailment': 0.3564862171187997, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 19, 'pegasus_ari': 21, 'pegasus_smog': 18}
*** Analysing case 596
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6826923076923077, 'r1_recall': 0.398876404494382, 'r1_f1': 0.5035460992907802, 'pegasus_entailment': 0.7748512923717499, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 19}
*** Analysing case 597
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.375, 'r1_recall': 0.6575342465753424, 'r1_f1': 0.47761194029850745, 'pegasus_entailment': 0.5249224901199341, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 15, 'pegasus_ari': 16, 'pegasus_smog': 15}
*** Analysing case 598
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.43103448275862066, 'r1_recall': 0.6578947368421053, 'r1_f1': 0.5208333333333334, 'pegasus_entailment': 0.35838659703731535, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 19, 'pegasus_smog': 17}
*** Analysing case 599
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.2905405405405405, 'r1_recall': 0.4725274725274725, 'r1_f1': 0.3598326359832636, 'pegasus_entailment': 0.562924205015103, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 19}
*** Analysing case 600
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6153846153846154, 'r1_recall': 0.6, 'r1_f1': 0.6075949367088608, 'pegasus_entailment': 0.7190227769315243, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 601
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7582417582417582, 'r1_recall': 0.09787234042553192, 'r1_f1': 0.17336683417085427, 'pegasus_entailment': 0.8651510179042816, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 20}
*** Analysing case 602
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.5625, 'r1_recall': 0.5704225352112676, 'r1_f1': 0.5664335664335666, 'pegasus_entailment': 0.6151691873868307, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 17, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 603
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.7582417582417582, 'r1_recall': 0.3770491803278688, 'r1_f1': 0.5036496350364964, 'pegasus_entailment': 0.36252453178167343, 'pegasus_flesch_kincaid': 14, 'pegasus_coleman_liau': 17, 'pegasus_ari': 18, 'pegasus_smog': 15}
*** Analysing case 604
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.42990654205607476, 'r1_recall': 0.4946236559139785, 'r1_f1': 0.45999999999999996, 'pegasus_entailment': 0.300208592414856, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 17, 'pegasus_ari': 17, 'pegasus_smog': 17}
*** Analysing case 605
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6020408163265306, 'r1_recall': 0.5086206896551724, 'r1_f1': 0.5514018691588785, 'pegasus_entailment': 0.6325386269949377, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 16, 'pegasus_ari': 18, 'pegasus_smog': 17}
*** Analysing case 606
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.410958904109589, 'r1_recall': 0.46153846153846156, 'r1_f1': 0.43478260869565216, 'pegasus_entailment': 0.6341108456254005, 'pegasus_flesch_kincaid': 15, 'pegasus_coleman_liau': 20, 'pegasus_ari': 19, 'pegasus_smog': 18}
*** Analysing case 607
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4370860927152318, 'r1_recall': 0.42038216560509556, 'r1_f1': 0.4285714285714286, 'pegasus_entailment': 0.44502071402966975, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 17, 'pegasus_ari': 22, 'pegasus_smog': 19}
*** Analysing case 608
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.16901408450704225, 'r1_recall': 0.5, 'r1_f1': 0.25263157894736843, 'pegasus_entailment': 0.6629133075475693, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 20}
*** Analysing case 609
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4519230769230769, 'r1_recall': 0.4845360824742268, 'r1_f1': 0.46766169154228854, 'pegasus_entailment': 0.9833232462406158, 'pegasus_flesch_kincaid': 30, 'pegasus_coleman_liau': 21, 'pegasus_ari': 35, 'pegasus_smog': 27}
*** Analysing case 610
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.18095238095238095, 'r1_recall': 0.5428571428571428, 'r1_f1': 0.2714285714285714, 'pegasus_entailment': 0.5110729851294309, 'pegasus_flesch_kincaid': 17, 'pegasus_coleman_liau': 19, 'pegasus_ari': 22, 'pegasus_smog': 18}
*** Analysing case 611
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.6129032258064516, 'r1_recall': 0.5876288659793815, 'r1_f1': 0.6, 'pegasus_entailment': 0.5715239215642214, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 19, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 612
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.4357142857142857, 'r1_recall': 0.5398230088495575, 'r1_f1': 0.48221343873517786, 'pegasus_entailment': 0.6321286675520241, 'pegasus_flesch_kincaid': 21, 'pegasus_coleman_liau': 18, 'pegasus_ari': 25, 'pegasus_smog': 21}
*** Analysing case 613
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.56, 'r1_recall': 0.5185185185185185, 'r1_f1': 0.5384615384615384, 'pegasus_entailment': 0.523535019531846, 'pegasus_flesch_kincaid': 16, 'pegasus_coleman_liau': 18, 'pegasus_ari': 20, 'pegasus_smog': 18}
*** Analysing case 614
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 1, 'r1_precision': 0.1901840490797546, 'r1_recall': 0.5740740740740741, 'r1_f1': 0.28571428571428575, 'pegasus_entailment': 0.5619571581482887, 'pegasus_flesch_kincaid': 18, 'pegasus_coleman_liau': 18, 'pegasus_ari': 21, 'pegasus_smog': 21}
*** Analysing case 615
** ROUGE...
** Entailment...
** Readability....
{'malformed_chain': 0, 'r1_precision': 0.5294117647058824, 'r1_recall': 0.36, 'r1_f1': 0.42857142857142855, 'pegasus_entailment': 0.6510004971253996, 'pegasus_flesch_kincaid': 11, 'pegasus_coleman_liau': 15, 'pegasus_ari': 12, 'pegasus_smog': 14}
** Analysing column: malformed_chain



malformed_chain
Length after nones removed
616
MIN
0
MEAN
0
MAX
1
** Analysing column: r1_precision



r1_precision
Length after nones removed
616
MIN
0.07627118644067797
MEAN
0.47257168190287435
MAX
0.916030534351145
** Analysing column: r1_recall



r1_recall
Length after nones removed
616
MIN
0.09787234042553192
MEAN
0.49503420273827936
MAX
0.855072463768116
** Analysing column: r1_f1



r1_f1
Length after nones removed
616
MIN
0.12720848056537104
MEAN
0.45860469375956603
MAX
0.6968325791855203
** Analysing column: pegasus_entailment



pegasus_entailment
Length after nones removed
616
MIN
0.002808688976801932
MEAN
0.5492142083866678
MAX
0.9904266893863678
** Analysing column: pegasus_flesch_kincaid



pegasus_flesch_kincaid
Length after nones removed
616
MIN
10
MEAN
17
MAX
38
** Analysing column: pegasus_coleman_liau



pegasus_coleman_liau
Length after nones removed
616
MIN
11
MEAN
17
MAX
23
** Analysing column: pegasus_ari



pegasus_ari
Length after nones removed
616
MIN
10
MEAN
21
MAX
45
** Analysing column: pegasus_smog



pegasus_smog
Length after nones removed
616
MIN
12
MEAN
18
MAX
30
{}
Entered file!
Imports done!
*** RUN *** 
eval_1cB
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 14:58:32.087425: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 14:58:32.628332: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/1cB_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
** Loading results csv
*** Analysing case 0
Traceback (most recent call last):
  File "/home/fsuser/dissertation/230731_fs_eval/1cB_eval_single_run-FS.py", line 407, in <module>
    main(args)
  File "/home/fsuser/dissertation/230731_fs_eval/1cB_eval_single_run-FS.py", line 333, in main
    gold_segmented = segmented_df.iloc[idx]['gold_sents'].split('[SENTMARKER]')
UnboundLocalError: local variable 'segmented_df' referenced before assignment
Entered file!
Imports done!
*** RUN *** 
eval_2cB
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 14:58:42.687268: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 14:58:43.232487: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/2cB_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
** Loading results csv
*** Analysing case 0
Traceback (most recent call last):
  File "/home/fsuser/dissertation/230731_fs_eval/2cB_eval_single_run-FS.py", line 407, in <module>
    main(args)
  File "/home/fsuser/dissertation/230731_fs_eval/2cB_eval_single_run-FS.py", line 333, in main
    gold_segmented = segmented_df.iloc[idx]['gold_sents'].split('[SENTMARKER]')
UnboundLocalError: local variable 'segmented_df' referenced before assignment
Entered file!
Imports done!
*** RUN *** 
eval_3cB
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 14:58:53.446081: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 14:58:54.007851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/3cB_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
** Loading results csv
*** Analysing case 0
Traceback (most recent call last):
  File "/home/fsuser/dissertation/230731_fs_eval/3cB_eval_single_run-FS.py", line 407, in <module>
    main(args)
  File "/home/fsuser/dissertation/230731_fs_eval/3cB_eval_single_run-FS.py", line 333, in main
    gold_segmented = segmented_df.iloc[idx]['gold_sents'].split('[SENTMARKER]')
UnboundLocalError: local variable 'segmented_df' referenced before assignment
Entered file!
Imports done!
*** RUN *** 
eval_4cB
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 14:59:04.443980: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 14:59:05.002914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/4cB_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
** Loading results csv
*** Analysing case 0
Traceback (most recent call last):
  File "/home/fsuser/dissertation/230731_fs_eval/4cB_eval_single_run-FS.py", line 407, in <module>
    main(args)
  File "/home/fsuser/dissertation/230731_fs_eval/4cB_eval_single_run-FS.py", line 333, in main
    gold_segmented = segmented_df.iloc[idx]['gold_sents'].split('[SENTMARKER]')
UnboundLocalError: local variable 'segmented_df' referenced before assignment
Entered file!
Imports done!
*** RUN *** 
eval_5cB
** Loading eval utils...
Loading entailment model facebook/bart-large-mnli...
2023-07-31 14:59:15.561440: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-31 14:59:16.112095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/fsuser/dissertation/230731_fs_eval/5cB_eval_single_run-FS.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  bertscore = load_metric("bertscore")   # move
** Loading results csv
*** Analysing case 0
Traceback (most recent call last):
  File "/home/fsuser/dissertation/230731_fs_eval/5cB_eval_single_run-FS.py", line 407, in <module>
    main(args)
  File "/home/fsuser/dissertation/230731_fs_eval/5cB_eval_single_run-FS.py", line 333, in main
    gold_segmented = segmented_df.iloc[idx]['gold_sents'].split('[SENTMARKER]')
UnboundLocalError: local variable 'segmented_df' referenced before assignment
Entered file!
Imports done!
Traceback (most recent call last):
  File "/home/fsuser/dissertation/230731_fs_eval/reprod_eval_single_run-FS.py", line 42, in <module>
*** RUN *** 
eval_reprod
** Loading eval utils...
    scorer_rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)
NameError: name 'rouge_scorer' is not defined
(base) fsuser@recakcsskvzdtnsqw:~/dissertation/230731_fs_eval$ 
